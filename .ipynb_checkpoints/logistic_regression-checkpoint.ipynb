{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Logistic Regression Using Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Linear Regression: $h_{\\theta}(x) = \\theta^{T}x$ <br>\n",
    "But for Logistic Regression, we want $0 <= h_{\\theta}(x) <= 1$ <br>\n",
    "$h_{\\theta}(x) = g(\\theta^{T}x)$ <br>\n",
    "$g(z) = \\frac{1}{1 + e^{-z}}$, this is a sigmoid/logistic function<br>\n",
    "So ... <br>\n",
    "**Hypothesis**: $h_{\\theta}(x) = \\frac{1}{1 + e^{-(\\theta^{T}x)}}$ <br>\n",
    "If probability 0.5 is the threshold to determine class 1 of 0, then <br>\n",
    "- $y=1$ when  $\\theta^{T}x >= 0$,  (becuase $g(\\theta^{T}x) >= 0.5$)<br>\n",
    "- $y=0$ when  $\\theta^{T}x < 0$,  (becuase $g(\\theta^{T}x) < 0.5$)<br>\n",
    "- $\\theta^{T}x = 0$ is the decision boundary which is based on the paramter $\\theta$ and hypothesis function <br>\n",
    "\n",
    "**Cost Function:** <br>\n",
    "\n",
    "$Cost(h_{\\theta}(x), y) =\n",
    "\\begin{cases}\n",
    "    -log(h_{\\theta}(x))    & \\quad \\text{if } y \\text{ is 1}\\\\\n",
    "    -log(1 - h_{\\theta}(x))  & \\quad \\text{if } y \\text{ is 0}\n",
    "\\end{cases}$ <br>\n",
    "OR:<br>\n",
    "$Cost(h_{\\theta}(x), y) = -ylog(h_{\\theta}(x)) - (1-y)log(1-h_{\\theta}(x))$\n",
    "\n",
    "$J(\\theta) = \\frac{1}{m}\\displaystyle\\sum_{i=1}^{m}Cost(h_{\\theta}(x^{(i)}), y^{(i)})$ <br>\n",
    "          $= -\\frac{1}{m}[\\displaystyle\\sum_{i=1}^{m}y^{(i)}logh_{\\theta}(x^{(i)}) + (1-y^{(i)})log(1-h_{\\theta}(x^{(i)}))]$ <br>\n",
    "          \n",
    "**Gradient Descent Algorithm:** repeat until converge to get paramter $\\theta$ vector<br>\n",
    "$\\theta_{j} := \\theta_{j} - \\alpha\\frac{\\partial}{\\partial\\theta_{j}}J(\\theta_{0}, \\theta_{1})$ <br>\n",
    "<br>\n",
    "$\\theta_{j} := \\theta_{j} - \\alpha\\frac{1}{m}\\displaystyle\\sum_{i=1}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)})x_{j}^{(i)}$ <br>\n",
    "<br>\n",
    " \n",
    "*Although the gradient descent math function looks the same as linear regression's, they are not same because the hypothsis in two algorithms are different!* <br>\n",
    "<br>\n",
    "**Maximum Likelihood Estimation(MLE)**<br>\n",
    "$loglikelihood = \\displaystyle\\sum_{i=1}^{m}y_{i}\\theta^{T}x_{i} - log(1 + e^{\\theta^{T}x_{i}})$ <br>\n",
    "To maximize loglikelihood for logistic regression, **Newtown-Raphson Algorithm** or **Newtown's Method** or **Iterative Reweighted Least Sqaures-IRLS** is used. It is faster than gradient descent <br>\n",
    "\n",
    "$\\theta^{(t+1)} = \\theta^{(t)} - \\frac{J'(\\theta^{(t)})}{J''(\\theta^{(t))}}$ <br>\n",
    "<br>\n",
    "To generalize on $\\theta$ vector <br>\n",
    "$\\theta^{(t+1)} = \\theta^{(t)} - H^{-1}{\\bigtriangledown_{\\theta}J}$ <br>\n",
    "$\\bigtriangledown_{\\theta}J$ is called gradient vector - partial or first derivatives of $\\theta$ (n+1 Vector)<br>\n",
    "$H$ (also called 'Hessian' is a matrix (n+1 X n+1), each element is the second derivative of $J$: $H_{ij} = \\frac{\\partial ^2J}{\\partial\\theta_{i}\\theta_{j}}$ <br>\n",
    "... <br>\n",
    "... <br>\n",
    "$\\bigtriangledown_{\\theta}J = \\frac{1}{m}\\displaystyle\\sum_{i=1}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)})x_{j}^{(i)}$ <br>\n",
    "$H = \\frac{1}{m}[\\displaystyle\\sum_{i=1}^{m}(h_{\\theta}(x^{(i)})(1-h_{\\theta}(x^{(i)})(x_{i})(x_{i})^{T}]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "x1 = np.random.multivariate_normal(mean=[0, 0], cov=[[1, .75],[.75, 1]], size=N)\n",
    "x2 = np.random.multivariate_normal(mean=[1, 3], cov=[[1, .5],[.5, 1]], size=N)\n",
    "\n",
    "y = np.hstack((np.zeros(N), np.ones(N)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack((x1, x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1907281 , -0.66281267],\n",
       "       [-0.36576079,  0.76765853],\n",
       "       [ 0.58711492,  0.75190051],\n",
       "       ...,\n",
       "       [ 1.91091559,  3.4496049 ],\n",
       "       [ 0.80664378,  2.87272391],\n",
       "       [ 2.00313983,  2.91426994]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fbe1c1a2048>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(X[:, 0], X[:, 1], c = y, alpha = .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(N*2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, iteration, alpha=0.05, tolerance=1e-4):\n",
    "    '''Use gradient descent to get parameter vector theta \n",
    "       for linear regression and logistic regression\n",
    "    Args:\n",
    "        X: feature matrix with shape (m, n)\n",
    "        y: target vector with shape (m, 1)\n",
    "        iteration: number of max iterations\n",
    "        alpha: learning rate for gradient descent\n",
    "        tolerance: set threshold to determine when to converge \n",
    "                   based on old vs. new paramter changes at end of each iteration\n",
    "    Returns:\n",
    "        Parameter vector, array like'''\n",
    "    N = X.shape[0]\n",
    "    X = np.hstack((X, np.ones(N).reshape(N, 1))) \n",
    "    theta = np.zeros(X.shape[1]).reshape(X.shape[1], 1)\n",
    "    X_trans = X.T\n",
    "    \n",
    "    for i in range(0, iteration):\n",
    "        z = np.dot(X, theta)\n",
    "        h = sigmoid(z)   # hypothesis\n",
    "        error = h - y\n",
    "        cost = (-y * np.log(h) - (1-y) * np.log(1 - h)).mean()\n",
    "        gradient = np.dot(X_trans, error) / len(X)\n",
    "        print(\"Iteration {} | Cost: {} | Gradient: {}\".format(i, cost, gradient))\n",
    "        # update theta\n",
    "        theta_new = theta - alpha * gradient\n",
    "        if sum(abs(theta_new - theta)).all() < tolerance:\n",
    "            break\n",
    "        theta = theta_new\n",
    "    return theta_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 | Cost: 0.6931471805599454 | Gradient: [[-0.23533865]\n",
      " [-0.74156378]\n",
      " [ 0.        ]]\n",
      "Iteration 1 | Cost: 0.692542350579756 | Gradient: [[-2.34871987e-01]\n",
      " [-7.40441201e-01]\n",
      " [ 3.04449411e-04]]\n",
      "Iteration 2 | Cost: 0.6919394020393262 | Gradient: [[-2.34406114e-01]\n",
      " [-7.39320491e-01]\n",
      " [ 6.08347057e-04]]\n",
      "Iteration 3 | Cost: 0.6913383286614899 | Gradient: [[-0.23394103]\n",
      " [-0.73820166]\n",
      " [ 0.00091169]]\n",
      "Iteration 4 | Cost: 0.6907391241819688 | Gradient: [[-0.23347673]\n",
      " [-0.7370847 ]\n",
      " [ 0.00121449]]\n",
      "Iteration 5 | Cost: 0.6901417823494523 | Gradient: [[-0.23301322]\n",
      " [-0.73596962]\n",
      " [ 0.00151673]]\n",
      "Iteration 6 | Cost: 0.6895462969256752 | Gradient: [[-0.23255051]\n",
      " [-0.73485642]\n",
      " [ 0.00181841]]\n",
      "Iteration 7 | Cost: 0.6889526616854937 | Gradient: [[-0.23208858]\n",
      " [-0.73374511]\n",
      " [ 0.00211955]]\n",
      "Iteration 8 | Cost: 0.688360870416961 | Gradient: [[-0.23162744]\n",
      " [-0.73263568]\n",
      " [ 0.00242013]]\n",
      "Iteration 9 | Cost: 0.6877709169214016 | Gradient: [[-0.2311671 ]\n",
      " [-0.73152813]\n",
      " [ 0.00272016]]\n",
      "Iteration 10 | Cost: 0.6871827950134826 | Gradient: [[-0.23070755]\n",
      " [-0.73042247]\n",
      " [ 0.00301963]]\n",
      "Iteration 11 | Cost: 0.686596498521286 | Gradient: [[-0.23024879]\n",
      " [-0.7293187 ]\n",
      " [ 0.00331855]]\n",
      "Iteration 12 | Cost: 0.6860120212863787 | Gradient: [[-0.22979083]\n",
      " [-0.72821681]\n",
      " [ 0.00361692]]\n",
      "Iteration 13 | Cost: 0.6854293571638806 | Gradient: [[-0.22933366]\n",
      " [-0.72711682]\n",
      " [ 0.00391473]]\n",
      "Iteration 14 | Cost: 0.6848485000225331 | Gradient: [[-0.22887728]\n",
      " [-0.72601872]\n",
      " [ 0.00421198]]\n",
      "Iteration 15 | Cost: 0.6842694437447635 | Gradient: [[-0.2284217 ]\n",
      " [-0.72492251]\n",
      " [ 0.00450868]]\n",
      "Iteration 16 | Cost: 0.6836921822267523 | Gradient: [[-0.22796692]\n",
      " [-0.72382819]\n",
      " [ 0.00480483]]\n",
      "Iteration 17 | Cost: 0.6831167093784948 | Gradient: [[-0.22751293]\n",
      " [-0.72273577]\n",
      " [ 0.00510042]]\n",
      "Iteration 18 | Cost: 0.6825430191238648 | Gradient: [[-0.22705974]\n",
      " [-0.72164525]\n",
      " [ 0.00539546]]\n",
      "Iteration 19 | Cost: 0.6819711054006758 | Gradient: [[-0.22660734]\n",
      " [-0.72055662]\n",
      " [ 0.00568994]]\n",
      "Iteration 20 | Cost: 0.6814009621607404 | Gradient: [[-0.22615575]\n",
      " [-0.71946989]\n",
      " [ 0.00598386]]\n",
      "Iteration 21 | Cost: 0.6808325833699297 | Gradient: [[-0.22570495]\n",
      " [-0.71838505]\n",
      " [ 0.00627723]]\n",
      "Iteration 22 | Cost: 0.6802659630082305 | Gradient: [[-0.22525495]\n",
      " [-0.71730212]\n",
      " [ 0.00657005]]\n",
      "Iteration 23 | Cost: 0.6797010950698024 | Gradient: [[-0.22480575]\n",
      " [-0.71622109]\n",
      " [ 0.00686231]]\n",
      "Iteration 24 | Cost: 0.679137973563032 | Gradient: [[-0.22435735]\n",
      " [-0.71514196]\n",
      " [ 0.00715401]]\n",
      "Iteration 25 | Cost: 0.6785765925105879 | Gradient: [[-0.22390975]\n",
      " [-0.71406473]\n",
      " [ 0.00744516]]\n",
      "Iteration 26 | Cost: 0.6780169459494735 | Gradient: [[-0.22346294]\n",
      " [-0.7129894 ]\n",
      " [ 0.00773575]]\n",
      "Iteration 27 | Cost: 0.6774590279310778 | Gradient: [[-0.22301694]\n",
      " [-0.71191597]\n",
      " [ 0.00802579]]\n",
      "Iteration 28 | Cost: 0.6769028325212278 | Gradient: [[-0.22257174]\n",
      " [-0.71084445]\n",
      " [ 0.00831527]]\n",
      "Iteration 29 | Cost: 0.6763483538002361 | Gradient: [[-0.22212734]\n",
      " [-0.70977483]\n",
      " [ 0.0086042 ]]\n",
      "Iteration 30 | Cost: 0.6757955858629497 | Gradient: [[-0.22168374]\n",
      " [-0.70870711]\n",
      " [ 0.00889257]]\n",
      "Iteration 31 | Cost: 0.675244522818799 | Gradient: [[-0.22124094]\n",
      " [-0.7076413 ]\n",
      " [ 0.00918038]]\n",
      "Iteration 32 | Cost: 0.6746951587918402 | Gradient: [[-0.22079894]\n",
      " [-0.7065774 ]\n",
      " [ 0.00946764]]\n",
      "Iteration 33 | Cost: 0.6741474879208045 | Gradient: [[-0.22035774]\n",
      " [-0.7055154 ]\n",
      " [ 0.00975434]]\n",
      "Iteration 34 | Cost: 0.6736015043591386 | Gradient: [[-0.21991734]\n",
      " [-0.7044553 ]\n",
      " [ 0.01004049]]\n",
      "Iteration 35 | Cost: 0.6730572022750493 | Gradient: [[-0.21947775]\n",
      " [-0.70339711]\n",
      " [ 0.01032608]]\n",
      "Iteration 36 | Cost: 0.6725145758515448 | Gradient: [[-0.21903896]\n",
      " [-0.70234083]\n",
      " [ 0.01061112]]\n",
      "Iteration 37 | Cost: 0.671973619286475 | Gradient: [[-0.21860097]\n",
      " [-0.70128645]\n",
      " [ 0.0108956 ]]\n",
      "Iteration 38 | Cost: 0.6714343267925714 | Gradient: [[-0.21816378]\n",
      " [-0.70023398]\n",
      " [ 0.01117953]]\n",
      "Iteration 39 | Cost: 0.6708966925974854 | Gradient: [[-0.21772739]\n",
      " [-0.69918342]\n",
      " [ 0.0114629 ]]\n",
      "Iteration 40 | Cost: 0.6703607109438262 | Gradient: [[-0.21729181]\n",
      " [-0.69813476]\n",
      " [ 0.01174572]]\n",
      "Iteration 41 | Cost: 0.6698263760891966 | Gradient: [[-0.21685702]\n",
      " [-0.69708801]\n",
      " [ 0.01202798]]\n",
      "Iteration 42 | Cost: 0.6692936823062287 | Gradient: [[-0.21642304]\n",
      " [-0.69604316]\n",
      " [ 0.01230969]]\n",
      "Iteration 43 | Cost: 0.668762623882618 | Gradient: [[-0.21598986]\n",
      " [-0.69500022]\n",
      " [ 0.01259084]]\n",
      "Iteration 44 | Cost: 0.6682331951211575 | Gradient: [[-0.21555749]\n",
      " [-0.69395919]\n",
      " [ 0.01287144]]\n",
      "Iteration 45 | Cost: 0.6677053903397696 | Gradient: [[-0.21512591]\n",
      " [-0.69292006]\n",
      " [ 0.01315149]]\n",
      "Iteration 46 | Cost: 0.6671792038715367 | Gradient: [[-0.21469514]\n",
      " [-0.69188284]\n",
      " [ 0.01343098]]\n",
      "Iteration 47 | Cost: 0.666654630064733 | Gradient: [[-0.21426517]\n",
      " [-0.69084753]\n",
      " [ 0.01370992]]\n",
      "Iteration 48 | Cost: 0.6661316632828528 | Gradient: [[-0.213836  ]\n",
      " [-0.68981412]\n",
      " [ 0.0139883 ]]\n",
      "Iteration 49 | Cost: 0.6656102979046393 | Gradient: [[-0.21340763]\n",
      " [-0.68878261]\n",
      " [ 0.01426613]]\n",
      "Iteration 50 | Cost: 0.6650905283241123 | Gradient: [[-0.21298007]\n",
      " [-0.68775301]\n",
      " [ 0.01454341]]\n",
      "Iteration 51 | Cost: 0.6645723489505942 | Gradient: [[-0.2125533 ]\n",
      " [-0.68672531]\n",
      " [ 0.01482013]]\n",
      "Iteration 52 | Cost: 0.6640557542087359 | Gradient: [[-0.21212734]\n",
      " [-0.68569952]\n",
      " [ 0.01509631]]\n",
      "Iteration 53 | Cost: 0.6635407385385415 | Gradient: [[-0.21170218]\n",
      " [-0.68467563]\n",
      " [ 0.01537193]]\n",
      "Iteration 54 | Cost: 0.6630272963953915 | Gradient: [[-0.21127781]\n",
      " [-0.68365364]\n",
      " [ 0.015647  ]]\n",
      "Iteration 55 | Cost: 0.6625154222500663 | Gradient: [[-0.21085425]\n",
      " [-0.68263356]\n",
      " [ 0.01592151]]\n",
      "Iteration 56 | Cost: 0.6620051105887675 | Gradient: [[-0.21043149]\n",
      " [-0.68161538]\n",
      " [ 0.01619548]]\n",
      "Iteration 57 | Cost: 0.6614963559131393 | Gradient: [[-0.21000953]\n",
      " [-0.6805991 ]\n",
      " [ 0.01646889]]\n",
      "Iteration 58 | Cost: 0.6609891527402881 | Gradient: [[-0.20958837]\n",
      " [-0.67958471]\n",
      " [ 0.01674176]]\n",
      "Iteration 59 | Cost: 0.6604834956028018 | Gradient: [[-0.20916801]\n",
      " [-0.67857223]\n",
      " [ 0.01701407]]\n",
      "Iteration 60 | Cost: 0.6599793790487692 | Gradient: [[-0.20874845]\n",
      " [-0.67756165]\n",
      " [ 0.01728583]]\n",
      "Iteration 61 | Cost: 0.6594767976417952 | Gradient: [[-0.20832969]\n",
      " [-0.67655297]\n",
      " [ 0.01755705]]\n",
      "Iteration 62 | Cost: 0.6589757459610197 | Gradient: [[-0.20791173]\n",
      " [-0.67554618]\n",
      " [ 0.01782771]]\n",
      "Iteration 63 | Cost: 0.6584762186011319 | Gradient: [[-0.20749456]\n",
      " [-0.67454129]\n",
      " [ 0.01809782]]\n",
      "Iteration 64 | Cost: 0.6579782101723861 | Gradient: [[-0.20707819]\n",
      " [-0.6735383 ]\n",
      " [ 0.01836739]]\n",
      "Iteration 65 | Cost: 0.6574817153006147 | Gradient: [[-0.20666262]\n",
      " [-0.6725372 ]\n",
      " [ 0.01863641]]\n",
      "Iteration 66 | Cost: 0.6569867286272425 | Gradient: [[-0.20624785]\n",
      " [-0.671538  ]\n",
      " [ 0.01890488]]\n",
      "Iteration 67 | Cost: 0.6564932448092989 | Gradient: [[-0.20583388]\n",
      " [-0.67054069]\n",
      " [ 0.0191728 ]]\n",
      "Iteration 68 | Cost: 0.656001258519429 | Gradient: [[-0.2054207 ]\n",
      " [-0.66954527]\n",
      " [ 0.01944017]]\n",
      "Iteration 69 | Cost: 0.6555107644459048 | Gradient: [[-0.20500832]\n",
      " [-0.66855175]\n",
      " [ 0.019707  ]]\n",
      "Iteration 70 | Cost: 0.655021757292635 | Gradient: [[-0.20459673]\n",
      " [-0.66756011]\n",
      " [ 0.01997328]]\n",
      "Iteration 71 | Cost: 0.6545342317791749 | Gradient: [[-0.20418594]\n",
      " [-0.66657036]\n",
      " [ 0.02023901]]\n",
      "Iteration 72 | Cost: 0.6540481826407337 | Gradient: [[-0.20377595]\n",
      " [-0.66558251]\n",
      " [ 0.0205042 ]]\n",
      "Iteration 73 | Cost: 0.6535636046281836 | Gradient: [[-0.20336675]\n",
      " [-0.66459653]\n",
      " [ 0.02076884]]\n",
      "Iteration 74 | Cost: 0.6530804925080654 | Gradient: [[-0.20295834]\n",
      " [-0.66361245]\n",
      " [ 0.02103294]]\n",
      "Iteration 75 | Cost: 0.6525988410625955 | Gradient: [[-0.20255073]\n",
      " [-0.66263025]\n",
      " [ 0.02129649]]\n",
      "Iteration 76 | Cost: 0.6521186450896717 | Gradient: [[-0.20214391]\n",
      " [-0.66164993]\n",
      " [ 0.0215595 ]]\n",
      "Iteration 77 | Cost: 0.6516398994028764 | Gradient: [[-0.20173788]\n",
      " [-0.6606715 ]\n",
      " [ 0.02182197]]\n",
      "Iteration 78 | Cost: 0.6511625988314821 | Gradient: [[-0.20133265]\n",
      " [-0.65969494]\n",
      " [ 0.02208389]]\n",
      "Iteration 79 | Cost: 0.6506867382204543 | Gradient: [[-0.2009282 ]\n",
      " [-0.65872027]\n",
      " [ 0.02234527]]\n",
      "Iteration 80 | Cost: 0.6502123124304532 | Gradient: [[-0.20052455]\n",
      " [-0.65774747]\n",
      " [ 0.02260611]]\n",
      "Iteration 81 | Cost: 0.6497393163378369 | Gradient: [[-0.20012169]\n",
      " [-0.65677655]\n",
      " [ 0.0228664 ]]\n",
      "Iteration 82 | Cost: 0.6492677448346612 | Gradient: [[-0.19971961]\n",
      " [-0.65580751]\n",
      " [ 0.02312616]]\n",
      "Iteration 83 | Cost: 0.6487975928286814 | Gradient: [[-0.19931833]\n",
      " [-0.65484034]\n",
      " [ 0.02338537]]\n",
      "Iteration 84 | Cost: 0.6483288552433512 | Gradient: [[-0.19891784]\n",
      " [-0.65387505]\n",
      " [ 0.02364404]]\n",
      "Iteration 85 | Cost: 0.6478615270178218 | Gradient: [[-0.19851813]\n",
      " [-0.65291162]\n",
      " [ 0.02390218]]\n",
      "Iteration 86 | Cost: 0.6473956031069406 | Gradient: [[-0.19811921]\n",
      " [-0.65195007]\n",
      " [ 0.02415977]]\n",
      "Iteration 87 | Cost: 0.6469310784812495 | Gradient: [[-0.19772108]\n",
      " [-0.65099039]\n",
      " [ 0.02441683]]\n",
      "Iteration 88 | Cost: 0.6464679481269809 | Gradient: [[-0.19732373]\n",
      " [-0.65003257]\n",
      " [ 0.02467334]]\n",
      "Iteration 89 | Cost: 0.646006207046055 | Gradient: [[-0.19692717]\n",
      " [-0.64907661]\n",
      " [ 0.02492932]]\n",
      "Iteration 90 | Cost: 0.6455458502560758 | Gradient: [[-0.19653139]\n",
      " [-0.64812252]\n",
      " [ 0.02518477]]\n",
      "Iteration 91 | Cost: 0.645086872790326 | Gradient: [[-0.1961364 ]\n",
      " [-0.6471703 ]\n",
      " [ 0.02543967]]\n",
      "Iteration 92 | Cost: 0.6446292696977612 | Gradient: [[-0.19574219]\n",
      " [-0.64621993]\n",
      " [ 0.02569404]]\n",
      "Iteration 93 | Cost: 0.6441730360430052 | Gradient: [[-0.19534877]\n",
      " [-0.64527142]\n",
      " [ 0.02594788]]\n",
      "Iteration 94 | Cost: 0.643718166906342 | Gradient: [[-0.19495612]\n",
      " [-0.64432477]\n",
      " [ 0.02620118]]\n",
      "Iteration 95 | Cost: 0.6432646573837092 | Gradient: [[-0.19456426]\n",
      " [-0.64337998]\n",
      " [ 0.02645394]]\n",
      "Iteration 96 | Cost: 0.6428125025866906 | Gradient: [[-0.19417318]\n",
      " [-0.64243704]\n",
      " [ 0.02670617]]\n",
      "Iteration 97 | Cost: 0.6423616976425076 | Gradient: [[-0.19378288]\n",
      " [-0.64149595]\n",
      " [ 0.02695787]]\n",
      "Iteration 98 | Cost: 0.6419122376940096 | Gradient: [[-0.19339336]\n",
      " [-0.64055671]\n",
      " [ 0.02720904]]\n",
      "Iteration 99 | Cost: 0.6414641178996657 | Gradient: [[-0.19300461]\n",
      " [-0.63961932]\n",
      " [ 0.02745967]]\n",
      "Iteration 100 | Cost: 0.6410173334335538 | Gradient: [[-0.19261664]\n",
      " [-0.63868378]\n",
      " [ 0.02770977]]\n",
      "Iteration 101 | Cost: 0.6405718794853501 | Gradient: [[-0.19222946]\n",
      " [-0.63775008]\n",
      " [ 0.02795935]]\n",
      "Iteration 102 | Cost: 0.6401277512603184 | Gradient: [[-0.19184304]\n",
      " [-0.63681822]\n",
      " [ 0.02820839]]\n",
      "Iteration 103 | Cost: 0.6396849439792975 | Gradient: [[-0.1914574 ]\n",
      " [-0.63588821]\n",
      " [ 0.0284569 ]]\n",
      "Iteration 104 | Cost: 0.63924345287869 | Gradient: [[-0.19107254]\n",
      " [-0.63496003]\n",
      " [ 0.02870488]]\n",
      "Iteration 105 | Cost: 0.6388032732104494 | Gradient: [[-0.19068845]\n",
      " [-0.63403369]\n",
      " [ 0.02895233]]\n",
      "Iteration 106 | Cost: 0.6383644002420656 | Gradient: [[-0.19030513]\n",
      " [-0.63310919]\n",
      " [ 0.02919926]]\n",
      "Iteration 107 | Cost: 0.6379268292565532 | Gradient: [[-0.18992259]\n",
      " [-0.63218652]\n",
      " [ 0.02944566]]\n",
      "Iteration 108 | Cost: 0.6374905555524353 | Gradient: [[-0.18954081]\n",
      " [-0.63126568]\n",
      " [ 0.02969153]]\n",
      "Iteration 109 | Cost: 0.6370555744437296 | Gradient: [[-0.18915981]\n",
      " [-0.63034667]\n",
      " [ 0.02993688]]\n",
      "Iteration 110 | Cost: 0.6366218812599332 | Gradient: [[-0.18877958]\n",
      " [-0.62942949]\n",
      " [ 0.0301817 ]]\n",
      "Iteration 111 | Cost: 0.6361894713460069 | Gradient: [[-0.18840011]\n",
      " [-0.62851413]\n",
      " [ 0.030426  ]]\n",
      "Iteration 112 | Cost: 0.6357583400623584 | Gradient: [[-0.18802141]\n",
      " [-0.62760059]\n",
      " [ 0.03066977]]\n",
      "Iteration 113 | Cost: 0.6353284827848263 | Gradient: [[-0.18764348]\n",
      " [-0.62668888]\n",
      " [ 0.03091302]]\n",
      "Iteration 114 | Cost: 0.6348998949046621 | Gradient: [[-0.18726632]\n",
      " [-0.62577899]\n",
      " [ 0.03115575]]\n",
      "Iteration 115 | Cost: 0.6344725718285138 | Gradient: [[-0.18688992]\n",
      " [-0.62487091]\n",
      " [ 0.03139796]]\n",
      "Iteration 116 | Cost: 0.6340465089784061 | Gradient: [[-0.18651428]\n",
      " [-0.62396465]\n",
      " [ 0.03163964]]\n",
      "Iteration 117 | Cost: 0.6336217017917241 | Gradient: [[-0.18613941]\n",
      " [-0.6230602 ]\n",
      " [ 0.03188081]]\n",
      "Iteration 118 | Cost: 0.633198145721192 | Gradient: [[-0.1857653 ]\n",
      " [-0.62215756]\n",
      " [ 0.03212145]]\n",
      "Iteration 119 | Cost: 0.6327758362348558 | Gradient: [[-0.18539195]\n",
      " [-0.62125672]\n",
      " [ 0.03236157]]\n",
      "Iteration 120 | Cost: 0.6323547688160619 | Gradient: [[-0.18501936]\n",
      " [-0.6203577 ]\n",
      " [ 0.03260118]]\n",
      "Iteration 121 | Cost: 0.6319349389634378 | Gradient: [[-0.18464753]\n",
      " [-0.61946047]\n",
      " [ 0.03284027]]\n",
      "Iteration 122 | Cost: 0.631516342190871 | Gradient: [[-0.18427646]\n",
      " [-0.61856505]\n",
      " [ 0.03307884]]\n",
      "Iteration 123 | Cost: 0.6310989740274882 | Gradient: [[-0.18390615]\n",
      " [-0.61767143]\n",
      " [ 0.0333169 ]]\n",
      "Iteration 124 | Cost: 0.6306828300176338 | Gradient: [[-0.18353659]\n",
      " [-0.6167796 ]\n",
      " [ 0.03355444]]\n",
      "Iteration 125 | Cost: 0.6302679057208481 | Gradient: [[-0.18316779]\n",
      " [-0.61588957]\n",
      " [ 0.03379146]]\n",
      "Iteration 126 | Cost: 0.6298541967118446 | Gradient: [[-0.18279975]\n",
      " [-0.61500133]\n",
      " [ 0.03402797]]\n",
      "Iteration 127 | Cost: 0.629441698580488 | Gradient: [[-0.18243246]\n",
      " [-0.61411488]\n",
      " [ 0.03426397]]\n",
      "Iteration 128 | Cost: 0.6290304069317713 | Gradient: [[-0.18206592]\n",
      " [-0.61323022]\n",
      " [ 0.03449946]]\n",
      "Iteration 129 | Cost: 0.6286203173857914 | Gradient: [[-0.18170013]\n",
      " [-0.61234734]\n",
      " [ 0.03473443]]\n",
      "Iteration 130 | Cost: 0.6282114255777265 | Gradient: [[-0.18133509]\n",
      " [-0.61146625]\n",
      " [ 0.03496889]]\n",
      "Iteration 131 | Cost: 0.6278037271578114 | Gradient: [[-0.1809708 ]\n",
      " [-0.61058694]\n",
      " [ 0.03520284]]\n",
      "Iteration 132 | Cost: 0.6273972177913135 | Gradient: [[-0.18060726]\n",
      " [-0.6097094 ]\n",
      " [ 0.03543628]]\n",
      "Iteration 133 | Cost: 0.6269918931585073 | Gradient: [[-0.18024447]\n",
      " [-0.60883364]\n",
      " [ 0.03566921]]\n",
      "Iteration 134 | Cost: 0.6265877489546501 | Gradient: [[-0.17988243]\n",
      " [-0.60795965]\n",
      " [ 0.03590164]]\n",
      "Iteration 135 | Cost: 0.6261847808899558 | Gradient: [[-0.17952113]\n",
      " [-0.60708743]\n",
      " [ 0.03613355]]\n",
      "Iteration 136 | Cost: 0.6257829846895695 | Gradient: [[-0.17916057]\n",
      " [-0.60621699]\n",
      " [ 0.03636496]]\n",
      "Iteration 137 | Cost: 0.6253823560935416 | Gradient: [[-0.17880076]\n",
      " [-0.6053483 ]\n",
      " [ 0.03659587]]\n",
      "Iteration 138 | Cost: 0.6249828908568004 | Gradient: [[-0.17844169]\n",
      " [-0.60448138]\n",
      " [ 0.03682627]]\n",
      "Iteration 139 | Cost: 0.6245845847491264 | Gradient: [[-0.17808336]\n",
      " [-0.60361622]\n",
      " [ 0.03705616]]\n",
      "Iteration 140 | Cost: 0.624187433555125 | Gradient: [[-0.17772578]\n",
      " [-0.60275282]\n",
      " [ 0.03728555]]\n",
      "Iteration 141 | Cost: 0.623791433074198 | Gradient: [[-0.17736893]\n",
      " [-0.60189117]\n",
      " [ 0.03751444]]\n",
      "Iteration 142 | Cost: 0.623396579120518 | Gradient: [[-0.17701282]\n",
      " [-0.60103128]\n",
      " [ 0.03774282]]\n",
      "Iteration 143 | Cost: 0.6230028675229985 | Gradient: [[-0.17665744]\n",
      " [-0.60017314]\n",
      " [ 0.0379707 ]]\n",
      "Iteration 144 | Cost: 0.6226102941252665 | Gradient: [[-0.17630281]\n",
      " [-0.59931674]\n",
      " [ 0.03819809]]\n",
      "Iteration 145 | Cost: 0.622218854785634 | Gradient: [[-0.1759489 ]\n",
      " [-0.59846209]\n",
      " [ 0.03842497]]\n",
      "Iteration 146 | Cost: 0.6218285453770688 | Gradient: [[-0.17559573]\n",
      " [-0.59760918]\n",
      " [ 0.03865135]]\n",
      "Iteration 147 | Cost: 0.6214393617871659 | Gradient: [[-0.1752433 ]\n",
      " [-0.59675801]\n",
      " [ 0.03887724]]\n",
      "Iteration 148 | Cost: 0.6210512999181174 | Gradient: [[-0.17489159]\n",
      " [-0.59590858]\n",
      " [ 0.03910263]]\n",
      "Iteration 149 | Cost: 0.6206643556866841 | Gradient: [[-0.17454061]\n",
      " [-0.59506088]\n",
      " [ 0.03932752]]\n",
      "Iteration 150 | Cost: 0.6202785250241639 | Gradient: [[-0.17419037]\n",
      " [-0.59421492]\n",
      " [ 0.03955192]]\n",
      "Iteration 151 | Cost: 0.6198938038763635 | Gradient: [[-0.17384085]\n",
      " [-0.59337069]\n",
      " [ 0.03977582]]\n",
      "Iteration 152 | Cost: 0.6195101882035664 | Gradient: [[-0.17349206]\n",
      " [-0.59252818]\n",
      " [ 0.03999922]]\n",
      "Iteration 153 | Cost: 0.6191276739805031 | Gradient: [[-0.17314399]\n",
      " [-0.59168739]\n",
      " [ 0.04022214]]\n",
      "Iteration 154 | Cost: 0.6187462571963203 | Gradient: [[-0.17279665]\n",
      " [-0.59084833]\n",
      " [ 0.04044456]]\n",
      "Iteration 155 | Cost: 0.6183659338545495 | Gradient: [[-0.17245003]\n",
      " [-0.59001098]\n",
      " [ 0.04066648]]\n",
      "Iteration 156 | Cost: 0.617986699973076 | Gradient: [[-0.17210414]\n",
      " [-0.58917536]\n",
      " [ 0.04088792]]\n",
      "Iteration 157 | Cost: 0.6176085515841061 | Gradient: [[-0.17175897]\n",
      " [-0.58834144]\n",
      " [ 0.04110887]]\n",
      "Iteration 158 | Cost: 0.6172314847341375 | Gradient: [[-0.17141451]\n",
      " [-0.58750923]\n",
      " [ 0.04132933]]\n",
      "Iteration 159 | Cost: 0.6168554954839254 | Gradient: [[-0.17107078]\n",
      " [-0.58667874]\n",
      " [ 0.0415493 ]]\n",
      "Iteration 160 | Cost: 0.6164805799084508 | Gradient: [[-0.17072776]\n",
      " [-0.58584994]\n",
      " [ 0.04176878]]\n",
      "Iteration 161 | Cost: 0.616106734096889 | Gradient: [[-0.17038546]\n",
      " [-0.58502285]\n",
      " [ 0.04198777]]\n",
      "Iteration 162 | Cost: 0.6157339541525754 | Gradient: [[-0.17004387]\n",
      " [-0.58419746]\n",
      " [ 0.04220628]]\n",
      "Iteration 163 | Cost: 0.6153622361929739 | Gradient: [[-0.169703  ]\n",
      " [-0.58337377]\n",
      " [ 0.0424243 ]]\n",
      "Iteration 164 | Cost: 0.6149915763496434 | Gradient: [[-0.16936284]\n",
      " [-0.58255176]\n",
      " [ 0.04264184]]\n",
      "Iteration 165 | Cost: 0.6146219707682044 | Gradient: [[-0.16902339]\n",
      " [-0.58173145]\n",
      " [ 0.0428589 ]]\n",
      "Iteration 166 | Cost: 0.6142534156083063 | Gradient: [[-0.16868465]\n",
      " [-0.58091283]\n",
      " [ 0.04307547]]\n",
      "Iteration 167 | Cost: 0.6138859070435928 | Gradient: [[-0.16834663]\n",
      " [-0.58009589]\n",
      " [ 0.04329156]]\n",
      "Iteration 168 | Cost: 0.6135194412616692 | Gradient: [[-0.16800931]\n",
      " [-0.57928064]\n",
      " [ 0.04350717]]\n",
      "Iteration 169 | Cost: 0.6131540144640678 | Gradient: [[-0.16767269]\n",
      " [-0.57846706]\n",
      " [ 0.0437223 ]]\n",
      "Iteration 170 | Cost: 0.6127896228662139 | Gradient: [[-0.16733679]\n",
      " [-0.57765517]\n",
      " [ 0.04393695]]\n",
      "Iteration 171 | Cost: 0.6124262626973916 | Gradient: [[-0.16700158]\n",
      " [-0.57684494]\n",
      " [ 0.04415112]]\n",
      "Iteration 172 | Cost: 0.6120639302007093 | Gradient: [[-0.16666708]\n",
      " [-0.57603639]\n",
      " [ 0.04436481]]\n",
      "Iteration 173 | Cost: 0.6117026216330653 | Gradient: [[-0.16633329]\n",
      " [-0.5752295 ]\n",
      " [ 0.04457803]]\n",
      "Iteration 174 | Cost: 0.611342333265113 | Gradient: [[-0.16600019]\n",
      " [-0.57442428]\n",
      " [ 0.04479077]]\n",
      "Iteration 175 | Cost: 0.6109830613812257 | Gradient: [[-0.16566779]\n",
      " [-0.57362072]\n",
      " [ 0.04500304]]\n",
      "Iteration 176 | Cost: 0.6106248022794618 | Gradient: [[-0.16533609]\n",
      " [-0.57281883]\n",
      " [ 0.04521483]]\n",
      "Iteration 177 | Cost: 0.61026755227153 | Gradient: [[-0.16500509]\n",
      " [-0.57201858]\n",
      " [ 0.04542615]]\n",
      "Iteration 178 | Cost: 0.6099113076827529 | Gradient: [[-0.16467479]\n",
      " [-0.57122   ]\n",
      " [ 0.04563699]]\n",
      "Iteration 179 | Cost: 0.6095560648520331 | Gradient: [[-0.16434517]\n",
      " [-0.57042306]\n",
      " [ 0.04584736]]\n",
      "Iteration 180 | Cost: 0.6092018201318156 | Gradient: [[-0.16401626]\n",
      " [-0.56962777]\n",
      " [ 0.04605727]]\n",
      "Iteration 181 | Cost: 0.6088485698880541 | Gradient: [[-0.16368803]\n",
      " [-0.56883412]\n",
      " [ 0.0462667 ]]\n",
      "Iteration 182 | Cost: 0.608496310500174 | Gradient: [[-0.1633605 ]\n",
      " [-0.56804212]\n",
      " [ 0.04647566]]\n",
      "Iteration 183 | Cost: 0.6081450383610368 | Gradient: [[-0.16303365]\n",
      " [-0.56725176]\n",
      " [ 0.04668416]]\n",
      "Iteration 184 | Cost: 0.6077947498769035 | Gradient: [[-0.16270749]\n",
      " [-0.56646303]\n",
      " [ 0.04689218]]\n",
      "Iteration 185 | Cost: 0.6074454414673993 | Gradient: [[-0.16238202]\n",
      " [-0.56567594]\n",
      " [ 0.04709975]]\n",
      "Iteration 186 | Cost: 0.6070971095654762 | Gradient: [[-0.16205724]\n",
      " [-0.56489047]\n",
      " [ 0.04730684]]\n",
      "Iteration 187 | Cost: 0.6067497506173779 | Gradient: [[-0.16173314]\n",
      " [-0.56410664]\n",
      " [ 0.04751347]]\n",
      "Iteration 188 | Cost: 0.6064033610826018 | Gradient: [[-0.16140973]\n",
      " [-0.56332442]\n",
      " [ 0.04771964]]\n",
      "Iteration 189 | Cost: 0.6060579374338638 | Gradient: [[-0.16108699]\n",
      " [-0.56254383]\n",
      " [ 0.04792534]]\n",
      "Iteration 190 | Cost: 0.6057134761570604 | Gradient: [[-0.16076494]\n",
      " [-0.56176486]\n",
      " [ 0.04813058]]\n",
      "Iteration 191 | Cost: 0.6053699737512327 | Gradient: [[-0.16044357]\n",
      " [-0.5609875 ]\n",
      " [ 0.04833536]]\n",
      "Iteration 192 | Cost: 0.6050274267285288 | Gradient: [[-0.16012287]\n",
      " [-0.56021176]\n",
      " [ 0.04853968]]\n",
      "Iteration 193 | Cost: 0.6046858316141674 | Gradient: [[-0.15980285]\n",
      " [-0.55943762]\n",
      " [ 0.04874354]]\n",
      "Iteration 194 | Cost: 0.6043451849464009 | Gradient: [[-0.15948351]\n",
      " [-0.55866509]\n",
      " [ 0.04894694]]\n",
      "Iteration 195 | Cost: 0.6040054832764767 | Gradient: [[-0.15916484]\n",
      " [-0.55789417]\n",
      " [ 0.04914989]]\n",
      "Iteration 196 | Cost: 0.6036667231686024 | Gradient: [[-0.15884685]\n",
      " [-0.55712484]\n",
      " [ 0.04935237]]\n",
      "Iteration 197 | Cost: 0.6033289011999059 | Gradient: [[-0.15852953]\n",
      " [-0.55635711]\n",
      " [ 0.0495544 ]]\n",
      "Iteration 198 | Cost: 0.6029920139604003 | Gradient: [[-0.15821287]\n",
      " [-0.55559098]\n",
      " [ 0.04975598]]\n",
      "Iteration 199 | Cost: 0.6026560580529446 | Gradient: [[-0.15789689]\n",
      " [-0.55482644]\n",
      " [ 0.0499571 ]]\n",
      "Iteration 200 | Cost: 0.6023210300932076 | Gradient: [[-0.15758158]\n",
      " [-0.55406348]\n",
      " [ 0.05015777]]\n",
      "Iteration 201 | Cost: 0.601986926709629 | Gradient: [[-0.15726693]\n",
      " [-0.55330211]\n",
      " [ 0.05035798]]\n",
      "Iteration 202 | Cost: 0.6016537445433828 | Gradient: [[-0.15695294]\n",
      " [-0.55254233]\n",
      " [ 0.05055774]]\n",
      "Iteration 203 | Cost: 0.601321480248339 | Gradient: [[-0.15663963]\n",
      " [-0.55178412]\n",
      " [ 0.05075706]]\n",
      "Iteration 204 | Cost: 0.600990130491026 | Gradient: [[-0.15632697]\n",
      " [-0.55102749]\n",
      " [ 0.05095592]]\n",
      "Iteration 205 | Cost: 0.6006596919505929 | Gradient: [[-0.15601498]\n",
      " [-0.55027243]\n",
      " [ 0.05115433]]\n",
      "Iteration 206 | Cost: 0.6003301613187711 | Gradient: [[-0.15570364]\n",
      " [-0.54951894]\n",
      " [ 0.0513523 ]]\n",
      "Iteration 207 | Cost: 0.6000015352998371 | Gradient: [[-0.15539297]\n",
      " [-0.54876702]\n",
      " [ 0.05154981]]\n",
      "Iteration 208 | Cost: 0.599673810610574 | Gradient: [[-0.15508295]\n",
      " [-0.54801667]\n",
      " [ 0.05174688]]\n",
      "Iteration 209 | Cost: 0.5993469839802338 | Gradient: [[-0.15477359]\n",
      " [-0.54726787]\n",
      " [ 0.05194351]]\n",
      "Iteration 210 | Cost: 0.5990210521504987 | Gradient: [[-0.15446489]\n",
      " [-0.54652063]\n",
      " [ 0.05213969]]\n",
      "Iteration 211 | Cost: 0.5986960118754436 | Gradient: [[-0.15415683]\n",
      " [-0.54577495]\n",
      " [ 0.05233543]]\n",
      "Iteration 212 | Cost: 0.5983718599214988 | Gradient: [[-0.15384943]\n",
      " [-0.54503082]\n",
      " [ 0.05253072]]\n",
      "Iteration 213 | Cost: 0.5980485930674092 | Gradient: [[-0.15354269]\n",
      " [-0.54428824]\n",
      " [ 0.05272558]]\n",
      "Iteration 214 | Cost: 0.5977262081041991 | Gradient: [[-0.15323659]\n",
      " [-0.5435472 ]\n",
      " [ 0.05291999]]\n",
      "Iteration 215 | Cost: 0.5974047018351316 | Gradient: [[-0.15293114]\n",
      " [-0.5428077 ]\n",
      " [ 0.05311396]]\n",
      "Iteration 216 | Cost: 0.5970840710756724 | Gradient: [[-0.15262634]\n",
      " [-0.54206975]\n",
      " [ 0.05330749]]\n",
      "Iteration 217 | Cost: 0.5967643126534498 | Gradient: [[-0.15232218]\n",
      " [-0.54133333]\n",
      " [ 0.05350059]]\n",
      "Iteration 218 | Cost: 0.596445423408217 | Gradient: [[-0.15201867]\n",
      " [-0.54059845]\n",
      " [ 0.05369324]]\n",
      "Iteration 219 | Cost: 0.5961274001918143 | Gradient: [[-0.1517158 ]\n",
      " [-0.53986509]\n",
      " [ 0.05388546]]\n",
      "Iteration 220 | Cost: 0.5958102398681301 | Gradient: [[-0.15141357]\n",
      " [-0.53913327]\n",
      " [ 0.05407725]]\n",
      "Iteration 221 | Cost: 0.5954939393130627 | Gradient: [[-0.15111199]\n",
      " [-0.53840296]\n",
      " [ 0.0542686 ]]\n",
      "Iteration 222 | Cost: 0.5951784954144819 | Gradient: [[-0.15081104]\n",
      " [-0.53767418]\n",
      " [ 0.05445951]]\n",
      "Iteration 223 | Cost: 0.5948639050721908 | Gradient: [[-0.15051074]\n",
      " [-0.53694692]\n",
      " [ 0.05464999]]\n",
      "Iteration 224 | Cost: 0.5945501651978875 | Gradient: [[-0.15021106]\n",
      " [-0.53622117]\n",
      " [ 0.05484004]]\n",
      "Iteration 225 | Cost: 0.5942372727151264 | Gradient: [[-0.14991203]\n",
      " [-0.53549693]\n",
      " [ 0.05502966]]\n",
      "Iteration 226 | Cost: 0.5939252245592798 | Gradient: [[-0.14961363]\n",
      " [-0.53477421]\n",
      " [ 0.05521885]]\n",
      "Iteration 227 | Cost: 0.5936140176774996 | Gradient: [[-0.14931586]\n",
      " [-0.53405298]\n",
      " [ 0.05540761]]\n",
      "Iteration 228 | Cost: 0.593303649028679 | Gradient: [[-0.14901872]\n",
      " [-0.53333326]\n",
      " [ 0.05559594]]\n",
      "Iteration 229 | Cost: 0.5929941155834143 | Gradient: [[-0.14872222]\n",
      " [-0.53261504]\n",
      " [ 0.05578384]]\n",
      "Iteration 230 | Cost: 0.5926854143239657 | Gradient: [[-0.14842634]\n",
      " [-0.53189832]\n",
      " [ 0.05597132]]\n",
      "Iteration 231 | Cost: 0.5923775422442198 | Gradient: [[-0.14813109]\n",
      " [-0.53118309]\n",
      " [ 0.05615837]]\n",
      "Iteration 232 | Cost: 0.5920704963496504 | Gradient: [[-0.14783647]\n",
      " [-0.53046935]\n",
      " [ 0.05634499]]\n",
      "Iteration 233 | Cost: 0.5917642736572811 | Gradient: [[-0.14754247]\n",
      " [-0.5297571 ]\n",
      " [ 0.05653119]]\n",
      "Iteration 234 | Cost: 0.591458871195646 | Gradient: [[-0.14724909]\n",
      " [-0.52904633]\n",
      " [ 0.05671697]]\n",
      "Iteration 235 | Cost: 0.5911542860047518 | Gradient: [[-0.14695634]\n",
      " [-0.52833704]\n",
      " [ 0.05690232]]\n",
      "Iteration 236 | Cost: 0.5908505151360397 | Gradient: [[-0.14666421]\n",
      " [-0.52762923]\n",
      " [ 0.05708726]]\n",
      "Iteration 237 | Cost: 0.5905475556523462 | Gradient: [[-0.1463727 ]\n",
      " [-0.5269229 ]\n",
      " [ 0.05727177]]\n",
      "Iteration 238 | Cost: 0.5902454046278658 | Gradient: [[-0.1460818 ]\n",
      " [-0.52621804]\n",
      " [ 0.05745586]]\n",
      "Iteration 239 | Cost: 0.5899440591481121 | Gradient: [[-0.14579153]\n",
      " [-0.52551464]\n",
      " [ 0.05763954]]\n",
      "Iteration 240 | Cost: 0.5896435163098798 | Gradient: [[-0.14550187]\n",
      " [-0.52481272]\n",
      " [ 0.05782279]]\n",
      "Iteration 241 | Cost: 0.589343773221206 | Gradient: [[-0.14521282]\n",
      " [-0.52411225]\n",
      " [ 0.05800563]]\n",
      "Iteration 242 | Cost: 0.589044827001333 | Gradient: [[-0.14492439]\n",
      " [-0.52341324]\n",
      " [ 0.05818806]]\n",
      "Iteration 243 | Cost: 0.5887466747806691 | Gradient: [[-0.14463657]\n",
      " [-0.5227157 ]\n",
      " [ 0.05837006]]\n",
      "Iteration 244 | Cost: 0.5884493137007505 | Gradient: [[-0.14434936]\n",
      " [-0.5220196 ]\n",
      " [ 0.05855166]]\n",
      "Iteration 245 | Cost: 0.5881527409142039 | Gradient: [[-0.14406276]\n",
      " [-0.52132495]\n",
      " [ 0.05873284]]\n",
      "Iteration 246 | Cost: 0.5878569535847078 | Gradient: [[-0.14377676]\n",
      " [-0.52063175]\n",
      " [ 0.0589136 ]]\n",
      "Iteration 247 | Cost: 0.5875619488869545 | Gradient: [[-0.14349138]\n",
      " [-0.51994   ]\n",
      " [ 0.05909396]]\n",
      "Iteration 248 | Cost: 0.5872677240066122 | Gradient: [[-0.1432066 ]\n",
      " [-0.51924969]\n",
      " [ 0.0592739 ]]\n",
      "Iteration 249 | Cost: 0.5869742761402867 | Gradient: [[-0.14292242]\n",
      " [-0.51856081]\n",
      " [ 0.05945344]]\n",
      "Iteration 250 | Cost: 0.5866816024954842 | Gradient: [[-0.14263885]\n",
      " [-0.51787337]\n",
      " [ 0.05963256]]\n",
      "Iteration 251 | Cost: 0.5863897002905724 | Gradient: [[-0.14235587]\n",
      " [-0.51718736]\n",
      " [ 0.05981128]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 252 | Cost: 0.5860985667547429 | Gradient: [[-0.1420735 ]\n",
      " [-0.51650278]\n",
      " [ 0.05998959]]\n",
      "Iteration 253 | Cost: 0.5858081991279741 | Gradient: [[-0.14179173]\n",
      " [-0.51581962]\n",
      " [ 0.06016749]]\n",
      "Iteration 254 | Cost: 0.5855185946609921 | Gradient: [[-0.14151055]\n",
      " [-0.51513789]\n",
      " [ 0.06034499]]\n",
      "Iteration 255 | Cost: 0.5852297506152341 | Gradient: [[-0.14122997]\n",
      " [-0.51445758]\n",
      " [ 0.06052209]]\n",
      "Iteration 256 | Cost: 0.5849416642628099 | Gradient: [[-0.14094998]\n",
      " [-0.51377868]\n",
      " [ 0.06069878]]\n",
      "Iteration 257 | Cost: 0.5846543328864646 | Gradient: [[-0.14067059]\n",
      " [-0.5131012 ]\n",
      " [ 0.06087506]]\n",
      "Iteration 258 | Cost: 0.5843677537795413 | Gradient: [[-0.14039179]\n",
      " [-0.51242512]\n",
      " [ 0.06105095]]\n",
      "Iteration 259 | Cost: 0.5840819242459424 | Gradient: [[-0.14011358]\n",
      " [-0.51175046]\n",
      " [ 0.06122643]]\n",
      "Iteration 260 | Cost: 0.5837968416000936 | Gradient: [[-0.13983597]\n",
      " [-0.5110772 ]\n",
      " [ 0.06140151]]\n",
      "Iteration 261 | Cost: 0.5835125031669047 | Gradient: [[-0.13955893]\n",
      " [-0.51040534]\n",
      " [ 0.0615762 ]]\n",
      "Iteration 262 | Cost: 0.5832289062817337 | Gradient: [[-0.13928249]\n",
      " [-0.50973487]\n",
      " [ 0.06175048]]\n",
      "Iteration 263 | Cost: 0.5829460482903489 | Gradient: [[-0.13900663]\n",
      " [-0.5090658 ]\n",
      " [ 0.06192437]]\n",
      "Iteration 264 | Cost: 0.5826639265488913 | Gradient: [[-0.13873136]\n",
      " [-0.50839813]\n",
      " [ 0.06209786]]\n",
      "Iteration 265 | Cost: 0.5823825384238376 | Gradient: [[-0.13845667]\n",
      " [-0.50773184]\n",
      " [ 0.06227096]]\n",
      "Iteration 266 | Cost: 0.5821018812919625 | Gradient: [[-0.13818256]\n",
      " [-0.50706694]\n",
      " [ 0.06244366]]\n",
      "Iteration 267 | Cost: 0.5818219525403029 | Gradient: [[-0.13790903]\n",
      " [-0.50640342]\n",
      " [ 0.06261596]]\n",
      "Iteration 268 | Cost: 0.581542749566119 | Gradient: [[-0.13763608]\n",
      " [-0.50574128]\n",
      " [ 0.06278788]]\n",
      "Iteration 269 | Cost: 0.5812642697768587 | Gradient: [[-0.13736371]\n",
      " [-0.50508052]\n",
      " [ 0.0629594 ]]\n",
      "Iteration 270 | Cost: 0.5809865105901202 | Gradient: [[-0.13709192]\n",
      " [-0.50442113]\n",
      " [ 0.06313052]]\n",
      "Iteration 271 | Cost: 0.5807094694336147 | Gradient: [[-0.1368207 ]\n",
      " [-0.50376311]\n",
      " [ 0.06330126]]\n",
      "Iteration 272 | Cost: 0.5804331437451297 | Gradient: [[-0.13655005]\n",
      " [-0.50310646]\n",
      " [ 0.06347161]]\n",
      "Iteration 273 | Cost: 0.5801575309724927 | Gradient: [[-0.13627998]\n",
      " [-0.50245118]\n",
      " [ 0.06364157]]\n",
      "Iteration 274 | Cost: 0.5798826285735341 | Gradient: [[-0.13601048]\n",
      " [-0.50179725]\n",
      " [ 0.06381114]]\n",
      "Iteration 275 | Cost: 0.5796084340160508 | Gradient: [[-0.13574155]\n",
      " [-0.50114468]\n",
      " [ 0.06398033]]\n",
      "Iteration 276 | Cost: 0.5793349447777693 | Gradient: [[-0.13547319]\n",
      " [-0.50049347]\n",
      " [ 0.06414912]]\n",
      "Iteration 277 | Cost: 0.5790621583463088 | Gradient: [[-0.13520539]\n",
      " [-0.49984361]\n",
      " [ 0.06431754]]\n",
      "Iteration 278 | Cost: 0.5787900722191462 | Gradient: [[-0.13493817]\n",
      " [-0.4991951 ]\n",
      " [ 0.06448556]]\n",
      "Iteration 279 | Cost: 0.5785186839035782 | Gradient: [[-0.1346715 ]\n",
      " [-0.49854794]\n",
      " [ 0.06465321]]\n",
      "Iteration 280 | Cost: 0.5782479909166857 | Gradient: [[-0.13440541]\n",
      " [-0.49790212]\n",
      " [ 0.06482047]]\n",
      "Iteration 281 | Cost: 0.5779779907852977 | Gradient: [[-0.13413987]\n",
      " [-0.49725764]\n",
      " [ 0.06498735]]\n",
      "Iteration 282 | Cost: 0.5777086810459541 | Gradient: [[-0.13387489]\n",
      " [-0.4966145 ]\n",
      " [ 0.06515385]]\n",
      "Iteration 283 | Cost: 0.5774400592448719 | Gradient: [[-0.13361048]\n",
      " [-0.49597269]\n",
      " [ 0.06531997]]\n",
      "Iteration 284 | Cost: 0.577172122937906 | Gradient: [[-0.13334662]\n",
      " [-0.49533221]\n",
      " [ 0.0654857 ]]\n",
      "Iteration 285 | Cost: 0.5769048696905164 | Gradient: [[-0.13308332]\n",
      " [-0.49469306]\n",
      " [ 0.06565106]]\n",
      "Iteration 286 | Cost: 0.5766382970777296 | Gradient: [[-0.13282058]\n",
      " [-0.49405524]\n",
      " [ 0.06581605]]\n",
      "Iteration 287 | Cost: 0.5763724026841051 | Gradient: [[-0.13255839]\n",
      " [-0.49341874]\n",
      " [ 0.06598065]]\n",
      "Iteration 288 | Cost: 0.5761071841036981 | Gradient: [[-0.13229675]\n",
      " [-0.49278356]\n",
      " [ 0.06614488]]\n",
      "Iteration 289 | Cost: 0.5758426389400245 | Gradient: [[-0.13203567]\n",
      " [-0.49214969]\n",
      " [ 0.06630873]]\n",
      "Iteration 290 | Cost: 0.5755787648060255 | Gradient: [[-0.13177514]\n",
      " [-0.49151714]\n",
      " [ 0.06647221]]\n",
      "Iteration 291 | Cost: 0.5753155593240319 | Gradient: [[-0.13151516]\n",
      " [-0.4908859 ]\n",
      " [ 0.06663532]]\n",
      "Iteration 292 | Cost: 0.5750530201257281 | Gradient: [[-0.13125572]\n",
      " [-0.49025596]\n",
      " [ 0.06679806]]\n",
      "Iteration 293 | Cost: 0.5747911448521182 | Gradient: [[-0.13099684]\n",
      " [-0.48962733]\n",
      " [ 0.06696042]]\n",
      "Iteration 294 | Cost: 0.5745299311534892 | Gradient: [[-0.1307385 ]\n",
      " [-0.489     ]\n",
      " [ 0.06712241]]\n",
      "Iteration 295 | Cost: 0.574269376689377 | Gradient: [[-0.1304807 ]\n",
      " [-0.48837397]\n",
      " [ 0.06728403]]\n",
      "Iteration 296 | Cost: 0.5740094791285305 | Gradient: [[-0.13022345]\n",
      " [-0.48774923]\n",
      " [ 0.06744528]]\n",
      "Iteration 297 | Cost: 0.5737502361488775 | Gradient: [[-0.12996674]\n",
      " [-0.48712579]\n",
      " [ 0.06760617]]\n",
      "Iteration 298 | Cost: 0.5734916454374887 | Gradient: [[-0.12971057]\n",
      " [-0.48650364]\n",
      " [ 0.06776668]]\n",
      "Iteration 299 | Cost: 0.5732337046905434 | Gradient: [[-0.12945494]\n",
      " [-0.48588277]\n",
      " [ 0.06792683]]\n",
      "Iteration 300 | Cost: 0.5729764116132956 | Gradient: [[-0.12919985]\n",
      " [-0.48526318]\n",
      " [ 0.06808662]]\n",
      "Iteration 301 | Cost: 0.5727197639200375 | Gradient: [[-0.12894529]\n",
      " [-0.48464488]\n",
      " [ 0.06824604]]\n",
      "Iteration 302 | Cost: 0.5724637593340666 | Gradient: [[-0.12869127]\n",
      " [-0.48402786]\n",
      " [ 0.06840509]]\n",
      "Iteration 303 | Cost: 0.5722083955876501 | Gradient: [[-0.12843779]\n",
      " [-0.4834121 ]\n",
      " [ 0.06856378]]\n",
      "Iteration 304 | Cost: 0.5719536704219914 | Gradient: [[-0.12818484]\n",
      " [-0.48279763]\n",
      " [ 0.06872211]]\n",
      "Iteration 305 | Cost: 0.5716995815871949 | Gradient: [[-0.12793242]\n",
      " [-0.48218442]\n",
      " [ 0.06888008]]\n",
      "Iteration 306 | Cost: 0.5714461268422324 | Gradient: [[-0.12768053]\n",
      " [-0.48157247]\n",
      " [ 0.06903768]]\n",
      "Iteration 307 | Cost: 0.5711933039549085 | Gradient: [[-0.12742918]\n",
      " [-0.48096179]\n",
      " [ 0.06919493]]\n",
      "Iteration 308 | Cost: 0.5709411107018271 | Gradient: [[-0.12717835]\n",
      " [-0.48035237]\n",
      " [ 0.06935182]]\n",
      "Iteration 309 | Cost: 0.570689544868357 | Gradient: [[-0.12692804]\n",
      " [-0.4797442 ]\n",
      " [ 0.06950835]]\n",
      "Iteration 310 | Cost: 0.5704386042485977 | Gradient: [[-0.12667827]\n",
      " [-0.47913729]\n",
      " [ 0.06966452]]\n",
      "Iteration 311 | Cost: 0.5701882866453468 | Gradient: [[-0.12642901]\n",
      " [-0.47853164]\n",
      " [ 0.06982034]]\n",
      "Iteration 312 | Cost: 0.5699385898700651 | Gradient: [[-0.12618029]\n",
      " [-0.47792723]\n",
      " [ 0.06997579]]\n",
      "Iteration 313 | Cost: 0.569689511742843 | Gradient: [[-0.12593208]\n",
      " [-0.47732406]\n",
      " [ 0.0701309 ]]\n",
      "Iteration 314 | Cost: 0.5694410500923683 | Gradient: [[-0.12568439]\n",
      " [-0.47672214]\n",
      " [ 0.07028565]]\n",
      "Iteration 315 | Cost: 0.5691932027558915 | Gradient: [[-0.12543723]\n",
      " [-0.47612146]\n",
      " [ 0.07044005]]\n",
      "Iteration 316 | Cost: 0.5689459675791922 | Gradient: [[-0.12519058]\n",
      " [-0.47552201]\n",
      " [ 0.07059409]]\n",
      "Iteration 317 | Cost: 0.5686993424165476 | Gradient: [[-0.12494445]\n",
      " [-0.4749238 ]\n",
      " [ 0.07074778]]\n",
      "Iteration 318 | Cost: 0.5684533251306976 | Gradient: [[-0.12469884]\n",
      " [-0.47432682]\n",
      " [ 0.07090113]]\n",
      "Iteration 319 | Cost: 0.5682079135928119 | Gradient: [[-0.12445374]\n",
      " [-0.47373107]\n",
      " [ 0.07105412]]\n",
      "Iteration 320 | Cost: 0.5679631056824584 | Gradient: [[-0.12420915]\n",
      " [-0.47313654]\n",
      " [ 0.07120676]]\n",
      "Iteration 321 | Cost: 0.5677188992875691 | Gradient: [[-0.12396508]\n",
      " [-0.47254324]\n",
      " [ 0.07135905]]\n",
      "Iteration 322 | Cost: 0.5674752923044074 | Gradient: [[-0.12372152]\n",
      " [-0.47195115]\n",
      " [ 0.071511  ]]\n",
      "Iteration 323 | Cost: 0.5672322826375358 | Gradient: [[-0.12347847]\n",
      " [-0.47136028]\n",
      " [ 0.0716626 ]]\n",
      "Iteration 324 | Cost: 0.5669898681997834 | Gradient: [[-0.12323592]\n",
      " [-0.47077063]\n",
      " [ 0.07181385]]\n",
      "Iteration 325 | Cost: 0.5667480469122124 | Gradient: [[-0.12299389]\n",
      " [-0.47018219]\n",
      " [ 0.07196476]]\n",
      "Iteration 326 | Cost: 0.5665068167040872 | Gradient: [[-0.12275236]\n",
      " [-0.46959495]\n",
      " [ 0.07211533]]\n",
      "Iteration 327 | Cost: 0.566266175512841 | Gradient: [[-0.12251133]\n",
      " [-0.46900892]\n",
      " [ 0.07226555]]\n",
      "Iteration 328 | Cost: 0.5660261212840437 | Gradient: [[-0.12227081]\n",
      " [-0.4684241 ]\n",
      " [ 0.07241543]]\n",
      "Iteration 329 | Cost: 0.5657866519713707 | Gradient: [[-0.1220308 ]\n",
      " [-0.46784047]\n",
      " [ 0.07256496]]\n",
      "Iteration 330 | Cost: 0.5655477655365693 | Gradient: [[-0.12179128]\n",
      " [-0.46725804]\n",
      " [ 0.07271416]]\n",
      "Iteration 331 | Cost: 0.5653094599494278 | Gradient: [[-0.12155227]\n",
      " [-0.4666768 ]\n",
      " [ 0.07286301]]\n",
      "Iteration 332 | Cost: 0.565071733187744 | Gradient: [[-0.12131375]\n",
      " [-0.46609676]\n",
      " [ 0.07301153]]\n",
      "Iteration 333 | Cost: 0.5648345832372921 | Gradient: [[-0.12107573]\n",
      " [-0.4655179 ]\n",
      " [ 0.0731597 ]]\n",
      "Iteration 334 | Cost: 0.5645980080917926 | Gradient: [[-0.12083821]\n",
      " [-0.46494023]\n",
      " [ 0.07330754]]\n",
      "Iteration 335 | Cost: 0.5643620057528799 | Gradient: [[-0.12060118]\n",
      " [-0.46436374]\n",
      " [ 0.07345504]]\n",
      "Iteration 336 | Cost: 0.5641265742300704 | Gradient: [[-0.12036465]\n",
      " [-0.46378843]\n",
      " [ 0.07360221]]\n",
      "Iteration 337 | Cost: 0.5638917115407327 | Gradient: [[-0.12012861]\n",
      " [-0.4632143 ]\n",
      " [ 0.07374904]]\n",
      "Iteration 338 | Cost: 0.5636574157100545 | Gradient: [[-0.11989307]\n",
      " [-0.46264134]\n",
      " [ 0.07389553]]\n",
      "Iteration 339 | Cost: 0.5634236847710127 | Gradient: [[-0.11965801]\n",
      " [-0.46206956]\n",
      " [ 0.07404169]]\n",
      "Iteration 340 | Cost: 0.5631905167643417 | Gradient: [[-0.11942344]\n",
      " [-0.46149894]\n",
      " [ 0.07418752]]\n",
      "Iteration 341 | Cost: 0.5629579097385033 | Gradient: [[-0.11918937]\n",
      " [-0.46092949]\n",
      " [ 0.07433302]]\n",
      "Iteration 342 | Cost: 0.5627258617496544 | Gradient: [[-0.11895578]\n",
      " [-0.4603612 ]\n",
      " [ 0.07447818]]\n",
      "Iteration 343 | Cost: 0.5624943708616175 | Gradient: [[-0.11872267]\n",
      " [-0.45979408]\n",
      " [ 0.07462301]]\n",
      "Iteration 344 | Cost: 0.5622634351458493 | Gradient: [[-0.11849005]\n",
      " [-0.45922811]\n",
      " [ 0.07476752]]\n",
      "Iteration 345 | Cost: 0.5620330526814105 | Gradient: [[-0.11825792]\n",
      " [-0.4586633 ]\n",
      " [ 0.07491169]]\n",
      "Iteration 346 | Cost: 0.5618032215549353 | Gradient: [[-0.11802626]\n",
      " [-0.45809963]\n",
      " [ 0.07505553]]\n",
      "Iteration 347 | Cost: 0.5615739398606008 | Gradient: [[-0.11779509]\n",
      " [-0.45753712]\n",
      " [ 0.07519905]]\n",
      "Iteration 348 | Cost: 0.5613452057000969 | Gradient: [[-0.1175644 ]\n",
      " [-0.45697576]\n",
      " [ 0.07534224]]\n",
      "Iteration 349 | Cost: 0.5611170171825959 | Gradient: [[-0.11733419]\n",
      " [-0.45641554]\n",
      " [ 0.07548511]]\n",
      "Iteration 350 | Cost: 0.5608893724247223 | Gradient: [[-0.11710446]\n",
      " [-0.45585646]\n",
      " [ 0.07562765]]\n",
      "Iteration 351 | Cost: 0.5606622695505239 | Gradient: [[-0.1168752 ]\n",
      " [-0.45529852]\n",
      " [ 0.07576986]]\n",
      "Iteration 352 | Cost: 0.5604357066914403 | Gradient: [[-0.11664642]\n",
      " [-0.45474171]\n",
      " [ 0.07591175]]\n",
      "Iteration 353 | Cost: 0.5602096819862741 | Gradient: [[-0.11641811]\n",
      " [-0.45418604]\n",
      " [ 0.07605332]]\n",
      "Iteration 354 | Cost: 0.5599841935811611 | Gradient: [[-0.11619028]\n",
      " [-0.4536315 ]\n",
      " [ 0.07619457]]\n",
      "Iteration 355 | Cost: 0.5597592396295406 | Gradient: [[-0.11596291]\n",
      " [-0.45307808]\n",
      " [ 0.07633549]]\n",
      "Iteration 356 | Cost: 0.5595348182921255 | Gradient: [[-0.11573602]\n",
      " [-0.4525258 ]\n",
      " [ 0.07647609]]\n",
      "Iteration 357 | Cost: 0.559310927736874 | Gradient: [[-0.1155096 ]\n",
      " [-0.45197463]\n",
      " [ 0.07661638]]\n",
      "Iteration 358 | Cost: 0.5590875661389592 | Gradient: [[-0.11528365]\n",
      " [-0.45142458]\n",
      " [ 0.07675634]]\n",
      "Iteration 359 | Cost: 0.5588647316807398 | Gradient: [[-0.11505817]\n",
      " [-0.45087565]\n",
      " [ 0.07689599]]\n",
      "Iteration 360 | Cost: 0.5586424225517326 | Gradient: [[-0.11483315]\n",
      " [-0.45032784]\n",
      " [ 0.07703531]]\n",
      "Iteration 361 | Cost: 0.5584206369485812 | Gradient: [[-0.1146086 ]\n",
      " [-0.44978113]\n",
      " [ 0.07717432]]\n",
      "Iteration 362 | Cost: 0.5581993730750294 | Gradient: [[-0.11438451]\n",
      " [-0.44923554]\n",
      " [ 0.07731302]]\n",
      "Iteration 363 | Cost: 0.5579786291418902 | Gradient: [[-0.11416088]\n",
      " [-0.44869105]\n",
      " [ 0.0774514 ]]\n",
      "Iteration 364 | Cost: 0.5577584033670191 | Gradient: [[-0.11393772]\n",
      " [-0.44814767]\n",
      " [ 0.07758946]]\n",
      "Iteration 365 | Cost: 0.5575386939752839 | Gradient: [[-0.11371502]\n",
      " [-0.44760538]\n",
      " [ 0.07772722]]\n",
      "Iteration 366 | Cost: 0.5573194991985372 | Gradient: [[-0.11349277]\n",
      " [-0.4470642 ]\n",
      " [ 0.07786465]]\n",
      "Iteration 367 | Cost: 0.5571008172755875 | Gradient: [[-0.11327099]\n",
      " [-0.44652411]\n",
      " [ 0.07800178]]\n",
      "Iteration 368 | Cost: 0.556882646452171 | Gradient: [[-0.11304966]\n",
      " [-0.44598511]\n",
      " [ 0.07813859]]\n",
      "Iteration 369 | Cost: 0.5566649849809233 | Gradient: [[-0.11282879]\n",
      " [-0.4454472 ]\n",
      " [ 0.0782751 ]]\n",
      "Iteration 370 | Cost: 0.5564478311213518 | Gradient: [[-0.11260838]\n",
      " [-0.44491039]\n",
      " [ 0.07841129]]\n",
      "Iteration 371 | Cost: 0.5562311831398066 | Gradient: [[-0.11238842]\n",
      " [-0.44437465]\n",
      " [ 0.07854717]]\n",
      "Iteration 372 | Cost: 0.5560150393094538 | Gradient: [[-0.11216891]\n",
      " [-0.44384   ]\n",
      " [ 0.07868275]]\n",
      "Iteration 373 | Cost: 0.5557993979102471 | Gradient: [[-0.11194985]\n",
      " [-0.44330643]\n",
      " [ 0.07881801]]\n",
      "Iteration 374 | Cost: 0.5555842572288996 | Gradient: [[-0.11173125]\n",
      " [-0.44277394]\n",
      " [ 0.07895297]]\n",
      "Iteration 375 | Cost: 0.5553696155588571 | Gradient: [[-0.11151309]\n",
      " [-0.44224252]\n",
      " [ 0.07908763]]\n",
      "Iteration 376 | Cost: 0.5551554712002701 | Gradient: [[-0.11129539]\n",
      " [-0.44171217]\n",
      " [ 0.07922197]]\n",
      "Iteration 377 | Cost: 0.5549418224599663 | Gradient: [[-0.11107813]\n",
      " [-0.4411829 ]\n",
      " [ 0.07935602]]\n",
      "Iteration 378 | Cost: 0.5547286676514233 | Gradient: [[-0.11086132]\n",
      " [-0.44065468]\n",
      " [ 0.07948976]]\n",
      "Iteration 379 | Cost: 0.5545160050947415 | Gradient: [[-0.11064495]\n",
      " [-0.44012754]\n",
      " [ 0.07962319]]\n",
      "Iteration 380 | Cost: 0.5543038331166172 | Gradient: [[-0.11042902]\n",
      " [-0.43960146]\n",
      " [ 0.07975632]]\n",
      "Iteration 381 | Cost: 0.554092150050315 | Gradient: [[-0.11021354]\n",
      " [-0.43907643]\n",
      " [ 0.07988915]]\n",
      "Iteration 382 | Cost: 0.5538809542356408 | Gradient: [[-0.10999851]\n",
      " [-0.43855246]\n",
      " [ 0.08002168]]\n",
      "Iteration 383 | Cost: 0.5536702440189157 | Gradient: [[-0.10978391]\n",
      " [-0.43802955]\n",
      " [ 0.08015391]]\n",
      "Iteration 384 | Cost: 0.5534600177529492 | Gradient: [[-0.10956975]\n",
      " [-0.43750769]\n",
      " [ 0.08028584]]\n",
      "Iteration 385 | Cost: 0.553250273797011 | Gradient: [[-0.10935603]\n",
      " [-0.43698687]\n",
      " [ 0.08041747]]\n",
      "Iteration 386 | Cost: 0.553041010516807 | Gradient: [[-0.10914275]\n",
      " [-0.43646711]\n",
      " [ 0.0805488 ]]\n",
      "Iteration 387 | Cost: 0.5528322262844505 | Gradient: [[-0.10892991]\n",
      " [-0.43594838]\n",
      " [ 0.08067983]]\n",
      "Iteration 388 | Cost: 0.552623919478437 | Gradient: [[-0.1087175 ]\n",
      " [-0.4354307 ]\n",
      " [ 0.08081057]]\n",
      "Iteration 389 | Cost: 0.5524160884836183 | Gradient: [[-0.10850553]\n",
      " [-0.43491406]\n",
      " [ 0.08094101]]\n",
      "Iteration 390 | Cost: 0.5522087316911751 | Gradient: [[-0.10829399]\n",
      " [-0.43439845]\n",
      " [ 0.08107115]]\n",
      "Iteration 391 | Cost: 0.5520018474985918 | Gradient: [[-0.10808288]\n",
      " [-0.43388388]\n",
      " [ 0.081201  ]]\n",
      "Iteration 392 | Cost: 0.5517954343096307 | Gradient: [[-0.1078722 ]\n",
      " [-0.43337034]\n",
      " [ 0.08133056]]\n",
      "Iteration 393 | Cost: 0.5515894905343055 | Gradient: [[-0.10766196]\n",
      " [-0.43285783]\n",
      " [ 0.08145982]]\n",
      "Iteration 394 | Cost: 0.5513840145888556 | Gradient: [[-0.10745214]\n",
      " [-0.43234634]\n",
      " [ 0.08158879]]\n",
      "Iteration 395 | Cost: 0.5511790048957207 | Gradient: [[-0.10724275]\n",
      " [-0.43183588]\n",
      " [ 0.08171747]]\n",
      "Iteration 396 | Cost: 0.5509744598835157 | Gradient: [[-0.10703379]\n",
      " [-0.43132644]\n",
      " [ 0.08184585]]\n",
      "Iteration 397 | Cost: 0.5507703779870037 | Gradient: [[-0.10682525]\n",
      " [-0.43081802]\n",
      " [ 0.08197395]]\n",
      "Iteration 398 | Cost: 0.5505667576470721 | Gradient: [[-0.10661714]\n",
      " [-0.43031061]\n",
      " [ 0.08210175]]\n",
      "Iteration 399 | Cost: 0.5503635973107068 | Gradient: [[-0.10640946]\n",
      " [-0.42980422]\n",
      " [ 0.08222927]]\n",
      "Iteration 400 | Cost: 0.5501608954309666 | Gradient: [[-0.10620219]\n",
      " [-0.42929884]\n",
      " [ 0.0823565 ]]\n",
      "Iteration 401 | Cost: 0.5499586504669581 | Gradient: [[-0.10599535]\n",
      " [-0.42879447]\n",
      " [ 0.08248344]]\n",
      "Iteration 402 | Cost: 0.5497568608838121 | Gradient: [[-0.10578893]\n",
      " [-0.42829111]\n",
      " [ 0.08261009]]\n",
      "Iteration 403 | Cost: 0.5495555251526565 | Gradient: [[-0.10558293]\n",
      " [-0.42778875]\n",
      " [ 0.08273646]]\n",
      "Iteration 404 | Cost: 0.549354641750593 | Gradient: [[-0.10537735]\n",
      " [-0.42728739]\n",
      " [ 0.08286254]]\n",
      "Iteration 405 | Cost: 0.5491542091606718 | Gradient: [[-0.10517218]\n",
      " [-0.42678703]\n",
      " [ 0.08298833]]\n",
      "Iteration 406 | Cost: 0.5489542258718673 | Gradient: [[-0.10496743]\n",
      " [-0.42628767]\n",
      " [ 0.08311385]]\n",
      "Iteration 407 | Cost: 0.5487546903790528 | Gradient: [[-0.1047631 ]\n",
      " [-0.4257893 ]\n",
      " [ 0.08323907]]\n",
      "Iteration 408 | Cost: 0.5485556011829773 | Gradient: [[-0.10455918]\n",
      " [-0.42529192]\n",
      " [ 0.08336402]]\n",
      "Iteration 409 | Cost: 0.5483569567902398 | Gradient: [[-0.10435568]\n",
      " [-0.42479554]\n",
      " [ 0.08348868]]\n",
      "Iteration 410 | Cost: 0.5481587557132657 | Gradient: [[-0.10415259]\n",
      " [-0.42430014]\n",
      " [ 0.08361306]]\n",
      "Iteration 411 | Cost: 0.5479609964702832 | Gradient: [[-0.10394991]\n",
      " [-0.42380572]\n",
      " [ 0.08373716]]\n",
      "Iteration 412 | Cost: 0.5477636775852979 | Gradient: [[-0.10374764]\n",
      " [-0.42331229]\n",
      " [ 0.08386098]]\n",
      "Iteration 413 | Cost: 0.5475667975880699 | Gradient: [[-0.10354578]\n",
      " [-0.42281984]\n",
      " [ 0.08398452]]\n",
      "Iteration 414 | Cost: 0.5473703550140894 | Gradient: [[-0.10334433]\n",
      " [-0.42232836]\n",
      " [ 0.08410779]]\n",
      "Iteration 415 | Cost: 0.5471743484045529 | Gradient: [[-0.10314328]\n",
      " [-0.42183786]\n",
      " [ 0.08423077]]\n",
      "Iteration 416 | Cost: 0.5469787763063402 | Gradient: [[-0.10294265]\n",
      " [-0.42134833]\n",
      " [ 0.08435347]]\n",
      "Iteration 417 | Cost: 0.5467836372719894 | Gradient: [[-0.10274241]\n",
      " [-0.42085978]\n",
      " [ 0.0844759 ]]\n",
      "Iteration 418 | Cost: 0.5465889298596748 | Gradient: [[-0.10254259]\n",
      " [-0.42037219]\n",
      " [ 0.08459806]]\n",
      "Iteration 419 | Cost: 0.5463946526331827 | Gradient: [[-0.10234316]\n",
      " [-0.41988556]\n",
      " [ 0.08471993]]\n",
      "Iteration 420 | Cost: 0.5462008041618879 | Gradient: [[-0.10214414]\n",
      " [-0.4193999 ]\n",
      " [ 0.08484154]]\n",
      "Iteration 421 | Cost: 0.5460073830207312 | Gradient: [[-0.10194552]\n",
      " [-0.4189152 ]\n",
      " [ 0.08496287]]\n",
      "Iteration 422 | Cost: 0.5458143877901958 | Gradient: [[-0.1017473 ]\n",
      " [-0.41843146]\n",
      " [ 0.08508392]]\n",
      "Iteration 423 | Cost: 0.5456218170562838 | Gradient: [[-0.10154948]\n",
      " [-0.41794868]\n",
      " [ 0.0852047 ]]\n",
      "Iteration 424 | Cost: 0.5454296694104943 | Gradient: [[-0.10135206]\n",
      " [-0.41746685]\n",
      " [ 0.08532521]]\n",
      "Iteration 425 | Cost: 0.5452379434497993 | Gradient: [[-0.10115504]\n",
      " [-0.41698597]\n",
      " [ 0.08544545]]\n",
      "Iteration 426 | Cost: 0.5450466377766218 | Gradient: [[-0.10095841]\n",
      " [-0.41650604]\n",
      " [ 0.08556542]]\n",
      "Iteration 427 | Cost: 0.5448557509988129 | Gradient: [[-0.10076218]\n",
      " [-0.41602706]\n",
      " [ 0.08568512]]\n",
      "Iteration 428 | Cost: 0.5446652817296288 | Gradient: [[-0.10056635]\n",
      " [-0.41554902]\n",
      " [ 0.08580455]]\n",
      "Iteration 429 | Cost: 0.5444752285877087 | Gradient: [[-0.1003709 ]\n",
      " [-0.41507192]\n",
      " [ 0.08592371]]\n",
      "Iteration 430 | Cost: 0.5442855901970521 | Gradient: [[-0.10017585]\n",
      " [-0.41459577]\n",
      " [ 0.0860426 ]]\n",
      "Iteration 431 | Cost: 0.5440963651869968 | Gradient: [[-0.09998119]\n",
      " [-0.41412055]\n",
      " [ 0.08616122]]\n",
      "Iteration 432 | Cost: 0.5439075521921961 | Gradient: [[-0.09978693]\n",
      " [-0.41364626]\n",
      " [ 0.08627958]]\n",
      "Iteration 433 | Cost: 0.5437191498525971 | Gradient: [[-0.09959305]\n",
      " [-0.41317292]\n",
      " [ 0.08639767]]\n",
      "Iteration 434 | Cost: 0.5435311568134187 | Gradient: [[-0.09939956]\n",
      " [-0.4127005 ]\n",
      " [ 0.08651549]]\n",
      "Iteration 435 | Cost: 0.5433435717251287 | Gradient: [[-0.09920646]\n",
      " [-0.41222901]\n",
      " [ 0.08663305]]\n",
      "Iteration 436 | Cost: 0.5431563932434234 | Gradient: [[-0.09901374]\n",
      " [-0.41175844]\n",
      " [ 0.08675035]]\n",
      "Iteration 437 | Cost: 0.5429696200292043 | Gradient: [[-0.09882141]\n",
      " [-0.4112888 ]\n",
      " [ 0.08686738]]\n",
      "Iteration 438 | Cost: 0.5427832507485573 | Gradient: [[-0.09862947]\n",
      " [-0.41082008]\n",
      " [ 0.08698415]]\n",
      "Iteration 439 | Cost: 0.5425972840727307 | Gradient: [[-0.09843791]\n",
      " [-0.41035229]\n",
      " [ 0.08710066]]\n",
      "Iteration 440 | Cost: 0.5424117186781138 | Gradient: [[-0.09824673]\n",
      " [-0.4098854 ]\n",
      " [ 0.0872169 ]]\n",
      "Iteration 441 | Cost: 0.5422265532462152 | Gradient: [[-0.09805594]\n",
      " [-0.40941944]\n",
      " [ 0.08733288]]\n",
      "Iteration 442 | Cost: 0.5420417864636418 | Gradient: [[-0.09786553]\n",
      " [-0.40895438]\n",
      " [ 0.08744861]]\n",
      "Iteration 443 | Cost: 0.541857417022077 | Gradient: [[-0.09767549]\n",
      " [-0.40849024]\n",
      " [ 0.08756407]]\n",
      "Iteration 444 | Cost: 0.5416734436182602 | Gradient: [[-0.09748584]\n",
      " [-0.40802701]\n",
      " [ 0.08767927]]\n",
      "Iteration 445 | Cost: 0.5414898649539646 | Gradient: [[-0.09729656]\n",
      " [-0.40756468]\n",
      " [ 0.08779422]]\n",
      "Iteration 446 | Cost: 0.5413066797359773 | Gradient: [[-0.09710767]\n",
      " [-0.40710325]\n",
      " [ 0.08790891]]\n",
      "Iteration 447 | Cost: 0.5411238866760779 | Gradient: [[-0.09691914]\n",
      " [-0.40664273]\n",
      " [ 0.08802334]]\n",
      "Iteration 448 | Cost: 0.5409414844910172 | Gradient: [[-0.096731  ]\n",
      " [-0.40618311]\n",
      " [ 0.08813751]]\n",
      "Iteration 449 | Cost: 0.5407594719024972 | Gradient: [[-0.09654323]\n",
      " [-0.40572438]\n",
      " [ 0.08825143]]\n",
      "Iteration 450 | Cost: 0.5405778476371494 | Gradient: [[-0.09635583]\n",
      " [-0.40526655]\n",
      " [ 0.08836509]]\n",
      "Iteration 451 | Cost: 0.540396610426516 | Gradient: [[-0.0961688 ]\n",
      " [-0.40480961]\n",
      " [ 0.0884785 ]]\n",
      "Iteration 452 | Cost: 0.5402157590070268 | Gradient: [[-0.09598215]\n",
      " [-0.40435356]\n",
      " [ 0.08859165]]\n",
      "Iteration 453 | Cost: 0.5400352921199808 | Gradient: [[-0.09579587]\n",
      " [-0.4038984 ]\n",
      " [ 0.08870455]]\n",
      "Iteration 454 | Cost: 0.5398552085115254 | Gradient: [[-0.09560996]\n",
      " [-0.40344413]\n",
      " [ 0.08881719]]\n",
      "Iteration 455 | Cost: 0.5396755069326351 | Gradient: [[-0.09542441]\n",
      " [-0.40299074]\n",
      " [ 0.08892959]]\n",
      "Iteration 456 | Cost: 0.5394961861390932 | Gradient: [[-0.09523924]\n",
      " [-0.40253824]\n",
      " [ 0.08904173]]\n",
      "Iteration 457 | Cost: 0.5393172448914693 | Gradient: [[-0.09505443]\n",
      " [-0.40208661]\n",
      " [ 0.08915362]]\n",
      "Iteration 458 | Cost: 0.5391386819551015 | Gradient: [[-0.09486999]\n",
      " [-0.40163586]\n",
      " [ 0.08926526]]\n",
      "Iteration 459 | Cost: 0.5389604961000753 | Gradient: [[-0.09468591]\n",
      " [-0.40118599]\n",
      " [ 0.08937665]]\n",
      "Iteration 460 | Cost: 0.5387826861012038 | Gradient: [[-0.0945022 ]\n",
      " [-0.40073699]\n",
      " [ 0.08948779]]\n",
      "Iteration 461 | Cost: 0.5386052507380079 | Gradient: [[-0.09431886]\n",
      " [-0.40028886]\n",
      " [ 0.08959868]]\n",
      "Iteration 462 | Cost: 0.5384281887946972 | Gradient: [[-0.09413587]\n",
      " [-0.3998416 ]\n",
      " [ 0.08970933]]\n",
      "Iteration 463 | Cost: 0.5382514990601496 | Gradient: [[-0.09395325]\n",
      " [-0.39939521]\n",
      " [ 0.08981973]]\n",
      "Iteration 464 | Cost: 0.5380751803278923 | Gradient: [[-0.09377099]\n",
      " [-0.39894968]\n",
      " [ 0.08992988]]\n",
      "Iteration 465 | Cost: 0.5378992313960819 | Gradient: [[-0.09358908]\n",
      " [-0.39850502]\n",
      " [ 0.09003978]]\n",
      "Iteration 466 | Cost: 0.5377236510674854 | Gradient: [[-0.09340754]\n",
      " [-0.39806121]\n",
      " [ 0.09014944]]\n",
      "Iteration 467 | Cost: 0.5375484381494608 | Gradient: [[-0.09322636]\n",
      " [-0.39761827]\n",
      " [ 0.09025885]]\n",
      "Iteration 468 | Cost: 0.5373735914539378 | Gradient: [[-0.09304553]\n",
      " [-0.39717618]\n",
      " [ 0.09036802]]\n",
      "Iteration 469 | Cost: 0.5371991097973989 | Gradient: [[-0.09286506]\n",
      " [-0.39673494]\n",
      " [ 0.09047694]]\n",
      "Iteration 470 | Cost: 0.5370249920008598 | Gradient: [[-0.09268494]\n",
      " [-0.39629456]\n",
      " [ 0.09058562]]\n",
      "Iteration 471 | Cost: 0.5368512368898509 | Gradient: [[-0.09250518]\n",
      " [-0.39585503]\n",
      " [ 0.09069406]]\n",
      "Iteration 472 | Cost: 0.5366778432943987 | Gradient: [[-0.09232578]\n",
      " [-0.39541634]\n",
      " [ 0.09080226]]\n",
      "Iteration 473 | Cost: 0.536504810049006 | Gradient: [[-0.09214672]\n",
      " [-0.3949785 ]\n",
      " [ 0.09091021]]\n",
      "Iteration 474 | Cost: 0.5363321359926337 | Gradient: [[-0.09196802]\n",
      " [-0.39454151]\n",
      " [ 0.09101793]]\n",
      "Iteration 475 | Cost: 0.5361598199686828 | Gradient: [[-0.09178967]\n",
      " [-0.39410536]\n",
      " [ 0.0911254 ]]\n",
      "Iteration 476 | Cost: 0.5359878608249746 | Gradient: [[-0.09161167]\n",
      " [-0.39367005]\n",
      " [ 0.09123263]]\n",
      "Iteration 477 | Cost: 0.5358162574137328 | Gradient: [[-0.09143402]\n",
      " [-0.39323557]\n",
      " [ 0.09133963]]\n",
      "Iteration 478 | Cost: 0.5356450085915655 | Gradient: [[-0.09125672]\n",
      " [-0.39280193]\n",
      " [ 0.09144638]]\n",
      "Iteration 479 | Cost: 0.5354741132194456 | Gradient: [[-0.09107977]\n",
      " [-0.39236913]\n",
      " [ 0.0915529 ]]\n",
      "Iteration 480 | Cost: 0.5353035701626939 | Gradient: [[-0.09090316]\n",
      " [-0.39193715]\n",
      " [ 0.09165918]]\n",
      "Iteration 481 | Cost: 0.5351333782909604 | Gradient: [[-0.0907269 ]\n",
      " [-0.39150601]\n",
      " [ 0.09176522]]\n",
      "Iteration 482 | Cost: 0.5349635364782057 | Gradient: [[-0.09055098]\n",
      " [-0.39107569]\n",
      " [ 0.09187103]]\n",
      "Iteration 483 | Cost: 0.5347940436026832 | Gradient: [[-0.09037541]\n",
      " [-0.3906462 ]\n",
      " [ 0.0919766 ]]\n",
      "Iteration 484 | Cost: 0.534624898546922 | Gradient: [[-0.09020018]\n",
      " [-0.39021754]\n",
      " [ 0.09208194]]\n",
      "Iteration 485 | Cost: 0.5344561001977074 | Gradient: [[-0.0900253 ]\n",
      " [-0.38978969]\n",
      " [ 0.09218704]]\n",
      "Iteration 486 | Cost: 0.5342876474460647 | Gradient: [[-0.08985076]\n",
      " [-0.38936267]\n",
      " [ 0.0922919 ]]\n",
      "Iteration 487 | Cost: 0.5341195391872403 | Gradient: [[-0.08967655]\n",
      " [-0.38893646]\n",
      " [ 0.09239654]]\n",
      "Iteration 488 | Cost: 0.5339517743206843 | Gradient: [[-0.08950269]\n",
      " [-0.38851107]\n",
      " [ 0.09250094]]\n",
      "Iteration 489 | Cost: 0.5337843517500336 | Gradient: [[-0.08932917]\n",
      " [-0.38808649]\n",
      " [ 0.09260511]]\n",
      "Iteration 490 | Cost: 0.5336172703830933 | Gradient: [[-0.08915598]\n",
      " [-0.38766272]\n",
      " [ 0.09270904]]\n",
      "Iteration 491 | Cost: 0.53345052913182 | Gradient: [[-0.08898314]\n",
      " [-0.38723976]\n",
      " [ 0.09281275]]\n",
      "Iteration 492 | Cost: 0.5332841269123044 | Gradient: [[-0.08881063]\n",
      " [-0.38681761]\n",
      " [ 0.09291622]]\n",
      "Iteration 493 | Cost: 0.533118062644753 | Gradient: [[-0.08863845]\n",
      " [-0.38639627]\n",
      " [ 0.09301947]]\n",
      "Iteration 494 | Cost: 0.532952335253473 | Gradient: [[-0.08846661]\n",
      " [-0.38597573]\n",
      " [ 0.09312248]]\n",
      "Iteration 495 | Cost: 0.5327869436668528 | Gradient: [[-0.08829511]\n",
      " [-0.38555599]\n",
      " [ 0.09322527]]\n",
      "Iteration 496 | Cost: 0.532621886817346 | Gradient: [[-0.08812394]\n",
      " [-0.38513705]\n",
      " [ 0.09332783]]\n",
      "Iteration 497 | Cost: 0.5324571636414549 | Gradient: [[-0.0879531 ]\n",
      " [-0.38471891]\n",
      " [ 0.09343016]]\n",
      "Iteration 498 | Cost: 0.5322927730797128 | Gradient: [[-0.08778259]\n",
      " [-0.38430156]\n",
      " [ 0.09353226]]\n",
      "Iteration 499 | Cost: 0.532128714076667 | Gradient: [[-0.08761242]\n",
      " [-0.38388501]\n",
      " [ 0.09363414]]\n",
      "Iteration 500 | Cost: 0.5319649855808627 | Gradient: [[-0.08744257]\n",
      " [-0.38346925]\n",
      " [ 0.09373579]]\n",
      "Iteration 501 | Cost: 0.5318015865448259 | Gradient: [[-0.08727306]\n",
      " [-0.38305428]\n",
      " [ 0.09383721]]\n",
      "Iteration 502 | Cost: 0.5316385159250467 | Gradient: [[-0.08710387]\n",
      " [-0.3826401 ]\n",
      " [ 0.09393841]]\n",
      "Iteration 503 | Cost: 0.531475772681963 | Gradient: [[-0.08693501]\n",
      " [-0.3822267 ]\n",
      " [ 0.09403938]]\n",
      "Iteration 504 | Cost: 0.5313133557799433 | Gradient: [[-0.08676648]\n",
      " [-0.38181409]\n",
      " [ 0.09414013]]\n",
      "Iteration 505 | Cost: 0.5311512641872714 | Gradient: [[-0.08659827]\n",
      " [-0.38140226]\n",
      " [ 0.09424066]]\n",
      "Iteration 506 | Cost: 0.5309894968761292 | Gradient: [[-0.08643039]\n",
      " [-0.38099122]\n",
      " [ 0.09434096]]\n",
      "Iteration 507 | Cost: 0.5308280528225803 | Gradient: [[-0.08626283]\n",
      " [-0.38058095]\n",
      " [ 0.09444104]]\n",
      "Iteration 508 | Cost: 0.5306669310065543 | Gradient: [[-0.0860956 ]\n",
      " [-0.38017145]\n",
      " [ 0.0945409 ]]\n",
      "Iteration 509 | Cost: 0.5305061304118306 | Gradient: [[-0.08592869]\n",
      " [-0.37976274]\n",
      " [ 0.09464054]]\n",
      "Iteration 510 | Cost: 0.5303456500260217 | Gradient: [[-0.0857621 ]\n",
      " [-0.37935479]\n",
      " [ 0.09473996]]\n",
      "Iteration 511 | Cost: 0.5301854888405583 | Gradient: [[-0.08559583]\n",
      " [-0.37894762]\n",
      " [ 0.09483916]]\n",
      "Iteration 512 | Cost: 0.5300256458506718 | Gradient: [[-0.08542989]\n",
      " [-0.37854121]\n",
      " [ 0.09493813]]\n",
      "Iteration 513 | Cost: 0.52986612005538 | Gradient: [[-0.08526426]\n",
      " [-0.37813558]\n",
      " [ 0.09503689]]\n",
      "Iteration 514 | Cost: 0.5297069104574702 | Gradient: [[-0.08509895]\n",
      " [-0.3777307 ]\n",
      " [ 0.09513543]]\n",
      "Iteration 515 | Cost: 0.529548016063484 | Gradient: [[-0.08493397]\n",
      " [-0.3773266 ]\n",
      " [ 0.09523375]]\n",
      "Iteration 516 | Cost: 0.5293894358837011 | Gradient: [[-0.08476929]\n",
      " [-0.37692325]\n",
      " [ 0.09533186]]\n",
      "Iteration 517 | Cost: 0.5292311689321247 | Gradient: [[-0.08460494]\n",
      " [-0.37652066]\n",
      " [ 0.09542974]]\n",
      "Iteration 518 | Cost: 0.5290732142264646 | Gradient: [[-0.0844409 ]\n",
      " [-0.37611883]\n",
      " [ 0.09552741]]\n",
      "Iteration 519 | Cost: 0.5289155707881227 | Gradient: [[-0.08427718]\n",
      " [-0.37571776]\n",
      " [ 0.09562487]]\n",
      "Iteration 520 | Cost: 0.5287582376421774 | Gradient: [[-0.08411377]\n",
      " [-0.37531744]\n",
      " [ 0.0957221 ]]\n",
      "Iteration 521 | Cost: 0.5286012138173678 | Gradient: [[-0.08395067]\n",
      " [-0.37491788]\n",
      " [ 0.09581913]]\n",
      "Iteration 522 | Cost: 0.5284444983460795 | Gradient: [[-0.08378789]\n",
      " [-0.37451906]\n",
      " [ 0.09591594]]\n",
      "Iteration 523 | Cost: 0.5282880902643278 | Gradient: [[-0.08362542]\n",
      " [-0.374121  ]\n",
      " [ 0.09601253]]\n",
      "Iteration 524 | Cost: 0.528131988611744 | Gradient: [[-0.08346326]\n",
      " [-0.37372368]\n",
      " [ 0.09610891]]\n",
      "Iteration 525 | Cost: 0.5279761924315596 | Gradient: [[-0.08330141]\n",
      " [-0.3733271 ]\n",
      " [ 0.09620508]]\n",
      "Iteration 526 | Cost: 0.5278207007705911 | Gradient: [[-0.08313987]\n",
      " [-0.37293127]\n",
      " [ 0.09630104]]\n",
      "Iteration 527 | Cost: 0.5276655126792259 | Gradient: [[-0.08297864]\n",
      " [-0.37253618]\n",
      " [ 0.09639678]]\n",
      "Iteration 528 | Cost: 0.5275106272114066 | Gradient: [[-0.08281771]\n",
      " [-0.37214183]\n",
      " [ 0.09649232]]\n",
      "Iteration 529 | Cost: 0.5273560434246164 | Gradient: [[-0.0826571 ]\n",
      " [-0.37174822]\n",
      " [ 0.09658764]]\n",
      "Iteration 530 | Cost: 0.5272017603798644 | Gradient: [[-0.08249679]\n",
      " [-0.37135535]\n",
      " [ 0.09668275]]\n",
      "Iteration 531 | Cost: 0.5270477771416715 | Gradient: [[-0.08233679]\n",
      " [-0.37096321]\n",
      " [ 0.09677765]]\n",
      "Iteration 532 | Cost: 0.5268940927780541 | Gradient: [[-0.08217709]\n",
      " [-0.3705718 ]\n",
      " [ 0.09687234]]\n",
      "Iteration 533 | Cost: 0.5267407063605115 | Gradient: [[-0.0820177 ]\n",
      " [-0.37018112]\n",
      " [ 0.09696683]]\n",
      "Iteration 534 | Cost: 0.5265876169640099 | Gradient: [[-0.08185861]\n",
      " [-0.36979118]\n",
      " [ 0.0970611 ]]\n",
      "Iteration 535 | Cost: 0.5264348236669691 | Gradient: [[-0.08169982]\n",
      " [-0.36940196]\n",
      " [ 0.09715517]]\n",
      "Iteration 536 | Cost: 0.5262823255512473 | Gradient: [[-0.08154134]\n",
      " [-0.36901346]\n",
      " [ 0.09724903]]\n",
      "Iteration 537 | Cost: 0.5261301217021271 | Gradient: [[-0.08138315]\n",
      " [-0.36862569]\n",
      " [ 0.09734268]]\n",
      "Iteration 538 | Cost: 0.525978211208301 | Gradient: [[-0.08122527]\n",
      " [-0.36823864]\n",
      " [ 0.09743613]]\n",
      "Iteration 539 | Cost: 0.5258265931618576 | Gradient: [[-0.08106769]\n",
      " [-0.36785231]\n",
      " [ 0.09752937]]\n",
      "Iteration 540 | Cost: 0.5256752666582677 | Gradient: [[-0.08091041]\n",
      " [-0.3674667 ]\n",
      " [ 0.09762241]]\n",
      "Iteration 541 | Cost: 0.5255242307963688 | Gradient: [[-0.08075342]\n",
      " [-0.36708181]\n",
      " [ 0.09771524]]\n",
      "Iteration 542 | Cost: 0.5253734846783532 | Gradient: [[-0.08059674]\n",
      " [-0.36669763]\n",
      " [ 0.09780786]]\n",
      "Iteration 543 | Cost: 0.525223027409752 | Gradient: [[-0.08044035]\n",
      " [-0.36631417]\n",
      " [ 0.09790029]]\n",
      "Iteration 544 | Cost: 0.5250728580994231 | Gradient: [[-0.08028426]\n",
      " [-0.36593141]\n",
      " [ 0.09799251]]\n",
      "Iteration 545 | Cost: 0.5249229758595356 | Gradient: [[-0.08012846]\n",
      " [-0.36554937]\n",
      " [ 0.09808452]]\n",
      "Iteration 546 | Cost: 0.5247733798055572 | Gradient: [[-0.07997296]\n",
      " [-0.36516804]\n",
      " [ 0.09817634]]\n",
      "Iteration 547 | Cost: 0.5246240690562404 | Gradient: [[-0.07981775]\n",
      " [-0.36478741]\n",
      " [ 0.09826795]]\n",
      "Iteration 548 | Cost: 0.5244750427336081 | Gradient: [[-0.07966283]\n",
      " [-0.36440749]\n",
      " [ 0.09835936]]\n",
      "Iteration 549 | Cost: 0.524326299962941 | Gradient: [[-0.07950821]\n",
      " [-0.36402827]\n",
      " [ 0.09845057]]\n",
      "Iteration 550 | Cost: 0.5241778398727633 | Gradient: [[-0.07935388]\n",
      " [-0.36364975]\n",
      " [ 0.09854158]]\n",
      "Iteration 551 | Cost: 0.5240296615948298 | Gradient: [[-0.07919984]\n",
      " [-0.36327193]\n",
      " [ 0.09863239]]\n",
      "Iteration 552 | Cost: 0.5238817642641118 | Gradient: [[-0.0790461 ]\n",
      " [-0.36289481]\n",
      " [ 0.09872299]]\n",
      "Iteration 553 | Cost: 0.5237341470187844 | Gradient: [[-0.07889264]\n",
      " [-0.36251838]\n",
      " [ 0.09881341]]\n",
      "Iteration 554 | Cost: 0.523586809000213 | Gradient: [[-0.07873947]\n",
      " [-0.36214265]\n",
      " [ 0.09890362]]\n",
      "Iteration 555 | Cost: 0.5234397493529402 | Gradient: [[-0.07858659]\n",
      " [-0.36176762]\n",
      " [ 0.09899363]]\n",
      "Iteration 556 | Cost: 0.5232929672246718 | Gradient: [[-0.078434  ]\n",
      " [-0.36139327]\n",
      " [ 0.09908345]]\n",
      "Iteration 557 | Cost: 0.5231464617662648 | Gradient: [[-0.07828169]\n",
      " [-0.36101961]\n",
      " [ 0.09917307]]\n",
      "Iteration 558 | Cost: 0.5230002321317139 | Gradient: [[-0.07812967]\n",
      " [-0.36064665]\n",
      " [ 0.09926249]]\n",
      "Iteration 559 | Cost: 0.5228542774781382 | Gradient: [[-0.07797794]\n",
      " [-0.36027436]\n",
      " [ 0.09935171]]\n",
      "Iteration 560 | Cost: 0.5227085969657688 | Gradient: [[-0.07782649]\n",
      " [-0.35990277]\n",
      " [ 0.09944074]]\n",
      "Iteration 561 | Cost: 0.5225631897579351 | Gradient: [[-0.07767533]\n",
      " [-0.35953185]\n",
      " [ 0.09952958]]\n",
      "Iteration 562 | Cost: 0.5224180550210531 | Gradient: [[-0.07752445]\n",
      " [-0.35916162]\n",
      " [ 0.09961822]]\n",
      "Iteration 563 | Cost: 0.5222731919246114 | Gradient: [[-0.07737385]\n",
      " [-0.35879207]\n",
      " [ 0.09970667]]\n",
      "Iteration 564 | Cost: 0.5221285996411592 | Gradient: [[-0.07722354]\n",
      " [-0.35842319]\n",
      " [ 0.09979492]]\n",
      "Iteration 565 | Cost: 0.5219842773462937 | Gradient: [[-0.0770735 ]\n",
      " [-0.358055  ]\n",
      " [ 0.09988298]]\n",
      "Iteration 566 | Cost: 0.5218402242186473 | Gradient: [[-0.07692375]\n",
      " [-0.35768747]\n",
      " [ 0.09997084]]\n",
      "Iteration 567 | Cost: 0.5216964394398745 | Gradient: [[-0.07677428]\n",
      " [-0.35732062]\n",
      " [ 0.10005852]]\n",
      "Iteration 568 | Cost: 0.5215529221946404 | Gradient: [[-0.07662509]\n",
      " [-0.35695444]\n",
      " [ 0.100146  ]]\n",
      "Iteration 569 | Cost: 0.5214096716706074 | Gradient: [[-0.07647617]\n",
      " [-0.35658894]\n",
      " [ 0.10023329]]\n",
      "Iteration 570 | Cost: 0.5212666870584235 | Gradient: [[-0.07632754]\n",
      " [-0.3562241 ]\n",
      " [ 0.10032039]]\n",
      "Iteration 571 | Cost: 0.5211239675517093 | Gradient: [[-0.07617918]\n",
      " [-0.35585992]\n",
      " [ 0.10040729]]\n",
      "Iteration 572 | Cost: 0.5209815123470458 | Gradient: [[-0.0760311 ]\n",
      " [-0.35549642]\n",
      " [ 0.10049401]]\n",
      "Iteration 573 | Cost: 0.5208393206439631 | Gradient: [[-0.07588329]\n",
      " [-0.35513357]\n",
      " [ 0.10058054]]\n",
      "Iteration 574 | Cost: 0.5206973916449269 | Gradient: [[-0.07573576]\n",
      " [-0.35477139]\n",
      " [ 0.10066688]]\n",
      "Iteration 575 | Cost: 0.5205557245553273 | Gradient: [[-0.07558851]\n",
      " [-0.35440987]\n",
      " [ 0.10075303]]\n",
      "Iteration 576 | Cost: 0.5204143185834661 | Gradient: [[-0.07544153]\n",
      " [-0.35404901]\n",
      " [ 0.10083899]]\n",
      "Iteration 577 | Cost: 0.520273172940545 | Gradient: [[-0.07529482]\n",
      " [-0.3536888 ]\n",
      " [ 0.10092476]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 578 | Cost: 0.5201322868406543 | Gradient: [[-0.07514838]\n",
      " [-0.35332925]\n",
      " [ 0.10101035]]\n",
      "Iteration 579 | Cost: 0.5199916595007598 | Gradient: [[-0.07500222]\n",
      " [-0.35297035]\n",
      " [ 0.10109575]]\n",
      "Iteration 580 | Cost: 0.5198512901406916 | Gradient: [[-0.07485633]\n",
      " [-0.35261211]\n",
      " [ 0.10118096]]\n",
      "Iteration 581 | Cost: 0.5197111779831325 | Gradient: [[-0.07471071]\n",
      " [-0.35225452]\n",
      " [ 0.10126599]]\n",
      "Iteration 582 | Cost: 0.5195713222536057 | Gradient: [[-0.07456536]\n",
      " [-0.35189758]\n",
      " [ 0.10135083]]\n",
      "Iteration 583 | Cost: 0.5194317221804633 | Gradient: [[-0.07442028]\n",
      " [-0.35154128]\n",
      " [ 0.10143548]]\n",
      "Iteration 584 | Cost: 0.5192923769948747 | Gradient: [[-0.07427547]\n",
      " [-0.35118563]\n",
      " [ 0.10151995]]\n",
      "Iteration 585 | Cost: 0.5191532859308154 | Gradient: [[-0.07413093]\n",
      " [-0.35083063]\n",
      " [ 0.10160424]]\n",
      "Iteration 586 | Cost: 0.5190144482250542 | Gradient: [[-0.07398665]\n",
      " [-0.35047627]\n",
      " [ 0.10168834]]\n",
      "Iteration 587 | Cost: 0.5188758631171432 | Gradient: [[-0.07384264]\n",
      " [-0.35012255]\n",
      " [ 0.10177226]]\n",
      "Iteration 588 | Cost: 0.518737529849405 | Gradient: [[-0.0736989 ]\n",
      " [-0.34976947]\n",
      " [ 0.101856  ]]\n",
      "Iteration 589 | Cost: 0.518599447666923 | Gradient: [[-0.07355543]\n",
      " [-0.34941703]\n",
      " [ 0.10193955]]\n",
      "Iteration 590 | Cost: 0.5184616158175277 | Gradient: [[-0.07341221]\n",
      " [-0.34906523]\n",
      " [ 0.10202292]]\n",
      "Iteration 591 | Cost: 0.5183240335517876 | Gradient: [[-0.07326927]\n",
      " [-0.34871406]\n",
      " [ 0.10210611]]\n",
      "Iteration 592 | Cost: 0.5181867001229966 | Gradient: [[-0.07312658]\n",
      " [-0.34836353]\n",
      " [ 0.10218912]]\n",
      "Iteration 593 | Cost: 0.5180496147871634 | Gradient: [[-0.07298416]\n",
      " [-0.34801363]\n",
      " [ 0.10227195]]\n",
      "Iteration 594 | Cost: 0.5179127768030001 | Gradient: [[-0.07284201]\n",
      " [-0.34766436]\n",
      " [ 0.10235459]]\n",
      "Iteration 595 | Cost: 0.5177761854319113 | Gradient: [[-0.07270011]\n",
      " [-0.34731572]\n",
      " [ 0.10243706]]\n",
      "Iteration 596 | Cost: 0.5176398399379823 | Gradient: [[-0.07255848]\n",
      " [-0.34696771]\n",
      " [ 0.10251935]]\n",
      "Iteration 597 | Cost: 0.5175037395879698 | Gradient: [[-0.0724171 ]\n",
      " [-0.34662033]\n",
      " [ 0.10260145]]\n",
      "Iteration 598 | Cost: 0.5173678836512887 | Gradient: [[-0.07227599]\n",
      " [-0.34627357]\n",
      " [ 0.10268338]]\n",
      "Iteration 599 | Cost: 0.5172322714000029 | Gradient: [[-0.07213513]\n",
      " [-0.34592743]\n",
      " [ 0.10276513]]\n",
      "Iteration 600 | Cost: 0.5170969021088136 | Gradient: [[-0.07199454]\n",
      " [-0.34558192]\n",
      " [ 0.1028467 ]]\n",
      "Iteration 601 | Cost: 0.5169617750550489 | Gradient: [[-0.0718542 ]\n",
      " [-0.34523702]\n",
      " [ 0.1029281 ]]\n",
      "Iteration 602 | Cost: 0.516826889518653 | Gradient: [[-0.07171412]\n",
      " [-0.34489275]\n",
      " [ 0.10300932]]\n",
      "Iteration 603 | Cost: 0.5166922447821746 | Gradient: [[-0.0715743 ]\n",
      " [-0.34454909]\n",
      " [ 0.10309036]]\n",
      "Iteration 604 | Cost: 0.516557840130758 | Gradient: [[-0.07143473]\n",
      " [-0.34420605]\n",
      " [ 0.10317122]]\n",
      "Iteration 605 | Cost: 0.5164236748521303 | Gradient: [[-0.07129542]\n",
      " [-0.34386363]\n",
      " [ 0.10325191]]\n",
      "Iteration 606 | Cost: 0.5162897482365929 | Gradient: [[-0.07115636]\n",
      " [-0.34352182]\n",
      " [ 0.10333243]]\n",
      "Iteration 607 | Cost: 0.5161560595770095 | Gradient: [[-0.07101756]\n",
      " [-0.34318062]\n",
      " [ 0.10341277]]\n",
      "Iteration 608 | Cost: 0.516022608168796 | Gradient: [[-0.07087901]\n",
      " [-0.34284003]\n",
      " [ 0.10349293]]\n",
      "Iteration 609 | Cost: 0.5158893933099106 | Gradient: [[-0.07074072]\n",
      " [-0.34250005]\n",
      " [ 0.10357292]]\n",
      "Iteration 610 | Cost: 0.5157564143008424 | Gradient: [[-0.07060267]\n",
      " [-0.34216067]\n",
      " [ 0.10365274]]\n",
      "Iteration 611 | Cost: 0.5156236704446023 | Gradient: [[-0.07046488]\n",
      " [-0.34182191]\n",
      " [ 0.10373238]]\n",
      "Iteration 612 | Cost: 0.5154911610467113 | Gradient: [[-0.07032735]\n",
      " [-0.34148375]\n",
      " [ 0.10381185]]\n",
      "Iteration 613 | Cost: 0.5153588854151915 | Gradient: [[-0.07019006]\n",
      " [-0.34114619]\n",
      " [ 0.10389115]]\n",
      "Iteration 614 | Cost: 0.5152268428605549 | Gradient: [[-0.07005302]\n",
      " [-0.34080923]\n",
      " [ 0.10397027]]\n",
      "Iteration 615 | Cost: 0.5150950326957936 | Gradient: [[-0.06991623]\n",
      " [-0.34047287]\n",
      " [ 0.10404922]]\n",
      "Iteration 616 | Cost: 0.5149634542363705 | Gradient: [[-0.06977969]\n",
      " [-0.34013712]\n",
      " [ 0.10412801]]\n",
      "Iteration 617 | Cost: 0.5148321068002074 | Gradient: [[-0.0696434 ]\n",
      " [-0.33980195]\n",
      " [ 0.10420662]]\n",
      "Iteration 618 | Cost: 0.5147009897076766 | Gradient: [[-0.06950736]\n",
      " [-0.33946739]\n",
      " [ 0.10428506]]\n",
      "Iteration 619 | Cost: 0.5145701022815902 | Gradient: [[-0.06937156]\n",
      " [-0.33913342]\n",
      " [ 0.10436333]]\n",
      "Iteration 620 | Cost: 0.5144394438471902 | Gradient: [[-0.06923601]\n",
      " [-0.33880005]\n",
      " [ 0.10444143]]\n",
      "Iteration 621 | Cost: 0.5143090137321386 | Gradient: [[-0.06910071]\n",
      " [-0.33846726]\n",
      " [ 0.10451936]]\n",
      "Iteration 622 | Cost: 0.5141788112665074 | Gradient: [[-0.06896565]\n",
      " [-0.33813507]\n",
      " [ 0.10459712]]\n",
      "Iteration 623 | Cost: 0.5140488357827696 | Gradient: [[-0.06883084]\n",
      " [-0.33780346]\n",
      " [ 0.10467472]]\n",
      "Iteration 624 | Cost: 0.5139190866157882 | Gradient: [[-0.06869627]\n",
      " [-0.33747245]\n",
      " [ 0.10475214]]\n",
      "Iteration 625 | Cost: 0.5137895631028073 | Gradient: [[-0.06856195]\n",
      " [-0.33714202]\n",
      " [ 0.1048294 ]]\n",
      "Iteration 626 | Cost: 0.5136602645834418 | Gradient: [[-0.06842786]\n",
      " [-0.33681217]\n",
      " [ 0.10490649]]\n",
      "Iteration 627 | Cost: 0.5135311903996685 | Gradient: [[-0.06829402]\n",
      " [-0.33648291]\n",
      " [ 0.10498342]]\n",
      "Iteration 628 | Cost: 0.513402339895816 | Gradient: [[-0.06816043]\n",
      " [-0.33615423]\n",
      " [ 0.10506018]]\n",
      "Iteration 629 | Cost: 0.5132737124185552 | Gradient: [[-0.06802707]\n",
      " [-0.33582613]\n",
      " [ 0.10513677]]\n",
      "Iteration 630 | Cost: 0.5131453073168897 | Gradient: [[-0.06789396]\n",
      " [-0.33549861]\n",
      " [ 0.10521319]]\n",
      "Iteration 631 | Cost: 0.5130171239421465 | Gradient: [[-0.06776108]\n",
      " [-0.33517167]\n",
      " [ 0.10528945]]\n",
      "Iteration 632 | Cost: 0.5128891616479665 | Gradient: [[-0.06762845]\n",
      " [-0.33484531]\n",
      " [ 0.10536555]]\n",
      "Iteration 633 | Cost: 0.5127614197902952 | Gradient: [[-0.06749605]\n",
      " [-0.33451952]\n",
      " [ 0.10544148]]\n",
      "Iteration 634 | Cost: 0.5126338977273731 | Gradient: [[-0.06736389]\n",
      " [-0.3341943 ]\n",
      " [ 0.10551724]]\n",
      "Iteration 635 | Cost: 0.5125065948197266 | Gradient: [[-0.06723198]\n",
      " [-0.33386966]\n",
      " [ 0.10559285]]\n",
      "Iteration 636 | Cost: 0.5123795104301585 | Gradient: [[-0.06710029]\n",
      " [-0.33354559]\n",
      " [ 0.10566829]]\n",
      "Iteration 637 | Cost: 0.5122526439237389 | Gradient: [[-0.06696885]\n",
      " [-0.33322209]\n",
      " [ 0.10574356]]\n",
      "Iteration 638 | Cost: 0.5121259946677964 | Gradient: [[-0.06683764]\n",
      " [-0.33289916]\n",
      " [ 0.10581868]]\n",
      "Iteration 639 | Cost: 0.511999562031908 | Gradient: [[-0.06670667]\n",
      " [-0.33257679]\n",
      " [ 0.10589363]]\n",
      "Iteration 640 | Cost: 0.511873345387891 | Gradient: [[-0.06657593]\n",
      " [-0.33225499]\n",
      " [ 0.10596842]]\n",
      "Iteration 641 | Cost: 0.5117473441097932 | Gradient: [[-0.06644543]\n",
      " [-0.33193376]\n",
      " [ 0.10604304]]\n",
      "Iteration 642 | Cost: 0.5116215575738843 | Gradient: [[-0.06631516]\n",
      " [-0.33161309]\n",
      " [ 0.10611751]]\n",
      "Iteration 643 | Cost: 0.5114959851586468 | Gradient: [[-0.06618512]\n",
      " [-0.33129298]\n",
      " [ 0.10619181]]\n",
      "Iteration 644 | Cost: 0.5113706262447667 | Gradient: [[-0.06605532]\n",
      " [-0.33097343]\n",
      " [ 0.10626596]]\n",
      "Iteration 645 | Cost: 0.5112454802151253 | Gradient: [[-0.06592575]\n",
      " [-0.33065444]\n",
      " [ 0.10633994]]\n",
      "Iteration 646 | Cost: 0.5111205464547895 | Gradient: [[-0.06579641]\n",
      " [-0.33033601]\n",
      " [ 0.10641377]]\n",
      "Iteration 647 | Cost: 0.5109958243510038 | Gradient: [[-0.06566731]\n",
      " [-0.33001814]\n",
      " [ 0.10648744]]\n",
      "Iteration 648 | Cost: 0.5108713132931805 | Gradient: [[-0.06553843]\n",
      " [-0.32970082]\n",
      " [ 0.10656094]]\n",
      "Iteration 649 | Cost: 0.510747012672892 | Gradient: [[-0.06540978]\n",
      " [-0.32938406]\n",
      " [ 0.10663429]]\n",
      "Iteration 650 | Cost: 0.5106229218838615 | Gradient: [[-0.06528137]\n",
      " [-0.32906785]\n",
      " [ 0.10670748]]\n",
      "Iteration 651 | Cost: 0.5104990403219543 | Gradient: [[-0.06515318]\n",
      " [-0.32875219]\n",
      " [ 0.10678051]]\n",
      "Iteration 652 | Cost: 0.5103753673851692 | Gradient: [[-0.06502522]\n",
      " [-0.32843708]\n",
      " [ 0.10685339]]\n",
      "Iteration 653 | Cost: 0.5102519024736303 | Gradient: [[-0.06489749]\n",
      " [-0.32812252]\n",
      " [ 0.10692611]]\n",
      "Iteration 654 | Cost: 0.5101286449895778 | Gradient: [[-0.06476999]\n",
      " [-0.32780851]\n",
      " [ 0.10699867]]\n",
      "Iteration 655 | Cost: 0.5100055943373596 | Gradient: [[-0.06464271]\n",
      " [-0.32749504]\n",
      " [ 0.10707107]]\n",
      "Iteration 656 | Cost: 0.5098827499234234 | Gradient: [[-0.06451567]\n",
      " [-0.32718212]\n",
      " [ 0.10714332]]\n",
      "Iteration 657 | Cost: 0.5097601111563076 | Gradient: [[-0.06438884]\n",
      " [-0.32686974]\n",
      " [ 0.10721541]]\n",
      "Iteration 658 | Cost: 0.509637677446633 | Gradient: [[-0.06426224]\n",
      " [-0.32655791]\n",
      " [ 0.10728735]]\n",
      "Iteration 659 | Cost: 0.5095154482070946 | Gradient: [[-0.06413587]\n",
      " [-0.32624662]\n",
      " [ 0.10735914]]\n",
      "Iteration 660 | Cost: 0.5093934228524531 | Gradient: [[-0.06400972]\n",
      " [-0.32593587]\n",
      " [ 0.10743076]]\n",
      "Iteration 661 | Cost: 0.509271600799527 | Gradient: [[-0.0638838 ]\n",
      " [-0.32562565]\n",
      " [ 0.10750224]]\n",
      "Iteration 662 | Cost: 0.5091499814671834 | Gradient: [[-0.0637581 ]\n",
      " [-0.32531598]\n",
      " [ 0.10757356]]\n",
      "Iteration 663 | Cost: 0.5090285642763308 | Gradient: [[-0.06363262]\n",
      " [-0.32500684]\n",
      " [ 0.10764473]]\n",
      "Iteration 664 | Cost: 0.50890734864991 | Gradient: [[-0.06350736]\n",
      " [-0.32469824]\n",
      " [ 0.10771574]]\n",
      "Iteration 665 | Cost: 0.508786334012887 | Gradient: [[-0.06338233]\n",
      " [-0.32439017]\n",
      " [ 0.1077866 ]]\n",
      "Iteration 666 | Cost: 0.5086655197922435 | Gradient: [[-0.06325751]\n",
      " [-0.32408263]\n",
      " [ 0.10785731]]\n",
      "Iteration 667 | Cost: 0.5085449054169703 | Gradient: [[-0.06313292]\n",
      " [-0.32377562]\n",
      " [ 0.10792787]]\n",
      "Iteration 668 | Cost: 0.5084244903180579 | Gradient: [[-0.06300855]\n",
      " [-0.32346915]\n",
      " [ 0.10799827]]\n",
      "Iteration 669 | Cost: 0.5083042739284896 | Gradient: [[-0.0628844 ]\n",
      " [-0.3231632 ]\n",
      " [ 0.10806852]]\n",
      "Iteration 670 | Cost: 0.5081842556832326 | Gradient: [[-0.06276046]\n",
      " [-0.32285778]\n",
      " [ 0.10813863]]\n",
      "Iteration 671 | Cost: 0.5080644350192304 | Gradient: [[-0.06263675]\n",
      " [-0.32255289]\n",
      " [ 0.10820858]]\n",
      "Iteration 672 | Cost: 0.5079448113753952 | Gradient: [[-0.06251325]\n",
      " [-0.32224853]\n",
      " [ 0.10827838]]\n",
      "Iteration 673 | Cost: 0.5078253841925996 | Gradient: [[-0.06238997]\n",
      " [-0.32194468]\n",
      " [ 0.10834803]]\n",
      "Iteration 674 | Cost: 0.5077061529136688 | Gradient: [[-0.06226691]\n",
      " [-0.32164136]\n",
      " [ 0.10841753]]\n",
      "Iteration 675 | Cost: 0.507587116983373 | Gradient: [[-0.06214407]\n",
      " [-0.32133857]\n",
      " [ 0.10848688]]\n",
      "Iteration 676 | Cost: 0.5074682758484195 | Gradient: [[-0.06202144]\n",
      " [-0.32103629]\n",
      " [ 0.10855609]]\n",
      "Iteration 677 | Cost: 0.5073496289574448 | Gradient: [[-0.06189902]\n",
      " [-0.32073453]\n",
      " [ 0.10862514]]\n",
      "Iteration 678 | Cost: 0.5072311757610073 | Gradient: [[-0.06177683]\n",
      " [-0.32043329]\n",
      " [ 0.10869405]]\n",
      "Iteration 679 | Cost: 0.507112915711579 | Gradient: [[-0.06165484]\n",
      " [-0.32013257]\n",
      " [ 0.10876281]]\n",
      "Iteration 680 | Cost: 0.5069948482635385 | Gradient: [[-0.06153307]\n",
      " [-0.31983236]\n",
      " [ 0.10883142]]\n",
      "Iteration 681 | Cost: 0.506876972873163 | Gradient: [[-0.06141152]\n",
      " [-0.31953267]\n",
      " [ 0.10889988]]\n",
      "Iteration 682 | Cost: 0.5067592889986208 | Gradient: [[-0.06129017]\n",
      " [-0.31923349]\n",
      " [ 0.1089682 ]]\n",
      "Iteration 683 | Cost: 0.5066417960999636 | Gradient: [[-0.06116904]\n",
      " [-0.31893482]\n",
      " [ 0.10903637]]\n",
      "Iteration 684 | Cost: 0.5065244936391197 | Gradient: [[-0.06104812]\n",
      " [-0.31863666]\n",
      " [ 0.1091044 ]]\n",
      "Iteration 685 | Cost: 0.5064073810798853 | Gradient: [[-0.06092742]\n",
      " [-0.31833902]\n",
      " [ 0.10917227]]\n",
      "Iteration 686 | Cost: 0.5062904578879183 | Gradient: [[-0.06080692]\n",
      " [-0.31804188]\n",
      " [ 0.10924001]]\n",
      "Iteration 687 | Cost: 0.5061737235307302 | Gradient: [[-0.06068664]\n",
      " [-0.31774525]\n",
      " [ 0.10930759]]\n",
      "Iteration 688 | Cost: 0.5060571774776783 | Gradient: [[-0.06056656]\n",
      " [-0.31744912]\n",
      " [ 0.10937504]]\n",
      "Iteration 689 | Cost: 0.5059408191999598 | Gradient: [[-0.0604467 ]\n",
      " [-0.3171535 ]\n",
      " [ 0.10944234]]\n",
      "Iteration 690 | Cost: 0.505824648170603 | Gradient: [[-0.06032704]\n",
      " [-0.31685839]\n",
      " [ 0.10950949]]\n",
      "Iteration 691 | Cost: 0.5057086638644607 | Gradient: [[-0.0602076 ]\n",
      " [-0.31656378]\n",
      " [ 0.1095765 ]]\n",
      "Iteration 692 | Cost: 0.5055928657582026 | Gradient: [[-0.06008836]\n",
      " [-0.31626967]\n",
      " [ 0.10964337]]\n",
      "Iteration 693 | Cost: 0.5054772533303089 | Gradient: [[-0.05996933]\n",
      " [-0.31597606]\n",
      " [ 0.10971009]]\n",
      "Iteration 694 | Cost: 0.5053618260610621 | Gradient: [[-0.0598505 ]\n",
      " [-0.31568295]\n",
      " [ 0.10977667]]\n",
      "Iteration 695 | Cost: 0.5052465834325401 | Gradient: [[-0.05973189]\n",
      " [-0.31539033]\n",
      " [ 0.10984311]]\n",
      "Iteration 696 | Cost: 0.5051315249286098 | Gradient: [[-0.05961348]\n",
      " [-0.31509822]\n",
      " [ 0.1099094 ]]\n",
      "Iteration 697 | Cost: 0.5050166500349189 | Gradient: [[-0.05949527]\n",
      " [-0.3148066 ]\n",
      " [ 0.10997556]]\n",
      "Iteration 698 | Cost: 0.5049019582388897 | Gradient: [[-0.05937727]\n",
      " [-0.31451547]\n",
      " [ 0.11004157]]\n",
      "Iteration 699 | Cost: 0.5047874490297116 | Gradient: [[-0.05925948]\n",
      " [-0.31422484]\n",
      " [ 0.11010744]]\n",
      "Iteration 700 | Cost: 0.5046731218983344 | Gradient: [[-0.05914189]\n",
      " [-0.3139347 ]\n",
      " [ 0.11017317]]\n",
      "Iteration 701 | Cost: 0.5045589763374607 | Gradient: [[-0.0590245 ]\n",
      " [-0.31364506]\n",
      " [ 0.11023876]]\n",
      "Iteration 702 | Cost: 0.5044450118415402 | Gradient: [[-0.05890732]\n",
      " [-0.3133559 ]\n",
      " [ 0.11030421]]\n",
      "Iteration 703 | Cost: 0.5043312279067612 | Gradient: [[-0.05879034]\n",
      " [-0.31306723]\n",
      " [ 0.11036952]]\n",
      "Iteration 704 | Cost: 0.5042176240310451 | Gradient: [[-0.05867356]\n",
      " [-0.31277905]\n",
      " [ 0.11043469]]\n",
      "Iteration 705 | Cost: 0.5041041997140385 | Gradient: [[-0.05855699]\n",
      " [-0.31249136]\n",
      " [ 0.11049972]]\n",
      "Iteration 706 | Cost: 0.5039909544571073 | Gradient: [[-0.05844061]\n",
      " [-0.31220415]\n",
      " [ 0.11056461]]\n",
      "Iteration 707 | Cost: 0.503877887763329 | Gradient: [[-0.05832444]\n",
      " [-0.31191743]\n",
      " [ 0.11062936]]\n",
      "Iteration 708 | Cost: 0.5037649991374868 | Gradient: [[-0.05820847]\n",
      " [-0.31163119]\n",
      " [ 0.11069397]]\n",
      "Iteration 709 | Cost: 0.5036522880860623 | Gradient: [[-0.0580927 ]\n",
      " [-0.31134544]\n",
      " [ 0.11075845]]\n",
      "Iteration 710 | Cost: 0.503539754117229 | Gradient: [[-0.05797713]\n",
      " [-0.31106016]\n",
      " [ 0.11082279]]\n",
      "Iteration 711 | Cost: 0.5034273967408451 | Gradient: [[-0.05786176]\n",
      " [-0.31077537]\n",
      " [ 0.11088699]]\n",
      "Iteration 712 | Cost: 0.503315215468448 | Gradient: [[-0.05774658]\n",
      " [-0.31049105]\n",
      " [ 0.11095105]]\n",
      "Iteration 713 | Cost: 0.5032032098132467 | Gradient: [[-0.05763161]\n",
      " [-0.31020722]\n",
      " [ 0.11101498]]\n",
      "Iteration 714 | Cost: 0.5030913792901153 | Gradient: [[-0.05751683]\n",
      " [-0.30992386]\n",
      " [ 0.11107877]]\n",
      "Iteration 715 | Cost: 0.5029797234155872 | Gradient: [[-0.05740225]\n",
      " [-0.30964097]\n",
      " [ 0.11114242]]\n",
      "Iteration 716 | Cost: 0.5028682417078475 | Gradient: [[-0.05728787]\n",
      " [-0.30935856]\n",
      " [ 0.11120594]]\n",
      "Iteration 717 | Cost: 0.5027569336867271 | Gradient: [[-0.05717369]\n",
      " [-0.30907663]\n",
      " [ 0.11126932]]\n",
      "Iteration 718 | Cost: 0.5026457988736965 | Gradient: [[-0.0570597 ]\n",
      " [-0.30879516]\n",
      " [ 0.11133257]]\n",
      "Iteration 719 | Cost: 0.5025348367918585 | Gradient: [[-0.0569459 ]\n",
      " [-0.30851417]\n",
      " [ 0.11139568]]\n",
      "Iteration 720 | Cost: 0.5024240469659427 | Gradient: [[-0.0568323 ]\n",
      " [-0.30823365]\n",
      " [ 0.11145866]]\n",
      "Iteration 721 | Cost: 0.5023134289222984 | Gradient: [[-0.0567189]\n",
      " [-0.3079536]\n",
      " [ 0.1115215]]\n",
      "Iteration 722 | Cost: 0.5022029821888886 | Gradient: [[-0.05660569]\n",
      " [-0.30767402]\n",
      " [ 0.11158421]]\n",
      "Iteration 723 | Cost: 0.5020927062952836 | Gradient: [[-0.05649267]\n",
      " [-0.30739491]\n",
      " [ 0.11164678]]\n",
      "Iteration 724 | Cost: 0.5019826007726546 | Gradient: [[-0.05637985]\n",
      " [-0.30711626]\n",
      " [ 0.11170922]]\n",
      "Iteration 725 | Cost: 0.5018726651537676 | Gradient: [[-0.05626722]\n",
      " [-0.30683807]\n",
      " [ 0.11177153]]\n",
      "Iteration 726 | Cost: 0.5017628989729768 | Gradient: [[-0.05615479]\n",
      " [-0.30656036]\n",
      " [ 0.11183371]]\n",
      "Iteration 727 | Cost: 0.5016533017662191 | Gradient: [[-0.05604254]\n",
      " [-0.3062831 ]\n",
      " [ 0.11189575]]\n",
      "Iteration 728 | Cost: 0.5015438730710068 | Gradient: [[-0.05593049]\n",
      " [-0.30600631]\n",
      " [ 0.11195766]]\n",
      "Iteration 729 | Cost: 0.5014346124264224 | Gradient: [[-0.05581863]\n",
      " [-0.30572997]\n",
      " [ 0.11201944]]\n",
      "Iteration 730 | Cost: 0.501325519373112 | Gradient: [[-0.05570696]\n",
      " [-0.3054541 ]\n",
      " [ 0.11208109]]\n",
      "Iteration 731 | Cost: 0.5012165934532792 | Gradient: [[-0.05559548]\n",
      " [-0.30517869]\n",
      " [ 0.1121426 ]]\n",
      "Iteration 732 | Cost: 0.5011078342106792 | Gradient: [[-0.05548419]\n",
      " [-0.30490373]\n",
      " [ 0.11220399]]\n",
      "Iteration 733 | Cost: 0.5009992411906125 | Gradient: [[-0.05537309]\n",
      " [-0.30462924]\n",
      " [ 0.11226524]]\n",
      "Iteration 734 | Cost: 0.5008908139399189 | Gradient: [[-0.05526218]\n",
      " [-0.30435519]\n",
      " [ 0.11232637]]\n",
      "Iteration 735 | Cost: 0.5007825520069716 | Gradient: [[-0.05515145]\n",
      " [-0.30408161]\n",
      " [ 0.11238736]]\n",
      "Iteration 736 | Cost: 0.5006744549416713 | Gradient: [[-0.05504092]\n",
      " [-0.30380847]\n",
      " [ 0.11244822]]\n",
      "Iteration 737 | Cost: 0.5005665222954401 | Gradient: [[-0.05493057]\n",
      " [-0.30353579]\n",
      " [ 0.11250896]]\n",
      "Iteration 738 | Cost: 0.5004587536212153 | Gradient: [[-0.05482042]\n",
      " [-0.30326356]\n",
      " [ 0.11256956]]\n",
      "Iteration 739 | Cost: 0.5003511484734436 | Gradient: [[-0.05471044]\n",
      " [-0.30299178]\n",
      " [ 0.11263004]]\n",
      "Iteration 740 | Cost: 0.500243706408076 | Gradient: [[-0.05460066]\n",
      " [-0.30272046]\n",
      " [ 0.11269038]]\n",
      "Iteration 741 | Cost: 0.5001364269825608 | Gradient: [[-0.05449106]\n",
      " [-0.30244958]\n",
      " [ 0.1127506 ]]\n",
      "Iteration 742 | Cost: 0.5000293097558383 | Gradient: [[-0.05438164]\n",
      " [-0.30217914]\n",
      " [ 0.11281069]]\n",
      "Iteration 743 | Cost: 0.49992235428833526 | Gradient: [[-0.05427242]\n",
      " [-0.30190916]\n",
      " [ 0.11287065]]\n",
      "Iteration 744 | Cost: 0.49981556014195827 | Gradient: [[-0.05416337]\n",
      " [-0.30163962]\n",
      " [ 0.11293049]]\n",
      "Iteration 745 | Cost: 0.499708926880089 | Gradient: [[-0.05405451]\n",
      " [-0.30137053]\n",
      " [ 0.1129902 ]]\n",
      "Iteration 746 | Cost: 0.4996024540675778 | Gradient: [[-0.05394584]\n",
      " [-0.30110188]\n",
      " [ 0.11304978]]\n",
      "Iteration 747 | Cost: 0.4994961412707382 | Gradient: [[-0.05383735]\n",
      " [-0.30083367]\n",
      " [ 0.11310923]]\n",
      "Iteration 748 | Cost: 0.499389988057341 | Gradient: [[-0.05372904]\n",
      " [-0.3005659 ]\n",
      " [ 0.11316856]]\n",
      "Iteration 749 | Cost: 0.49928399399660933 | Gradient: [[-0.05362091]\n",
      " [-0.30029858]\n",
      " [ 0.11322776]]\n",
      "Iteration 750 | Cost: 0.499178158659212 | Gradient: [[-0.05351297]\n",
      " [-0.30003169]\n",
      " [ 0.11328683]]\n",
      "Iteration 751 | Cost: 0.49907248161725853 | Gradient: [[-0.05340521]\n",
      " [-0.29976524]\n",
      " [ 0.11334578]]\n",
      "Iteration 752 | Cost: 0.4989669624442932 | Gradient: [[-0.05329763]\n",
      " [-0.29949924]\n",
      " [ 0.11340461]]\n",
      "Iteration 753 | Cost: 0.49886160071529034 | Gradient: [[-0.05319023]\n",
      " [-0.29923366]\n",
      " [ 0.11346331]]\n",
      "Iteration 754 | Cost: 0.49875639600664745 | Gradient: [[-0.05308302]\n",
      " [-0.29896853]\n",
      " [ 0.11352188]]\n",
      "Iteration 755 | Cost: 0.4986513478961806 | Gradient: [[-0.05297598]\n",
      " [-0.29870383]\n",
      " [ 0.11358033]]\n",
      "Iteration 756 | Cost: 0.49854645596311875 | Gradient: [[-0.05286912]\n",
      " [-0.29843956]\n",
      " [ 0.11363866]]\n",
      "Iteration 757 | Cost: 0.49844171978809854 | Gradient: [[-0.05276245]\n",
      " [-0.29817573]\n",
      " [ 0.11369686]]\n",
      "Iteration 758 | Cost: 0.498337138953158 | Gradient: [[-0.05265595]\n",
      " [-0.29791233]\n",
      " [ 0.11375494]]\n",
      "Iteration 759 | Cost: 0.49823271304173183 | Gradient: [[-0.05254963]\n",
      " [-0.29764936]\n",
      " [ 0.11381289]]\n",
      "Iteration 760 | Cost: 0.4981284416386462 | Gradient: [[-0.05244349]\n",
      " [-0.29738681]\n",
      " [ 0.11387073]]\n",
      "Iteration 761 | Cost: 0.49802432433011257 | Gradient: [[-0.05233752]\n",
      " [-0.2971247 ]\n",
      " [ 0.11392843]]\n",
      "Iteration 762 | Cost: 0.497920360703723 | Gradient: [[-0.05223174]\n",
      " [-0.29686302]\n",
      " [ 0.11398602]]\n",
      "Iteration 763 | Cost: 0.4978165503484445 | Gradient: [[-0.05212613]\n",
      " [-0.29660176]\n",
      " [ 0.11404349]]\n",
      "Iteration 764 | Cost: 0.4977128928546142 | Gradient: [[-0.0520207 ]\n",
      " [-0.29634093]\n",
      " [ 0.11410083]]\n",
      "Iteration 765 | Cost: 0.49760938781393305 | Gradient: [[-0.05191544]\n",
      " [-0.29608053]\n",
      " [ 0.11415805]]\n",
      "Iteration 766 | Cost: 0.49750603481946165 | Gradient: [[-0.05181036]\n",
      " [-0.29582055]\n",
      " [ 0.11421515]]\n",
      "Iteration 767 | Cost: 0.49740283346561454 | Gradient: [[-0.05170546]\n",
      " [-0.29556099]\n",
      " [ 0.11427213]]\n",
      "Iteration 768 | Cost: 0.49729978334815483 | Gradient: [[-0.05160073]\n",
      " [-0.29530186]\n",
      " [ 0.11432898]]\n",
      "Iteration 769 | Cost: 0.4971968840641894 | Gradient: [[-0.05149618]\n",
      " [-0.29504315]\n",
      " [ 0.11438572]]\n",
      "Iteration 770 | Cost: 0.49709413521216306 | Gradient: [[-0.0513918 ]\n",
      " [-0.29478486]\n",
      " [ 0.11444234]]\n",
      "Iteration 771 | Cost: 0.49699153639185456 | Gradient: [[-0.05128759]\n",
      " [-0.29452699]\n",
      " [ 0.11449883]]\n",
      "Iteration 772 | Cost: 0.49688908720437014 | Gradient: [[-0.05118356]\n",
      " [-0.29426953]\n",
      " [ 0.11455521]]\n",
      "Iteration 773 | Cost: 0.4967867872521391 | Gradient: [[-0.0510797 ]\n",
      " [-0.2940125 ]\n",
      " [ 0.11461146]]\n",
      "Iteration 774 | Cost: 0.49668463613890906 | Gradient: [[-0.05097601]\n",
      " [-0.29375588]\n",
      " [ 0.1146676 ]]\n",
      "Iteration 775 | Cost: 0.49658263346974 | Gradient: [[-0.0508725 ]\n",
      " [-0.29349968]\n",
      " [ 0.11472362]]\n",
      "Iteration 776 | Cost: 0.4964807788510001 | Gradient: [[-0.05076916]\n",
      " [-0.29324389]\n",
      " [ 0.11477952]]\n",
      "Iteration 777 | Cost: 0.49637907189036 | Gradient: [[-0.05066599]\n",
      " [-0.29298852]\n",
      " [ 0.1148353 ]]\n",
      "Iteration 778 | Cost: 0.4962775121967884 | Gradient: [[-0.05056299]\n",
      " [-0.29273356]\n",
      " [ 0.11489096]]\n",
      "Iteration 779 | Cost: 0.4961760993805466 | Gradient: [[-0.05046017]\n",
      " [-0.29247901]\n",
      " [ 0.11494651]]\n",
      "Iteration 780 | Cost: 0.4960748330531838 | Gradient: [[-0.05035751]\n",
      " [-0.29222488]\n",
      " [ 0.11500193]]\n",
      "Iteration 781 | Cost: 0.49597371282753216 | Gradient: [[-0.05025502]\n",
      " [-0.29197115]\n",
      " [ 0.11505724]]\n",
      "Iteration 782 | Cost: 0.4958727383177019 | Gradient: [[-0.05015271]\n",
      " [-0.29171784]\n",
      " [ 0.11511243]]\n",
      "Iteration 783 | Cost: 0.4957719091390762 | Gradient: [[-0.05005056]\n",
      " [-0.29146493]\n",
      " [ 0.11516751]]\n",
      "Iteration 784 | Cost: 0.49567122490830684 | Gradient: [[-0.04994858]\n",
      " [-0.29121243]\n",
      " [ 0.11522247]]\n",
      "Iteration 785 | Cost: 0.49557068524330844 | Gradient: [[-0.04984677]\n",
      " [-0.29096034]\n",
      " [ 0.11527731]]\n",
      "Iteration 786 | Cost: 0.4954702897632546 | Gradient: [[-0.04974513]\n",
      " [-0.29070865]\n",
      " [ 0.11533204]]\n",
      "Iteration 787 | Cost: 0.4953700380885726 | Gradient: [[-0.04964366]\n",
      " [-0.29045737]\n",
      " [ 0.11538665]]\n",
      "Iteration 788 | Cost: 0.4952699298409386 | Gradient: [[-0.04954235]\n",
      " [-0.2902065 ]\n",
      " [ 0.11544114]]\n",
      "Iteration 789 | Cost: 0.4951699646432729 | Gradient: [[-0.04944121]\n",
      " [-0.28995602]\n",
      " [ 0.11549552]]\n",
      "Iteration 790 | Cost: 0.4950701421197356 | Gradient: [[-0.04934024]\n",
      " [-0.28970595]\n",
      " [ 0.11554978]]\n",
      "Iteration 791 | Cost: 0.49497046189572097 | Gradient: [[-0.04923944]\n",
      " [-0.28945628]\n",
      " [ 0.11560393]]\n",
      "Iteration 792 | Cost: 0.4948709235978539 | Gradient: [[-0.0491388 ]\n",
      " [-0.28920702]\n",
      " [ 0.11565796]]\n",
      "Iteration 793 | Cost: 0.49477152685398407 | Gradient: [[-0.04903832]\n",
      " [-0.28895815]\n",
      " [ 0.11571188]]\n",
      "Iteration 794 | Cost: 0.49467227129318225 | Gradient: [[-0.04893802]\n",
      " [-0.28870968]\n",
      " [ 0.11576569]]\n",
      "Iteration 795 | Cost: 0.49457315654573486 | Gradient: [[-0.04883787]\n",
      " [-0.28846161]\n",
      " [ 0.11581938]]\n",
      "Iteration 796 | Cost: 0.4944741822431398 | Gradient: [[-0.04873789]\n",
      " [-0.28821393]\n",
      " [ 0.11587296]]\n",
      "Iteration 797 | Cost: 0.4943753480181021 | Gradient: [[-0.04863808]\n",
      " [-0.28796666]\n",
      " [ 0.11592642]]\n",
      "Iteration 798 | Cost: 0.4942766535045285 | Gradient: [[-0.04853843]\n",
      " [-0.28771978]\n",
      " [ 0.11597977]]\n",
      "Iteration 799 | Cost: 0.49417809833752346 | Gradient: [[-0.04843894]\n",
      " [-0.28747329]\n",
      " [ 0.11603301]]\n",
      "Iteration 800 | Cost: 0.4940796821533848 | Gradient: [[-0.04833962]\n",
      " [-0.2872272 ]\n",
      " [ 0.11608614]]\n",
      "Iteration 801 | Cost: 0.4939814045895987 | Gradient: [[-0.04824046]\n",
      " [-0.28698149]\n",
      " [ 0.11613915]]\n",
      "Iteration 802 | Cost: 0.49388326528483506 | Gradient: [[-0.04814146]\n",
      " [-0.28673619]\n",
      " [ 0.11619205]]\n",
      "Iteration 803 | Cost: 0.49378526387894384 | Gradient: [[-0.04804263]\n",
      " [-0.28649127]\n",
      " [ 0.11624484]]\n",
      "Iteration 804 | Cost: 0.4936874000129496 | Gradient: [[-0.04794395]\n",
      " [-0.28624674]\n",
      " [ 0.11629752]]\n",
      "Iteration 805 | Cost: 0.49358967332904785 | Gradient: [[-0.04784544]\n",
      " [-0.28600261]\n",
      " [ 0.11635009]]\n",
      "Iteration 806 | Cost: 0.49349208347060014 | Gradient: [[-0.04774709]\n",
      " [-0.28575886]\n",
      " [ 0.11640254]]\n",
      "Iteration 807 | Cost: 0.49339463008212964 | Gradient: [[-0.0476489 ]\n",
      " [-0.2855155 ]\n",
      " [ 0.11645488]]\n",
      "Iteration 808 | Cost: 0.49329731280931716 | Gradient: [[-0.04755087]\n",
      " [-0.28527252]\n",
      " [ 0.11650712]]\n",
      "Iteration 809 | Cost: 0.4932001312989962 | Gradient: [[-0.04745299]\n",
      " [-0.28502994]\n",
      " [ 0.11655924]]\n",
      "Iteration 810 | Cost: 0.49310308519914897 | Gradient: [[-0.04735528]\n",
      " [-0.28478773]\n",
      " [ 0.11661125]]\n",
      "Iteration 811 | Cost: 0.49300617415890213 | Gradient: [[-0.04725773]\n",
      " [-0.28454592]\n",
      " [ 0.11666316]]\n",
      "Iteration 812 | Cost: 0.492909397828522 | Gradient: [[-0.04716034]\n",
      " [-0.28430448]\n",
      " [ 0.11671495]]\n",
      "Iteration 813 | Cost: 0.49281275585941076 | Gradient: [[-0.04706311]\n",
      " [-0.28406343]\n",
      " [ 0.11676663]]\n",
      "Iteration 814 | Cost: 0.4927162479041018 | Gradient: [[-0.04696603]\n",
      " [-0.28382276]\n",
      " [ 0.11681821]]\n",
      "Iteration 815 | Cost: 0.4926198736162557 | Gradient: [[-0.04686911]\n",
      " [-0.28358247]\n",
      " [ 0.11686967]]\n",
      "Iteration 816 | Cost: 0.49252363265065585 | Gradient: [[-0.04677235]\n",
      " [-0.28334256]\n",
      " [ 0.11692103]]\n",
      "Iteration 817 | Cost: 0.4924275246632042 | Gradient: [[-0.04667575]\n",
      " [-0.28310304]\n",
      " [ 0.11697227]]\n",
      "Iteration 818 | Cost: 0.4923315493109171 | Gradient: [[-0.0465793 ]\n",
      " [-0.28286389]\n",
      " [ 0.11702341]]\n",
      "Iteration 819 | Cost: 0.4922357062519212 | Gradient: [[-0.04648301]\n",
      " [-0.28262511]\n",
      " [ 0.11707444]]\n",
      "Iteration 820 | Cost: 0.4921399951454489 | Gradient: [[-0.04638688]\n",
      " [-0.28238672]\n",
      " [ 0.11712537]]\n",
      "Iteration 821 | Cost: 0.4920444156518348 | Gradient: [[-0.0462909 ]\n",
      " [-0.2821487 ]\n",
      " [ 0.11717618]]\n",
      "Iteration 822 | Cost: 0.49194896743251093 | Gradient: [[-0.04619508]\n",
      " [-0.28191106]\n",
      " [ 0.11722689]]\n",
      "Iteration 823 | Cost: 0.4918536501500029 | Gradient: [[-0.04609941]\n",
      " [-0.28167379]\n",
      " [ 0.11727749]]\n",
      "Iteration 824 | Cost: 0.4917584634679258 | Gradient: [[-0.0460039 ]\n",
      " [-0.28143689]\n",
      " [ 0.11732799]]\n",
      "Iteration 825 | Cost: 0.4916634070509803 | Gradient: [[-0.04590854]\n",
      " [-0.28120037]\n",
      " [ 0.11737837]]\n",
      "Iteration 826 | Cost: 0.4915684805649482 | Gradient: [[-0.04581334]\n",
      " [-0.28096422]\n",
      " [ 0.11742866]]\n",
      "Iteration 827 | Cost: 0.4914736836766884 | Gradient: [[-0.04571829]\n",
      " [-0.28072844]\n",
      " [ 0.11747883]]\n",
      "Iteration 828 | Cost: 0.49137901605413326 | Gradient: [[-0.04562339]\n",
      " [-0.28049303]\n",
      " [ 0.1175289 ]]\n",
      "Iteration 829 | Cost: 0.49128447736628433 | Gradient: [[-0.04552865]\n",
      " [-0.280258  ]\n",
      " [ 0.11757886]]\n",
      "Iteration 830 | Cost: 0.4911900672832079 | Gradient: [[-0.04543406]\n",
      " [-0.28002333]\n",
      " [ 0.11762872]]\n",
      "Iteration 831 | Cost: 0.4910957854760319 | Gradient: [[-0.04533962]\n",
      " [-0.27978903]\n",
      " [ 0.11767847]]\n",
      "Iteration 832 | Cost: 0.4910016316169412 | Gradient: [[-0.04524534]\n",
      " [-0.27955509]\n",
      " [ 0.11772812]]\n",
      "Iteration 833 | Cost: 0.49090760537917405 | Gradient: [[-0.0451512 ]\n",
      " [-0.27932153]\n",
      " [ 0.11777766]]\n",
      "Iteration 834 | Cost: 0.49081370643701794 | Gradient: [[-0.04505722]\n",
      " [-0.27908833]\n",
      " [ 0.1178271 ]]\n",
      "Iteration 835 | Cost: 0.49071993446580575 | Gradient: [[-0.04496339]\n",
      " [-0.27885549]\n",
      " [ 0.11787643]]\n",
      "Iteration 836 | Cost: 0.4906262891419118 | Gradient: [[-0.04486971]\n",
      " [-0.27862302]\n",
      " [ 0.11792566]]\n",
      "Iteration 837 | Cost: 0.4905327701427479 | Gradient: [[-0.04477618]\n",
      " [-0.27839091]\n",
      " [ 0.11797479]]\n",
      "Iteration 838 | Cost: 0.4904393771467599 | Gradient: [[-0.0446828 ]\n",
      " [-0.27815916]\n",
      " [ 0.11802381]]\n",
      "Iteration 839 | Cost: 0.49034610983342325 | Gradient: [[-0.04458958]\n",
      " [-0.27792778]\n",
      " [ 0.11807273]]\n",
      "Iteration 840 | Cost: 0.4902529678832393 | Gradient: [[-0.0444965 ]\n",
      " [-0.27769676]\n",
      " [ 0.11812154]]\n",
      "Iteration 841 | Cost: 0.49015995097773185 | Gradient: [[-0.04440357]\n",
      " [-0.2774661 ]\n",
      " [ 0.11817025]]\n",
      "Iteration 842 | Cost: 0.49006705879944285 | Gradient: [[-0.04431078]\n",
      " [-0.27723579]\n",
      " [ 0.11821886]]\n",
      "Iteration 843 | Cost: 0.48997429103192897 | Gradient: [[-0.04421815]\n",
      " [-0.27700585]\n",
      " [ 0.11826737]]\n",
      "Iteration 844 | Cost: 0.48988164735975737 | Gradient: [[-0.04412567]\n",
      " [-0.27677626]\n",
      " [ 0.11831577]]\n",
      "Iteration 845 | Cost: 0.48978912746850284 | Gradient: [[-0.04403333]\n",
      " [-0.27654703]\n",
      " [ 0.11836407]]\n",
      "Iteration 846 | Cost: 0.4896967310447429 | Gradient: [[-0.04394114]\n",
      " [-0.27631816]\n",
      " [ 0.11841227]]\n",
      "Iteration 847 | Cost: 0.4896044577760548 | Gradient: [[-0.0438491 ]\n",
      " [-0.27608965]\n",
      " [ 0.11846037]]\n",
      "Iteration 848 | Cost: 0.4895123073510118 | Gradient: [[-0.04375721]\n",
      " [-0.27586149]\n",
      " [ 0.11850837]]\n",
      "Iteration 849 | Cost: 0.489420279459179 | Gradient: [[-0.04366546]\n",
      " [-0.27563368]\n",
      " [ 0.11855626]]\n",
      "Iteration 850 | Cost: 0.48932837379111016 | Gradient: [[-0.04357386]\n",
      " [-0.27540623]\n",
      " [ 0.11860405]]\n",
      "Iteration 851 | Cost: 0.4892365900383438 | Gradient: [[-0.0434824 ]\n",
      " [-0.27517912]\n",
      " [ 0.11865175]]\n",
      "Iteration 852 | Cost: 0.4891449278933994 | Gradient: [[-0.04339109]\n",
      " [-0.27495238]\n",
      " [ 0.11869934]]\n",
      "Iteration 853 | Cost: 0.48905338704977436 | Gradient: [[-0.04329993]\n",
      " [-0.27472598]\n",
      " [ 0.11874683]]\n",
      "Iteration 854 | Cost: 0.48896196720193946 | Gradient: [[-0.04320891]\n",
      " [-0.27449993]\n",
      " [ 0.11879422]]\n",
      "Iteration 855 | Cost: 0.48887066804533597 | Gradient: [[-0.04311804]\n",
      " [-0.27427423]\n",
      " [ 0.11884152]]\n",
      "Iteration 856 | Cost: 0.48877948927637166 | Gradient: [[-0.04302731]\n",
      " [-0.27404889]\n",
      " [ 0.11888871]]\n",
      "Iteration 857 | Cost: 0.4886884305924178 | Gradient: [[-0.04293672]\n",
      " [-0.27382389]\n",
      " [ 0.1189358 ]]\n",
      "Iteration 858 | Cost: 0.48859749169180466 | Gradient: [[-0.04284628]\n",
      " [-0.27359923]\n",
      " [ 0.11898279]]\n",
      "Iteration 859 | Cost: 0.48850667227381905 | Gradient: [[-0.04275599]\n",
      " [-0.27337493]\n",
      " [ 0.11902969]]\n",
      "Iteration 860 | Cost: 0.48841597203869963 | Gradient: [[-0.04266583]\n",
      " [-0.27315097]\n",
      " [ 0.11907648]]\n",
      "Iteration 861 | Cost: 0.48832539068763436 | Gradient: [[-0.04257582]\n",
      " [-0.27292736]\n",
      " [ 0.11912318]]\n",
      "Iteration 862 | Cost: 0.4882349279227565 | Gradient: [[-0.04248595]\n",
      " [-0.27270409]\n",
      " [ 0.11916977]]\n",
      "Iteration 863 | Cost: 0.4881445834471413 | Gradient: [[-0.04239623]\n",
      " [-0.27248116]\n",
      " [ 0.11921627]]\n",
      "Iteration 864 | Cost: 0.48805435696480237 | Gradient: [[-0.04230664]\n",
      " [-0.27225858]\n",
      " [ 0.11926267]]\n",
      "Iteration 865 | Cost: 0.4879642481806884 | Gradient: [[-0.0422172 ]\n",
      " [-0.27203634]\n",
      " [ 0.11930898]]\n",
      "Iteration 866 | Cost: 0.48787425680067964 | Gradient: [[-0.0421279 ]\n",
      " [-0.27181444]\n",
      " [ 0.11935518]]\n",
      "Iteration 867 | Cost: 0.48778438253158424 | Gradient: [[-0.04203874]\n",
      " [-0.27159288]\n",
      " [ 0.11940129]]\n",
      "Iteration 868 | Cost: 0.4876946250811353 | Gradient: [[-0.04194972]\n",
      " [-0.27137166]\n",
      " [ 0.1194473 ]]\n",
      "Iteration 869 | Cost: 0.48760498415798714 | Gradient: [[-0.04186084]\n",
      " [-0.27115079]\n",
      " [ 0.11949322]]\n",
      "Iteration 870 | Cost: 0.4875154594717119 | Gradient: [[-0.04177211]\n",
      " [-0.27093025]\n",
      " [ 0.11953903]]\n",
      "Iteration 871 | Cost: 0.4874260507327962 | Gradient: [[-0.04168351]\n",
      " [-0.27071005]\n",
      " [ 0.11958475]]\n",
      "Iteration 872 | Cost: 0.48733675765263823 | Gradient: [[-0.04159505]\n",
      " [-0.27049018]\n",
      " [ 0.11963038]]\n",
      "Iteration 873 | Cost: 0.48724757994354345 | Gradient: [[-0.04150673]\n",
      " [-0.27027066]\n",
      " [ 0.1196759 ]]\n",
      "Iteration 874 | Cost: 0.48715851731872195 | Gradient: [[-0.04141855]\n",
      " [-0.27005147]\n",
      " [ 0.11972134]]\n",
      "Iteration 875 | Cost: 0.48706956949228514 | Gradient: [[-0.04133051]\n",
      " [-0.26983261]\n",
      " [ 0.11976667]]\n",
      "Iteration 876 | Cost: 0.4869807361792424 | Gradient: [[-0.04124261]\n",
      " [-0.26961409]\n",
      " [ 0.11981191]]\n",
      "Iteration 877 | Cost: 0.48689201709549706 | Gradient: [[-0.04115485]\n",
      " [-0.2693959 ]\n",
      " [ 0.11985706]]\n",
      "Iteration 878 | Cost: 0.48680341195784443 | Gradient: [[-0.04106722]\n",
      " [-0.26917805]\n",
      " [ 0.1199021 ]]\n",
      "Iteration 879 | Cost: 0.4867149204839674 | Gradient: [[-0.04097973]\n",
      " [-0.26896053]\n",
      " [ 0.11994706]]\n",
      "Iteration 880 | Cost: 0.48662654239243397 | Gradient: [[-0.04089238]\n",
      " [-0.26874334]\n",
      " [ 0.11999192]]\n",
      "Iteration 881 | Cost: 0.48653827740269323 | Gradient: [[-0.04080517]\n",
      " [-0.26852648]\n",
      " [ 0.12003668]]\n",
      "Iteration 882 | Cost: 0.48645012523507286 | Gradient: [[-0.04071809]\n",
      " [-0.26830995]\n",
      " [ 0.12008135]]\n",
      "Iteration 883 | Cost: 0.4863620856107756 | Gradient: [[-0.04063115]\n",
      " [-0.26809375]\n",
      " [ 0.12012593]]\n",
      "Iteration 884 | Cost: 0.486274158251876 | Gradient: [[-0.04054435]\n",
      " [-0.26787788]\n",
      " [ 0.12017041]]\n",
      "Iteration 885 | Cost: 0.48618634288131723 | Gradient: [[-0.04045768]\n",
      " [-0.26766234]\n",
      " [ 0.1202148 ]]\n",
      "Iteration 886 | Cost: 0.4860986392229083 | Gradient: [[-0.04037114]\n",
      " [-0.26744713]\n",
      " [ 0.12025909]]\n",
      "Iteration 887 | Cost: 0.4860110470013202 | Gradient: [[-0.04028475]\n",
      " [-0.26723224]\n",
      " [ 0.1203033 ]]\n",
      "Iteration 888 | Cost: 0.4859235659420834 | Gradient: [[-0.04019849]\n",
      " [-0.26701768]\n",
      " [ 0.1203474 ]]\n",
      "Iteration 889 | Cost: 0.4858361957715845 | Gradient: [[-0.04011236]\n",
      " [-0.26680345]\n",
      " [ 0.12039142]]\n",
      "Iteration 890 | Cost: 0.4857489362170626 | Gradient: [[-0.04002636]\n",
      " [-0.26658954]\n",
      " [ 0.12043534]]\n",
      "Iteration 891 | Cost: 0.4856617870066075 | Gradient: [[-0.03994051]\n",
      " [-0.26637595]\n",
      " [ 0.12047917]]\n",
      "Iteration 892 | Cost: 0.4855747478691549 | Gradient: [[-0.03985478]\n",
      " [-0.26616269]\n",
      " [ 0.12052291]]\n",
      "Iteration 893 | Cost: 0.4854878185344845 | Gradient: [[-0.03976919]\n",
      " [-0.26594975]\n",
      " [ 0.12056655]]\n",
      "Iteration 894 | Cost: 0.48540099873321696 | Gradient: [[-0.03968373]\n",
      " [-0.26573713]\n",
      " [ 0.1206101 ]]\n",
      "Iteration 895 | Cost: 0.48531428819681 | Gradient: [[-0.03959841]\n",
      " [-0.26552483]\n",
      " [ 0.12065356]]\n",
      "Iteration 896 | Cost: 0.485227686657556 | Gradient: [[-0.03951321]\n",
      " [-0.26531286]\n",
      " [ 0.12069693]]\n",
      "Iteration 897 | Cost: 0.485141193848579 | Gradient: [[-0.03942816]\n",
      " [-0.2651012 ]\n",
      " [ 0.12074021]]\n",
      "Iteration 898 | Cost: 0.4850548095038312 | Gradient: [[-0.03934323]\n",
      " [-0.26488987]\n",
      " [ 0.1207834 ]]\n",
      "Iteration 899 | Cost: 0.4849685333580905 | Gradient: [[-0.03925843]\n",
      " [-0.26467885]\n",
      " [ 0.12082649]]\n",
      "Iteration 900 | Cost: 0.48488236514695704 | Gradient: [[-0.03917377]\n",
      " [-0.26446815]\n",
      " [ 0.1208695 ]]\n",
      "Iteration 901 | Cost: 0.4847963046068508 | Gradient: [[-0.03908924]\n",
      " [-0.26425777]\n",
      " [ 0.12091241]]\n",
      "Iteration 902 | Cost: 0.48471035147500774 | Gradient: [[-0.03900484]\n",
      " [-0.26404771]\n",
      " [ 0.12095523]]\n",
      "Iteration 903 | Cost: 0.48462450548947766 | Gradient: [[-0.03892057]\n",
      " [-0.26383796]\n",
      " [ 0.12099797]]\n",
      "Iteration 904 | Cost: 0.4845387663891211 | Gradient: [[-0.03883643]\n",
      " [-0.26362853]\n",
      " [ 0.12104061]]\n",
      "Iteration 905 | Cost: 0.48445313391360584 | Gradient: [[-0.03875242]\n",
      " [-0.26341941]\n",
      " [ 0.12108316]]\n",
      "Iteration 906 | Cost: 0.4843676078034049 | Gradient: [[-0.03866854]\n",
      " [-0.26321061]\n",
      " [ 0.12112562]]\n",
      "Iteration 907 | Cost: 0.4842821877997926 | Gradient: [[-0.03858479]\n",
      " [-0.26300212]\n",
      " [ 0.121168  ]]\n",
      "Iteration 908 | Cost: 0.48419687364484265 | Gradient: [[-0.03850117]\n",
      " [-0.26279394]\n",
      " [ 0.12121028]]\n",
      "Iteration 909 | Cost: 0.4841116650814246 | Gradient: [[-0.03841768]\n",
      " [-0.26258608]\n",
      " [ 0.12125247]]\n",
      "Iteration 910 | Cost: 0.4840265618532012 | Gradient: [[-0.03833432]\n",
      " [-0.26237853]\n",
      " [ 0.12129458]]\n",
      "Iteration 911 | Cost: 0.4839415637046253 | Gradient: [[-0.03825109]\n",
      " [-0.26217128]\n",
      " [ 0.1213366 ]]\n",
      "Iteration 912 | Cost: 0.4838566703809377 | Gradient: [[-0.03816798]\n",
      " [-0.26196435]\n",
      " [ 0.12137852]]\n",
      "Iteration 913 | Cost: 0.48377188162816326 | Gradient: [[-0.03808501]\n",
      " [-0.26175773]\n",
      " [ 0.12142036]]\n",
      "Iteration 914 | Cost: 0.48368719719310904 | Gradient: [[-0.03800216]\n",
      " [-0.26155142]\n",
      " [ 0.12146211]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 915 | Cost: 0.4836026168233608 | Gradient: [[-0.03791944]\n",
      " [-0.26134541]\n",
      " [ 0.12150378]]\n",
      "Iteration 916 | Cost: 0.4835181402672806 | Gradient: [[-0.03783685]\n",
      " [-0.26113972]\n",
      " [ 0.12154535]]\n",
      "Iteration 917 | Cost: 0.48343376727400383 | Gradient: [[-0.03775438]\n",
      " [-0.26093433]\n",
      " [ 0.12158684]]\n",
      "Iteration 918 | Cost: 0.4833494975934366 | Gradient: [[-0.03767204]\n",
      " [-0.26072925]\n",
      " [ 0.12162824]]\n",
      "Iteration 919 | Cost: 0.48326533097625246 | Gradient: [[-0.03758983]\n",
      " [-0.26052447]\n",
      " [ 0.12166955]]\n",
      "Iteration 920 | Cost: 0.4831812671738906 | Gradient: [[-0.03750774]\n",
      " [-0.26032   ]\n",
      " [ 0.12171078]]\n",
      "Iteration 921 | Cost: 0.48309730593855194 | Gradient: [[-0.03742578]\n",
      " [-0.26011583]\n",
      " [ 0.12175191]]\n",
      "Iteration 922 | Cost: 0.4830134470231973 | Gradient: [[-0.03734395]\n",
      " [-0.25991197]\n",
      " [ 0.12179297]]\n",
      "Iteration 923 | Cost: 0.48292969018154436 | Gradient: [[-0.03726224]\n",
      " [-0.25970841]\n",
      " [ 0.12183393]]\n",
      "Iteration 924 | Cost: 0.4828460351680646 | Gradient: [[-0.03718066]\n",
      " [-0.25950515]\n",
      " [ 0.12187481]]\n",
      "Iteration 925 | Cost: 0.48276248173798153 | Gradient: [[-0.0370992]\n",
      " [-0.2593022]\n",
      " [ 0.1219156]]\n",
      "Iteration 926 | Cost: 0.4826790296472667 | Gradient: [[-0.03701787]\n",
      " [-0.25909954]\n",
      " [ 0.12195631]]\n",
      "Iteration 927 | Cost: 0.4825956786526382 | Gradient: [[-0.03693666]\n",
      " [-0.25889719]\n",
      " [ 0.12199693]]\n",
      "Iteration 928 | Cost: 0.4825124285115573 | Gradient: [[-0.03685557]\n",
      " [-0.25869514]\n",
      " [ 0.12203746]]\n",
      "Iteration 929 | Cost: 0.48242927898222593 | Gradient: [[-0.03677461]\n",
      " [-0.25849339]\n",
      " [ 0.12207791]]\n",
      "Iteration 930 | Cost: 0.4823462298235844 | Gradient: [[-0.03669378]\n",
      " [-0.25829194]\n",
      " [ 0.12211827]]\n",
      "Iteration 931 | Cost: 0.48226328079530806 | Gradient: [[-0.03661306]\n",
      " [-0.25809078]\n",
      " [ 0.12215855]]\n",
      "Iteration 932 | Cost: 0.4821804316578052 | Gradient: [[-0.03653247]\n",
      " [-0.25788993]\n",
      " [ 0.12219874]]\n",
      "Iteration 933 | Cost: 0.4820976821722145 | Gradient: [[-0.03645201]\n",
      " [-0.25768937]\n",
      " [ 0.12223885]]\n",
      "Iteration 934 | Cost: 0.4820150321004018 | Gradient: [[-0.03637166]\n",
      " [-0.2574891 ]\n",
      " [ 0.12227887]]\n",
      "Iteration 935 | Cost: 0.4819324812049583 | Gradient: [[-0.03629144]\n",
      " [-0.25728914]\n",
      " [ 0.12231881]]\n",
      "Iteration 936 | Cost: 0.4818500292491975 | Gradient: [[-0.03621134]\n",
      " [-0.25708947]\n",
      " [ 0.12235867]]\n",
      "Iteration 937 | Cost: 0.48176767599715253 | Gradient: [[-0.03613136]\n",
      " [-0.25689009]\n",
      " [ 0.12239844]]\n",
      "Iteration 938 | Cost: 0.48168542121357394 | Gradient: [[-0.03605151]\n",
      " [-0.25669101]\n",
      " [ 0.12243812]]\n",
      "Iteration 939 | Cost: 0.481603264663927 | Gradient: [[-0.03597177]\n",
      " [-0.25649222]\n",
      " [ 0.12247772]]\n",
      "Iteration 940 | Cost: 0.481521206114389 | Gradient: [[-0.03589216]\n",
      " [-0.25629372]\n",
      " [ 0.12251724]]\n",
      "Iteration 941 | Cost: 0.4814392453318469 | Gradient: [[-0.03581267]\n",
      " [-0.25609552]\n",
      " [ 0.12255668]]\n",
      "Iteration 942 | Cost: 0.4813573820838948 | Gradient: [[-0.0357333 ]\n",
      " [-0.25589761]\n",
      " [ 0.12259603]]\n",
      "Iteration 943 | Cost: 0.48127561613883135 | Gradient: [[-0.03565405]\n",
      " [-0.25569999]\n",
      " [ 0.1226353 ]]\n",
      "Iteration 944 | Cost: 0.48119394726565723 | Gradient: [[-0.03557492]\n",
      " [-0.25550266]\n",
      " [ 0.12267448]]\n",
      "Iteration 945 | Cost: 0.48111237523407285 | Gradient: [[-0.03549591]\n",
      " [-0.25530562]\n",
      " [ 0.12271359]]\n",
      "Iteration 946 | Cost: 0.48103089981447544 | Gradient: [[-0.03541702]\n",
      " [-0.25510887]\n",
      " [ 0.12275261]]\n",
      "Iteration 947 | Cost: 0.48094952077795716 | Gradient: [[-0.03533825]\n",
      " [-0.25491241]\n",
      " [ 0.12279154]]\n",
      "Iteration 948 | Cost: 0.4808682378963022 | Gradient: [[-0.0352596 ]\n",
      " [-0.25471624]\n",
      " [ 0.1228304 ]]\n",
      "Iteration 949 | Cost: 0.4807870509419842 | Gradient: [[-0.03518106]\n",
      " [-0.25452035]\n",
      " [ 0.12286917]]\n",
      "Iteration 950 | Cost: 0.4807059596881645 | Gradient: [[-0.03510265]\n",
      " [-0.25432475]\n",
      " [ 0.12290786]]\n",
      "Iteration 951 | Cost: 0.4806249639086891 | Gradient: [[-0.03502435]\n",
      " [-0.25412944]\n",
      " [ 0.12294647]]\n",
      "Iteration 952 | Cost: 0.48054406337808625 | Gradient: [[-0.03494618]\n",
      " [-0.25393442]\n",
      " [ 0.122985  ]]\n",
      "Iteration 953 | Cost: 0.4804632578715644 | Gradient: [[-0.03486812]\n",
      " [-0.25373968]\n",
      " [ 0.12302345]]\n",
      "Iteration 954 | Cost: 0.4803825471650094 | Gradient: [[-0.03479018]\n",
      " [-0.25354522]\n",
      " [ 0.12306181]]\n",
      "Iteration 955 | Cost: 0.4803019310349824 | Gradient: [[-0.03471236]\n",
      " [-0.25335105]\n",
      " [ 0.1231001 ]]\n",
      "Iteration 956 | Cost: 0.48022140925871737 | Gradient: [[-0.03463465]\n",
      " [-0.25315716]\n",
      " [ 0.1231383 ]]\n",
      "Iteration 957 | Cost: 0.48014098161411867 | Gradient: [[-0.03455706]\n",
      " [-0.25296356]\n",
      " [ 0.12317642]]\n",
      "Iteration 958 | Cost: 0.4800606478797586 | Gradient: [[-0.03447959]\n",
      " [-0.25277024]\n",
      " [ 0.12321446]]\n",
      "Iteration 959 | Cost: 0.47998040783487533 | Gradient: [[-0.03440223]\n",
      " [-0.2525772 ]\n",
      " [ 0.12325243]]\n",
      "Iteration 960 | Cost: 0.47990026125937024 | Gradient: [[-0.034325  ]\n",
      " [-0.25238444]\n",
      " [ 0.12329031]]\n",
      "Iteration 961 | Cost: 0.4798202079338059 | Gradient: [[-0.03424787]\n",
      " [-0.25219196]\n",
      " [ 0.12332811]]\n",
      "Iteration 962 | Cost: 0.4797402476394035 | Gradient: [[-0.03417087]\n",
      " [-0.25199976]\n",
      " [ 0.12336583]]\n",
      "Iteration 963 | Cost: 0.4796603801580403 | Gradient: [[-0.03409398]\n",
      " [-0.25180785]\n",
      " [ 0.12340347]]\n",
      "Iteration 964 | Cost: 0.47958060527224816 | Gradient: [[-0.0340172 ]\n",
      " [-0.25161621]\n",
      " [ 0.12344103]]\n",
      "Iteration 965 | Cost: 0.4795009227652102 | Gradient: [[-0.03394054]\n",
      " [-0.25142485]\n",
      " [ 0.12347851]]\n",
      "Iteration 966 | Cost: 0.4794213324207593 | Gradient: [[-0.033864  ]\n",
      " [-0.25123377]\n",
      " [ 0.12351591]]\n",
      "Iteration 967 | Cost: 0.4793418340233754 | Gradient: [[-0.03378757]\n",
      " [-0.25104296]\n",
      " [ 0.12355324]]\n",
      "Iteration 968 | Cost: 0.47926242735818336 | Gradient: [[-0.03371125]\n",
      " [-0.25085243]\n",
      " [ 0.12359048]]\n",
      "Iteration 969 | Cost: 0.4791831122109506 | Gradient: [[-0.03363505]\n",
      " [-0.25066218]\n",
      " [ 0.12362765]]\n",
      "Iteration 970 | Cost: 0.4791038883680851 | Gradient: [[-0.03355896]\n",
      " [-0.25047221]\n",
      " [ 0.12366473]]\n",
      "Iteration 971 | Cost: 0.4790247556166328 | Gradient: [[-0.03348299]\n",
      " [-0.25028251]\n",
      " [ 0.12370174]]\n",
      "Iteration 972 | Cost: 0.47894571374427575 | Gradient: [[-0.03340713]\n",
      " [-0.25009308]\n",
      " [ 0.12373867]]\n",
      "Iteration 973 | Cost: 0.4788667625393293 | Gradient: [[-0.03333138]\n",
      " [-0.24990393]\n",
      " [ 0.12377552]]\n",
      "Iteration 974 | Cost: 0.47878790179074066 | Gradient: [[-0.03325575]\n",
      " [-0.24971505]\n",
      " [ 0.1238123 ]]\n",
      "Iteration 975 | Cost: 0.4787091312880861 | Gradient: [[-0.03318023]\n",
      " [-0.24952645]\n",
      " [ 0.12384899]]\n",
      "Iteration 976 | Cost: 0.4786304508215688 | Gradient: [[-0.03310482]\n",
      " [-0.24933812]\n",
      " [ 0.12388561]]\n",
      "Iteration 977 | Cost: 0.4785518601820169 | Gradient: [[-0.03302953]\n",
      " [-0.24915005]\n",
      " [ 0.12392215]]\n",
      "Iteration 978 | Cost: 0.4784733591608813 | Gradient: [[-0.03295434]\n",
      " [-0.24896227]\n",
      " [ 0.12395861]]\n",
      "Iteration 979 | Cost: 0.4783949475502332 | Gradient: [[-0.03287927]\n",
      " [-0.24877475]\n",
      " [ 0.123995  ]]\n",
      "Iteration 980 | Cost: 0.47831662514276224 | Gradient: [[-0.03280431]\n",
      " [-0.2485875 ]\n",
      " [ 0.12403131]]\n",
      "Iteration 981 | Cost: 0.47823839173177407 | Gradient: [[-0.03272947]\n",
      " [-0.24840052]\n",
      " [ 0.12406754]]\n",
      "Iteration 982 | Cost: 0.4781602471111885 | Gradient: [[-0.03265473]\n",
      " [-0.24821381]\n",
      " [ 0.1241037 ]]\n",
      "Iteration 983 | Cost: 0.4780821910755371 | Gradient: [[-0.03258011]\n",
      " [-0.24802737]\n",
      " [ 0.12413977]]\n",
      "Iteration 984 | Cost: 0.47800422341996124 | Gradient: [[-0.03250559]\n",
      " [-0.2478412 ]\n",
      " [ 0.12417578]]\n",
      "Iteration 985 | Cost: 0.4779263439402098 | Gradient: [[-0.03243119]\n",
      " [-0.2476553 ]\n",
      " [ 0.1242117 ]]\n",
      "Iteration 986 | Cost: 0.47784855243263724 | Gradient: [[-0.0323569 ]\n",
      " [-0.24746966]\n",
      " [ 0.12424755]]\n",
      "Iteration 987 | Cost: 0.4777708486942012 | Gradient: [[-0.03228272]\n",
      " [-0.24728429]\n",
      " [ 0.12428332]]\n",
      "Iteration 988 | Cost: 0.477693232522461 | Gradient: [[-0.03220864]\n",
      " [-0.24709918]\n",
      " [ 0.12431902]]\n",
      "Iteration 989 | Cost: 0.47761570371557455 | Gradient: [[-0.03213468]\n",
      " [-0.24691434]\n",
      " [ 0.12435464]]\n",
      "Iteration 990 | Cost: 0.4775382620722974 | Gradient: [[-0.03206083]\n",
      " [-0.24672977]\n",
      " [ 0.12439019]]\n",
      "Iteration 991 | Cost: 0.4774609073919799 | Gradient: [[-0.03198709]\n",
      " [-0.24654546]\n",
      " [ 0.12442566]]\n",
      "Iteration 992 | Cost: 0.4773836394745654 | Gradient: [[-0.03191345]\n",
      " [-0.24636141]\n",
      " [ 0.12446105]]\n",
      "Iteration 993 | Cost: 0.47730645812058814 | Gradient: [[-0.03183993]\n",
      " [-0.24617763]\n",
      " [ 0.12449637]]\n",
      "Iteration 994 | Cost: 0.4772293631311711 | Gradient: [[-0.03176651]\n",
      " [-0.24599411]\n",
      " [ 0.12453162]]\n",
      "Iteration 995 | Cost: 0.4771523543080242 | Gradient: [[-0.0316932 ]\n",
      " [-0.24581086]\n",
      " [ 0.12456679]]\n",
      "Iteration 996 | Cost: 0.4770754314534422 | Gradient: [[-0.03162   ]\n",
      " [-0.24562786]\n",
      " [ 0.12460189]]\n",
      "Iteration 997 | Cost: 0.4769985943703024 | Gradient: [[-0.03154691]\n",
      " [-0.24544513]\n",
      " [ 0.12463691]]\n",
      "Iteration 998 | Cost: 0.4769218428620629 | Gradient: [[-0.03147393]\n",
      " [-0.24526265]\n",
      " [ 0.12467185]]\n",
      "Iteration 999 | Cost: 0.47684517673276067 | Gradient: [[-0.03140105]\n",
      " [-0.24508044]\n",
      " [ 0.12470673]]\n",
      "Iteration 1000 | Cost: 0.4767685957870091 | Gradient: [[-0.03132829]\n",
      " [-0.24489849]\n",
      " [ 0.12474153]]\n",
      "Iteration 1001 | Cost: 0.4766920998299965 | Gradient: [[-0.03125563]\n",
      " [-0.24471679]\n",
      " [ 0.12477625]]\n",
      "Iteration 1002 | Cost: 0.47661568866748405 | Gradient: [[-0.03118307]\n",
      " [-0.24453536]\n",
      " [ 0.1248109 ]]\n",
      "Iteration 1003 | Cost: 0.47653936210580333 | Gradient: [[-0.03111062]\n",
      " [-0.24435418]\n",
      " [ 0.12484548]]\n",
      "Iteration 1004 | Cost: 0.4764631199518549 | Gradient: [[-0.03103828]\n",
      " [-0.24417326]\n",
      " [ 0.12487998]]\n",
      "Iteration 1005 | Cost: 0.4763869620131062 | Gradient: [[-0.03096605]\n",
      " [-0.2439926 ]\n",
      " [ 0.12491441]]\n",
      "Iteration 1006 | Cost: 0.4763108880975894 | Gradient: [[-0.03089392]\n",
      " [-0.2438122 ]\n",
      " [ 0.12494877]]\n",
      "Iteration 1007 | Cost: 0.4762348980138996 | Gradient: [[-0.0308219 ]\n",
      " [-0.24363205]\n",
      " [ 0.12498306]]\n",
      "Iteration 1008 | Cost: 0.47615899157119307 | Gradient: [[-0.03074998]\n",
      " [-0.24345215]\n",
      " [ 0.12501727]]\n",
      "Iteration 1009 | Cost: 0.47608316857918465 | Gradient: [[-0.03067817]\n",
      " [-0.24327252]\n",
      " [ 0.12505141]]\n",
      "Iteration 1010 | Cost: 0.4760074288481468 | Gradient: [[-0.03060647]\n",
      " [-0.24309313]\n",
      " [ 0.12508547]]\n",
      "Iteration 1011 | Cost: 0.475931772188907 | Gradient: [[-0.03053487]\n",
      " [-0.242914  ]\n",
      " [ 0.12511947]]\n",
      "Iteration 1012 | Cost: 0.4758561984128458 | Gradient: [[-0.03046337]\n",
      " [-0.24273513]\n",
      " [ 0.12515339]]\n",
      "Iteration 1013 | Cost: 0.47578070733189565 | Gradient: [[-0.03039198]\n",
      " [-0.24255651]\n",
      " [ 0.12518724]]\n",
      "Iteration 1014 | Cost: 0.47570529875853784 | Gradient: [[-0.0303207 ]\n",
      " [-0.24237814]\n",
      " [ 0.12522101]]\n",
      "Iteration 1015 | Cost: 0.4756299725058017 | Gradient: [[-0.03024952]\n",
      " [-0.24220002]\n",
      " [ 0.12525472]]\n",
      "Iteration 1016 | Cost: 0.47555472838726204 | Gradient: [[-0.03017844]\n",
      " [-0.24202216]\n",
      " [ 0.12528835]]\n",
      "Iteration 1017 | Cost: 0.4754795662170379 | Gradient: [[-0.03010747]\n",
      " [-0.24184454]\n",
      " [ 0.12532191]]\n",
      "Iteration 1018 | Cost: 0.47540448580978983 | Gradient: [[-0.0300366 ]\n",
      " [-0.24166718]\n",
      " [ 0.12535541]]\n",
      "Iteration 1019 | Cost: 0.4753294869807187 | Gradient: [[-0.02996583]\n",
      " [-0.24149007]\n",
      " [ 0.12538882]]\n",
      "Iteration 1020 | Cost: 0.4752545695455638 | Gradient: [[-0.02989517]\n",
      " [-0.2413132 ]\n",
      " [ 0.12542217]]\n",
      "Iteration 1021 | Cost: 0.4751797333206005 | Gradient: [[-0.02982461]\n",
      " [-0.24113659]\n",
      " [ 0.12545545]]\n",
      "Iteration 1022 | Cost: 0.475104978122639 | Gradient: [[-0.02975415]\n",
      " [-0.24096022]\n",
      " [ 0.12548866]]\n",
      "Iteration 1023 | Cost: 0.4750303037690222 | Gradient: [[-0.0296838 ]\n",
      " [-0.24078411]\n",
      " [ 0.12552179]]\n",
      "Iteration 1024 | Cost: 0.4749557100776242 | Gradient: [[-0.02961355]\n",
      " [-0.24060824]\n",
      " [ 0.12555486]]\n",
      "Iteration 1025 | Cost: 0.47488119686684765 | Gradient: [[-0.0295434 ]\n",
      " [-0.24043261]\n",
      " [ 0.12558785]]\n",
      "Iteration 1026 | Cost: 0.47480676395562277 | Gradient: [[-0.02947335]\n",
      " [-0.24025724]\n",
      " [ 0.12562078]]\n",
      "Iteration 1027 | Cost: 0.4747324111634058 | Gradient: [[-0.0294034 ]\n",
      " [-0.24008211]\n",
      " [ 0.12565363]]\n",
      "Iteration 1028 | Cost: 0.4746581383101758 | Gradient: [[-0.02933356]\n",
      " [-0.23990723]\n",
      " [ 0.12568641]]\n",
      "Iteration 1029 | Cost: 0.4745839452164344 | Gradient: [[-0.02926382]\n",
      " [-0.23973259]\n",
      " [ 0.12571913]]\n",
      "Iteration 1030 | Cost: 0.474509831703203 | Gradient: [[-0.02919418]\n",
      " [-0.2395582 ]\n",
      " [ 0.12575177]]\n",
      "Iteration 1031 | Cost: 0.4744357975920217 | Gradient: [[-0.02912464]\n",
      " [-0.23938405]\n",
      " [ 0.12578435]]\n",
      "Iteration 1032 | Cost: 0.474361842704947 | Gradient: [[-0.0290552 ]\n",
      " [-0.23921015]\n",
      " [ 0.12581685]]\n",
      "Iteration 1033 | Cost: 0.47428796686455044 | Gradient: [[-0.02898586]\n",
      " [-0.23903649]\n",
      " [ 0.12584929]]\n",
      "Iteration 1034 | Cost: 0.47421416989391624 | Gradient: [[-0.02891662]\n",
      " [-0.23886307]\n",
      " [ 0.12588165]]\n",
      "Iteration 1035 | Cost: 0.4741404516166405 | Gradient: [[-0.02884749]\n",
      " [-0.23868989]\n",
      " [ 0.12591395]]\n",
      "Iteration 1036 | Cost: 0.4740668118568284 | Gradient: [[-0.02877845]\n",
      " [-0.23851696]\n",
      " [ 0.12594618]]\n",
      "Iteration 1037 | Cost: 0.47399325043909346 | Gradient: [[-0.02870951]\n",
      " [-0.23834427]\n",
      " [ 0.12597834]]\n",
      "Iteration 1038 | Cost: 0.47391976718855516 | Gradient: [[-0.02864068]\n",
      " [-0.23817182]\n",
      " [ 0.12601043]]\n",
      "Iteration 1039 | Cost: 0.4738463619308373 | Gradient: [[-0.02857194]\n",
      " [-0.23799961]\n",
      " [ 0.12604245]]\n",
      "Iteration 1040 | Cost: 0.4737730344920664 | Gradient: [[-0.0285033 ]\n",
      " [-0.23782764]\n",
      " [ 0.12607441]]\n",
      "Iteration 1041 | Cost: 0.47369978469887036 | Gradient: [[-0.02843476]\n",
      " [-0.23765591]\n",
      " [ 0.12610629]]\n",
      "Iteration 1042 | Cost: 0.47362661237837583 | Gradient: [[-0.02836632]\n",
      " [-0.23748442]\n",
      " [ 0.12613811]]\n",
      "Iteration 1043 | Cost: 0.4735535173582075 | Gradient: [[-0.02829798]\n",
      " [-0.23731317]\n",
      " [ 0.12616986]]\n",
      "Iteration 1044 | Cost: 0.47348049946648574 | Gradient: [[-0.02822974]\n",
      " [-0.23714216]\n",
      " [ 0.12620154]]\n",
      "Iteration 1045 | Cost: 0.4734075585318255 | Gradient: [[-0.02816159]\n",
      " [-0.23697139]\n",
      " [ 0.12623316]]\n",
      "Iteration 1046 | Cost: 0.47333469438333386 | Gradient: [[-0.02809355]\n",
      " [-0.23680085]\n",
      " [ 0.1262647 ]]\n",
      "Iteration 1047 | Cost: 0.4732619068506092 | Gradient: [[-0.0280256 ]\n",
      " [-0.23663055]\n",
      " [ 0.12629618]]\n",
      "Iteration 1048 | Cost: 0.4731891957637389 | Gradient: [[-0.02795775]\n",
      " [-0.23646049]\n",
      " [ 0.12632759]]\n",
      "Iteration 1049 | Cost: 0.47311656095329796 | Gradient: [[-0.02789   ]\n",
      " [-0.23629066]\n",
      " [ 0.12635894]]\n",
      "Iteration 1050 | Cost: 0.4730440022503475 | Gradient: [[-0.02782234]\n",
      " [-0.23612107]\n",
      " [ 0.12639022]]\n",
      "Iteration 1051 | Cost: 0.47297151948643285 | Gradient: [[-0.02775478]\n",
      " [-0.23595171]\n",
      " [ 0.12642143]]\n",
      "Iteration 1052 | Cost: 0.47289911249358185 | Gradient: [[-0.02768732]\n",
      " [-0.23578259]\n",
      " [ 0.12645257]]\n",
      "Iteration 1053 | Cost: 0.4728267811043038 | Gradient: [[-0.02761996]\n",
      " [-0.2356137 ]\n",
      " [ 0.12648365]]\n",
      "Iteration 1054 | Cost: 0.4727545251515869 | Gradient: [[-0.02755269]\n",
      " [-0.23544505]\n",
      " [ 0.12651466]]\n",
      "Iteration 1055 | Cost: 0.4726823444688975 | Gradient: [[-0.02748552]\n",
      " [-0.23527662]\n",
      " [ 0.1265456 ]]\n",
      "Iteration 1056 | Cost: 0.47261023889017806 | Gradient: [[-0.02741844]\n",
      " [-0.23510844]\n",
      " [ 0.12657648]]\n",
      "Iteration 1057 | Cost: 0.47253820824984566 | Gradient: [[-0.02735147]\n",
      " [-0.23494048]\n",
      " [ 0.12660729]]\n",
      "Iteration 1058 | Cost: 0.4724662523827902 | Gradient: [[-0.02728458]\n",
      " [-0.23477276]\n",
      " [ 0.12663804]]\n",
      "Iteration 1059 | Cost: 0.47239437112437316 | Gradient: [[-0.0272178 ]\n",
      " [-0.23460527]\n",
      " [ 0.12666872]]\n",
      "Iteration 1060 | Cost: 0.47232256431042585 | Gradient: [[-0.02715111]\n",
      " [-0.23443801]\n",
      " [ 0.12669933]]\n",
      "Iteration 1061 | Cost: 0.4722508317772477 | Gradient: [[-0.02708451]\n",
      " [-0.23427098]\n",
      " [ 0.12672988]]\n",
      "Iteration 1062 | Cost: 0.47217917336160486 | Gradient: [[-0.02701801]\n",
      " [-0.23410418]\n",
      " [ 0.12676036]]\n",
      "Iteration 1063 | Cost: 0.4721075889007286 | Gradient: [[-0.02695161]\n",
      " [-0.23393761]\n",
      " [ 0.12679078]]\n",
      "Iteration 1064 | Cost: 0.4720360782323137 | Gradient: [[-0.0268853 ]\n",
      " [-0.23377127]\n",
      " [ 0.12682113]]\n",
      "Iteration 1065 | Cost: 0.47196464119451687 | Gradient: [[-0.02681908]\n",
      " [-0.23360516]\n",
      " [ 0.12685142]]\n",
      "Iteration 1066 | Cost: 0.4718932776259552 | Gradient: [[-0.02675296]\n",
      " [-0.23343927]\n",
      " [ 0.12688164]]\n",
      "Iteration 1067 | Cost: 0.4718219873657049 | Gradient: [[-0.02668693]\n",
      " [-0.23327362]\n",
      " [ 0.1269118 ]]\n",
      "Iteration 1068 | Cost: 0.4717507702532993 | Gradient: [[-0.026621  ]\n",
      " [-0.23310819]\n",
      " [ 0.12694189]]\n",
      "Iteration 1069 | Cost: 0.4716796261287277 | Gradient: [[-0.02655516]\n",
      " [-0.23294299]\n",
      " [ 0.12697192]]\n",
      "Iteration 1070 | Cost: 0.4716085548324336 | Gradient: [[-0.02648942]\n",
      " [-0.23277802]\n",
      " [ 0.12700188]]\n",
      "Iteration 1071 | Cost: 0.4715375562053132 | Gradient: [[-0.02642377]\n",
      " [-0.23261327]\n",
      " [ 0.12703178]]\n",
      "Iteration 1072 | Cost: 0.4714666300887141 | Gradient: [[-0.02635821]\n",
      " [-0.23244875]\n",
      " [ 0.12706161]]\n",
      "Iteration 1073 | Cost: 0.4713957763244335 | Gradient: [[-0.02629274]\n",
      " [-0.23228446]\n",
      " [ 0.12709139]]\n",
      "Iteration 1074 | Cost: 0.4713249947547172 | Gradient: [[-0.02622737]\n",
      " [-0.23212039]\n",
      " [ 0.12712109]]\n",
      "Iteration 1075 | Cost: 0.4712542852222572 | Gradient: [[-0.02616209]\n",
      " [-0.23195654]\n",
      " [ 0.12715073]]\n",
      "Iteration 1076 | Cost: 0.4711836475701911 | Gradient: [[-0.02609691]\n",
      " [-0.23179292]\n",
      " [ 0.12718031]]\n",
      "Iteration 1077 | Cost: 0.47111308164210025 | Gradient: [[-0.02603181]\n",
      " [-0.23162952]\n",
      " [ 0.12720983]]\n",
      "Iteration 1078 | Cost: 0.4710425872820084 | Gradient: [[-0.02596681]\n",
      " [-0.23146635]\n",
      " [ 0.12723928]]\n",
      "Iteration 1079 | Cost: 0.4709721643343796 | Gradient: [[-0.0259019 ]\n",
      " [-0.2313034 ]\n",
      " [ 0.12726867]]\n",
      "Iteration 1080 | Cost: 0.47090181264411796 | Gradient: [[-0.02583709]\n",
      " [-0.23114067]\n",
      " [ 0.12729799]]\n",
      "Iteration 1081 | Cost: 0.4708315320565649 | Gradient: [[-0.02577236]\n",
      " [-0.23097816]\n",
      " [ 0.12732726]]\n",
      "Iteration 1082 | Cost: 0.47076132241749863 | Gradient: [[-0.02570773]\n",
      " [-0.23081588]\n",
      " [ 0.12735645]]\n",
      "Iteration 1083 | Cost: 0.47069118357313217 | Gradient: [[-0.02564319]\n",
      " [-0.23065381]\n",
      " [ 0.12738559]]\n",
      "Iteration 1084 | Cost: 0.47062111537011203 | Gradient: [[-0.02557874]\n",
      " [-0.23049197]\n",
      " [ 0.12741466]]\n",
      "Iteration 1085 | Cost: 0.47055111765551694 | Gradient: [[-0.02551438]\n",
      " [-0.23033035]\n",
      " [ 0.12744367]]\n",
      "Iteration 1086 | Cost: 0.4704811902768562 | Gradient: [[-0.02545011]\n",
      " [-0.23016895]\n",
      " [ 0.12747262]]\n",
      "Iteration 1087 | Cost: 0.47041133308206845 | Gradient: [[-0.02538593]\n",
      " [-0.23000776]\n",
      " [ 0.12750151]]\n",
      "Iteration 1088 | Cost: 0.4703415459195198 | Gradient: [[-0.02532184]\n",
      " [-0.2298468 ]\n",
      " [ 0.12753033]]\n",
      "Iteration 1089 | Cost: 0.47027182863800315 | Gradient: [[-0.02525785]\n",
      " [-0.22968605]\n",
      " [ 0.12755909]]\n",
      "Iteration 1090 | Cost: 0.47020218108673617 | Gradient: [[-0.02519394]\n",
      " [-0.22952553]\n",
      " [ 0.12758779]]\n",
      "Iteration 1091 | Cost: 0.47013260311536 | Gradient: [[-0.02513013]\n",
      " [-0.22936522]\n",
      " [ 0.12761643]]\n",
      "Iteration 1092 | Cost: 0.4700630945739381 | Gradient: [[-0.0250664 ]\n",
      " [-0.22920513]\n",
      " [ 0.12764501]]\n",
      "Iteration 1093 | Cost: 0.4699936553129547 | Gradient: [[-0.02500276]\n",
      " [-0.22904525]\n",
      " [ 0.12767352]]\n",
      "Iteration 1094 | Cost: 0.4699242851833131 | Gradient: [[-0.02493922]\n",
      " [-0.22888559]\n",
      " [ 0.12770197]]\n",
      "Iteration 1095 | Cost: 0.469854984036335 | Gradient: [[-0.02487576]\n",
      " [-0.22872615]\n",
      " [ 0.12773036]]\n",
      "Iteration 1096 | Cost: 0.46978575172375825 | Gradient: [[-0.02481239]\n",
      " [-0.22856693]\n",
      " [ 0.12775869]]\n",
      "Iteration 1097 | Cost: 0.46971658809773625 | Gradient: [[-0.02474911]\n",
      " [-0.22840792]\n",
      " [ 0.12778696]]\n",
      "Iteration 1098 | Cost: 0.46964749301083625 | Gradient: [[-0.02468592]\n",
      " [-0.22824912]\n",
      " [ 0.12781517]]\n",
      "Iteration 1099 | Cost: 0.46957846631603767 | Gradient: [[-0.02462282]\n",
      " [-0.22809054]\n",
      " [ 0.12784331]]\n",
      "Iteration 1100 | Cost: 0.4695095078667313 | Gradient: [[-0.02455981]\n",
      " [-0.22793218]\n",
      " [ 0.1278714 ]]\n",
      "Iteration 1101 | Cost: 0.4694406175167177 | Gradient: [[-0.02449689]\n",
      " [-0.22777403]\n",
      " [ 0.12789942]]\n",
      "Iteration 1102 | Cost: 0.46937179512020566 | Gradient: [[-0.02443405]\n",
      " [-0.22761609]\n",
      " [ 0.12792739]]\n",
      "Iteration 1103 | Cost: 0.4693030405318112 | Gradient: [[-0.0243713 ]\n",
      " [-0.22745836]\n",
      " [ 0.12795529]]\n",
      "Iteration 1104 | Cost: 0.4692343536065561 | Gradient: [[-0.02430864]\n",
      " [-0.22730085]\n",
      " [ 0.12798313]]\n",
      "Iteration 1105 | Cost: 0.4691657341998662 | Gradient: [[-0.02424607]\n",
      " [-0.22714355]\n",
      " [ 0.12801091]]\n",
      "Iteration 1106 | Cost: 0.4690971821675707 | Gradient: [[-0.02418359]\n",
      " [-0.22698646]\n",
      " [ 0.12803864]]\n",
      "Iteration 1107 | Cost: 0.4690286973659005 | Gradient: [[-0.02412119]\n",
      " [-0.22682958]\n",
      " [ 0.1280663 ]]\n",
      "Iteration 1108 | Cost: 0.46896027965148696 | Gradient: [[-0.02405888]\n",
      " [-0.22667292]\n",
      " [ 0.1280939 ]]\n",
      "Iteration 1109 | Cost: 0.4688919288813602 | Gradient: [[-0.02399666]\n",
      " [-0.22651646]\n",
      " [ 0.12812144]]\n",
      "Iteration 1110 | Cost: 0.46882364491294853 | Gradient: [[-0.02393452]\n",
      " [-0.22636021]\n",
      " [ 0.12814893]]\n",
      "Iteration 1111 | Cost: 0.46875542760407657 | Gradient: [[-0.02387247]\n",
      " [-0.22620418]\n",
      " [ 0.12817635]]\n",
      "Iteration 1112 | Cost: 0.468687276812964 | Gradient: [[-0.02381051]\n",
      " [-0.22604835]\n",
      " [ 0.12820371]]\n",
      "Iteration 1113 | Cost: 0.4686191923982244 | Gradient: [[-0.02374864]\n",
      " [-0.22589274]\n",
      " [ 0.12823102]]\n",
      "Iteration 1114 | Cost: 0.4685511742188644 | Gradient: [[-0.02368685]\n",
      " [-0.22573733]\n",
      " [ 0.12825826]]\n",
      "Iteration 1115 | Cost: 0.46848322213428106 | Gradient: [[-0.02362514]\n",
      " [-0.22558213]\n",
      " [ 0.12828545]]\n",
      "Iteration 1116 | Cost: 0.46841533600426233 | Gradient: [[-0.02356353]\n",
      " [-0.22542714]\n",
      " [ 0.12831258]]\n",
      "Iteration 1117 | Cost: 0.4683475156889843 | Gradient: [[-0.02350199]\n",
      " [-0.22527235]\n",
      " [ 0.12833964]]\n",
      "Iteration 1118 | Cost: 0.46827976104901076 | Gradient: [[-0.02344055]\n",
      " [-0.22511778]\n",
      " [ 0.12836665]]\n",
      "Iteration 1119 | Cost: 0.46821207194529174 | Gradient: [[-0.02337919]\n",
      " [-0.2249634 ]\n",
      " [ 0.1283936 ]]\n",
      "Iteration 1120 | Cost: 0.46814444823916235 | Gradient: [[-0.02331791]\n",
      " [-0.22480924]\n",
      " [ 0.1284205 ]]\n",
      "Iteration 1121 | Cost: 0.4680768897923408 | Gradient: [[-0.02325672]\n",
      " [-0.22465528]\n",
      " [ 0.12844733]]\n",
      "Iteration 1122 | Cost: 0.4680093964669283 | Gradient: [[-0.02319562]\n",
      " [-0.22450153]\n",
      " [ 0.12847411]]\n",
      "Iteration 1123 | Cost: 0.4679419681254072 | Gradient: [[-0.0231346 ]\n",
      " [-0.22434798]\n",
      " [ 0.12850082]]\n",
      "Iteration 1124 | Cost: 0.46787460463063946 | Gradient: [[-0.02307366]\n",
      " [-0.22419464]\n",
      " [ 0.12852748]]\n",
      "Iteration 1125 | Cost: 0.46780730584586594 | Gradient: [[-0.02301281]\n",
      " [-0.2240415 ]\n",
      " [ 0.12855408]]\n",
      "Iteration 1126 | Cost: 0.46774007163470505 | Gradient: [[-0.02295205]\n",
      " [-0.22388857]\n",
      " [ 0.12858062]]\n",
      "Iteration 1127 | Cost: 0.4676729018611511 | Gradient: [[-0.02289137]\n",
      " [-0.22373584]\n",
      " [ 0.12860711]]\n",
      "Iteration 1128 | Cost: 0.4676057963895739 | Gradient: [[-0.02283077]\n",
      " [-0.22358331]\n",
      " [ 0.12863354]]\n",
      "Iteration 1129 | Cost: 0.46753875508471654 | Gradient: [[-0.02277026]\n",
      " [-0.22343099]\n",
      " [ 0.12865991]]\n",
      "Iteration 1130 | Cost: 0.467471777811695 | Gradient: [[-0.02270983]\n",
      " [-0.22327887]\n",
      " [ 0.12868622]]\n",
      "Iteration 1131 | Cost: 0.4674048644359965 | Gradient: [[-0.02264948]\n",
      " [-0.22312695]\n",
      " [ 0.12871247]]\n",
      "Iteration 1132 | Cost: 0.4673380148234785 | Gradient: [[-0.02258922]\n",
      " [-0.22297523]\n",
      " [ 0.12873867]]\n",
      "Iteration 1133 | Cost: 0.46727122884036737 | Gradient: [[-0.02252904]\n",
      " [-0.22282372]\n",
      " [ 0.12876481]]\n",
      "Iteration 1134 | Cost: 0.46720450635325705 | Gradient: [[-0.02246894]\n",
      " [-0.22267241]\n",
      " [ 0.12879089]]\n",
      "Iteration 1135 | Cost: 0.46713784722910817 | Gradient: [[-0.02240893]\n",
      " [-0.22252129]\n",
      " [ 0.12881692]]\n",
      "Iteration 1136 | Cost: 0.46707125133524685 | Gradient: [[-0.022349  ]\n",
      " [-0.22237038]\n",
      " [ 0.12884289]]\n",
      "Iteration 1137 | Cost: 0.4670047185393634 | Gradient: [[-0.02228915]\n",
      " [-0.22221967]\n",
      " [ 0.1288688 ]]\n",
      "Iteration 1138 | Cost: 0.46693824870951073 | Gradient: [[-0.02222938]\n",
      " [-0.22206915]\n",
      " [ 0.12889466]]\n",
      "Iteration 1139 | Cost: 0.46687184171410406 | Gradient: [[-0.0221697 ]\n",
      " [-0.22191884]\n",
      " [ 0.12892046]]\n",
      "Iteration 1140 | Cost: 0.46680549742191885 | Gradient: [[-0.0221101 ]\n",
      " [-0.22176872]\n",
      " [ 0.1289462 ]]\n",
      "Iteration 1141 | Cost: 0.4667392157020904 | Gradient: [[-0.02205058]\n",
      " [-0.22161881]\n",
      " [ 0.12897189]]\n",
      "Iteration 1142 | Cost: 0.4666729964241122 | Gradient: [[-0.02199114]\n",
      " [-0.22146909]\n",
      " [ 0.12899752]]\n",
      "Iteration 1143 | Cost: 0.4666068394578346 | Gradient: [[-0.02193179]\n",
      " [-0.22131957]\n",
      " [ 0.12902309]]\n",
      "Iteration 1144 | Cost: 0.46654074467346457 | Gradient: [[-0.02187252]\n",
      " [-0.22117024]\n",
      " [ 0.12904861]]\n",
      "Iteration 1145 | Cost: 0.4664747119415634 | Gradient: [[-0.02181333]\n",
      " [-0.22102112]\n",
      " [ 0.12907408]]\n",
      "Iteration 1146 | Cost: 0.4664087411330463 | Gradient: [[-0.02175422]\n",
      " [-0.22087219]\n",
      " [ 0.12909948]]\n",
      "Iteration 1147 | Cost: 0.46634283211918115 | Gradient: [[-0.02169519]\n",
      " [-0.22072346]\n",
      " [ 0.12912483]]\n",
      "Iteration 1148 | Cost: 0.466276984771587 | Gradient: [[-0.02163624]\n",
      " [-0.22057492]\n",
      " [ 0.12915013]]\n",
      "Iteration 1149 | Cost: 0.4662111989622334 | Gradient: [[-0.02157737]\n",
      " [-0.22042658]\n",
      " [ 0.12917537]]\n",
      "Iteration 1150 | Cost: 0.466145474563439 | Gradient: [[-0.02151858]\n",
      " [-0.22027843]\n",
      " [ 0.12920056]]\n",
      "Iteration 1151 | Cost: 0.4660798114478705 | Gradient: [[-0.02145988]\n",
      " [-0.22013048]\n",
      " [ 0.12922568]]\n",
      "Iteration 1152 | Cost: 0.46601420948854144 | Gradient: [[-0.02140125]\n",
      " [-0.21998272]\n",
      " [ 0.12925076]]\n",
      "Iteration 1153 | Cost: 0.46594866855881145 | Gradient: [[-0.02134271]\n",
      " [-0.21983516]\n",
      " [ 0.12927578]]\n",
      "Iteration 1154 | Cost: 0.4658831885323843 | Gradient: [[-0.02128424]\n",
      " [-0.21968779]\n",
      " [ 0.12930074]]\n",
      "Iteration 1155 | Cost: 0.4658177692833079 | Gradient: [[-0.02122586]\n",
      " [-0.21954062]\n",
      " [ 0.12932565]]\n",
      "Iteration 1156 | Cost: 0.46575241068597256 | Gradient: [[-0.02116755]\n",
      " [-0.21939363]\n",
      " [ 0.12935051]]\n",
      "Iteration 1157 | Cost: 0.46568711261510964 | Gradient: [[-0.02110933]\n",
      " [-0.21924685]\n",
      " [ 0.12937531]]\n",
      "Iteration 1158 | Cost: 0.4656218749457909 | Gradient: [[-0.02105118]\n",
      " [-0.21910025]\n",
      " [ 0.12940005]]\n",
      "Iteration 1159 | Cost: 0.4655566975534275 | Gradient: [[-0.02099312]\n",
      " [-0.21895384]\n",
      " [ 0.12942475]]\n",
      "Iteration 1160 | Cost: 0.4654915803137687 | Gradient: [[-0.02093513]\n",
      " [-0.21880763]\n",
      " [ 0.12944938]]\n",
      "Iteration 1161 | Cost: 0.4654265231029003 | Gradient: [[-0.02087722]\n",
      " [-0.21866161]\n",
      " [ 0.12947397]]\n",
      "Iteration 1162 | Cost: 0.46536152579724455 | Gradient: [[-0.02081939]\n",
      " [-0.21851578]\n",
      " [ 0.12949849]]\n",
      "Iteration 1163 | Cost: 0.4652965882735583 | Gradient: [[-0.02076164]\n",
      " [-0.21837014]\n",
      " [ 0.12952297]]\n",
      "Iteration 1164 | Cost: 0.46523171040893246 | Gradient: [[-0.02070397]\n",
      " [-0.21822469]\n",
      " [ 0.12954739]]\n",
      "Iteration 1165 | Cost: 0.4651668920807903 | Gradient: [[-0.02064638]\n",
      " [-0.21807943]\n",
      " [ 0.12957176]]\n",
      "Iteration 1166 | Cost: 0.465102133166887 | Gradient: [[-0.02058887]\n",
      " [-0.21793436]\n",
      " [ 0.12959607]]\n",
      "Iteration 1167 | Cost: 0.46503743354530813 | Gradient: [[-0.02053143]\n",
      " [-0.21778948]\n",
      " [ 0.12962033]]\n",
      "Iteration 1168 | Cost: 0.46497279309446904 | Gradient: [[-0.02047407]\n",
      " [-0.21764479]\n",
      " [ 0.12964454]]\n",
      "Iteration 1169 | Cost: 0.46490821169311325 | Gradient: [[-0.02041679]\n",
      " [-0.21750029]\n",
      " [ 0.12966869]]\n",
      "Iteration 1170 | Cost: 0.46484368922031205 | Gradient: [[-0.02035959]\n",
      " [-0.21735597]\n",
      " [ 0.12969279]]\n",
      "Iteration 1171 | Cost: 0.46477922555546286 | Gradient: [[-0.02030247]\n",
      " [-0.21721185]\n",
      " [ 0.12971683]]\n",
      "Iteration 1172 | Cost: 0.4647148205782886 | Gradient: [[-0.02024542]\n",
      " [-0.21706791]\n",
      " [ 0.12974083]]\n",
      "Iteration 1173 | Cost: 0.4646504741688366 | Gradient: [[-0.02018845]\n",
      " [-0.21692416]\n",
      " [ 0.12976477]]\n",
      "Iteration 1174 | Cost: 0.464586186207477 | Gradient: [[-0.02013156]\n",
      " [-0.21678059]\n",
      " [ 0.12978865]]\n",
      "Iteration 1175 | Cost: 0.46452195657490264 | Gradient: [[-0.02007475]\n",
      " [-0.21663721]\n",
      " [ 0.12981249]]\n",
      "Iteration 1176 | Cost: 0.46445778515212743 | Gradient: [[-0.02001801]\n",
      " [-0.21649402]\n",
      " [ 0.12983627]]\n",
      "Iteration 1177 | Cost: 0.4643936718204856 | Gradient: [[-0.01996135]\n",
      " [-0.21635102]\n",
      " [ 0.12986   ]]\n",
      "Iteration 1178 | Cost: 0.4643296164616302 | Gradient: [[-0.01990476]\n",
      " [-0.2162082 ]\n",
      " [ 0.12988367]]\n",
      "Iteration 1179 | Cost: 0.4642656189575328 | Gradient: [[-0.01984826]\n",
      " [-0.21606556]\n",
      " [ 0.1299073 ]]\n",
      "Iteration 1180 | Cost: 0.46420167919048194 | Gradient: [[-0.01979183]\n",
      " [-0.21592311]\n",
      " [ 0.12993087]]\n",
      "Iteration 1181 | Cost: 0.4641377970430826 | Gradient: [[-0.01973547]\n",
      " [-0.21578085]\n",
      " [ 0.12995439]]\n",
      "Iteration 1182 | Cost: 0.4640739723982543 | Gradient: [[-0.01967919]\n",
      " [-0.21563876]\n",
      " [ 0.12997786]]\n",
      "Iteration 1183 | Cost: 0.46401020513923136 | Gradient: [[-0.01962299]\n",
      " [-0.21549687]\n",
      " [ 0.13000127]]\n",
      "Iteration 1184 | Cost: 0.46394649514956077 | Gradient: [[-0.01956686]\n",
      " [-0.21535515]\n",
      " [ 0.13002463]]\n",
      "Iteration 1185 | Cost: 0.46388284231310184 | Gradient: [[-0.01951081]\n",
      " [-0.21521362]\n",
      " [ 0.13004795]]\n",
      "Iteration 1186 | Cost: 0.46381924651402506 | Gradient: [[-0.01945484]\n",
      " [-0.21507228]\n",
      " [ 0.1300712 ]]\n",
      "Iteration 1187 | Cost: 0.46375570763681107 | Gradient: [[-0.01939894]\n",
      " [-0.21493111]\n",
      " [ 0.13009441]]\n",
      "Iteration 1188 | Cost: 0.4636922255662497 | Gradient: [[-0.01934311]\n",
      " [-0.21479013]\n",
      " [ 0.13011757]]\n",
      "Iteration 1189 | Cost: 0.46362880018743885 | Gradient: [[-0.01928737]\n",
      " [-0.21464933]\n",
      " [ 0.13014067]]\n",
      "Iteration 1190 | Cost: 0.46356543138578404 | Gradient: [[-0.01923169]\n",
      " [-0.21450871]\n",
      " [ 0.13016373]]\n",
      "Iteration 1191 | Cost: 0.4635021190469967 | Gradient: [[-0.01917609]\n",
      " [-0.21436827]\n",
      " [ 0.13018673]]\n",
      "Iteration 1192 | Cost: 0.46343886305709353 | Gradient: [[-0.01912057]\n",
      " [-0.21422801]\n",
      " [ 0.13020968]]\n",
      "Iteration 1193 | Cost: 0.4633756633023958 | Gradient: [[-0.01906512]\n",
      " [-0.21408794]\n",
      " [ 0.13023258]]\n",
      "Iteration 1194 | Cost: 0.4633125196695281 | Gradient: [[-0.01900975]\n",
      " [-0.21394804]\n",
      " [ 0.13025543]]\n",
      "Iteration 1195 | Cost: 0.46324943204541724 | Gradient: [[-0.01895445]\n",
      " [-0.21380833]\n",
      " [ 0.13027823]]\n",
      "Iteration 1196 | Cost: 0.4631864003172916 | Gradient: [[-0.01889922]\n",
      " [-0.21366879]\n",
      " [ 0.13030097]]\n",
      "Iteration 1197 | Cost: 0.4631234243726803 | Gradient: [[-0.01884407]\n",
      " [-0.21352943]\n",
      " [ 0.13032367]]\n",
      "Iteration 1198 | Cost: 0.4630605040994116 | Gradient: [[-0.01878899]\n",
      " [-0.21339026]\n",
      " [ 0.13034632]]\n",
      "Iteration 1199 | Cost: 0.4629976393856125 | Gradient: [[-0.01873399]\n",
      " [-0.21325126]\n",
      " [ 0.13036891]]\n",
      "Iteration 1200 | Cost: 0.46293483011970793 | Gradient: [[-0.01867906]\n",
      " [-0.21311244]\n",
      " [ 0.13039146]]\n",
      "Iteration 1201 | Cost: 0.4628720761904195 | Gradient: [[-0.0186242 ]\n",
      " [-0.21297379]\n",
      " [ 0.13041395]]\n",
      "Iteration 1202 | Cost: 0.46280937748676415 | Gradient: [[-0.01856942]\n",
      " [-0.21283533]\n",
      " [ 0.13043639]]\n",
      "Iteration 1203 | Cost: 0.4627467338980542 | Gradient: [[-0.01851471]\n",
      " [-0.21269704]\n",
      " [ 0.13045879]]\n",
      "Iteration 1204 | Cost: 0.46268414531389596 | Gradient: [[-0.01846007]\n",
      " [-0.21255893]\n",
      " [ 0.13048113]]\n",
      "Iteration 1205 | Cost: 0.4626216116241882 | Gradient: [[-0.01840551]\n",
      " [-0.212421  ]\n",
      " [ 0.13050343]]\n",
      "Iteration 1206 | Cost: 0.4625591327191224 | Gradient: [[-0.01835102]\n",
      " [-0.21228324]\n",
      " [ 0.13052567]]\n",
      "Iteration 1207 | Cost: 0.46249670848918095 | Gradient: [[-0.0182966 ]\n",
      " [-0.21214566]\n",
      " [ 0.13054786]]\n",
      "Iteration 1208 | Cost: 0.46243433882513635 | Gradient: [[-0.01824226]\n",
      " [-0.21200826]\n",
      " [ 0.13057001]]\n",
      "Iteration 1209 | Cost: 0.4623720236180509 | Gradient: [[-0.01818798]\n",
      " [-0.21187103]\n",
      " [ 0.1305921 ]]\n",
      "Iteration 1210 | Cost: 0.462309762759275 | Gradient: [[-0.01813378]\n",
      " [-0.21173397]\n",
      " [ 0.13061415]]\n",
      "Iteration 1211 | Cost: 0.46224755614044655 | Gradient: [[-0.01807966]\n",
      " [-0.21159709]\n",
      " [ 0.13063614]]\n",
      "Iteration 1212 | Cost: 0.4621854036534904 | Gradient: [[-0.0180256 ]\n",
      " [-0.21146039]\n",
      " [ 0.13065809]]\n",
      "Iteration 1213 | Cost: 0.46212330519061706 | Gradient: [[-0.01797162]\n",
      " [-0.21132386]\n",
      " [ 0.13067999]]\n",
      "Iteration 1214 | Cost: 0.4620612606443217 | Gradient: [[-0.01791771]\n",
      " [-0.2111875 ]\n",
      " [ 0.13070184]]\n",
      "Iteration 1215 | Cost: 0.4619992699073836 | Gradient: [[-0.01786387]\n",
      " [-0.21105132]\n",
      " [ 0.13072364]]\n",
      "Iteration 1216 | Cost: 0.4619373328728652 | Gradient: [[-0.0178101 ]\n",
      " [-0.21091531]\n",
      " [ 0.13074539]]\n",
      "Iteration 1217 | Cost: 0.4618754494341109 | Gradient: [[-0.01775641]\n",
      " [-0.21077947]\n",
      " [ 0.13076709]]\n",
      "Iteration 1218 | Cost: 0.46181361948474664 | Gradient: [[-0.01770278]\n",
      " [-0.21064381]\n",
      " [ 0.13078874]]\n",
      "Iteration 1219 | Cost: 0.46175184291867866 | Gradient: [[-0.01764923]\n",
      " [-0.21050832]\n",
      " [ 0.13081034]]\n",
      "Iteration 1220 | Cost: 0.4616901196300928 | Gradient: [[-0.01759575]\n",
      " [-0.210373  ]\n",
      " [ 0.1308319 ]]\n",
      "Iteration 1221 | Cost: 0.46162844951345355 | Gradient: [[-0.01754234]\n",
      " [-0.21023786]\n",
      " [ 0.1308534 ]]\n",
      "Iteration 1222 | Cost: 0.4615668324635034 | Gradient: [[-0.017489  ]\n",
      " [-0.21010288]\n",
      " [ 0.13087486]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1223 | Cost: 0.4615052683752614 | Gradient: [[-0.01743573]\n",
      " [-0.20996808]\n",
      " [ 0.13089627]]\n",
      "Iteration 1224 | Cost: 0.46144375714402314 | Gradient: [[-0.01738253]\n",
      " [-0.20983344]\n",
      " [ 0.13091763]]\n",
      "Iteration 1225 | Cost: 0.461382298665359 | Gradient: [[-0.0173294 ]\n",
      " [-0.20969898]\n",
      " [ 0.13093895]]\n",
      "Iteration 1226 | Cost: 0.4613208928351142 | Gradient: [[-0.01727634]\n",
      " [-0.20956469]\n",
      " [ 0.13096021]]\n",
      "Iteration 1227 | Cost: 0.4612595395494071 | Gradient: [[-0.01722336]\n",
      " [-0.20943057]\n",
      " [ 0.13098143]]\n",
      "Iteration 1228 | Cost: 0.46119823870462884 | Gradient: [[-0.01717044]\n",
      " [-0.20929662]\n",
      " [ 0.1310026 ]]\n",
      "Iteration 1229 | Cost: 0.4611369901974425 | Gradient: [[-0.01711759]\n",
      " [-0.20916283]\n",
      " [ 0.13102372]]\n",
      "Iteration 1230 | Cost: 0.4610757939247818 | Gradient: [[-0.01706482]\n",
      " [-0.20902922]\n",
      " [ 0.13104479]]\n",
      "Iteration 1231 | Cost: 0.4610146497838511 | Gradient: [[-0.01701211]\n",
      " [-0.20889578]\n",
      " [ 0.13106582]]\n",
      "Iteration 1232 | Cost: 0.4609535576721237 | Gradient: [[-0.01695947]\n",
      " [-0.2087625 ]\n",
      " [ 0.1310868 ]]\n",
      "Iteration 1233 | Cost: 0.4608925174873414 | Gradient: [[-0.01690691]\n",
      " [-0.20862939]\n",
      " [ 0.13110773]]\n",
      "Iteration 1234 | Cost: 0.4608315291275137 | Gradient: [[-0.01685441]\n",
      " [-0.20849645]\n",
      " [ 0.13112861]]\n",
      "Iteration 1235 | Cost: 0.46077059249091673 | Gradient: [[-0.01680198]\n",
      " [-0.20836368]\n",
      " [ 0.13114945]]\n",
      "Iteration 1236 | Cost: 0.46070970747609297 | Gradient: [[-0.01674962]\n",
      " [-0.20823108]\n",
      " [ 0.13117024]]\n",
      "Iteration 1237 | Cost: 0.46064887398184967 | Gradient: [[-0.01669733]\n",
      " [-0.20809864]\n",
      " [ 0.13119098]]\n",
      "Iteration 1238 | Cost: 0.46058809190725847 | Gradient: [[-0.01664511]\n",
      " [-0.20796637]\n",
      " [ 0.13121167]]\n",
      "Iteration 1239 | Cost: 0.46052736115165466 | Gradient: [[-0.01659296]\n",
      " [-0.20783426]\n",
      " [ 0.13123232]]\n",
      "Iteration 1240 | Cost: 0.4604666816146362 | Gradient: [[-0.01654087]\n",
      " [-0.20770232]\n",
      " [ 0.13125292]]\n",
      "Iteration 1241 | Cost: 0.46040605319606287 | Gradient: [[-0.01648886]\n",
      " [-0.20757055]\n",
      " [ 0.13127348]]\n",
      "Iteration 1242 | Cost: 0.46034547579605556 | Gradient: [[-0.01643691]\n",
      " [-0.20743895]\n",
      " [ 0.13129398]]\n",
      "Iteration 1243 | Cost: 0.46028494931499525 | Gradient: [[-0.01638503]\n",
      " [-0.2073075 ]\n",
      " [ 0.13131444]]\n",
      "Iteration 1244 | Cost: 0.46022447365352265 | Gradient: [[-0.01633322]\n",
      " [-0.20717623]\n",
      " [ 0.13133486]]\n",
      "Iteration 1245 | Cost: 0.46016404871253713 | Gradient: [[-0.01628148]\n",
      " [-0.20704512]\n",
      " [ 0.13135522]]\n",
      "Iteration 1246 | Cost: 0.46010367439319555 | Gradient: [[-0.01622981]\n",
      " [-0.20691417]\n",
      " [ 0.13137555]]\n",
      "Iteration 1247 | Cost: 0.4600433505969123 | Gradient: [[-0.0161782 ]\n",
      " [-0.20678339]\n",
      " [ 0.13139582]]\n",
      "Iteration 1248 | Cost: 0.45998307722535786 | Gradient: [[-0.01612666]\n",
      " [-0.20665277]\n",
      " [ 0.13141605]]\n",
      "Iteration 1249 | Cost: 0.4599228541804581 | Gradient: [[-0.01607519]\n",
      " [-0.20652231]\n",
      " [ 0.13143623]]\n",
      "Iteration 1250 | Cost: 0.45986268136439373 | Gradient: [[-0.01602379]\n",
      " [-0.20639202]\n",
      " [ 0.13145637]]\n",
      "Iteration 1251 | Cost: 0.45980255867959924 | Gradient: [[-0.01597245]\n",
      " [-0.20626189]\n",
      " [ 0.13147646]]\n",
      "Iteration 1252 | Cost: 0.45974248602876255 | Gradient: [[-0.01592118]\n",
      " [-0.20613193]\n",
      " [ 0.1314965 ]]\n",
      "Iteration 1253 | Cost: 0.45968246331482343 | Gradient: [[-0.01586998]\n",
      " [-0.20600212]\n",
      " [ 0.1315165 ]]\n",
      "Iteration 1254 | Cost: 0.45962249044097386 | Gradient: [[-0.01581885]\n",
      " [-0.20587248]\n",
      " [ 0.13153646]]\n",
      "Iteration 1255 | Cost: 0.45956256731065614 | Gradient: [[-0.01576778]\n",
      " [-0.205743  ]\n",
      " [ 0.13155636]]\n",
      "Iteration 1256 | Cost: 0.45950269382756276 | Gradient: [[-0.01571678]\n",
      " [-0.20561368]\n",
      " [ 0.13157623]]\n",
      "Iteration 1257 | Cost: 0.45944286989563554 | Gradient: [[-0.01566585]\n",
      " [-0.20548453]\n",
      " [ 0.13159604]]\n",
      "Iteration 1258 | Cost: 0.4593830954190649 | Gradient: [[-0.01561498]\n",
      " [-0.20535553]\n",
      " [ 0.13161581]]\n",
      "Iteration 1259 | Cost: 0.4593233703022887 | Gradient: [[-0.01556418]\n",
      " [-0.2052267 ]\n",
      " [ 0.13163554]]\n",
      "Iteration 1260 | Cost: 0.45926369444999193 | Gradient: [[-0.01551345]\n",
      " [-0.20509802]\n",
      " [ 0.13165522]]\n",
      "Iteration 1261 | Cost: 0.45920406776710604 | Gradient: [[-0.01546278]\n",
      " [-0.20496951]\n",
      " [ 0.13167485]]\n",
      "Iteration 1262 | Cost: 0.4591444901588077 | Gradient: [[-0.01541218]\n",
      " [-0.20484116]\n",
      " [ 0.13169444]]\n",
      "Iteration 1263 | Cost: 0.45908496153051825 | Gradient: [[-0.01536164]\n",
      " [-0.20471296]\n",
      " [ 0.13171399]]\n",
      "Iteration 1264 | Cost: 0.4590254817879033 | Gradient: [[-0.01531117]\n",
      " [-0.20458493]\n",
      " [ 0.13173349]]\n",
      "Iteration 1265 | Cost: 0.4589660508368713 | Gradient: [[-0.01526077]\n",
      " [-0.20445705]\n",
      " [ 0.13175295]]\n",
      "Iteration 1266 | Cost: 0.4589066685835736 | Gradient: [[-0.01521043]\n",
      " [-0.20432934]\n",
      " [ 0.13177236]]\n",
      "Iteration 1267 | Cost: 0.4588473349344031 | Gradient: [[-0.01516016]\n",
      " [-0.20420178]\n",
      " [ 0.13179172]]\n",
      "Iteration 1268 | Cost: 0.45878804979599364 | Gradient: [[-0.01510995]\n",
      " [-0.20407438]\n",
      " [ 0.13181104]]\n",
      "Iteration 1269 | Cost: 0.4587288130752194 | Gradient: [[-0.01505981]\n",
      " [-0.20394714]\n",
      " [ 0.13183032]]\n",
      "Iteration 1270 | Cost: 0.45866962467919414 | Gradient: [[-0.01500973]\n",
      " [-0.20382005]\n",
      " [ 0.13184955]]\n",
      "Iteration 1271 | Cost: 0.4586104845152705 | Gradient: [[-0.01495972]\n",
      " [-0.20369312]\n",
      " [ 0.13186874]]\n",
      "Iteration 1272 | Cost: 0.4585513924910388 | Gradient: [[-0.01490978]\n",
      " [-0.20356636]\n",
      " [ 0.13188789]]\n",
      "Iteration 1273 | Cost: 0.4584923485143273 | Gradient: [[-0.01485989]\n",
      " [-0.20343974]\n",
      " [ 0.13190699]]\n",
      "Iteration 1274 | Cost: 0.45843335249320055 | Gradient: [[-0.01481008]\n",
      " [-0.20331329]\n",
      " [ 0.13192604]]\n",
      "Iteration 1275 | Cost: 0.45837440433595894 | Gradient: [[-0.01476033]\n",
      " [-0.20318699]\n",
      " [ 0.13194505]]\n",
      "Iteration 1276 | Cost: 0.45831550395113835 | Gradient: [[-0.01471064]\n",
      " [-0.20306084]\n",
      " [ 0.13196402]]\n",
      "Iteration 1277 | Cost: 0.458256651247509 | Gradient: [[-0.01466102]\n",
      " [-0.20293486]\n",
      " [ 0.13198294]]\n",
      "Iteration 1278 | Cost: 0.45819784613407466 | Gradient: [[-0.01461146]\n",
      " [-0.20280903]\n",
      " [ 0.13200182]]\n",
      "Iteration 1279 | Cost: 0.4581390885200725 | Gradient: [[-0.01456196]\n",
      " [-0.20268335]\n",
      " [ 0.13202066]]\n",
      "Iteration 1280 | Cost: 0.45808037831497195 | Gradient: [[-0.01451253]\n",
      " [-0.20255783]\n",
      " [ 0.13203945]]\n",
      "Iteration 1281 | Cost: 0.45802171542847386 | Gradient: [[-0.01446317]\n",
      " [-0.20243246]\n",
      " [ 0.1320582 ]]\n",
      "Iteration 1282 | Cost: 0.4579630997705103 | Gradient: [[-0.01441386]\n",
      " [-0.20230725]\n",
      " [ 0.13207691]]\n",
      "Iteration 1283 | Cost: 0.4579045312512435 | Gradient: [[-0.01436463]\n",
      " [-0.20218219]\n",
      " [ 0.13209557]]\n",
      "Iteration 1284 | Cost: 0.4578460097810652 | Gradient: [[-0.01431545]\n",
      " [-0.20205729]\n",
      " [ 0.13211419]]\n",
      "Iteration 1285 | Cost: 0.45778753527059585 | Gradient: [[-0.01426634]\n",
      " [-0.20193254]\n",
      " [ 0.13213276]]\n",
      "Iteration 1286 | Cost: 0.4577291076306844 | Gradient: [[-0.01421729]\n",
      " [-0.20180794]\n",
      " [ 0.1321513 ]]\n",
      "Iteration 1287 | Cost: 0.457670726772407 | Gradient: [[-0.01416831]\n",
      " [-0.2016835 ]\n",
      " [ 0.13216978]]\n",
      "Iteration 1288 | Cost: 0.4576123926070666 | Gradient: [[-0.01411939]\n",
      " [-0.20155921]\n",
      " [ 0.13218823]]\n",
      "Iteration 1289 | Cost: 0.4575541050461923 | Gradient: [[-0.01407053]\n",
      " [-0.20143507]\n",
      " [ 0.13220663]]\n",
      "Iteration 1290 | Cost: 0.4574958640015386 | Gradient: [[-0.01402174]\n",
      " [-0.20131109]\n",
      " [ 0.13222499]]\n",
      "Iteration 1291 | Cost: 0.4574376693850847 | Gradient: [[-0.013973  ]\n",
      " [-0.20118725]\n",
      " [ 0.13224331]]\n",
      "Iteration 1292 | Cost: 0.4573795211090338 | Gradient: [[-0.01392434]\n",
      " [-0.20106357]\n",
      " [ 0.13226159]]\n",
      "Iteration 1293 | Cost: 0.45732141908581275 | Gradient: [[-0.01387573]\n",
      " [-0.20094004]\n",
      " [ 0.13227982]]\n",
      "Iteration 1294 | Cost: 0.4572633632280706 | Gradient: [[-0.01382719]\n",
      " [-0.20081667]\n",
      " [ 0.13229801]]\n",
      "Iteration 1295 | Cost: 0.45720535344867885 | Gradient: [[-0.01377871]\n",
      " [-0.20069344]\n",
      " [ 0.13231616]]\n",
      "Iteration 1296 | Cost: 0.45714738966073026 | Gradient: [[-0.01373029]\n",
      " [-0.20057036]\n",
      " [ 0.13233426]]\n",
      "Iteration 1297 | Cost: 0.45708947177753806 | Gradient: [[-0.01368193]\n",
      " [-0.20044744]\n",
      " [ 0.13235232]]\n",
      "Iteration 1298 | Cost: 0.45703159971263574 | Gradient: [[-0.01363364]\n",
      " [-0.20032466]\n",
      " [ 0.13237034]]\n",
      "Iteration 1299 | Cost: 0.45697377337977607 | Gradient: [[-0.0135854 ]\n",
      " [-0.20020204]\n",
      " [ 0.13238832]]\n",
      "Iteration 1300 | Cost: 0.45691599269293054 | Gradient: [[-0.01353723]\n",
      " [-0.20007956]\n",
      " [ 0.13240626]]\n",
      "Iteration 1301 | Cost: 0.45685825756628873 | Gradient: [[-0.01348913]\n",
      " [-0.19995724]\n",
      " [ 0.13242415]]\n",
      "Iteration 1302 | Cost: 0.4568005679142574 | Gradient: [[-0.01344108]\n",
      " [-0.19983506]\n",
      " [ 0.132442  ]]\n",
      "Iteration 1303 | Cost: 0.4567429236514603 | Gradient: [[-0.01339309]\n",
      " [-0.19971304]\n",
      " [ 0.13245981]]\n",
      "Iteration 1304 | Cost: 0.45668532469273715 | Gradient: [[-0.01334517]\n",
      " [-0.19959116]\n",
      " [ 0.13247758]]\n",
      "Iteration 1305 | Cost: 0.456627770953143 | Gradient: [[-0.01329731]\n",
      " [-0.19946943]\n",
      " [ 0.13249531]]\n",
      "Iteration 1306 | Cost: 0.45657026234794795 | Gradient: [[-0.01324951]\n",
      " [-0.19934785]\n",
      " [ 0.13251299]]\n",
      "Iteration 1307 | Cost: 0.45651279879263595 | Gradient: [[-0.01320177]\n",
      " [-0.19922642]\n",
      " [ 0.13253063]]\n",
      "Iteration 1308 | Cost: 0.4564553802029046 | Gradient: [[-0.01315409]\n",
      " [-0.19910513]\n",
      " [ 0.13254824]]\n",
      "Iteration 1309 | Cost: 0.45639800649466433 | Gradient: [[-0.01310648]\n",
      " [-0.19898399]\n",
      " [ 0.1325658 ]]\n",
      "Iteration 1310 | Cost: 0.45634067758403785 | Gradient: [[-0.01305892]\n",
      " [-0.198863  ]\n",
      " [ 0.13258331]]\n",
      "Iteration 1311 | Cost: 0.4562833933873595 | Gradient: [[-0.01301142]\n",
      " [-0.19874216]\n",
      " [ 0.13260079]]\n",
      "Iteration 1312 | Cost: 0.45622615382117443 | Gradient: [[-0.01296399]\n",
      " [-0.19862146]\n",
      " [ 0.13261823]]\n",
      "Iteration 1313 | Cost: 0.45616895880223796 | Gradient: [[-0.01291662]\n",
      " [-0.19850091]\n",
      " [ 0.13263562]]\n",
      "Iteration 1314 | Cost: 0.45611180824751557 | Gradient: [[-0.0128693 ]\n",
      " [-0.19838051]\n",
      " [ 0.13265298]]\n",
      "Iteration 1315 | Cost: 0.45605470207418136 | Gradient: [[-0.01282205]\n",
      " [-0.19826025]\n",
      " [ 0.13267029]]\n",
      "Iteration 1316 | Cost: 0.4559976401996182 | Gradient: [[-0.01277486]\n",
      " [-0.19814014]\n",
      " [ 0.13268756]]\n",
      "Iteration 1317 | Cost: 0.45594062254141654 | Gradient: [[-0.01272773]\n",
      " [-0.19802018]\n",
      " [ 0.13270479]]\n",
      "Iteration 1318 | Cost: 0.4558836490173742 | Gradient: [[-0.01268065]\n",
      " [-0.19790036]\n",
      " [ 0.13272198]]\n",
      "Iteration 1319 | Cost: 0.45582671954549553 | Gradient: [[-0.01263364]\n",
      " [-0.19778068]\n",
      " [ 0.13273913]]\n",
      "Iteration 1320 | Cost: 0.45576983404399063 | Gradient: [[-0.01258669]\n",
      " [-0.19766115]\n",
      " [ 0.13275624]]\n",
      "Iteration 1321 | Cost: 0.45571299243127533 | Gradient: [[-0.0125398 ]\n",
      " [-0.19754177]\n",
      " [ 0.13277331]]\n",
      "Iteration 1322 | Cost: 0.4556561946259698 | Gradient: [[-0.01249297]\n",
      " [-0.19742252]\n",
      " [ 0.13279034]]\n",
      "Iteration 1323 | Cost: 0.4555994405468989 | Gradient: [[-0.01244619]\n",
      " [-0.19730343]\n",
      " [ 0.13280732]]\n",
      "Iteration 1324 | Cost: 0.45554273011309027 | Gradient: [[-0.01239948]\n",
      " [-0.19718447]\n",
      " [ 0.13282427]]\n",
      "Iteration 1325 | Cost: 0.4554860632437751 | Gradient: [[-0.01235283]\n",
      " [-0.19706566]\n",
      " [ 0.13284118]]\n",
      "Iteration 1326 | Cost: 0.45542943985838646 | Gradient: [[-0.01230623]\n",
      " [-0.196947  ]\n",
      " [ 0.13285804]]\n",
      "Iteration 1327 | Cost: 0.4553728598765594 | Gradient: [[-0.0122597 ]\n",
      " [-0.19682847]\n",
      " [ 0.13287487]]\n",
      "Iteration 1328 | Cost: 0.45531632321813004 | Gradient: [[-0.01221322]\n",
      " [-0.19671009]\n",
      " [ 0.13289165]]\n",
      "Iteration 1329 | Cost: 0.45525982980313484 | Gradient: [[-0.0121668 ]\n",
      " [-0.19659186]\n",
      " [ 0.1329084 ]]\n",
      "Iteration 1330 | Cost: 0.4552033795518104 | Gradient: [[-0.01212044]\n",
      " [-0.19647376]\n",
      " [ 0.13292511]]\n",
      "Iteration 1331 | Cost: 0.4551469723845924 | Gradient: [[-0.01207414]\n",
      " [-0.19635581]\n",
      " [ 0.13294177]]\n",
      "Iteration 1332 | Cost: 0.4550906082221155 | Gradient: [[-0.0120279]\n",
      " [-0.196238 ]\n",
      " [ 0.1329584]]\n",
      "Iteration 1333 | Cost: 0.4550342869852124 | Gradient: [[-0.01198172]\n",
      " [-0.19612033]\n",
      " [ 0.13297498]]\n",
      "Iteration 1334 | Cost: 0.4549780085949133 | Gradient: [[-0.0119356 ]\n",
      " [-0.1960028 ]\n",
      " [ 0.13299153]]\n",
      "Iteration 1335 | Cost: 0.4549217729724454 | Gradient: [[-0.01188953]\n",
      " [-0.19588542]\n",
      " [ 0.13300804]]\n",
      "Iteration 1336 | Cost: 0.45486558003923233 | Gradient: [[-0.01184353]\n",
      " [-0.19576817]\n",
      " [ 0.13302451]]\n",
      "Iteration 1337 | Cost: 0.45480942971689353 | Gradient: [[-0.01179758]\n",
      " [-0.19565107]\n",
      " [ 0.13304093]]\n",
      "Iteration 1338 | Cost: 0.45475332192724366 | Gradient: [[-0.01175169]\n",
      " [-0.1955341 ]\n",
      " [ 0.13305732]]\n",
      "Iteration 1339 | Cost: 0.4546972565922919 | Gradient: [[-0.01170585]\n",
      " [-0.19541728]\n",
      " [ 0.13307367]]\n",
      "Iteration 1340 | Cost: 0.4546412336342415 | Gradient: [[-0.01166008]\n",
      " [-0.1953006 ]\n",
      " [ 0.13308998]]\n",
      "Iteration 1341 | Cost: 0.4545852529754895 | Gradient: [[-0.01161436]\n",
      " [-0.19518405]\n",
      " [ 0.13310625]]\n",
      "Iteration 1342 | Cost: 0.4545293145386258 | Gradient: [[-0.0115687 ]\n",
      " [-0.19506765]\n",
      " [ 0.13312248]]\n",
      "Iteration 1343 | Cost: 0.45447341824643217 | Gradient: [[-0.0115231 ]\n",
      " [-0.19495138]\n",
      " [ 0.13313868]]\n",
      "Iteration 1344 | Cost: 0.4544175640218829 | Gradient: [[-0.01147756]\n",
      " [-0.19483526]\n",
      " [ 0.13315483]]\n",
      "Iteration 1345 | Cost: 0.45436175178814286 | Gradient: [[-0.01143207]\n",
      " [-0.19471927]\n",
      " [ 0.13317095]]\n",
      "Iteration 1346 | Cost: 0.45430598146856804 | Gradient: [[-0.01138665]\n",
      " [-0.19460343]\n",
      " [ 0.13318702]]\n",
      "Iteration 1347 | Cost: 0.4542502529867043 | Gradient: [[-0.01134127]\n",
      " [-0.19448772]\n",
      " [ 0.13320306]]\n",
      "Iteration 1348 | Cost: 0.45419456626628707 | Gradient: [[-0.01129596]\n",
      " [-0.19437214]\n",
      " [ 0.13321906]]\n",
      "Iteration 1349 | Cost: 0.4541389212312408 | Gradient: [[-0.0112507 ]\n",
      " [-0.19425671]\n",
      " [ 0.13323502]]\n",
      "Iteration 1350 | Cost: 0.45408331780567823 | Gradient: [[-0.0112055 ]\n",
      " [-0.19414142]\n",
      " [ 0.13325094]]\n",
      "Iteration 1351 | Cost: 0.4540277559139003 | Gradient: [[-0.01116036]\n",
      " [-0.19402626]\n",
      " [ 0.13326682]]\n",
      "Iteration 1352 | Cost: 0.453972235480395 | Gradient: [[-0.01111527]\n",
      " [-0.19391124]\n",
      " [ 0.13328266]]\n",
      "Iteration 1353 | Cost: 0.453916756429837 | Gradient: [[-0.01107024]\n",
      " [-0.19379636]\n",
      " [ 0.13329847]]\n",
      "Iteration 1354 | Cost: 0.4538613186870874 | Gradient: [[-0.01102527]\n",
      " [-0.19368161]\n",
      " [ 0.13331424]]\n",
      "Iteration 1355 | Cost: 0.4538059221771929 | Gradient: [[-0.01098035]\n",
      " [-0.193567  ]\n",
      " [ 0.13332997]]\n",
      "Iteration 1356 | Cost: 0.4537505668253853 | Gradient: [[-0.01093549]\n",
      " [-0.19345253]\n",
      " [ 0.13334566]]\n",
      "Iteration 1357 | Cost: 0.45369525255708104 | Gradient: [[-0.01089069]\n",
      " [-0.19333819]\n",
      " [ 0.13336131]]\n",
      "Iteration 1358 | Cost: 0.45363997929788064 | Gradient: [[-0.01084594]\n",
      " [-0.19322399]\n",
      " [ 0.13337693]]\n",
      "Iteration 1359 | Cost: 0.4535847469735679 | Gradient: [[-0.01080125]\n",
      " [-0.19310992]\n",
      " [ 0.1333925 ]]\n",
      "Iteration 1360 | Cost: 0.4535295555101097 | Gradient: [[-0.01075662]\n",
      " [-0.19299599]\n",
      " [ 0.13340804]]\n",
      "Iteration 1361 | Cost: 0.4534744048336556 | Gradient: [[-0.01071204]\n",
      " [-0.1928822 ]\n",
      " [ 0.13342354]]\n",
      "Iteration 1362 | Cost: 0.45341929487053667 | Gradient: [[-0.01066751]\n",
      " [-0.19276854]\n",
      " [ 0.13343901]]\n",
      "Iteration 1363 | Cost: 0.4533642255472655 | Gradient: [[-0.01062305]\n",
      " [-0.19265501]\n",
      " [ 0.13345443]]\n",
      "Iteration 1364 | Cost: 0.45330919679053544 | Gradient: [[-0.01057863]\n",
      " [-0.19254163]\n",
      " [ 0.13346982]]\n",
      "Iteration 1365 | Cost: 0.4532542085272205 | Gradient: [[-0.01053428]\n",
      " [-0.19242837]\n",
      " [ 0.13348517]]\n",
      "Iteration 1366 | Cost: 0.45319926068437405 | Gradient: [[-0.01048998]\n",
      " [-0.19231525]\n",
      " [ 0.13350048]]\n",
      "Iteration 1367 | Cost: 0.4531443531892287 | Gradient: [[-0.01044573]\n",
      " [-0.19220226]\n",
      " [ 0.13351576]]\n",
      "Iteration 1368 | Cost: 0.453089485969196 | Gradient: [[-0.01040154]\n",
      " [-0.19208941]\n",
      " [ 0.13353099]]\n",
      "Iteration 1369 | Cost: 0.45303465895186573 | Gradient: [[-0.01035741]\n",
      " [-0.19197669]\n",
      " [ 0.13354619]]\n",
      "Iteration 1370 | Cost: 0.4529798720650052 | Gradient: [[-0.01031333]\n",
      " [-0.1918641 ]\n",
      " [ 0.13356136]]\n",
      "Iteration 1371 | Cost: 0.4529251252365589 | Gradient: [[-0.0102693 ]\n",
      " [-0.19175165]\n",
      " [ 0.13357648]]\n",
      "Iteration 1372 | Cost: 0.45287041839464814 | Gradient: [[-0.01022533]\n",
      " [-0.19163933]\n",
      " [ 0.13359157]]\n",
      "Iteration 1373 | Cost: 0.45281575146757014 | Gradient: [[-0.01018142]\n",
      " [-0.19152714]\n",
      " [ 0.13360662]]\n",
      "Iteration 1374 | Cost: 0.45276112438379784 | Gradient: [[-0.01013756]\n",
      " [-0.19141508]\n",
      " [ 0.13362164]]\n",
      "Iteration 1375 | Cost: 0.4527065370719794 | Gradient: [[-0.01009375]\n",
      " [-0.19130316]\n",
      " [ 0.13363662]]\n",
      "Iteration 1376 | Cost: 0.4526519894609373 | Gradient: [[-0.01005   ]\n",
      " [-0.19119137]\n",
      " [ 0.13365156]]\n",
      "Iteration 1377 | Cost: 0.45259748147966844 | Gradient: [[-0.01000631]\n",
      " [-0.19107971]\n",
      " [ 0.13366646]]\n",
      "Iteration 1378 | Cost: 0.45254301305734307 | Gradient: [[-0.00996266]\n",
      " [-0.19096818]\n",
      " [ 0.13368133]]\n",
      "Iteration 1379 | Cost: 0.45248858412330467 | Gradient: [[-0.00991908]\n",
      " [-0.19085678]\n",
      " [ 0.13369616]]\n",
      "Iteration 1380 | Cost: 0.45243419460706924 | Gradient: [[-0.00987554]\n",
      " [-0.19074552]\n",
      " [ 0.13371095]]\n",
      "Iteration 1381 | Cost: 0.4523798444383248 | Gradient: [[-0.00983207]\n",
      " [-0.19063438]\n",
      " [ 0.13372571]]\n",
      "Iteration 1382 | Cost: 0.45232553354693106 | Gradient: [[-0.00978864]\n",
      " [-0.19052338]\n",
      " [ 0.13374043]]\n",
      "Iteration 1383 | Cost: 0.4522712618629188 | Gradient: [[-0.00974527]\n",
      " [-0.1904125 ]\n",
      " [ 0.13375511]]\n",
      "Iteration 1384 | Cost: 0.4522170293164893 | Gradient: [[-0.00970195]\n",
      " [-0.19030176]\n",
      " [ 0.13376976]]\n",
      "Iteration 1385 | Cost: 0.45216283583801403 | Gradient: [[-0.00965869]\n",
      " [-0.19019115]\n",
      " [ 0.13378437]]\n",
      "Iteration 1386 | Cost: 0.4521086813580339 | Gradient: [[-0.00961548]\n",
      " [-0.19008066]\n",
      " [ 0.13379895]]\n",
      "Iteration 1387 | Cost: 0.4520545658072591 | Gradient: [[-0.00957232]\n",
      " [-0.18997031]\n",
      " [ 0.13381349]]\n",
      "Iteration 1388 | Cost: 0.45200048911656837 | Gradient: [[-0.00952922]\n",
      " [-0.18986008]\n",
      " [ 0.13382799]]\n",
      "Iteration 1389 | Cost: 0.4519464512170087 | Gradient: [[-0.00948617]\n",
      " [-0.18974999]\n",
      " [ 0.13384246]]\n",
      "Iteration 1390 | Cost: 0.45189245203979433 | Gradient: [[-0.00944318]\n",
      " [-0.18964002]\n",
      " [ 0.13385689]]\n",
      "Iteration 1391 | Cost: 0.4518384915163073 | Gradient: [[-0.00940024]\n",
      " [-0.18953019]\n",
      " [ 0.13387128]]\n",
      "Iteration 1392 | Cost: 0.4517845695780956 | Gradient: [[-0.00935735]\n",
      " [-0.18942048]\n",
      " [ 0.13388564]]\n",
      "Iteration 1393 | Cost: 0.451730686156874 | Gradient: [[-0.00931451]\n",
      " [-0.1893109 ]\n",
      " [ 0.13389996]]\n",
      "Iteration 1394 | Cost: 0.4516768411845228 | Gradient: [[-0.00927173]\n",
      " [-0.18920144]\n",
      " [ 0.13391425]]\n",
      "Iteration 1395 | Cost: 0.4516230345930874 | Gradient: [[-0.009229  ]\n",
      " [-0.18909212]\n",
      " [ 0.1339285 ]]\n",
      "Iteration 1396 | Cost: 0.451569266314778 | Gradient: [[-0.00918632]\n",
      " [-0.18898292]\n",
      " [ 0.13394272]]\n",
      "Iteration 1397 | Cost: 0.4515155362819692 | Gradient: [[-0.0091437 ]\n",
      " [-0.18887385]\n",
      " [ 0.1339569 ]]\n",
      "Iteration 1398 | Cost: 0.45146184442719944 | Gradient: [[-0.00910113]\n",
      " [-0.18876491]\n",
      " [ 0.13397104]]\n",
      "Iteration 1399 | Cost: 0.45140819068317034 | Gradient: [[-0.00905861]\n",
      " [-0.1886561 ]\n",
      " [ 0.13398515]]\n",
      "Iteration 1400 | Cost: 0.4513545749827464 | Gradient: [[-0.00901614]\n",
      " [-0.18854741]\n",
      " [ 0.13399923]]\n",
      "Iteration 1401 | Cost: 0.4513009972589548 | Gradient: [[-0.00897373]\n",
      " [-0.18843885]\n",
      " [ 0.13401326]]\n",
      "Iteration 1402 | Cost: 0.4512474574449842 | Gradient: [[-0.00893137]\n",
      " [-0.18833042]\n",
      " [ 0.13402727]]\n",
      "Iteration 1403 | Cost: 0.451193955474185 | Gradient: [[-0.00888906]\n",
      " [-0.18822211]\n",
      " [ 0.13404123]]\n",
      "Iteration 1404 | Cost: 0.45114049128006867 | Gradient: [[-0.0088468 ]\n",
      " [-0.18811393]\n",
      " [ 0.13405517]]\n",
      "Iteration 1405 | Cost: 0.45108706479630706 | Gradient: [[-0.0088046 ]\n",
      " [-0.18800587]\n",
      " [ 0.13406906]]\n",
      "Iteration 1406 | Cost: 0.45103367595673216 | Gradient: [[-0.00876244]\n",
      " [-0.18789794]\n",
      " [ 0.13408293]]\n",
      "Iteration 1407 | Cost: 0.4509803246953357 | Gradient: [[-0.00872034]\n",
      " [-0.18779013]\n",
      " [ 0.13409675]]\n",
      "Iteration 1408 | Cost: 0.4509270109462682 | Gradient: [[-0.00867829]\n",
      " [-0.18768246]\n",
      " [ 0.13411055]]\n",
      "Iteration 1409 | Cost: 0.4508737346438393 | Gradient: [[-0.0086363]\n",
      " [-0.1875749]\n",
      " [ 0.1341243]]\n",
      "Iteration 1410 | Cost: 0.45082049572251676 | Gradient: [[-0.00859435]\n",
      " [-0.18746747]\n",
      " [ 0.13413803]]\n",
      "Iteration 1411 | Cost: 0.45076729411692595 | Gradient: [[-0.00855246]\n",
      " [-0.18736017]\n",
      " [ 0.13415172]]\n",
      "Iteration 1412 | Cost: 0.4507141297618499 | Gradient: [[-0.00851061]\n",
      " [-0.18725299]\n",
      " [ 0.13416537]]\n",
      "Iteration 1413 | Cost: 0.45066100259222813 | Gradient: [[-0.00846882]\n",
      " [-0.18714593]\n",
      " [ 0.13417899]]\n",
      "Iteration 1414 | Cost: 0.45060791254315713 | Gradient: [[-0.00842708]\n",
      " [-0.187039  ]\n",
      " [ 0.13419257]]\n",
      "Iteration 1415 | Cost: 0.4505548595498889 | Gradient: [[-0.00838539]\n",
      " [-0.18693219]\n",
      " [ 0.13420612]]\n",
      "Iteration 1416 | Cost: 0.4505018435478313 | Gradient: [[-0.00834376]\n",
      " [-0.18682551]\n",
      " [ 0.13421964]]\n",
      "Iteration 1417 | Cost: 0.4504488644725471 | Gradient: [[-0.00830217]\n",
      " [-0.18671895]\n",
      " [ 0.13423312]]\n",
      "Iteration 1418 | Cost: 0.4503959222597539 | Gradient: [[-0.00826064]\n",
      " [-0.18661251]\n",
      " [ 0.13424656]]\n",
      "Iteration 1419 | Cost: 0.4503430168453234 | Gradient: [[-0.00821915]\n",
      " [-0.18650619]\n",
      " [ 0.13425998]]\n",
      "Iteration 1420 | Cost: 0.4502901481652812 | Gradient: [[-0.00817772]\n",
      " [-0.1864    ]\n",
      " [ 0.13427335]]\n",
      "Iteration 1421 | Cost: 0.450237316155806 | Gradient: [[-0.00813634]\n",
      " [-0.18629393]\n",
      " [ 0.1342867 ]]\n",
      "Iteration 1422 | Cost: 0.4501845207532296 | Gradient: [[-0.008095  ]\n",
      " [-0.18618799]\n",
      " [ 0.13430001]]\n",
      "Iteration 1423 | Cost: 0.4501317618940365 | Gradient: [[-0.00805372]\n",
      " [-0.18608216]\n",
      " [ 0.13431328]]\n",
      "Iteration 1424 | Cost: 0.4500790395148626 | Gradient: [[-0.00801249]\n",
      " [-0.18597646]\n",
      " [ 0.13432652]]\n",
      "Iteration 1425 | Cost: 0.45002635355249604 | Gradient: [[-0.00797131]\n",
      " [-0.18587088]\n",
      " [ 0.13433973]]\n",
      "Iteration 1426 | Cost: 0.44997370394387576 | Gradient: [[-0.00793018]\n",
      " [-0.18576542]\n",
      " [ 0.1343529 ]]\n",
      "Iteration 1427 | Cost: 0.44992109062609154 | Gradient: [[-0.0078891 ]\n",
      " [-0.18566008]\n",
      " [ 0.13436604]]\n",
      "Iteration 1428 | Cost: 0.44986851353638346 | Gradient: [[-0.00784807]\n",
      " [-0.18555487]\n",
      " [ 0.13437915]]\n",
      "Iteration 1429 | Cost: 0.4498159726121418 | Gradient: [[-0.00780709]\n",
      " [-0.18544977]\n",
      " [ 0.13439222]]\n",
      "Iteration 1430 | Cost: 0.4497634677909054 | Gradient: [[-0.00776616]\n",
      " [-0.1853448 ]\n",
      " [ 0.13440526]]\n",
      "Iteration 1431 | Cost: 0.44971099901036327 | Gradient: [[-0.00772529]\n",
      " [-0.18523995]\n",
      " [ 0.13441827]]\n",
      "Iteration 1432 | Cost: 0.4496585662083521 | Gradient: [[-0.00768446]\n",
      " [-0.18513522]\n",
      " [ 0.13443124]]\n",
      "Iteration 1433 | Cost: 0.44960616932285746 | Gradient: [[-0.00764368]\n",
      " [-0.1850306 ]\n",
      " [ 0.13444417]]\n",
      "Iteration 1434 | Cost: 0.4495538082920122 | Gradient: [[-0.00760295]\n",
      " [-0.18492611]\n",
      " [ 0.13445708]]\n",
      "Iteration 1435 | Cost: 0.44950148305409676 | Gradient: [[-0.00756227]\n",
      " [-0.18482174]\n",
      " [ 0.13446995]]\n",
      "Iteration 1436 | Cost: 0.4494491935475384 | Gradient: [[-0.00752164]\n",
      " [-0.18471749]\n",
      " [ 0.13448279]]\n",
      "Iteration 1437 | Cost: 0.449396939710911 | Gradient: [[-0.00748105]\n",
      " [-0.18461336]\n",
      " [ 0.13449559]]\n",
      "Iteration 1438 | Cost: 0.4493447214829345 | Gradient: [[-0.00744052]\n",
      " [-0.18450934]\n",
      " [ 0.13450836]]\n",
      "Iteration 1439 | Cost: 0.44929253880247433 | Gradient: [[-0.00740004]\n",
      " [-0.18440545]\n",
      " [ 0.1345211 ]]\n",
      "Iteration 1440 | Cost: 0.4492403916085415 | Gradient: [[-0.00735961]\n",
      " [-0.18430168]\n",
      " [ 0.13453381]]\n",
      "Iteration 1441 | Cost: 0.4491882798402918 | Gradient: [[-0.00731922]\n",
      " [-0.18419802]\n",
      " [ 0.13454648]]\n",
      "Iteration 1442 | Cost: 0.4491362034370253 | Gradient: [[-0.00727889]\n",
      " [-0.18409448]\n",
      " [ 0.13455912]]\n",
      "Iteration 1443 | Cost: 0.44908416233818627 | Gradient: [[-0.0072386 ]\n",
      " [-0.18399106]\n",
      " [ 0.13457172]]\n",
      "Iteration 1444 | Cost: 0.4490321564833626 | Gradient: [[-0.00719837]\n",
      " [-0.18388776]\n",
      " [ 0.1345843 ]]\n",
      "Iteration 1445 | Cost: 0.44898018581228544 | Gradient: [[-0.00715818]\n",
      " [-0.18378458]\n",
      " [ 0.13459684]]\n",
      "Iteration 1446 | Cost: 0.4489282502648286 | Gradient: [[-0.00711804]\n",
      " [-0.18368152]\n",
      " [ 0.13460934]]\n",
      "Iteration 1447 | Cost: 0.4488763497810083 | Gradient: [[-0.00707795]\n",
      " [-0.18357857]\n",
      " [ 0.13462182]]\n",
      "Iteration 1448 | Cost: 0.4488244843009833 | Gradient: [[-0.00703791]\n",
      " [-0.18347574]\n",
      " [ 0.13463426]]\n",
      "Iteration 1449 | Cost: 0.44877265376505326 | Gradient: [[-0.00699791]\n",
      " [-0.18337303]\n",
      " [ 0.13464667]]\n",
      "Iteration 1450 | Cost: 0.44872085811365947 | Gradient: [[-0.00695797]\n",
      " [-0.18327043]\n",
      " [ 0.13465905]]\n",
      "Iteration 1451 | Cost: 0.44866909728738397 | Gradient: [[-0.00691807]\n",
      " [-0.18316796]\n",
      " [ 0.13467139]]\n",
      "Iteration 1452 | Cost: 0.4486173712269493 | Gradient: [[-0.00687823]\n",
      " [-0.1830656 ]\n",
      " [ 0.1346837 ]]\n",
      "Iteration 1453 | Cost: 0.4485656798732179 | Gradient: [[-0.00683843]\n",
      " [-0.18296335]\n",
      " [ 0.13469598]]\n",
      "Iteration 1454 | Cost: 0.4485140231671918 | Gradient: [[-0.00679867]\n",
      " [-0.18286122]\n",
      " [ 0.13470823]]\n",
      "Iteration 1455 | Cost: 0.4484624010500125 | Gradient: [[-0.00675897]\n",
      " [-0.18275921]\n",
      " [ 0.13472045]]\n",
      "Iteration 1456 | Cost: 0.4484108134629602 | Gradient: [[-0.00671932]\n",
      " [-0.18265732]\n",
      " [ 0.13473263]]\n",
      "Iteration 1457 | Cost: 0.44835926034745355 | Gradient: [[-0.00667971]\n",
      " [-0.18255554]\n",
      " [ 0.13474478]]\n",
      "Iteration 1458 | Cost: 0.44830774164504933 | Gradient: [[-0.00664015]\n",
      " [-0.18245387]\n",
      " [ 0.1347569 ]]\n",
      "Iteration 1459 | Cost: 0.44825625729744206 | Gradient: [[-0.00660064]\n",
      " [-0.18235232]\n",
      " [ 0.13476898]]\n",
      "Iteration 1460 | Cost: 0.4482048072464634 | Gradient: [[-0.00656117]\n",
      " [-0.18225089]\n",
      " [ 0.13478104]]\n",
      "Iteration 1461 | Cost: 0.44815339143408206 | Gradient: [[-0.00652176]\n",
      " [-0.18214957]\n",
      " [ 0.13479306]]\n",
      "Iteration 1462 | Cost: 0.4481020098024032 | Gradient: [[-0.00648239]\n",
      " [-0.18204837]\n",
      " [ 0.13480505]]\n",
      "Iteration 1463 | Cost: 0.44805066229366824 | Gradient: [[-0.00644307]\n",
      " [-0.18194728]\n",
      " [ 0.13481701]]\n",
      "Iteration 1464 | Cost: 0.44799934885025433 | Gradient: [[-0.00640379]\n",
      " [-0.18184631]\n",
      " [ 0.13482894]]\n",
      "Iteration 1465 | Cost: 0.44794806941467386 | Gradient: [[-0.00636457]\n",
      " [-0.18174545]\n",
      " [ 0.13484083]]\n",
      "Iteration 1466 | Cost: 0.44789682392957436 | Gradient: [[-0.00632539]\n",
      " [-0.1816447 ]\n",
      " [ 0.1348527 ]]\n",
      "Iteration 1467 | Cost: 0.44784561233773795 | Gradient: [[-0.00628626]\n",
      " [-0.18154407]\n",
      " [ 0.13486453]]\n",
      "Iteration 1468 | Cost: 0.4477944345820812 | Gradient: [[-0.00624717]\n",
      " [-0.18144355]\n",
      " [ 0.13487633]]\n",
      "Iteration 1469 | Cost: 0.4477432906056543 | Gradient: [[-0.00620813]\n",
      " [-0.18134315]\n",
      " [ 0.1348881 ]]\n",
      "Iteration 1470 | Cost: 0.4476921803516409 | Gradient: [[-0.00616914]\n",
      " [-0.18124286]\n",
      " [ 0.13489983]]\n",
      "Iteration 1471 | Cost: 0.44764110376335803 | Gradient: [[-0.0061302 ]\n",
      " [-0.18114268]\n",
      " [ 0.13491154]]\n",
      "Iteration 1472 | Cost: 0.4475900607842553 | Gradient: [[-0.0060913 ]\n",
      " [-0.18104262]\n",
      " [ 0.13492321]]\n",
      "Iteration 1473 | Cost: 0.4475390513579148 | Gradient: [[-0.00605245]\n",
      " [-0.18094267]\n",
      " [ 0.13493486]]\n",
      "Iteration 1474 | Cost: 0.44748807542805064 | Gradient: [[-0.00601365]\n",
      " [-0.18084283]\n",
      " [ 0.13494647]]\n",
      "Iteration 1475 | Cost: 0.4474371329385085 | Gradient: [[-0.00597489]\n",
      " [-0.1807431 ]\n",
      " [ 0.13495805]]\n",
      "Iteration 1476 | Cost: 0.4473862238332654 | Gradient: [[-0.00593618]\n",
      " [-0.18064349]\n",
      " [ 0.1349696 ]]\n",
      "Iteration 1477 | Cost: 0.4473353480564293 | Gradient: [[-0.00589752]\n",
      " [-0.18054399]\n",
      " [ 0.13498112]]\n",
      "Iteration 1478 | Cost: 0.4472845055522388 | Gradient: [[-0.0058589]\n",
      " [-0.1804446]\n",
      " [ 0.1349926]]\n",
      "Iteration 1479 | Cost: 0.4472336962650622 | Gradient: [[-0.00582033]\n",
      " [-0.18034533]\n",
      " [ 0.13500406]]\n",
      "Iteration 1480 | Cost: 0.4471829201393984 | Gradient: [[-0.00578181]\n",
      " [-0.18024616]\n",
      " [ 0.13501548]]\n",
      "Iteration 1481 | Cost: 0.44713217711987535 | Gradient: [[-0.00574333]\n",
      " [-0.18014711]\n",
      " [ 0.13502688]]\n",
      "Iteration 1482 | Cost: 0.4470814671512499 | Gradient: [[-0.00570489]\n",
      " [-0.18004817]\n",
      " [ 0.13503824]]\n",
      "Iteration 1483 | Cost: 0.4470307901784081 | Gradient: [[-0.00566651]\n",
      " [-0.17994934]\n",
      " [ 0.13504957]]\n",
      "Iteration 1484 | Cost: 0.44698014614636394 | Gradient: [[-0.00562817]\n",
      " [-0.17985062]\n",
      " [ 0.13506088]]\n",
      "Iteration 1485 | Cost: 0.44692953500025984 | Gradient: [[-0.00558987]\n",
      " [-0.17975201]\n",
      " [ 0.13507215]]\n",
      "Iteration 1486 | Cost: 0.44687895668536576 | Gradient: [[-0.00555162]\n",
      " [-0.17965351]\n",
      " [ 0.13508339]]\n",
      "Iteration 1487 | Cost: 0.4468284111470788 | Gradient: [[-0.00551342]\n",
      " [-0.17955512]\n",
      " [ 0.1350946 ]]\n",
      "Iteration 1488 | Cost: 0.4467778983309234 | Gradient: [[-0.00547526]\n",
      " [-0.17945685]\n",
      " [ 0.13510578]]\n",
      "Iteration 1489 | Cost: 0.4467274181825502 | Gradient: [[-0.00543715]\n",
      " [-0.17935868]\n",
      " [ 0.13511692]]\n",
      "Iteration 1490 | Cost: 0.44667697064773654 | Gradient: [[-0.00539909]\n",
      " [-0.17926062]\n",
      " [ 0.13512804]]\n",
      "Iteration 1491 | Cost: 0.4466265556723853 | Gradient: [[-0.00536107]\n",
      " [-0.17916267]\n",
      " [ 0.13513913]]\n",
      "Iteration 1492 | Cost: 0.4465761732025251 | Gradient: [[-0.00532309]\n",
      " [-0.17906484]\n",
      " [ 0.13515019]]\n",
      "Iteration 1493 | Cost: 0.4465258231843096 | Gradient: [[-0.00528516]\n",
      " [-0.17896711]\n",
      " [ 0.13516121]]\n",
      "Iteration 1494 | Cost: 0.44647550556401805 | Gradient: [[-0.00524728]\n",
      " [-0.17886949]\n",
      " [ 0.13517221]]\n",
      "Iteration 1495 | Cost: 0.4464252202880531 | Gradient: [[-0.00520944]\n",
      " [-0.17877198]\n",
      " [ 0.13518318]]\n",
      "Iteration 1496 | Cost: 0.44637496730294246 | Gradient: [[-0.00517164]\n",
      " [-0.17867458]\n",
      " [ 0.13519411]]\n",
      "Iteration 1497 | Cost: 0.4463247465553375 | Gradient: [[-0.00513389]\n",
      " [-0.17857729]\n",
      " [ 0.13520502]]\n",
      "Iteration 1498 | Cost: 0.4462745579920126 | Gradient: [[-0.00509619]\n",
      " [-0.17848011]\n",
      " [ 0.1352159 ]]\n",
      "Iteration 1499 | Cost: 0.44622440155986615 | Gradient: [[-0.00505853]\n",
      " [-0.17838303]\n",
      " [ 0.13522674]]\n",
      "Iteration 1500 | Cost: 0.44617427720591857 | Gradient: [[-0.00502091]\n",
      " [-0.17828607]\n",
      " [ 0.13523756]]\n",
      "Iteration 1501 | Cost: 0.4461241848773132 | Gradient: [[-0.00498334]\n",
      " [-0.17818921]\n",
      " [ 0.13524834]]\n",
      "Iteration 1502 | Cost: 0.44607412452131545 | Gradient: [[-0.00494582]\n",
      " [-0.17809246]\n",
      " [ 0.1352591 ]]\n",
      "Iteration 1503 | Cost: 0.4460240960853125 | Gradient: [[-0.00490834]\n",
      " [-0.17799582]\n",
      " [ 0.13526983]]\n",
      "Iteration 1504 | Cost: 0.4459740995168131 | Gradient: [[-0.0048709 ]\n",
      " [-0.17789928]\n",
      " [ 0.13528052]]\n",
      "Iteration 1505 | Cost: 0.44592413476344683 | Gradient: [[-0.00483351]\n",
      " [-0.17780285]\n",
      " [ 0.13529119]]\n",
      "Iteration 1506 | Cost: 0.44587420177296433 | Gradient: [[-0.00479617]\n",
      " [-0.17770653]\n",
      " [ 0.13530183]]\n",
      "Iteration 1507 | Cost: 0.4458243004932369 | Gradient: [[-0.00475886]\n",
      " [-0.17761032]\n",
      " [ 0.13531244]]\n",
      "Iteration 1508 | Cost: 0.4457744308722555 | Gradient: [[-0.00472161]\n",
      " [-0.17751422]\n",
      " [ 0.13532302]]\n",
      "Iteration 1509 | Cost: 0.44572459285813126 | Gradient: [[-0.00468439]\n",
      " [-0.17741822]\n",
      " [ 0.13533356]]\n",
      "Iteration 1510 | Cost: 0.4456747863990946 | Gradient: [[-0.00464722]\n",
      " [-0.17732233]\n",
      " [ 0.13534408]]\n",
      "Iteration 1511 | Cost: 0.44562501144349526 | Gradient: [[-0.0046101 ]\n",
      " [-0.17722654]\n",
      " [ 0.13535457]]\n",
      "Iteration 1512 | Cost: 0.44557526793980173 | Gradient: [[-0.00457301]\n",
      " [-0.17713086]\n",
      " [ 0.13536503]]\n",
      "Iteration 1513 | Cost: 0.4455255558366009 | Gradient: [[-0.00453598]\n",
      " [-0.17703529]\n",
      " [ 0.13537546]]\n",
      "Iteration 1514 | Cost: 0.44547587508259806 | Gradient: [[-0.00449898]\n",
      " [-0.17693982]\n",
      " [ 0.13538587]]\n",
      "Iteration 1515 | Cost: 0.4454262256266161 | Gradient: [[-0.00446203]\n",
      " [-0.17684446]\n",
      " [ 0.13539624]]\n",
      "Iteration 1516 | Cost: 0.44537660741759566 | Gradient: [[-0.00442513]\n",
      " [-0.1767492 ]\n",
      " [ 0.13540658]]\n",
      "Iteration 1517 | Cost: 0.44532702040459443 | Gradient: [[-0.00438826]\n",
      " [-0.17665405]\n",
      " [ 0.1354169 ]]\n",
      "Iteration 1518 | Cost: 0.44527746453678696 | Gradient: [[-0.00435145]\n",
      " [-0.17655901]\n",
      " [ 0.13542718]]\n",
      "Iteration 1519 | Cost: 0.4452279397634645 | Gradient: [[-0.00431467]\n",
      " [-0.17646407]\n",
      " [ 0.13543744]]\n",
      "Iteration 1520 | Cost: 0.44517844603403445 | Gradient: [[-0.00427794]\n",
      " [-0.17636924]\n",
      " [ 0.13544766]]\n",
      "Iteration 1521 | Cost: 0.4451289832980202 | Gradient: [[-0.00424125]\n",
      " [-0.17627451]\n",
      " [ 0.13545786]]\n",
      "Iteration 1522 | Cost: 0.44507955150506073 | Gradient: [[-0.00420461]\n",
      " [-0.17617988]\n",
      " [ 0.13546803]]\n",
      "Iteration 1523 | Cost: 0.4450301506049102 | Gradient: [[-0.004168  ]\n",
      " [-0.17608536]\n",
      " [ 0.13547817]]\n",
      "Iteration 1524 | Cost: 0.444980780547438 | Gradient: [[-0.00413145]\n",
      " [-0.17599095]\n",
      " [ 0.13548828]]\n",
      "Iteration 1525 | Cost: 0.4449314412826281 | Gradient: [[-0.00409493]\n",
      " [-0.17589663]\n",
      " [ 0.13549837]]\n",
      "Iteration 1526 | Cost: 0.44488213276057853 | Gradient: [[-0.00405846]\n",
      " [-0.17580243]\n",
      " [ 0.13550842]]\n",
      "Iteration 1527 | Cost: 0.44483285493150176 | Gradient: [[-0.00402203]\n",
      " [-0.17570832]\n",
      " [ 0.13551845]]\n",
      "Iteration 1528 | Cost: 0.44478360774572373 | Gradient: [[-0.00398564]\n",
      " [-0.17561432]\n",
      " [ 0.13552844]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1529 | Cost: 0.44473439115368385 | Gradient: [[-0.0039493 ]\n",
      " [-0.17552043]\n",
      " [ 0.13553841]]\n",
      "Iteration 1530 | Cost: 0.4446852051059348 | Gradient: [[-0.003913  ]\n",
      " [-0.17542663]\n",
      " [ 0.13554835]]\n",
      "Iteration 1531 | Cost: 0.4446360495531419 | Gradient: [[-0.00387674]\n",
      " [-0.17533294]\n",
      " [ 0.13555826]]\n",
      "Iteration 1532 | Cost: 0.444586924446083 | Gradient: [[-0.00384053]\n",
      " [-0.17523936]\n",
      " [ 0.13556814]]\n",
      "Iteration 1533 | Cost: 0.44453782973564815 | Gradient: [[-0.00380435]\n",
      " [-0.17514587]\n",
      " [ 0.135578  ]]\n",
      "Iteration 1534 | Cost: 0.4444887653728392 | Gradient: [[-0.00376822]\n",
      " [-0.17505249]\n",
      " [ 0.13558782]]\n",
      "Iteration 1535 | Cost: 0.44443973130876985 | Gradient: [[-0.00373214]\n",
      " [-0.17495921]\n",
      " [ 0.13559762]]\n",
      "Iteration 1536 | Cost: 0.4443907274946647 | Gradient: [[-0.00369609]\n",
      " [-0.17486604]\n",
      " [ 0.13560739]]\n",
      "Iteration 1537 | Cost: 0.44434175388185954 | Gradient: [[-0.00366009]\n",
      " [-0.17477297]\n",
      " [ 0.13561713]]\n",
      "Iteration 1538 | Cost: 0.44429281042180085 | Gradient: [[-0.00362413]\n",
      " [-0.17467999]\n",
      " [ 0.13562684]]\n",
      "Iteration 1539 | Cost: 0.4442438970660455 | Gradient: [[-0.00358821]\n",
      " [-0.17458713]\n",
      " [ 0.13563653]]\n",
      "Iteration 1540 | Cost: 0.4441950137662602 | Gradient: [[-0.00355234]\n",
      " [-0.17449436]\n",
      " [ 0.13564619]]\n",
      "Iteration 1541 | Cost: 0.44414616047422156 | Gradient: [[-0.0035165 ]\n",
      " [-0.17440169]\n",
      " [ 0.13565581]]\n",
      "Iteration 1542 | Cost: 0.44409733714181604 | Gradient: [[-0.00348071]\n",
      " [-0.17430913]\n",
      " [ 0.13566542]]\n",
      "Iteration 1543 | Cost: 0.4440485437210385 | Gradient: [[-0.00344496]\n",
      " [-0.17421667]\n",
      " [ 0.13567499]]\n",
      "Iteration 1544 | Cost: 0.44399978016399344 | Gradient: [[-0.00340925]\n",
      " [-0.1741243 ]\n",
      " [ 0.13568453]]\n",
      "Iteration 1545 | Cost: 0.4439510464228936 | Gradient: [[-0.00337359]\n",
      " [-0.17403204]\n",
      " [ 0.13569405]]\n",
      "Iteration 1546 | Cost: 0.4439023424500598 | Gradient: [[-0.00333796]\n",
      " [-0.17393989]\n",
      " [ 0.13570354]]\n",
      "Iteration 1547 | Cost: 0.44385366819792144 | Gradient: [[-0.00330238]\n",
      " [-0.17384783]\n",
      " [ 0.135713  ]]\n",
      "Iteration 1548 | Cost: 0.443805023619015 | Gradient: [[-0.00326684]\n",
      " [-0.17375587]\n",
      " [ 0.13572243]]\n",
      "Iteration 1549 | Cost: 0.4437564086659849 | Gradient: [[-0.00323134]\n",
      " [-0.17366401]\n",
      " [ 0.13573184]]\n",
      "Iteration 1550 | Cost: 0.4437078232915823 | Gradient: [[-0.00319589]\n",
      " [-0.17357225]\n",
      " [ 0.13574122]]\n",
      "Iteration 1551 | Cost: 0.4436592674486655 | Gradient: [[-0.00316047]\n",
      " [-0.1734806 ]\n",
      " [ 0.13575057]]\n",
      "Iteration 1552 | Cost: 0.4436107410901991 | Gradient: [[-0.0031251 ]\n",
      " [-0.17338904]\n",
      " [ 0.13575989]]\n",
      "Iteration 1553 | Cost: 0.4435622441692541 | Gradient: [[-0.00308976]\n",
      " [-0.17329758]\n",
      " [ 0.13576919]]\n",
      "Iteration 1554 | Cost: 0.4435137766390075 | Gradient: [[-0.00305447]\n",
      " [-0.17320623]\n",
      " [ 0.13577846]]\n",
      "Iteration 1555 | Cost: 0.4434653384527418 | Gradient: [[-0.00301922]\n",
      " [-0.17311497]\n",
      " [ 0.1357877 ]]\n",
      "Iteration 1556 | Cost: 0.4434169295638452 | Gradient: [[-0.00298401]\n",
      " [-0.17302381]\n",
      " [ 0.13579691]]\n",
      "Iteration 1557 | Cost: 0.44336854992581076 | Gradient: [[-0.00294884]\n",
      " [-0.17293275]\n",
      " [ 0.1358061 ]]\n",
      "Iteration 1558 | Cost: 0.44332019949223656 | Gradient: [[-0.00291372]\n",
      " [-0.17284179]\n",
      " [ 0.13581526]]\n",
      "Iteration 1559 | Cost: 0.4432718782168251 | Gradient: [[-0.00287863]\n",
      " [-0.17275093]\n",
      " [ 0.13582439]]\n",
      "Iteration 1560 | Cost: 0.4432235860533831 | Gradient: [[-0.00284359]\n",
      " [-0.17266017]\n",
      " [ 0.13583349]]\n",
      "Iteration 1561 | Cost: 0.44317532295582157 | Gradient: [[-0.00280858]\n",
      " [-0.17256951]\n",
      " [ 0.13584257]]\n",
      "Iteration 1562 | Cost: 0.4431270888781549 | Gradient: [[-0.00277362]\n",
      " [-0.17247894]\n",
      " [ 0.13585162]]\n",
      "Iteration 1563 | Cost: 0.44307888377450116 | Gradient: [[-0.0027387 ]\n",
      " [-0.17238847]\n",
      " [ 0.13586065]]\n",
      "Iteration 1564 | Cost: 0.4430307075990813 | Gradient: [[-0.00270381]\n",
      " [-0.17229811]\n",
      " [ 0.13586964]]\n",
      "Iteration 1565 | Cost: 0.4429825603062196 | Gradient: [[-0.00266897]\n",
      " [-0.17220784]\n",
      " [ 0.13587861]]\n",
      "Iteration 1566 | Cost: 0.4429344418503424 | Gradient: [[-0.00263417]\n",
      " [-0.17211766]\n",
      " [ 0.13588755]]\n",
      "Iteration 1567 | Cost: 0.4428863521859787 | Gradient: [[-0.00259941]\n",
      " [-0.17202759]\n",
      " [ 0.13589647]]\n",
      "Iteration 1568 | Cost: 0.4428382912677596 | Gradient: [[-0.00256469]\n",
      " [-0.17193761]\n",
      " [ 0.13590536]]\n",
      "Iteration 1569 | Cost: 0.44279025905041763 | Gradient: [[-0.00253001]\n",
      " [-0.17184773]\n",
      " [ 0.13591422]]\n",
      "Iteration 1570 | Cost: 0.4427422554887874 | Gradient: [[-0.00249537]\n",
      " [-0.17175795]\n",
      " [ 0.13592306]]\n",
      "Iteration 1571 | Cost: 0.4426942805378041 | Gradient: [[-0.00246077]\n",
      " [-0.17166827]\n",
      " [ 0.13593186]]\n",
      "Iteration 1572 | Cost: 0.4426463341525043 | Gradient: [[-0.00242622]\n",
      " [-0.17157868]\n",
      " [ 0.13594065]]\n",
      "Iteration 1573 | Cost: 0.4425984162880252 | Gradient: [[-0.0023917 ]\n",
      " [-0.17148919]\n",
      " [ 0.1359494 ]]\n",
      "Iteration 1574 | Cost: 0.44255052689960434 | Gradient: [[-0.00235722]\n",
      " [-0.17139979]\n",
      " [ 0.13595813]]\n",
      "Iteration 1575 | Cost: 0.4425026659425795 | Gradient: [[-0.00232278]\n",
      " [-0.1713105 ]\n",
      " [ 0.13596683]]\n",
      "Iteration 1576 | Cost: 0.4424548333723882 | Gradient: [[-0.00228838]\n",
      " [-0.1712213 ]\n",
      " [ 0.13597551]]\n",
      "Iteration 1577 | Cost: 0.44240702914456786 | Gradient: [[-0.00225402]\n",
      " [-0.17113219]\n",
      " [ 0.13598416]]\n",
      "Iteration 1578 | Cost: 0.442359253214755 | Gradient: [[-0.00221971]\n",
      " [-0.17104318]\n",
      " [ 0.13599278]]\n",
      "Iteration 1579 | Cost: 0.4423115055386852 | Gradient: [[-0.00218543]\n",
      " [-0.17095427]\n",
      " [ 0.13600138]]\n",
      "Iteration 1580 | Cost: 0.442263786072193 | Gradient: [[-0.00215119]\n",
      " [-0.17086546]\n",
      " [ 0.13600995]]\n",
      "Iteration 1581 | Cost: 0.44221609477121165 | Gradient: [[-0.00211699]\n",
      " [-0.17077673]\n",
      " [ 0.13601849]]\n",
      "Iteration 1582 | Cost: 0.4421684315917723 | Gradient: [[-0.00208283]\n",
      " [-0.17068811]\n",
      " [ 0.13602701]]\n",
      "Iteration 1583 | Cost: 0.4421207964900046 | Gradient: [[-0.00204871]\n",
      " [-0.17059958]\n",
      " [ 0.1360355 ]]\n",
      "Iteration 1584 | Cost: 0.4420731894221355 | Gradient: [[-0.00201463]\n",
      " [-0.17051115]\n",
      " [ 0.13604396]]\n",
      "Iteration 1585 | Cost: 0.4420256103444897 | Gradient: [[-0.00198059]\n",
      " [-0.17042281]\n",
      " [ 0.1360524 ]]\n",
      "Iteration 1586 | Cost: 0.44197805921348926 | Gradient: [[-0.00194659]\n",
      " [-0.17033456]\n",
      " [ 0.13606082]]\n",
      "Iteration 1587 | Cost: 0.441930535985653 | Gradient: [[-0.00191262]\n",
      " [-0.17024641]\n",
      " [ 0.1360692 ]]\n",
      "Iteration 1588 | Cost: 0.44188304061759676 | Gradient: [[-0.0018787 ]\n",
      " [-0.17015836]\n",
      " [ 0.13607756]]\n",
      "Iteration 1589 | Cost: 0.4418355730660325 | Gradient: [[-0.00184482]\n",
      " [-0.1700704 ]\n",
      " [ 0.1360859 ]]\n",
      "Iteration 1590 | Cost: 0.4417881332877687 | Gradient: [[-0.00181097]\n",
      " [-0.16998253]\n",
      " [ 0.13609421]]\n",
      "Iteration 1591 | Cost: 0.44174072123970975 | Gradient: [[-0.00177716]\n",
      " [-0.16989476]\n",
      " [ 0.13610249]]\n",
      "Iteration 1592 | Cost: 0.44169333687885565 | Gradient: [[-0.0017434 ]\n",
      " [-0.16980709]\n",
      " [ 0.13611075]]\n",
      "Iteration 1593 | Cost: 0.4416459801623017 | Gradient: [[-0.00170967]\n",
      " [-0.1697195 ]\n",
      " [ 0.13611898]]\n",
      "Iteration 1594 | Cost: 0.441598651047239 | Gradient: [[-0.00167598]\n",
      " [-0.16963202]\n",
      " [ 0.13612719]]\n",
      "Iteration 1595 | Cost: 0.44155134949095304 | Gradient: [[-0.00164233]\n",
      " [-0.16954462]\n",
      " [ 0.13613537]]\n",
      "Iteration 1596 | Cost: 0.4415040754508241 | Gradient: [[-0.00160872]\n",
      " [-0.16945732]\n",
      " [ 0.13614352]]\n",
      "Iteration 1597 | Cost: 0.4414568288843271 | Gradient: [[-0.00157515]\n",
      " [-0.16937011]\n",
      " [ 0.13615165]]\n",
      "Iteration 1598 | Cost: 0.441409609749031 | Gradient: [[-0.00154161]\n",
      " [-0.169283  ]\n",
      " [ 0.13615975]]\n",
      "Iteration 1599 | Cost: 0.44136241800259873 | Gradient: [[-0.00150812]\n",
      " [-0.16919598]\n",
      " [ 0.13616783]]\n",
      "Iteration 1600 | Cost: 0.4413152536027871 | Gradient: [[-0.00147466]\n",
      " [-0.16910905]\n",
      " [ 0.13617588]]\n",
      "Iteration 1601 | Cost: 0.44126811650744613 | Gradient: [[-0.00144124]\n",
      " [-0.16902221]\n",
      " [ 0.13618391]]\n",
      "Iteration 1602 | Cost: 0.44122100667451924 | Gradient: [[-0.00140786]\n",
      " [-0.16893547]\n",
      " [ 0.13619191]]\n",
      "Iteration 1603 | Cost: 0.4411739240620425 | Gradient: [[-0.00137452]\n",
      " [-0.16884882]\n",
      " [ 0.13619989]]\n",
      "Iteration 1604 | Cost: 0.441126868628145 | Gradient: [[-0.00134122]\n",
      " [-0.16876226]\n",
      " [ 0.13620784]]\n",
      "Iteration 1605 | Cost: 0.4410798403310481 | Gradient: [[-0.00130796]\n",
      " [-0.1686758 ]\n",
      " [ 0.13621576]]\n",
      "Iteration 1606 | Cost: 0.44103283912906566 | Gradient: [[-0.00127473]\n",
      " [-0.16858943]\n",
      " [ 0.13622366]]\n",
      "Iteration 1607 | Cost: 0.4409858649806033 | Gradient: [[-0.00124154]\n",
      " [-0.16850315]\n",
      " [ 0.13623154]]\n",
      "Iteration 1608 | Cost: 0.4409389178441583 | Gradient: [[-0.00120839]\n",
      " [-0.16841696]\n",
      " [ 0.13623939]]\n",
      "Iteration 1609 | Cost: 0.4408919976783196 | Gradient: [[-0.00117528]\n",
      " [-0.16833086]\n",
      " [ 0.13624721]]\n",
      "Iteration 1610 | Cost: 0.4408451044417675 | Gradient: [[-0.00114221]\n",
      " [-0.16824486]\n",
      " [ 0.13625501]]\n",
      "Iteration 1611 | Cost: 0.44079823809327284 | Gradient: [[-0.00110917]\n",
      " [-0.16815894]\n",
      " [ 0.13626279]]\n",
      "Iteration 1612 | Cost: 0.4407513985916978 | Gradient: [[-0.00107617]\n",
      " [-0.16807312]\n",
      " [ 0.13627054]]\n",
      "Iteration 1613 | Cost: 0.4407045858959947 | Gradient: [[-0.00104321]\n",
      " [-0.16798739]\n",
      " [ 0.13627826]]\n",
      "Iteration 1614 | Cost: 0.4406577999652064 | Gradient: [[-0.00101029]\n",
      " [-0.16790175]\n",
      " [ 0.13628596]]\n",
      "Iteration 1615 | Cost: 0.44061104075846563 | Gradient: [[-0.0009774 ]\n",
      " [-0.16781621]\n",
      " [ 0.13629363]]\n",
      "Iteration 1616 | Cost: 0.4405643082349951 | Gradient: [[-0.00094456]\n",
      " [-0.16773075]\n",
      " [ 0.13630128]]\n",
      "Iteration 1617 | Cost: 0.44051760235410686 | Gradient: [[-0.00091175]\n",
      " [-0.16764538]\n",
      " [ 0.13630891]]\n",
      "Iteration 1618 | Cost: 0.4404709230752027 | Gradient: [[-0.00087898]\n",
      " [-0.16756011]\n",
      " [ 0.13631651]]\n",
      "Iteration 1619 | Cost: 0.44042427035777315 | Gradient: [[-0.00084624]\n",
      " [-0.16747492]\n",
      " [ 0.13632409]]\n",
      "Iteration 1620 | Cost: 0.44037764416139774 | Gradient: [[-0.00081354]\n",
      " [-0.16738983]\n",
      " [ 0.13633164]]\n",
      "Iteration 1621 | Cost: 0.44033104444574483 | Gradient: [[-0.00078088]\n",
      " [-0.16730482]\n",
      " [ 0.13633916]]\n",
      "Iteration 1622 | Cost: 0.440284471170571 | Gradient: [[-0.00074826]\n",
      " [-0.16721991]\n",
      " [ 0.13634666]]\n",
      "Iteration 1623 | Cost: 0.4402379242957209 | Gradient: [[-0.00071568]\n",
      " [-0.16713508]\n",
      " [ 0.13635414]]\n",
      "Iteration 1624 | Cost: 0.44019140378112737 | Gradient: [[-0.00068313]\n",
      " [-0.16705035]\n",
      " [ 0.13636159]]\n",
      "Iteration 1625 | Cost: 0.44014490958681085 | Gradient: [[-0.00065062]\n",
      " [-0.1669657 ]\n",
      " [ 0.13636902]]\n",
      "Iteration 1626 | Cost: 0.4400984416728794 | Gradient: [[-0.00061815]\n",
      " [-0.16688115]\n",
      " [ 0.13637642]]\n",
      "Iteration 1627 | Cost: 0.44005199999952815 | Gradient: [[-0.00058571]\n",
      " [-0.16679668]\n",
      " [ 0.1363838 ]]\n",
      "Iteration 1628 | Cost: 0.4400055845270395 | Gradient: [[-0.00055331]\n",
      " [-0.1667123 ]\n",
      " [ 0.13639116]]\n",
      "Iteration 1629 | Cost: 0.43995919521578225 | Gradient: [[-0.00052095]\n",
      " [-0.16662802]\n",
      " [ 0.13639849]]\n",
      "Iteration 1630 | Cost: 0.43991283202621206 | Gradient: [[-0.00048862]\n",
      " [-0.16654382]\n",
      " [ 0.13640579]]\n",
      "Iteration 1631 | Cost: 0.43986649491887125 | Gradient: [[-0.00045634]\n",
      " [-0.16645971]\n",
      " [ 0.13641307]]\n",
      "Iteration 1632 | Cost: 0.4398201838543874 | Gradient: [[-0.00042408]\n",
      " [-0.16637569]\n",
      " [ 0.13642033]]\n",
      "Iteration 1633 | Cost: 0.439773898793475 | Gradient: [[-0.00039187]\n",
      " [-0.16629176]\n",
      " [ 0.13642757]]\n",
      "Iteration 1634 | Cost: 0.43972763969693346 | Gradient: [[-0.00035969]\n",
      " [-0.16620791]\n",
      " [ 0.13643477]]\n",
      "Iteration 1635 | Cost: 0.4396814065256481 | Gradient: [[-0.00032755]\n",
      " [-0.16612416]\n",
      " [ 0.13644196]]\n",
      "Iteration 1636 | Cost: 0.439635199240589 | Gradient: [[-0.00029544]\n",
      " [-0.16604049]\n",
      " [ 0.13644912]]\n",
      "Iteration 1637 | Cost: 0.4395890178028118 | Gradient: [[-0.00026338]\n",
      " [-0.16595691]\n",
      " [ 0.13645626]]\n",
      "Iteration 1638 | Cost: 0.4395428621734565 | Gradient: [[-0.00023134]\n",
      " [-0.16587342]\n",
      " [ 0.13646337]]\n",
      "Iteration 1639 | Cost: 0.4394967323137479 | Gradient: [[-0.00019935]\n",
      " [-0.16579002]\n",
      " [ 0.13647046]]\n",
      "Iteration 1640 | Cost: 0.43945062818499503 | Gradient: [[-0.00016739]\n",
      " [-0.16570671]\n",
      " [ 0.13647752]]\n",
      "Iteration 1641 | Cost: 0.43940454974859094 | Gradient: [[-1.35466515e-04]\n",
      " [-1.65623479e-01]\n",
      " [ 1.36484563e-01]]\n",
      "Iteration 1642 | Cost: 0.43935849696601303 | Gradient: [[-1.03580064e-04]\n",
      " [-1.65540339e-01]\n",
      " [ 1.36491580e-01]]\n",
      "Iteration 1643 | Cost: 0.4393124697988218 | Gradient: [[-7.17298393e-05]\n",
      " [-1.65457287e-01]\n",
      " [ 1.36498574e-01]]\n",
      "Iteration 1644 | Cost: 0.4392664682086616 | Gradient: [[-3.99157895e-05]\n",
      " [-1.65374322e-01]\n",
      " [ 1.36505543e-01]]\n",
      "Iteration 1645 | Cost: 0.43922049215725983 | Gradient: [[-8.13786194e-06]\n",
      " [-1.65291444e-01]\n",
      " [ 1.36512489e-01]]\n",
      "Iteration 1646 | Cost: 0.43917454160642716 | Gradient: [[ 2.36039955e-05]\n",
      " [-1.65208653e-01]\n",
      " [ 1.36519411e-01]]\n",
      "Iteration 1647 | Cost: 0.4391286165180568 | Gradient: [[ 5.53098349e-05]\n",
      " [-1.65125949e-01]\n",
      " [ 1.36526309e-01]]\n",
      "Iteration 1648 | Cost: 0.43908271685412464 | Gradient: [[ 8.69797083e-05]\n",
      " [-1.65043332e-01]\n",
      " [ 1.36533183e-01]]\n",
      "Iteration 1649 | Cost: 0.4390368425766893 | Gradient: [[ 1.18613667e-04]\n",
      " [-1.64960801e-01]\n",
      " [ 1.36540034e-01]]\n",
      "Iteration 1650 | Cost: 0.438990993647891 | Gradient: [[ 1.50211764e-04]\n",
      " [-1.64878357e-01]\n",
      " [ 1.36546862e-01]]\n",
      "Iteration 1651 | Cost: 0.43894517002995237 | Gradient: [[ 0.00018177]\n",
      " [-0.164796  ]\n",
      " [ 0.13655367]]\n",
      "Iteration 1652 | Cost: 0.43889937168517756 | Gradient: [[ 0.0002133 ]\n",
      " [-0.16471373]\n",
      " [ 0.13656045]]\n",
      "Iteration 1653 | Cost: 0.43885359857595235 | Gradient: [[ 0.00024479]\n",
      " [-0.16463154]\n",
      " [ 0.1365672 ]]\n",
      "Iteration 1654 | Cost: 0.4388078506647438 | Gradient: [[ 0.00027625]\n",
      " [-0.16454944]\n",
      " [ 0.13657394]]\n",
      "Iteration 1655 | Cost: 0.43876212791410024 | Gradient: [[ 0.00030767]\n",
      " [-0.16446743]\n",
      " [ 0.13658065]]\n",
      "Iteration 1656 | Cost: 0.4387164302866505 | Gradient: [[ 0.00033905]\n",
      " [-0.1643855 ]\n",
      " [ 0.13658733]]\n",
      "Iteration 1657 | Cost: 0.4386707577451046 | Gradient: [[ 0.0003704 ]\n",
      " [-0.16430366]\n",
      " [ 0.136594  ]]\n",
      "Iteration 1658 | Cost: 0.4386251102522528 | Gradient: [[ 0.00040171]\n",
      " [-0.1642219 ]\n",
      " [ 0.13660064]]\n",
      "Iteration 1659 | Cost: 0.43857948777096567 | Gradient: [[ 0.00043299]\n",
      " [-0.16414023]\n",
      " [ 0.13660725]]\n",
      "Iteration 1660 | Cost: 0.43853389026419376 | Gradient: [[ 0.00046423]\n",
      " [-0.16405865]\n",
      " [ 0.13661385]]\n",
      "Iteration 1661 | Cost: 0.43848831769496754 | Gradient: [[ 0.00049544]\n",
      " [-0.16397715]\n",
      " [ 0.13662042]]\n",
      "Iteration 1662 | Cost: 0.4384427700263974 | Gradient: [[ 0.00052661]\n",
      " [-0.16389573]\n",
      " [ 0.13662697]]\n",
      "Iteration 1663 | Cost: 0.4383972472216727 | Gradient: [[ 0.00055775]\n",
      " [-0.1638144 ]\n",
      " [ 0.13663349]]\n",
      "Iteration 1664 | Cost: 0.4383517492440625 | Gradient: [[ 0.00058885]\n",
      " [-0.16373315]\n",
      " [ 0.13663999]]\n",
      "Iteration 1665 | Cost: 0.43830627605691447 | Gradient: [[ 0.00061991]\n",
      " [-0.16365199]\n",
      " [ 0.13664647]]\n",
      "Iteration 1666 | Cost: 0.43826082762365554 | Gradient: [[ 0.00065095]\n",
      " [-0.16357092]\n",
      " [ 0.13665293]]\n",
      "Iteration 1667 | Cost: 0.4382154039077909 | Gradient: [[ 0.00068194]\n",
      " [-0.16348992]\n",
      " [ 0.13665936]]\n",
      "Iteration 1668 | Cost: 0.4381700048729046 | Gradient: [[ 0.0007129 ]\n",
      " [-0.16340902]\n",
      " [ 0.13666577]]\n",
      "Iteration 1669 | Cost: 0.4381246304826585 | Gradient: [[ 0.00074383]\n",
      " [-0.16332819]\n",
      " [ 0.13667215]]\n",
      "Iteration 1670 | Cost: 0.43807928070079266 | Gradient: [[ 0.00077472]\n",
      " [-0.16324745]\n",
      " [ 0.13667852]]\n",
      "Iteration 1671 | Cost: 0.43803395549112506 | Gradient: [[ 0.00080558]\n",
      " [-0.1631668 ]\n",
      " [ 0.13668486]]\n",
      "Iteration 1672 | Cost: 0.43798865481755117 | Gradient: [[ 0.0008364 ]\n",
      " [-0.16308622]\n",
      " [ 0.13669118]]\n",
      "Iteration 1673 | Cost: 0.4379433786440438 | Gradient: [[ 0.00086719]\n",
      " [-0.16300573]\n",
      " [ 0.13669747]]\n",
      "Iteration 1674 | Cost: 0.4378981269346534 | Gradient: [[ 0.00089794]\n",
      " [-0.16292533]\n",
      " [ 0.13670375]]\n",
      "Iteration 1675 | Cost: 0.437852899653507 | Gradient: [[ 0.00092866]\n",
      " [-0.16284501]\n",
      " [ 0.13671   ]]\n",
      "Iteration 1676 | Cost: 0.43780769676480874 | Gradient: [[ 0.00095934]\n",
      " [-0.16276477]\n",
      " [ 0.13671622]]\n",
      "Iteration 1677 | Cost: 0.4377625182328391 | Gradient: [[ 0.00098999]\n",
      " [-0.16268462]\n",
      " [ 0.13672243]]\n",
      "Iteration 1678 | Cost: 0.43771736402195544 | Gradient: [[ 0.00102061]\n",
      " [-0.16260454]\n",
      " [ 0.13672861]]\n",
      "Iteration 1679 | Cost: 0.43767223409659095 | Gradient: [[ 0.00105119]\n",
      " [-0.16252455]\n",
      " [ 0.13673477]]\n",
      "Iteration 1680 | Cost: 0.4376271284212551 | Gradient: [[ 0.00108173]\n",
      " [-0.16244465]\n",
      " [ 0.13674091]]\n",
      "Iteration 1681 | Cost: 0.43758204696053316 | Gradient: [[ 0.00111224]\n",
      " [-0.16236482]\n",
      " [ 0.13674702]]\n",
      "Iteration 1682 | Cost: 0.43753698967908594 | Gradient: [[ 0.00114272]\n",
      " [-0.16228508]\n",
      " [ 0.13675312]]\n",
      "Iteration 1683 | Cost: 0.4374919565416498 | Gradient: [[ 0.00117316]\n",
      " [-0.16220543]\n",
      " [ 0.13675919]]\n",
      "Iteration 1684 | Cost: 0.4374469475130366 | Gradient: [[ 0.00120357]\n",
      " [-0.16212585]\n",
      " [ 0.13676523]]\n",
      "Iteration 1685 | Cost: 0.4374019625581328 | Gradient: [[ 0.00123395]\n",
      " [-0.16204636]\n",
      " [ 0.13677126]]\n",
      "Iteration 1686 | Cost: 0.43735700164190017 | Gradient: [[ 0.00126429]\n",
      " [-0.16196694]\n",
      " [ 0.13677726]]\n",
      "Iteration 1687 | Cost: 0.43731206472937495 | Gradient: [[ 0.00129459]\n",
      " [-0.16188762]\n",
      " [ 0.13678324]]\n",
      "Iteration 1688 | Cost: 0.437267151785668 | Gradient: [[ 0.00132487]\n",
      " [-0.16180837]\n",
      " [ 0.1367892 ]]\n",
      "Iteration 1689 | Cost: 0.4372222627759643 | Gradient: [[ 0.00135511]\n",
      " [-0.1617292 ]\n",
      " [ 0.13679514]]\n",
      "Iteration 1690 | Cost: 0.4371773976655232 | Gradient: [[ 0.00138531]\n",
      " [-0.16165012]\n",
      " [ 0.13680105]]\n",
      "Iteration 1691 | Cost: 0.43713255641967785 | Gradient: [[ 0.00141548]\n",
      " [-0.16157111]\n",
      " [ 0.13680694]]\n",
      "Iteration 1692 | Cost: 0.4370877390038351 | Gradient: [[ 0.00144562]\n",
      " [-0.16149219]\n",
      " [ 0.13681281]]\n",
      "Iteration 1693 | Cost: 0.4370429453834754 | Gradient: [[ 0.00147572]\n",
      " [-0.16141335]\n",
      " [ 0.13681866]]\n",
      "Iteration 1694 | Cost: 0.43699817552415265 | Gradient: [[ 0.00150579]\n",
      " [-0.1613346 ]\n",
      " [ 0.13682449]]\n",
      "Iteration 1695 | Cost: 0.43695342939149395 | Gradient: [[ 0.00153583]\n",
      " [-0.16125592]\n",
      " [ 0.13683029]]\n",
      "Iteration 1696 | Cost: 0.4369087069511991 | Gradient: [[ 0.00156583]\n",
      " [-0.16117732]\n",
      " [ 0.13683608]]\n",
      "Iteration 1697 | Cost: 0.4368640081690411 | Gradient: [[ 0.0015958 ]\n",
      " [-0.16109881]\n",
      " [ 0.13684184]]\n",
      "Iteration 1698 | Cost: 0.4368193330108653 | Gradient: [[ 0.00162574]\n",
      " [-0.16102037]\n",
      " [ 0.13684757]]\n",
      "Iteration 1699 | Cost: 0.43677468144258963 | Gradient: [[ 0.00165564]\n",
      " [-0.16094202]\n",
      " [ 0.13685329]]\n",
      "Iteration 1700 | Cost: 0.43673005343020405 | Gradient: [[ 0.00168551]\n",
      " [-0.16086374]\n",
      " [ 0.13685899]]\n",
      "Iteration 1701 | Cost: 0.43668544893977107 | Gradient: [[ 0.00171534]\n",
      " [-0.16078555]\n",
      " [ 0.13686466]]\n",
      "Iteration 1702 | Cost: 0.43664086793742446 | Gradient: [[ 0.00174515]\n",
      " [-0.16070744]\n",
      " [ 0.13687031]]\n",
      "Iteration 1703 | Cost: 0.4365963103893703 | Gradient: [[ 0.00177491]\n",
      " [-0.1606294 ]\n",
      " [ 0.13687594]]\n",
      "Iteration 1704 | Cost: 0.4365517762618857 | Gradient: [[ 0.00180465]\n",
      " [-0.16055145]\n",
      " [ 0.13688155]]\n",
      "Iteration 1705 | Cost: 0.4365072655213193 | Gradient: [[ 0.00183435]\n",
      " [-0.16047358]\n",
      " [ 0.13688713]]\n",
      "Iteration 1706 | Cost: 0.436462778134091 | Gradient: [[ 0.00186402]\n",
      " [-0.16039578]\n",
      " [ 0.1368927 ]]\n",
      "Iteration 1707 | Cost: 0.43641831406669157 | Gradient: [[ 0.00189366]\n",
      " [-0.16031807]\n",
      " [ 0.13689824]]\n",
      "Iteration 1708 | Cost: 0.4363738732856826 | Gradient: [[ 0.00192326]\n",
      " [-0.16024044]\n",
      " [ 0.13690376]]\n",
      "Iteration 1709 | Cost: 0.43632945575769627 | Gradient: [[ 0.00195283]\n",
      " [-0.16016288]\n",
      " [ 0.13690926]]\n",
      "Iteration 1710 | Cost: 0.43628506144943524 | Gradient: [[ 0.00198237]\n",
      " [-0.16008541]\n",
      " [ 0.13691474]]\n",
      "Iteration 1711 | Cost: 0.43624069032767243 | Gradient: [[ 0.00201188]\n",
      " [-0.16000801]\n",
      " [ 0.1369202 ]]\n",
      "Iteration 1712 | Cost: 0.4361963423592508 | Gradient: [[ 0.00204135]\n",
      " [-0.1599307 ]\n",
      " [ 0.13692564]]\n",
      "Iteration 1713 | Cost: 0.4361520175110833 | Gradient: [[ 0.00207079]\n",
      " [-0.15985346]\n",
      " [ 0.13693105]]\n",
      "Iteration 1714 | Cost: 0.43610771575015234 | Gradient: [[ 0.00210019]\n",
      " [-0.1597763 ]\n",
      " [ 0.13693644]]\n",
      "Iteration 1715 | Cost: 0.4360634370435103 | Gradient: [[ 0.00212957]\n",
      " [-0.15969922]\n",
      " [ 0.13694181]]\n",
      "Iteration 1716 | Cost: 0.4360191813582786 | Gradient: [[ 0.00215891]\n",
      " [-0.15962222]\n",
      " [ 0.13694717]]\n",
      "Iteration 1717 | Cost: 0.43597494866164815 | Gradient: [[ 0.00218822]\n",
      " [-0.1595453 ]\n",
      " [ 0.13695249]]\n",
      "Iteration 1718 | Cost: 0.4359307389208785 | Gradient: [[ 0.00221749]\n",
      " [-0.15946845]\n",
      " [ 0.1369578 ]]\n",
      "Iteration 1719 | Cost: 0.4358865521032985 | Gradient: [[ 0.00224673]\n",
      " [-0.15939169]\n",
      " [ 0.13696309]]\n",
      "Iteration 1720 | Cost: 0.4358423881763052 | Gradient: [[ 0.00227594]\n",
      " [-0.159315  ]\n",
      " [ 0.13696836]]\n",
      "Iteration 1721 | Cost: 0.43579824710736453 | Gradient: [[ 0.00230512]\n",
      " [-0.15923839]\n",
      " [ 0.1369736 ]]\n",
      "Iteration 1722 | Cost: 0.43575412886401066 | Gradient: [[ 0.00233427]\n",
      " [-0.15916186]\n",
      " [ 0.13697882]]\n",
      "Iteration 1723 | Cost: 0.43571003341384584 | Gradient: [[ 0.00236338]\n",
      " [-0.15908541]\n",
      " [ 0.13698403]]\n",
      "Iteration 1724 | Cost: 0.4356659607245403 | Gradient: [[ 0.00239246]\n",
      " [-0.15900903]\n",
      " [ 0.13698921]]\n",
      "Iteration 1725 | Cost: 0.4356219107638322 | Gradient: [[ 0.00242151]\n",
      " [-0.15893273]\n",
      " [ 0.13699437]]\n",
      "Iteration 1726 | Cost: 0.4355778834995271 | Gradient: [[ 0.00245053]\n",
      " [-0.15885651]\n",
      " [ 0.13699951]]\n",
      "Iteration 1727 | Cost: 0.4355338788994985 | Gradient: [[ 0.00247952]\n",
      " [-0.15878037]\n",
      " [ 0.13700463]]\n",
      "Iteration 1728 | Cost: 0.43548989693168677 | Gradient: [[ 0.00250847]\n",
      " [-0.15870431]\n",
      " [ 0.13700972]]\n",
      "Iteration 1729 | Cost: 0.4354459375640994 | Gradient: [[ 0.00253739]\n",
      " [-0.15862832]\n",
      " [ 0.1370148 ]]\n",
      "Iteration 1730 | Cost: 0.43540200076481106 | Gradient: [[ 0.00256628]\n",
      " [-0.15855241]\n",
      " [ 0.13701986]]\n",
      "Iteration 1731 | Cost: 0.4353580865019634 | Gradient: [[ 0.00259513]\n",
      " [-0.15847657]\n",
      " [ 0.13702489]]\n",
      "Iteration 1732 | Cost: 0.43531419474376426 | Gradient: [[ 0.00262396]\n",
      " [-0.15840082]\n",
      " [ 0.13702991]]\n",
      "Iteration 1733 | Cost: 0.435270325458488 | Gradient: [[ 0.00265275]\n",
      " [-0.15832514]\n",
      " [ 0.1370349 ]]\n",
      "Iteration 1734 | Cost: 0.43522647861447566 | Gradient: [[ 0.00268151]\n",
      " [-0.15824953]\n",
      " [ 0.13703987]]\n",
      "Iteration 1735 | Cost: 0.43518265418013397 | Gradient: [[ 0.00271024]\n",
      " [-0.15817401]\n",
      " [ 0.13704483]]\n",
      "Iteration 1736 | Cost: 0.435138852123936 | Gradient: [[ 0.00273894]\n",
      " [-0.15809856]\n",
      " [ 0.13704976]]\n",
      "Iteration 1737 | Cost: 0.4350950724144202 | Gradient: [[ 0.0027676 ]\n",
      " [-0.15802318]\n",
      " [ 0.13705467]]\n",
      "Iteration 1738 | Cost: 0.4350513150201911 | Gradient: [[ 0.00279624]\n",
      " [-0.15794789]\n",
      " [ 0.13705956]]\n",
      "Iteration 1739 | Cost: 0.4350075799099184 | Gradient: [[ 0.00282484]\n",
      " [-0.15787267]\n",
      " [ 0.13706443]]\n",
      "Iteration 1740 | Cost: 0.434963867052337 | Gradient: [[ 0.00285341]\n",
      " [-0.15779752]\n",
      " [ 0.13706928]]\n",
      "Iteration 1741 | Cost: 0.43492017641624725 | Gradient: [[ 0.00288195]\n",
      " [-0.15772245]\n",
      " [ 0.13707411]]\n",
      "Iteration 1742 | Cost: 0.4348765079705145 | Gradient: [[ 0.00291046]\n",
      " [-0.15764746]\n",
      " [ 0.13707892]]\n",
      "Iteration 1743 | Cost: 0.4348328616840685 | Gradient: [[ 0.00293893]\n",
      " [-0.15757254]\n",
      " [ 0.13708371]]\n",
      "Iteration 1744 | Cost: 0.43478923752590404 | Gradient: [[ 0.00296738]\n",
      " [-0.1574977 ]\n",
      " [ 0.13708847]]\n",
      "Iteration 1745 | Cost: 0.43474563546508016 | Gradient: [[ 0.00299579]\n",
      " [-0.15742294]\n",
      " [ 0.13709322]]\n",
      "Iteration 1746 | Cost: 0.4347020554707204 | Gradient: [[ 0.00302418]\n",
      " [-0.15734825]\n",
      " [ 0.13709795]]\n",
      "Iteration 1747 | Cost: 0.4346584975120124 | Gradient: [[ 0.00305253]\n",
      " [-0.15727363]\n",
      " [ 0.13710266]]\n",
      "Iteration 1748 | Cost: 0.43461496155820784 | Gradient: [[ 0.00308085]\n",
      " [-0.15719909]\n",
      " [ 0.13710734]]\n",
      "Iteration 1749 | Cost: 0.4345714475786221 | Gradient: [[ 0.00310914]\n",
      " [-0.15712463]\n",
      " [ 0.13711201]]\n",
      "Iteration 1750 | Cost: 0.43452795554263446 | Gradient: [[ 0.00313739]\n",
      " [-0.15705024]\n",
      " [ 0.13711666]]\n",
      "Iteration 1751 | Cost: 0.4344844854196876 | Gradient: [[ 0.00316562]\n",
      " [-0.15697592]\n",
      " [ 0.13712128]]\n",
      "Iteration 1752 | Cost: 0.43444103717928756 | Gradient: [[ 0.00319381]\n",
      " [-0.15690168]\n",
      " [ 0.13712589]]\n",
      "Iteration 1753 | Cost: 0.43439761079100364 | Gradient: [[ 0.00322198]\n",
      " [-0.15682752]\n",
      " [ 0.13713047]]\n",
      "Iteration 1754 | Cost: 0.43435420622446813 | Gradient: [[ 0.00325011]\n",
      " [-0.15675343]\n",
      " [ 0.13713504]]\n",
      "Iteration 1755 | Cost: 0.4343108234493765 | Gradient: [[ 0.00327821]\n",
      " [-0.15667941]\n",
      " [ 0.13713959]]\n",
      "Iteration 1756 | Cost: 0.4342674624354864 | Gradient: [[ 0.00330629]\n",
      " [-0.15660547]\n",
      " [ 0.13714411]]\n",
      "Iteration 1757 | Cost: 0.43422412315261866 | Gradient: [[ 0.00333433]\n",
      " [-0.1565316 ]\n",
      " [ 0.13714862]]\n",
      "Iteration 1758 | Cost: 0.43418080557065614 | Gradient: [[ 0.00336234]\n",
      " [-0.15645781]\n",
      " [ 0.1371531 ]]\n",
      "Iteration 1759 | Cost: 0.4341375096595442 | Gradient: [[ 0.00339032]\n",
      " [-0.15638409]\n",
      " [ 0.13715757]]\n",
      "Iteration 1760 | Cost: 0.4340942353892901 | Gradient: [[ 0.00341826]\n",
      " [-0.15631045]\n",
      " [ 0.13716201]]\n",
      "Iteration 1761 | Cost: 0.4340509827299632 | Gradient: [[ 0.00344618]\n",
      " [-0.15623687]\n",
      " [ 0.13716644]]\n",
      "Iteration 1762 | Cost: 0.43400775165169464 | Gradient: [[ 0.00347407]\n",
      " [-0.15616338]\n",
      " [ 0.13717085]]\n",
      "Iteration 1763 | Cost: 0.43396454212467733 | Gradient: [[ 0.00350193]\n",
      " [-0.15608995]\n",
      " [ 0.13717523]]\n",
      "Iteration 1764 | Cost: 0.4339213541191656 | Gradient: [[ 0.00352975]\n",
      " [-0.1560166 ]\n",
      " [ 0.1371796 ]]\n",
      "Iteration 1765 | Cost: 0.43387818760547503 | Gradient: [[ 0.00355755]\n",
      " [-0.15594333]\n",
      " [ 0.13718395]]\n",
      "Iteration 1766 | Cost: 0.4338350425539825 | Gradient: [[ 0.00358531]\n",
      " [-0.15587013]\n",
      " [ 0.13718827]]\n",
      "Iteration 1767 | Cost: 0.433791918935126 | Gradient: [[ 0.00361305]\n",
      " [-0.155797  ]\n",
      " [ 0.13719258]]\n",
      "Iteration 1768 | Cost: 0.4337488167194042 | Gradient: [[ 0.00364075]\n",
      " [-0.15572394]\n",
      " [ 0.13719687]]\n",
      "Iteration 1769 | Cost: 0.4337057358773766 | Gradient: [[ 0.00366842]\n",
      " [-0.15565096]\n",
      " [ 0.13720114]]\n",
      "Iteration 1770 | Cost: 0.4336626763796636 | Gradient: [[ 0.00369607]\n",
      " [-0.15557805]\n",
      " [ 0.13720539]]\n",
      "Iteration 1771 | Cost: 0.43361963819694566 | Gradient: [[ 0.00372368]\n",
      " [-0.15550521]\n",
      " [ 0.13720962]]\n",
      "Iteration 1772 | Cost: 0.43357662129996344 | Gradient: [[ 0.00375126]\n",
      " [-0.15543244]\n",
      " [ 0.13721383]]\n",
      "Iteration 1773 | Cost: 0.43353362565951825 | Gradient: [[ 0.00377882]\n",
      " [-0.15535975]\n",
      " [ 0.13721802]]\n",
      "Iteration 1774 | Cost: 0.4334906512464709 | Gradient: [[ 0.00380634]\n",
      " [-0.15528713]\n",
      " [ 0.13722219]]\n",
      "Iteration 1775 | Cost: 0.43344769803174243 | Gradient: [[ 0.00383383]\n",
      " [-0.15521459]\n",
      " [ 0.13722634]]\n",
      "Iteration 1776 | Cost: 0.43340476598631333 | Gradient: [[ 0.0038613 ]\n",
      " [-0.15514211]\n",
      " [ 0.13723047]]\n",
      "Iteration 1777 | Cost: 0.4333618550812237 | Gradient: [[ 0.00388873]\n",
      " [-0.15506971]\n",
      " [ 0.13723458]]\n",
      "Iteration 1778 | Cost: 0.4333189652875731 | Gradient: [[ 0.00391613]\n",
      " [-0.15499738]\n",
      " [ 0.13723868]]\n",
      "Iteration 1779 | Cost: 0.4332760965765201 | Gradient: [[ 0.0039435 ]\n",
      " [-0.15492512]\n",
      " [ 0.13724275]]\n",
      "Iteration 1780 | Cost: 0.43323324891928283 | Gradient: [[ 0.00397085]\n",
      " [-0.15485294]\n",
      " [ 0.1372468 ]]\n",
      "Iteration 1781 | Cost: 0.43319042228713805 | Gradient: [[ 0.00399816]\n",
      " [-0.15478082]\n",
      " [ 0.13725084]]\n",
      "Iteration 1782 | Cost: 0.4331476166514215 | Gradient: [[ 0.00402544]\n",
      " [-0.15470878]\n",
      " [ 0.13725486]]\n",
      "Iteration 1783 | Cost: 0.43310483198352734 | Gradient: [[ 0.0040527 ]\n",
      " [-0.15463681]\n",
      " [ 0.13725885]]\n",
      "Iteration 1784 | Cost: 0.43306206825490856 | Gradient: [[ 0.00407992]\n",
      " [-0.15456491]\n",
      " [ 0.13726283]]\n",
      "Iteration 1785 | Cost: 0.4330193254370765 | Gradient: [[ 0.00410711]\n",
      " [-0.15449308]\n",
      " [ 0.13726679]]\n",
      "Iteration 1786 | Cost: 0.4329766035016005 | Gradient: [[ 0.00413428]\n",
      " [-0.15442133]\n",
      " [ 0.13727073]]\n",
      "Iteration 1787 | Cost: 0.4329339024201083 | Gradient: [[ 0.00416141]\n",
      " [-0.15434964]\n",
      " [ 0.13727465]]\n",
      "Iteration 1788 | Cost: 0.4328912221642854 | Gradient: [[ 0.00418852]\n",
      " [-0.15427803]\n",
      " [ 0.13727855]]\n",
      "Iteration 1789 | Cost: 0.43284856270587513 | Gradient: [[ 0.00421559]\n",
      " [-0.15420649]\n",
      " [ 0.13728243]]\n",
      "Iteration 1790 | Cost: 0.43280592401667856 | Gradient: [[ 0.00424264]\n",
      " [-0.15413502]\n",
      " [ 0.13728629]]\n",
      "Iteration 1791 | Cost: 0.43276330606855423 | Gradient: [[ 0.00426966]\n",
      " [-0.15406362]\n",
      " [ 0.13729014]]\n",
      "Iteration 1792 | Cost: 0.4327207088334182 | Gradient: [[ 0.00429664]\n",
      " [-0.15399229]\n",
      " [ 0.13729396]]\n",
      "Iteration 1793 | Cost: 0.4326781322832435 | Gradient: [[ 0.0043236 ]\n",
      " [-0.15392103]\n",
      " [ 0.13729777]]\n",
      "Iteration 1794 | Cost: 0.43263557639006067 | Gradient: [[ 0.00435053]\n",
      " [-0.15384984]\n",
      " [ 0.13730156]]\n",
      "Iteration 1795 | Cost: 0.4325930411259568 | Gradient: [[ 0.00437743]\n",
      " [-0.15377872]\n",
      " [ 0.13730533]]\n",
      "Iteration 1796 | Cost: 0.432550526463076 | Gradient: [[ 0.0044043 ]\n",
      " [-0.15370767]\n",
      " [ 0.13730908]]\n",
      "Iteration 1797 | Cost: 0.43250803237361923 | Gradient: [[ 0.00443114]\n",
      " [-0.1536367 ]\n",
      " [ 0.13731281]]\n",
      "Iteration 1798 | Cost: 0.43246555882984367 | Gradient: [[ 0.00445795]\n",
      " [-0.15356579]\n",
      " [ 0.13731652]]\n",
      "Iteration 1799 | Cost: 0.43242310580406296 | Gradient: [[ 0.00448474]\n",
      " [-0.15349495]\n",
      " [ 0.13732021]]\n",
      "Iteration 1800 | Cost: 0.4323806732686473 | Gradient: [[ 0.00451149]\n",
      " [-0.15342419]\n",
      " [ 0.13732389]]\n",
      "Iteration 1801 | Cost: 0.4323382611960228 | Gradient: [[ 0.00453822]\n",
      " [-0.15335349]\n",
      " [ 0.13732754]]\n",
      "Iteration 1802 | Cost: 0.4322958695586716 | Gradient: [[ 0.00456491]\n",
      " [-0.15328286]\n",
      " [ 0.13733118]]\n",
      "Iteration 1803 | Cost: 0.4322534983291316 | Gradient: [[ 0.00459158]\n",
      " [-0.15321231]\n",
      " [ 0.1373348 ]]\n",
      "Iteration 1804 | Cost: 0.4322111474799967 | Gradient: [[ 0.00461822]\n",
      " [-0.15314182]\n",
      " [ 0.1373384 ]]\n",
      "Iteration 1805 | Cost: 0.4321688169839162 | Gradient: [[ 0.00464482]\n",
      " [-0.1530714 ]\n",
      " [ 0.13734198]]\n",
      "Iteration 1806 | Cost: 0.4321265068135947 | Gradient: [[ 0.0046714 ]\n",
      " [-0.15300105]\n",
      " [ 0.13734554]]\n",
      "Iteration 1807 | Cost: 0.43208421694179233 | Gradient: [[ 0.00469795]\n",
      " [-0.15293078]\n",
      " [ 0.13734909]]\n",
      "Iteration 1808 | Cost: 0.43204194734132445 | Gradient: [[ 0.00472448]\n",
      " [-0.15286057]\n",
      " [ 0.13735261]]\n",
      "Iteration 1809 | Cost: 0.43199969798506116 | Gradient: [[ 0.00475097]\n",
      " [-0.15279043]\n",
      " [ 0.13735612]]\n",
      "Iteration 1810 | Cost: 0.4319574688459278 | Gradient: [[ 0.00477744]\n",
      " [-0.15272036]\n",
      " [ 0.13735961]]\n",
      "Iteration 1811 | Cost: 0.4319152598969044 | Gradient: [[ 0.00480387]\n",
      " [-0.15265035]\n",
      " [ 0.13736308]]\n",
      "Iteration 1812 | Cost: 0.4318730711110254 | Gradient: [[ 0.00483028]\n",
      " [-0.15258042]\n",
      " [ 0.13736653]]\n",
      "Iteration 1813 | Cost: 0.43183090246138006 | Gradient: [[ 0.00485666]\n",
      " [-0.15251056]\n",
      " [ 0.13736997]]\n",
      "Iteration 1814 | Cost: 0.43178875392111193 | Gradient: [[ 0.00488301]\n",
      " [-0.15244076]\n",
      " [ 0.13737338]]\n",
      "Iteration 1815 | Cost: 0.4317466254634187 | Gradient: [[ 0.00490933]\n",
      " [-0.15237103]\n",
      " [ 0.13737678]]\n",
      "Iteration 1816 | Cost: 0.43170451706155216 | Gradient: [[ 0.00493563]\n",
      " [-0.15230137]\n",
      " [ 0.13738016]]\n",
      "Iteration 1817 | Cost: 0.4316624286888183 | Gradient: [[ 0.00496189]\n",
      " [-0.15223178]\n",
      " [ 0.13738352]]\n",
      "Iteration 1818 | Cost: 0.43162036031857665 | Gradient: [[ 0.00498813]\n",
      " [-0.15216226]\n",
      " [ 0.13738686]]\n",
      "Iteration 1819 | Cost: 0.4315783119242408 | Gradient: [[ 0.00501434]\n",
      " [-0.15209281]\n",
      " [ 0.13739018]]\n",
      "Iteration 1820 | Cost: 0.4315362834792776 | Gradient: [[ 0.00504052]\n",
      " [-0.15202342]\n",
      " [ 0.13739349]]\n",
      "Iteration 1821 | Cost: 0.43149427495720755 | Gradient: [[ 0.00506667]\n",
      " [-0.15195411]\n",
      " [ 0.13739678]]\n",
      "Iteration 1822 | Cost: 0.43145228633160443 | Gradient: [[ 0.00509279]\n",
      " [-0.15188486]\n",
      " [ 0.13740005]]\n",
      "Iteration 1823 | Cost: 0.43141031757609527 | Gradient: [[ 0.00511889]\n",
      " [-0.15181568]\n",
      " [ 0.1374033 ]]\n",
      "Iteration 1824 | Cost: 0.43136836866436 | Gradient: [[ 0.00514495]\n",
      " [-0.15174656]\n",
      " [ 0.13740653]]\n",
      "Iteration 1825 | Cost: 0.43132643957013156 | Gradient: [[ 0.00517099]\n",
      " [-0.15167752]\n",
      " [ 0.13740975]]\n",
      "Iteration 1826 | Cost: 0.43128453026719604 | Gradient: [[ 0.005197  ]\n",
      " [-0.15160854]\n",
      " [ 0.13741295]]\n",
      "Iteration 1827 | Cost: 0.4312426407293916 | Gradient: [[ 0.00522299]\n",
      " [-0.15153963]\n",
      " [ 0.13741613]]\n",
      "Iteration 1828 | Cost: 0.4312007709306093 | Gradient: [[ 0.00524894]\n",
      " [-0.15147079]\n",
      " [ 0.13741929]]\n",
      "Iteration 1829 | Cost: 0.43115892084479274 | Gradient: [[ 0.00527487]\n",
      " [-0.15140201]\n",
      " [ 0.13742243]]\n",
      "Iteration 1830 | Cost: 0.43111709044593766 | Gradient: [[ 0.00530077]\n",
      " [-0.1513333 ]\n",
      " [ 0.13742556]]\n",
      "Iteration 1831 | Cost: 0.43107527970809184 | Gradient: [[ 0.00532664]\n",
      " [-0.15126466]\n",
      " [ 0.13742866]]\n",
      "Iteration 1832 | Cost: 0.43103348860535545 | Gradient: [[ 0.00535248]\n",
      " [-0.15119609]\n",
      " [ 0.13743175]]\n",
      "Iteration 1833 | Cost: 0.4309917171118801 | Gradient: [[ 0.0053783 ]\n",
      " [-0.15112758]\n",
      " [ 0.13743483]]\n",
      "Iteration 1834 | Cost: 0.4309499652018699 | Gradient: [[ 0.00540409]\n",
      " [-0.15105914]\n",
      " [ 0.13743788]]\n",
      "Iteration 1835 | Cost: 0.43090823284957974 | Gradient: [[ 0.00542985]\n",
      " [-0.15099076]\n",
      " [ 0.13744092]]\n",
      "Iteration 1836 | Cost: 0.4308665200293169 | Gradient: [[ 0.00545558]\n",
      " [-0.15092246]\n",
      " [ 0.13744394]]\n",
      "Iteration 1837 | Cost: 0.4308248267154396 | Gradient: [[ 0.00548128]\n",
      " [-0.15085422]\n",
      " [ 0.13744694]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1838 | Cost: 0.4307831528823574 | Gradient: [[ 0.00550696]\n",
      " [-0.15078604]\n",
      " [ 0.13744992]]\n",
      "Iteration 1839 | Cost: 0.43074149850453103 | Gradient: [[ 0.00553261]\n",
      " [-0.15071794]\n",
      " [ 0.13745289]]\n",
      "Iteration 1840 | Cost: 0.4306998635564725 | Gradient: [[ 0.00555823]\n",
      " [-0.1506499 ]\n",
      " [ 0.13745583]]\n",
      "Iteration 1841 | Cost: 0.4306582480127446 | Gradient: [[ 0.00558383]\n",
      " [-0.15058192]\n",
      " [ 0.13745877]]\n",
      "Iteration 1842 | Cost: 0.4306166518479606 | Gradient: [[ 0.00560939]\n",
      " [-0.15051401]\n",
      " [ 0.13746168]]\n",
      "Iteration 1843 | Cost: 0.43057507503678505 | Gradient: [[ 0.00563493]\n",
      " [-0.15044617]\n",
      " [ 0.13746457]]\n",
      "Iteration 1844 | Cost: 0.4305335175539328 | Gradient: [[ 0.00566044]\n",
      " [-0.15037839]\n",
      " [ 0.13746745]]\n",
      "Iteration 1845 | Cost: 0.4304919793741689 | Gradient: [[ 0.00568593]\n",
      " [-0.15031068]\n",
      " [ 0.13747031]]\n",
      "Iteration 1846 | Cost: 0.43045046047230906 | Gradient: [[ 0.00571139]\n",
      " [-0.15024304]\n",
      " [ 0.13747315]]\n",
      "Iteration 1847 | Cost: 0.4304089608232188 | Gradient: [[ 0.00573682]\n",
      " [-0.15017546]\n",
      " [ 0.13747598]]\n",
      "Iteration 1848 | Cost: 0.4303674804018143 | Gradient: [[ 0.00576222]\n",
      " [-0.15010795]\n",
      " [ 0.13747879]]\n",
      "Iteration 1849 | Cost: 0.430326019183061 | Gradient: [[ 0.00578759]\n",
      " [-0.1500405 ]\n",
      " [ 0.13748158]]\n",
      "Iteration 1850 | Cost: 0.4302845771419747 | Gradient: [[ 0.00581294]\n",
      " [-0.14997312]\n",
      " [ 0.13748435]]\n",
      "Iteration 1851 | Cost: 0.4302431542536207 | Gradient: [[ 0.00583826]\n",
      " [-0.1499058 ]\n",
      " [ 0.13748711]]\n",
      "Iteration 1852 | Cost: 0.430201750493114 | Gradient: [[ 0.00586356]\n",
      " [-0.14983855]\n",
      " [ 0.13748985]]\n",
      "Iteration 1853 | Cost: 0.4301603658356188 | Gradient: [[ 0.00588882]\n",
      " [-0.14977136]\n",
      " [ 0.13749257]]\n",
      "Iteration 1854 | Cost: 0.430119000256349 | Gradient: [[ 0.00591406]\n",
      " [-0.14970424]\n",
      " [ 0.13749527]]\n",
      "Iteration 1855 | Cost: 0.4300776537305676 | Gradient: [[ 0.00593928]\n",
      " [-0.14963719]\n",
      " [ 0.13749796]]\n",
      "Iteration 1856 | Cost: 0.4300363262335865 | Gradient: [[ 0.00596446]\n",
      " [-0.14957019]\n",
      " [ 0.13750063]]\n",
      "Iteration 1857 | Cost: 0.429995017740767 | Gradient: [[ 0.00598962]\n",
      " [-0.14950327]\n",
      " [ 0.13750328]]\n",
      "Iteration 1858 | Cost: 0.42995372822751904 | Gradient: [[ 0.00601475]\n",
      " [-0.14943641]\n",
      " [ 0.13750592]]\n",
      "Iteration 1859 | Cost: 0.4299124576693013 | Gradient: [[ 0.00603986]\n",
      " [-0.14936961]\n",
      " [ 0.13750853]]\n",
      "Iteration 1860 | Cost: 0.4298712060416213 | Gradient: [[ 0.00606494]\n",
      " [-0.14930288]\n",
      " [ 0.13751113]]\n",
      "Iteration 1861 | Cost: 0.42982997332003486 | Gradient: [[ 0.00608999]\n",
      " [-0.14923621]\n",
      " [ 0.13751372]]\n",
      "Iteration 1862 | Cost: 0.4297887594801464 | Gradient: [[ 0.00611501]\n",
      " [-0.14916961]\n",
      " [ 0.13751628]]\n",
      "Iteration 1863 | Cost: 0.4297475644976084 | Gradient: [[ 0.00614001]\n",
      " [-0.14910307]\n",
      " [ 0.13751883]]\n",
      "Iteration 1864 | Cost: 0.4297063883481221 | Gradient: [[ 0.00616498]\n",
      " [-0.14903659]\n",
      " [ 0.13752137]]\n",
      "Iteration 1865 | Cost: 0.4296652310074359 | Gradient: [[ 0.00618993]\n",
      " [-0.14897018]\n",
      " [ 0.13752388]]\n",
      "Iteration 1866 | Cost: 0.4296240924513469 | Gradient: [[ 0.00621484]\n",
      " [-0.14890384]\n",
      " [ 0.13752638]]\n",
      "Iteration 1867 | Cost: 0.4295829726556999 | Gradient: [[ 0.00623974]\n",
      " [-0.14883756]\n",
      " [ 0.13752886]]\n",
      "Iteration 1868 | Cost: 0.4295418715963871 | Gradient: [[ 0.0062646 ]\n",
      " [-0.14877134]\n",
      " [ 0.13753133]]\n",
      "Iteration 1869 | Cost: 0.42950078924934865 | Gradient: [[ 0.00628944]\n",
      " [-0.14870518]\n",
      " [ 0.13753378]]\n",
      "Iteration 1870 | Cost: 0.42945972559057205 | Gradient: [[ 0.00631425]\n",
      " [-0.14863909]\n",
      " [ 0.13753621]]\n",
      "Iteration 1871 | Cost: 0.4294186805960923 | Gradient: [[ 0.00633904]\n",
      " [-0.14857306]\n",
      " [ 0.13753862]]\n",
      "Iteration 1872 | Cost: 0.4293776542419913 | Gradient: [[ 0.00636379]\n",
      " [-0.1485071 ]\n",
      " [ 0.13754102]]\n",
      "Iteration 1873 | Cost: 0.4293366465043988 | Gradient: [[ 0.00638853]\n",
      " [-0.1484412 ]\n",
      " [ 0.1375434 ]]\n",
      "Iteration 1874 | Cost: 0.4292956573594909 | Gradient: [[ 0.00641323]\n",
      " [-0.14837536]\n",
      " [ 0.13754576]]\n",
      "Iteration 1875 | Cost: 0.42925468678349105 | Gradient: [[ 0.00643791]\n",
      " [-0.14830959]\n",
      " [ 0.13754811]]\n",
      "Iteration 1876 | Cost: 0.42921373475266933 | Gradient: [[ 0.00646257]\n",
      " [-0.14824388]\n",
      " [ 0.13755044]]\n",
      "Iteration 1877 | Cost: 0.4291728012433425 | Gradient: [[ 0.00648719]\n",
      " [-0.14817823]\n",
      " [ 0.13755275]]\n",
      "Iteration 1878 | Cost: 0.4291318862318742 | Gradient: [[ 0.00651179]\n",
      " [-0.14811265]\n",
      " [ 0.13755505]]\n",
      "Iteration 1879 | Cost: 0.42909098969467424 | Gradient: [[ 0.00653637]\n",
      " [-0.14804713]\n",
      " [ 0.13755733]]\n",
      "Iteration 1880 | Cost: 0.4290501116081991 | Gradient: [[ 0.00656092]\n",
      " [-0.14798167]\n",
      " [ 0.13755959]]\n",
      "Iteration 1881 | Cost: 0.4290092519489511 | Gradient: [[ 0.00658544]\n",
      " [-0.14791628]\n",
      " [ 0.13756184]]\n",
      "Iteration 1882 | Cost: 0.4289684106934793 | Gradient: [[ 0.00660994]\n",
      " [-0.14785094]\n",
      " [ 0.13756407]]\n",
      "Iteration 1883 | Cost: 0.42892758781837825 | Gradient: [[ 0.00663441]\n",
      " [-0.14778568]\n",
      " [ 0.13756629]]\n",
      "Iteration 1884 | Cost: 0.4288867833002888 | Gradient: [[ 0.00665885]\n",
      " [-0.14772047]\n",
      " [ 0.13756848]]\n",
      "Iteration 1885 | Cost: 0.42884599711589744 | Gradient: [[ 0.00668327]\n",
      " [-0.14765532]\n",
      " [ 0.13757066]]\n",
      "Iteration 1886 | Cost: 0.4288052292419364 | Gradient: [[ 0.00670766]\n",
      " [-0.14759024]\n",
      " [ 0.13757283]]\n",
      "Iteration 1887 | Cost: 0.4287644796551839 | Gradient: [[ 0.00673203]\n",
      " [-0.14752522]\n",
      " [ 0.13757498]]\n",
      "Iteration 1888 | Cost: 0.42872374833246285 | Gradient: [[ 0.00675637]\n",
      " [-0.14746026]\n",
      " [ 0.13757711]]\n",
      "Iteration 1889 | Cost: 0.42868303525064233 | Gradient: [[ 0.00678069]\n",
      " [-0.14739537]\n",
      " [ 0.13757922]]\n",
      "Iteration 1890 | Cost: 0.4286423403866364 | Gradient: [[ 0.00680498]\n",
      " [-0.14733054]\n",
      " [ 0.13758132]]\n",
      "Iteration 1891 | Cost: 0.4286016637174043 | Gradient: [[ 0.00682924]\n",
      " [-0.14726577]\n",
      " [ 0.13758341]]\n",
      "Iteration 1892 | Cost: 0.4285610052199502 | Gradient: [[ 0.00685348]\n",
      " [-0.14720106]\n",
      " [ 0.13758547]]\n",
      "Iteration 1893 | Cost: 0.4285203648713237 | Gradient: [[ 0.00687769]\n",
      " [-0.14713641]\n",
      " [ 0.13758752]]\n",
      "Iteration 1894 | Cost: 0.42847974264861877 | Gradient: [[ 0.00690187]\n",
      " [-0.14707182]\n",
      " [ 0.13758955]]\n",
      "Iteration 1895 | Cost: 0.4284391385289743 | Gradient: [[ 0.00692604]\n",
      " [-0.1470073 ]\n",
      " [ 0.13759157]]\n",
      "Iteration 1896 | Cost: 0.42839855248957404 | Gradient: [[ 0.00695017]\n",
      " [-0.14694284]\n",
      " [ 0.13759357]]\n",
      "Iteration 1897 | Cost: 0.42835798450764584 | Gradient: [[ 0.00697428]\n",
      " [-0.14687844]\n",
      " [ 0.13759556]]\n",
      "Iteration 1898 | Cost: 0.4283174345604624 | Gradient: [[ 0.00699836]\n",
      " [-0.1468141 ]\n",
      " [ 0.13759753]]\n",
      "Iteration 1899 | Cost: 0.4282769026253405 | Gradient: [[ 0.00702242]\n",
      " [-0.14674982]\n",
      " [ 0.13759948]]\n",
      "Iteration 1900 | Cost: 0.4282363886796414 | Gradient: [[ 0.00704646]\n",
      " [-0.1466856 ]\n",
      " [ 0.13760142]]\n",
      "Iteration 1901 | Cost: 0.4281958927007703 | Gradient: [[ 0.00707046]\n",
      " [-0.14662145]\n",
      " [ 0.13760334]]\n",
      "Iteration 1902 | Cost: 0.42815541466617624 | Gradient: [[ 0.00709444]\n",
      " [-0.14655735]\n",
      " [ 0.13760524]]\n",
      "Iteration 1903 | Cost: 0.42811495455335263 | Gradient: [[ 0.0071184 ]\n",
      " [-0.14649332]\n",
      " [ 0.13760713]]\n",
      "Iteration 1904 | Cost: 0.4280745123398363 | Gradient: [[ 0.00714233]\n",
      " [-0.14642935]\n",
      " [ 0.137609  ]]\n",
      "Iteration 1905 | Cost: 0.428034088003208 | Gradient: [[ 0.00716624]\n",
      " [-0.14636543]\n",
      " [ 0.13761086]]\n",
      "Iteration 1906 | Cost: 0.42799368152109196 | Gradient: [[ 0.00719012]\n",
      " [-0.14630158]\n",
      " [ 0.1376127 ]]\n",
      "Iteration 1907 | Cost: 0.4279532928711561 | Gradient: [[ 0.00721398]\n",
      " [-0.14623779]\n",
      " [ 0.13761452]]\n",
      "Iteration 1908 | Cost: 0.4279129220311114 | Gradient: [[ 0.00723781]\n",
      " [-0.14617406]\n",
      " [ 0.13761633]]\n",
      "Iteration 1909 | Cost: 0.42787256897871245 | Gradient: [[ 0.00726161]\n",
      " [-0.1461104 ]\n",
      " [ 0.13761812]]\n",
      "Iteration 1910 | Cost: 0.42783223369175705 | Gradient: [[ 0.00728539]\n",
      " [-0.14604679]\n",
      " [ 0.1376199 ]]\n",
      "Iteration 1911 | Cost: 0.42779191614808587 | Gradient: [[ 0.00730915]\n",
      " [-0.14598324]\n",
      " [ 0.13762166]]\n",
      "Iteration 1912 | Cost: 0.4277516163255826 | Gradient: [[ 0.00733288]\n",
      " [-0.14591975]\n",
      " [ 0.1376234 ]]\n",
      "Iteration 1913 | Cost: 0.4277113342021741 | Gradient: [[ 0.00735658]\n",
      " [-0.14585632]\n",
      " [ 0.13762513]]\n",
      "Iteration 1914 | Cost: 0.42767106975582964 | Gradient: [[ 0.00738026]\n",
      " [-0.14579296]\n",
      " [ 0.13762684]]\n",
      "Iteration 1915 | Cost: 0.42763082296456156 | Gradient: [[ 0.00740392]\n",
      " [-0.14572965]\n",
      " [ 0.13762854]]\n",
      "Iteration 1916 | Cost: 0.42759059380642445 | Gradient: [[ 0.00742755]\n",
      " [-0.1456664 ]\n",
      " [ 0.13763022]]\n",
      "Iteration 1917 | Cost: 0.4275503822595156 | Gradient: [[ 0.00745115]\n",
      " [-0.14560322]\n",
      " [ 0.13763189]]\n",
      "Iteration 1918 | Cost: 0.4275101883019746 | Gradient: [[ 0.00747473]\n",
      " [-0.14554009]\n",
      " [ 0.13763354]]\n",
      "Iteration 1919 | Cost: 0.42747001191198336 | Gradient: [[ 0.00749829]\n",
      " [-0.14547702]\n",
      " [ 0.13763517]]\n",
      "Iteration 1920 | Cost: 0.4274298530677661 | Gradient: [[ 0.00752182]\n",
      " [-0.14541401]\n",
      " [ 0.13763679]]\n",
      "Iteration 1921 | Cost: 0.42738971174758883 | Gradient: [[ 0.00754532]\n",
      " [-0.14535107]\n",
      " [ 0.13763839]]\n",
      "Iteration 1922 | Cost: 0.4273495879297598 | Gradient: [[ 0.0075688 ]\n",
      " [-0.14528818]\n",
      " [ 0.13763998]]\n",
      "Iteration 1923 | Cost: 0.42730948159262916 | Gradient: [[ 0.00759226]\n",
      " [-0.14522535]\n",
      " [ 0.13764155]]\n",
      "Iteration 1924 | Cost: 0.4272693927145889 | Gradient: [[ 0.00761569]\n",
      " [-0.14516258]\n",
      " [ 0.1376431 ]]\n",
      "Iteration 1925 | Cost: 0.42722932127407226 | Gradient: [[ 0.0076391 ]\n",
      " [-0.14509987]\n",
      " [ 0.13764465]]\n",
      "Iteration 1926 | Cost: 0.42718926724955475 | Gradient: [[ 0.00766248]\n",
      " [-0.14503722]\n",
      " [ 0.13764617]]\n",
      "Iteration 1927 | Cost: 0.427149230619553 | Gradient: [[ 0.00768584]\n",
      " [-0.14497462]\n",
      " [ 0.13764768]]\n",
      "Iteration 1928 | Cost: 0.427109211362625 | Gradient: [[ 0.00770917]\n",
      " [-0.14491209]\n",
      " [ 0.13764917]]\n",
      "Iteration 1929 | Cost: 0.4270692094573702 | Gradient: [[ 0.00773248]\n",
      " [-0.14484962]\n",
      " [ 0.13765065]]\n",
      "Iteration 1930 | Cost: 0.4270292248824294 | Gradient: [[ 0.00775576]\n",
      " [-0.1447872 ]\n",
      " [ 0.13765211]]\n",
      "Iteration 1931 | Cost: 0.4269892576164841 | Gradient: [[ 0.00777902]\n",
      " [-0.14472485]\n",
      " [ 0.13765356]]\n",
      "Iteration 1932 | Cost: 0.4269493076382572 | Gradient: [[ 0.00780226]\n",
      " [-0.14466255]\n",
      " [ 0.13765499]]\n",
      "Iteration 1933 | Cost: 0.42690937492651243 | Gradient: [[ 0.00782547]\n",
      " [-0.14460031]\n",
      " [ 0.13765641]]\n",
      "Iteration 1934 | Cost: 0.42686945946005417 | Gradient: [[ 0.00784866]\n",
      " [-0.14453813]\n",
      " [ 0.13765781]]\n",
      "Iteration 1935 | Cost: 0.42682956121772786 | Gradient: [[ 0.00787182]\n",
      " [-0.14447601]\n",
      " [ 0.1376592 ]]\n",
      "Iteration 1936 | Cost: 0.4267896801784193 | Gradient: [[ 0.00789496]\n",
      " [-0.14441395]\n",
      " [ 0.13766057]]\n",
      "Iteration 1937 | Cost: 0.426749816321055 | Gradient: [[ 0.00791807]\n",
      " [-0.14435194]\n",
      " [ 0.13766192]]\n",
      "Iteration 1938 | Cost: 0.4267099696246018 | Gradient: [[ 0.00794116]\n",
      " [-0.14429   ]\n",
      " [ 0.13766326]]\n",
      "Iteration 1939 | Cost: 0.42667014006806697 | Gradient: [[ 0.00796422]\n",
      " [-0.14422811]\n",
      " [ 0.13766459]]\n",
      "Iteration 1940 | Cost: 0.4266303276304982 | Gradient: [[ 0.00798726]\n",
      " [-0.14416628]\n",
      " [ 0.1376659 ]]\n",
      "Iteration 1941 | Cost: 0.4265905322909829 | Gradient: [[ 0.00801028]\n",
      " [-0.14410451]\n",
      " [ 0.13766719]]\n",
      "Iteration 1942 | Cost: 0.42655075402864917 | Gradient: [[ 0.00803327]\n",
      " [-0.14404279]\n",
      " [ 0.13766847]]\n",
      "Iteration 1943 | Cost: 0.42651099282266447 | Gradient: [[ 0.00805624]\n",
      " [-0.14398114]\n",
      " [ 0.13766974]]\n",
      "Iteration 1944 | Cost: 0.4264712486522366 | Gradient: [[ 0.00807919]\n",
      " [-0.14391954]\n",
      " [ 0.13767098]]\n",
      "Iteration 1945 | Cost: 0.42643152149661295 | Gradient: [[ 0.00810211]\n",
      " [-0.143858  ]\n",
      " [ 0.13767222]]\n",
      "Iteration 1946 | Cost: 0.42639181133508075 | Gradient: [[ 0.008125  ]\n",
      " [-0.14379652]\n",
      " [ 0.13767344]]\n",
      "Iteration 1947 | Cost: 0.4263521181469666 | Gradient: [[ 0.00814787]\n",
      " [-0.14373509]\n",
      " [ 0.13767464]]\n",
      "Iteration 1948 | Cost: 0.42631244191163703 | Gradient: [[ 0.00817072]\n",
      " [-0.14367372]\n",
      " [ 0.13767583]]\n",
      "Iteration 1949 | Cost: 0.42627278260849755 | Gradient: [[ 0.00819355]\n",
      " [-0.14361241]\n",
      " [ 0.137677  ]]\n",
      "Iteration 1950 | Cost: 0.4262331402169932 | Gradient: [[ 0.00821635]\n",
      " [-0.14355116]\n",
      " [ 0.13767816]]\n",
      "Iteration 1951 | Cost: 0.42619351471660843 | Gradient: [[ 0.00823912]\n",
      " [-0.14348997]\n",
      " [ 0.13767931]]\n",
      "Iteration 1952 | Cost: 0.4261539060868666 | Gradient: [[ 0.00826188]\n",
      " [-0.14342883]\n",
      " [ 0.13768043]]\n",
      "Iteration 1953 | Cost: 0.4261143143073302 | Gradient: [[ 0.00828461]\n",
      " [-0.14336775]\n",
      " [ 0.13768155]]\n",
      "Iteration 1954 | Cost: 0.4260747393576008 | Gradient: [[ 0.00830731]\n",
      " [-0.14330673]\n",
      " [ 0.13768265]]\n",
      "Iteration 1955 | Cost: 0.4260351812173187 | Gradient: [[ 0.00832999]\n",
      " [-0.14324576]\n",
      " [ 0.13768373]]\n",
      "Iteration 1956 | Cost: 0.4259956398661631 | Gradient: [[ 0.00835265]\n",
      " [-0.14318485]\n",
      " [ 0.1376848 ]]\n",
      "Iteration 1957 | Cost: 0.42595611528385185 | Gradient: [[ 0.00837529]\n",
      " [-0.143124  ]\n",
      " [ 0.13768585]]\n",
      "Iteration 1958 | Cost: 0.4259166074501415 | Gradient: [[ 0.0083979 ]\n",
      " [-0.1430632 ]\n",
      " [ 0.13768689]]\n",
      "Iteration 1959 | Cost: 0.42587711634482694 | Gradient: [[ 0.00842048]\n",
      " [-0.14300246]\n",
      " [ 0.13768792]]\n",
      "Iteration 1960 | Cost: 0.4258376419477419 | Gradient: [[ 0.00844305]\n",
      " [-0.14294178]\n",
      " [ 0.13768893]]\n",
      "Iteration 1961 | Cost: 0.4257981842387578 | Gradient: [[ 0.00846559]\n",
      " [-0.14288116]\n",
      " [ 0.13768992]]\n",
      "Iteration 1962 | Cost: 0.4257587431977849 | Gradient: [[ 0.0084881 ]\n",
      " [-0.14282059]\n",
      " [ 0.1376909 ]]\n",
      "Iteration 1963 | Cost: 0.4257193188047714 | Gradient: [[ 0.0085106 ]\n",
      " [-0.14276008]\n",
      " [ 0.13769187]]\n",
      "Iteration 1964 | Cost: 0.4256799110397036 | Gradient: [[ 0.00853306]\n",
      " [-0.14269962]\n",
      " [ 0.13769282]]\n",
      "Iteration 1965 | Cost: 0.42564051988260576 | Gradient: [[ 0.00855551]\n",
      " [-0.14263922]\n",
      " [ 0.13769375]]\n",
      "Iteration 1966 | Cost: 0.4256011453135402 | Gradient: [[ 0.00857793]\n",
      " [-0.14257888]\n",
      " [ 0.13769468]]\n",
      "Iteration 1967 | Cost: 0.42556178731260685 | Gradient: [[ 0.00860033]\n",
      " [-0.14251859]\n",
      " [ 0.13769558]]\n",
      "Iteration 1968 | Cost: 0.4255224458599434 | Gradient: [[ 0.00862271]\n",
      " [-0.14245836]\n",
      " [ 0.13769647]]\n",
      "Iteration 1969 | Cost: 0.42548312093572555 | Gradient: [[ 0.00864506]\n",
      " [-0.14239818]\n",
      " [ 0.13769735]]\n",
      "Iteration 1970 | Cost: 0.42544381252016594 | Gradient: [[ 0.00866739]\n",
      " [-0.14233806]\n",
      " [ 0.13769821]]\n",
      "Iteration 1971 | Cost: 0.42540452059351513 | Gradient: [[ 0.0086897 ]\n",
      " [-0.142278  ]\n",
      " [ 0.13769906]]\n",
      "Iteration 1972 | Cost: 0.42536524513606094 | Gradient: [[ 0.00871198]\n",
      " [-0.14221799]\n",
      " [ 0.1376999 ]]\n",
      "Iteration 1973 | Cost: 0.42532598612812855 | Gradient: [[ 0.00873424]\n",
      " [-0.14215804]\n",
      " [ 0.13770072]]\n",
      "Iteration 1974 | Cost: 0.4252867435500801 | Gradient: [[ 0.00875648]\n",
      " [-0.14209815]\n",
      " [ 0.13770152]]\n",
      "Iteration 1975 | Cost: 0.42524751738231525 | Gradient: [[ 0.00877869]\n",
      " [-0.14203831]\n",
      " [ 0.13770231]]\n",
      "Iteration 1976 | Cost: 0.4252083076052705 | Gradient: [[ 0.00880088]\n",
      " [-0.14197852]\n",
      " [ 0.13770309]]\n",
      "Iteration 1977 | Cost: 0.4251691141994191 | Gradient: [[ 0.00882305]\n",
      " [-0.14191879]\n",
      " [ 0.13770385]]\n",
      "Iteration 1978 | Cost: 0.42512993714527164 | Gradient: [[ 0.00884519]\n",
      " [-0.14185912]\n",
      " [ 0.1377046 ]]\n",
      "Iteration 1979 | Cost: 0.42509077642337506 | Gradient: [[ 0.00886731]\n",
      " [-0.1417995 ]\n",
      " [ 0.13770533]]\n",
      "Iteration 1980 | Cost: 0.42505163201431334 | Gradient: [[ 0.00888941]\n",
      " [-0.14173994]\n",
      " [ 0.13770605]]\n",
      "Iteration 1981 | Cost: 0.42501250389870676 | Gradient: [[ 0.00891148]\n",
      " [-0.14168043]\n",
      " [ 0.13770675]]\n",
      "Iteration 1982 | Cost: 0.4249733920572123 | Gradient: [[ 0.00893354]\n",
      " [-0.14162098]\n",
      " [ 0.13770744]]\n",
      "Iteration 1983 | Cost: 0.4249342964705236 | Gradient: [[ 0.00895557]\n",
      " [-0.14156158]\n",
      " [ 0.13770812]]\n",
      "Iteration 1984 | Cost: 0.4248952171193703 | Gradient: [[ 0.00897757]\n",
      " [-0.14150223]\n",
      " [ 0.13770878]]\n",
      "Iteration 1985 | Cost: 0.4248561539845185 | Gradient: [[ 0.00899956]\n",
      " [-0.14144295]\n",
      " [ 0.13770942]]\n",
      "Iteration 1986 | Cost: 0.4248171070467704 | Gradient: [[ 0.00902152]\n",
      " [-0.14138371]\n",
      " [ 0.13771006]]\n",
      "Iteration 1987 | Cost: 0.4247780762869646 | Gradient: [[ 0.00904345]\n",
      " [-0.14132454]\n",
      " [ 0.13771067]]\n",
      "Iteration 1988 | Cost: 0.42473906168597536 | Gradient: [[ 0.00906537]\n",
      " [-0.14126541]\n",
      " [ 0.13771128]]\n",
      "Iteration 1989 | Cost: 0.42470006322471315 | Gradient: [[ 0.00908726]\n",
      " [-0.14120634]\n",
      " [ 0.13771187]]\n",
      "Iteration 1990 | Cost: 0.4246610808841243 | Gradient: [[ 0.00910913]\n",
      " [-0.14114733]\n",
      " [ 0.13771244]]\n",
      "Iteration 1991 | Cost: 0.4246221146451907 | Gradient: [[ 0.00913098]\n",
      " [-0.14108837]\n",
      " [ 0.13771301]]\n",
      "Iteration 1992 | Cost: 0.42458316448893024 | Gradient: [[ 0.0091528 ]\n",
      " [-0.14102946]\n",
      " [ 0.13771355]]\n",
      "Iteration 1993 | Cost: 0.42454423039639616 | Gradient: [[ 0.00917461]\n",
      " [-0.14097061]\n",
      " [ 0.13771409]]\n",
      "Iteration 1994 | Cost: 0.4245053123486778 | Gradient: [[ 0.00919638]\n",
      " [-0.14091182]\n",
      " [ 0.13771461]]\n",
      "Iteration 1995 | Cost: 0.42446641032689886 | Gradient: [[ 0.00921814]\n",
      " [-0.14085307]\n",
      " [ 0.13771511]]\n",
      "Iteration 1996 | Cost: 0.4244275243122197 | Gradient: [[ 0.00923988]\n",
      " [-0.14079438]\n",
      " [ 0.1377156 ]]\n",
      "Iteration 1997 | Cost: 0.4243886542858351 | Gradient: [[ 0.00926159]\n",
      " [-0.14073575]\n",
      " [ 0.13771608]]\n",
      "Iteration 1998 | Cost: 0.4243498002289755 | Gradient: [[ 0.00928328]\n",
      " [-0.14067717]\n",
      " [ 0.13771654]]\n",
      "Iteration 1999 | Cost: 0.42431096212290625 | Gradient: [[ 0.00930494]\n",
      " [-0.14061864]\n",
      " [ 0.13771699]]\n",
      "Iteration 2000 | Cost: 0.42427213994892793 | Gradient: [[ 0.00932659]\n",
      " [-0.14056017]\n",
      " [ 0.13771743]]\n",
      "Iteration 2001 | Cost: 0.42423333368837585 | Gradient: [[ 0.00934821]\n",
      " [-0.14050175]\n",
      " [ 0.13771785]]\n",
      "Iteration 2002 | Cost: 0.42419454332262047 | Gradient: [[ 0.00936981]\n",
      " [-0.14044339]\n",
      " [ 0.13771826]]\n",
      "Iteration 2003 | Cost: 0.4241557688330671 | Gradient: [[ 0.00939139]\n",
      " [-0.14038508]\n",
      " [ 0.13771865]]\n",
      "Iteration 2004 | Cost: 0.4241170102011556 | Gradient: [[ 0.00941294]\n",
      " [-0.14032682]\n",
      " [ 0.13771903]]\n",
      "Iteration 2005 | Cost: 0.42407826740836047 | Gradient: [[ 0.00943447]\n",
      " [-0.14026861]\n",
      " [ 0.13771939]]\n",
      "Iteration 2006 | Cost: 0.4240395404361911 | Gradient: [[ 0.00945598]\n",
      " [-0.14021046]\n",
      " [ 0.13771975]]\n",
      "Iteration 2007 | Cost: 0.424000829266191 | Gradient: [[ 0.00947747]\n",
      " [-0.14015237]\n",
      " [ 0.13772008]]\n",
      "Iteration 2008 | Cost: 0.4239621338799383 | Gradient: [[ 0.00949894]\n",
      " [-0.14009432]\n",
      " [ 0.13772041]]\n",
      "Iteration 2009 | Cost: 0.4239234542590456 | Gradient: [[ 0.00952038]\n",
      " [-0.14003633]\n",
      " [ 0.13772072]]\n",
      "Iteration 2010 | Cost: 0.4238847903851596 | Gradient: [[ 0.0095418 ]\n",
      " [-0.13997839]\n",
      " [ 0.13772102]]\n",
      "Iteration 2011 | Cost: 0.4238461422399611 | Gradient: [[ 0.0095632 ]\n",
      " [-0.13992051]\n",
      " [ 0.1377213 ]]\n",
      "Iteration 2012 | Cost: 0.42380750980516524 | Gradient: [[ 0.00958458]\n",
      " [-0.13986268]\n",
      " [ 0.13772157]]\n",
      "Iteration 2013 | Cost: 0.423768893062521 | Gradient: [[ 0.00960594]\n",
      " [-0.1398049 ]\n",
      " [ 0.13772182]]\n",
      "Iteration 2014 | Cost: 0.4237302919938116 | Gradient: [[ 0.00962727]\n",
      " [-0.13974718]\n",
      " [ 0.13772207]]\n",
      "Iteration 2015 | Cost: 0.42369170658085387 | Gradient: [[ 0.00964858]\n",
      " [-0.1396895 ]\n",
      " [ 0.13772229]]\n",
      "Iteration 2016 | Cost: 0.42365313680549854 | Gradient: [[ 0.00966987]\n",
      " [-0.13963188]\n",
      " [ 0.13772251]]\n",
      "Iteration 2017 | Cost: 0.4236145826496301 | Gradient: [[ 0.00969114]\n",
      " [-0.13957432]\n",
      " [ 0.13772271]]\n",
      "Iteration 2018 | Cost: 0.4235760440951666 | Gradient: [[ 0.00971238]\n",
      " [-0.1395168 ]\n",
      " [ 0.1377229 ]]\n",
      "Iteration 2019 | Cost: 0.4235375211240598 | Gradient: [[ 0.00973361]\n",
      " [-0.13945934]\n",
      " [ 0.13772307]]\n",
      "Iteration 2020 | Cost: 0.4234990137182948 | Gradient: [[ 0.00975481]\n",
      " [-0.13940193]\n",
      " [ 0.13772323]]\n",
      "Iteration 2021 | Cost: 0.4234605218598903 | Gradient: [[ 0.00977599]\n",
      " [-0.13934457]\n",
      " [ 0.13772338]]\n",
      "Iteration 2022 | Cost: 0.42342204553089835 | Gradient: [[ 0.00979715]\n",
      " [-0.13928727]\n",
      " [ 0.13772351]]\n",
      "Iteration 2023 | Cost: 0.4233835847134039 | Gradient: [[ 0.00981828]\n",
      " [-0.13923002]\n",
      " [ 0.13772363]]\n",
      "Iteration 2024 | Cost: 0.4233451393895257 | Gradient: [[ 0.0098394 ]\n",
      " [-0.13917282]\n",
      " [ 0.13772374]]\n",
      "Iteration 2025 | Cost: 0.4233067095414152 | Gradient: [[ 0.00986049]\n",
      " [-0.13911567]\n",
      " [ 0.13772383]]\n",
      "Iteration 2026 | Cost: 0.423268295151257 | Gradient: [[ 0.00988156]\n",
      " [-0.13905858]\n",
      " [ 0.13772391]]\n",
      "Iteration 2027 | Cost: 0.42322989620126866 | Gradient: [[ 0.00990261]\n",
      " [-0.13900153]\n",
      " [ 0.13772397]]\n",
      "Iteration 2028 | Cost: 0.42319151267370075 | Gradient: [[ 0.00992364]\n",
      " [-0.13894454]\n",
      " [ 0.13772403]]\n",
      "Iteration 2029 | Cost: 0.4231531445508365 | Gradient: [[ 0.00994465]\n",
      " [-0.1388876 ]\n",
      " [ 0.13772406]]\n",
      "Iteration 2030 | Cost: 0.423114791814992 | Gradient: [[ 0.00996563]\n",
      " [-0.13883072]\n",
      " [ 0.13772409]]\n",
      "Iteration 2031 | Cost: 0.423076454448516 | Gradient: [[ 0.00998659]\n",
      " [-0.13877388]\n",
      " [ 0.1377241 ]]\n",
      "Iteration 2032 | Cost: 0.4230381324337899 | Gradient: [[ 0.01000753]\n",
      " [-0.1387171 ]\n",
      " [ 0.1377241 ]]\n",
      "Iteration 2033 | Cost: 0.4229998257532275 | Gradient: [[ 0.01002845]\n",
      " [-0.13866037]\n",
      " [ 0.13772409]]\n",
      "Iteration 2034 | Cost: 0.42296153438927514 | Gradient: [[ 0.01004935]\n",
      " [-0.13860369]\n",
      " [ 0.13772406]]\n",
      "Iteration 2035 | Cost: 0.4229232583244116 | Gradient: [[ 0.01007023]\n",
      " [-0.13854706]\n",
      " [ 0.13772402]]\n",
      "Iteration 2036 | Cost: 0.42288499754114783 | Gradient: [[ 0.01009109]\n",
      " [-0.13849048]\n",
      " [ 0.13772396]]\n",
      "Iteration 2037 | Cost: 0.42284675202202715 | Gradient: [[ 0.01011192]\n",
      " [-0.13843395]\n",
      " [ 0.1377239 ]]\n",
      "Iteration 2038 | Cost: 0.422808521749625 | Gradient: [[ 0.01013273]\n",
      " [-0.13837748]\n",
      " [ 0.13772382]]\n",
      "Iteration 2039 | Cost: 0.4227703067065488 | Gradient: [[ 0.01015352]\n",
      " [-0.13832106]\n",
      " [ 0.13772372]]\n",
      "Iteration 2040 | Cost: 0.4227321068754383 | Gradient: [[ 0.01017429]\n",
      " [-0.13826468]\n",
      " [ 0.13772361]]\n",
      "Iteration 2041 | Cost: 0.42269392223896485 | Gradient: [[ 0.01019504]\n",
      " [-0.13820836]\n",
      " [ 0.13772349]]\n",
      "Iteration 2042 | Cost: 0.4226557527798318 | Gradient: [[ 0.01021577]\n",
      " [-0.13815209]\n",
      " [ 0.13772336]]\n",
      "Iteration 2043 | Cost: 0.4226175984807745 | Gradient: [[ 0.01023648]\n",
      " [-0.13809587]\n",
      " [ 0.13772321]]\n",
      "Iteration 2044 | Cost: 0.42257945932455965 | Gradient: [[ 0.01025716]\n",
      " [-0.13803971]\n",
      " [ 0.13772305]]\n",
      "Iteration 2045 | Cost: 0.42254133529398596 | Gradient: [[ 0.01027783]\n",
      " [-0.13798359]\n",
      " [ 0.13772288]]\n",
      "Iteration 2046 | Cost: 0.42250322637188364 | Gradient: [[ 0.01029847]\n",
      " [-0.13792753]\n",
      " [ 0.1377227 ]]\n",
      "Iteration 2047 | Cost: 0.4224651325411144 | Gradient: [[ 0.01031909]\n",
      " [-0.13787151]\n",
      " [ 0.1377225 ]]\n",
      "Iteration 2048 | Cost: 0.4224270537845712 | Gradient: [[ 0.01033969]\n",
      " [-0.13781555]\n",
      " [ 0.13772228]]\n",
      "Iteration 2049 | Cost: 0.42238899008517855 | Gradient: [[ 0.01036027]\n",
      " [-0.13775963]\n",
      " [ 0.13772206]]\n",
      "Iteration 2050 | Cost: 0.4223509414258926 | Gradient: [[ 0.01038083]\n",
      " [-0.13770377]\n",
      " [ 0.13772182]]\n",
      "Iteration 2051 | Cost: 0.42231290778970015 | Gradient: [[ 0.01040136]\n",
      " [-0.13764796]\n",
      " [ 0.13772157]]\n",
      "Iteration 2052 | Cost: 0.4222748891596195 | Gradient: [[ 0.01042188]\n",
      " [-0.1375922 ]\n",
      " [ 0.13772131]]\n",
      "Iteration 2053 | Cost: 0.4222368855187 | Gradient: [[ 0.01044238]\n",
      " [-0.13753648]\n",
      " [ 0.13772103]]\n",
      "Iteration 2054 | Cost: 0.42219889685002204 | Gradient: [[ 0.01046285]\n",
      " [-0.13748082]\n",
      " [ 0.13772074]]\n",
      "Iteration 2055 | Cost: 0.422160923136697 | Gradient: [[ 0.0104833 ]\n",
      " [-0.13742521]\n",
      " [ 0.13772044]]\n",
      "Iteration 2056 | Cost: 0.422122964361867 | Gradient: [[ 0.01050374]\n",
      " [-0.13736965]\n",
      " [ 0.13772012]]\n",
      "Iteration 2057 | Cost: 0.4220850205087052 | Gradient: [[ 0.01052415]\n",
      " [-0.13731414]\n",
      " [ 0.13771979]]\n",
      "Iteration 2058 | Cost: 0.4220470915604154 | Gradient: [[ 0.01054454]\n",
      " [-0.13725868]\n",
      " [ 0.13771945]]\n",
      "Iteration 2059 | Cost: 0.42200917750023187 | Gradient: [[ 0.01056491]\n",
      " [-0.13720327]\n",
      " [ 0.1377191 ]]\n",
      "Iteration 2060 | Cost: 0.42197127831141995 | Gradient: [[ 0.01058526]\n",
      " [-0.13714791]\n",
      " [ 0.13771873]]\n",
      "Iteration 2061 | Cost: 0.42193339397727525 | Gradient: [[ 0.01060558]\n",
      " [-0.1370926 ]\n",
      " [ 0.13771835]]\n",
      "Iteration 2062 | Cost: 0.4218955244811239 | Gradient: [[ 0.01062589]\n",
      " [-0.13703734]\n",
      " [ 0.13771796]]\n",
      "Iteration 2063 | Cost: 0.4218576698063223 | Gradient: [[ 0.01064618]\n",
      " [-0.13698213]\n",
      " [ 0.13771755]]\n",
      "Iteration 2064 | Cost: 0.4218198299362575 | Gradient: [[ 0.01066644]\n",
      " [-0.13692697]\n",
      " [ 0.13771714]]\n",
      "Iteration 2065 | Cost: 0.42178200485434664 | Gradient: [[ 0.01068669]\n",
      " [-0.13687186]\n",
      " [ 0.1377167 ]]\n",
      "Iteration 2066 | Cost: 0.4217441945440371 | Gradient: [[ 0.01070691]\n",
      " [-0.13681679]\n",
      " [ 0.13771626]]\n",
      "Iteration 2067 | Cost: 0.42170639898880624 | Gradient: [[ 0.01072712]\n",
      " [-0.13676178]\n",
      " [ 0.1377158 ]]\n",
      "Iteration 2068 | Cost: 0.42166861817216184 | Gradient: [[ 0.0107473 ]\n",
      " [-0.13670682]\n",
      " [ 0.13771534]]\n",
      "Iteration 2069 | Cost: 0.4216308520776414 | Gradient: [[ 0.01076746]\n",
      " [-0.13665191]\n",
      " [ 0.13771485]]\n",
      "Iteration 2070 | Cost: 0.42159310068881256 | Gradient: [[ 0.01078761]\n",
      " [-0.13659704]\n",
      " [ 0.13771436]]\n",
      "Iteration 2071 | Cost: 0.42155536398927257 | Gradient: [[ 0.01080773]\n",
      " [-0.13654223]\n",
      " [ 0.13771385]]\n",
      "Iteration 2072 | Cost: 0.4215176419626487 | Gradient: [[ 0.01082783]\n",
      " [-0.13648746]\n",
      " [ 0.13771333]]\n",
      "Iteration 2073 | Cost: 0.421479934592598 | Gradient: [[ 0.01084791]\n",
      " [-0.13643275]\n",
      " [ 0.1377128 ]]\n",
      "Iteration 2074 | Cost: 0.421442241862807 | Gradient: [[ 0.01086797]\n",
      " [-0.13637808]\n",
      " [ 0.13771226]]\n",
      "Iteration 2075 | Cost: 0.42140456375699203 | Gradient: [[ 0.01088801]\n",
      " [-0.13632346]\n",
      " [ 0.1377117 ]]\n",
      "Iteration 2076 | Cost: 0.4213669002588988 | Gradient: [[ 0.01090803]\n",
      " [-0.13626889]\n",
      " [ 0.13771113]]\n",
      "Iteration 2077 | Cost: 0.42132925135230265 | Gradient: [[ 0.01092803]\n",
      " [-0.13621437]\n",
      " [ 0.13771055]]\n",
      "Iteration 2078 | Cost: 0.4212916170210081 | Gradient: [[ 0.01094801]\n",
      " [-0.1361599 ]\n",
      " [ 0.13770996]]\n",
      "Iteration 2079 | Cost: 0.42125399724884943 | Gradient: [[ 0.01096797]\n",
      " [-0.13610548]\n",
      " [ 0.13770935]]\n",
      "Iteration 2080 | Cost: 0.4212163920196898 | Gradient: [[ 0.0109879 ]\n",
      " [-0.13605111]\n",
      " [ 0.13770873]]\n",
      "Iteration 2081 | Cost: 0.42117880131742164 | Gradient: [[ 0.01100782]\n",
      " [-0.13599678]\n",
      " [ 0.1377081 ]]\n",
      "Iteration 2082 | Cost: 0.42114122512596686 | Gradient: [[ 0.01102772]\n",
      " [-0.13594251]\n",
      " [ 0.13770745]]\n",
      "Iteration 2083 | Cost: 0.42110366342927597 | Gradient: [[ 0.0110476 ]\n",
      " [-0.13588828]\n",
      " [ 0.1377068 ]]\n",
      "Iteration 2084 | Cost: 0.4210661162113289 | Gradient: [[ 0.01106745]\n",
      " [-0.1358341 ]\n",
      " [ 0.13770613]]\n",
      "Iteration 2085 | Cost: 0.4210285834561344 | Gradient: [[ 0.01108729]\n",
      " [-0.13577997]\n",
      " [ 0.13770544]]\n",
      "Iteration 2086 | Cost: 0.42099106514773005 | Gradient: [[ 0.01110711]\n",
      " [-0.13572589]\n",
      " [ 0.13770475]]\n",
      "Iteration 2087 | Cost: 0.42095356127018246 | Gradient: [[ 0.0111269 ]\n",
      " [-0.13567186]\n",
      " [ 0.13770404]]\n",
      "Iteration 2088 | Cost: 0.4209160718075867 | Gradient: [[ 0.01114668]\n",
      " [-0.13561787]\n",
      " [ 0.13770333]]\n",
      "Iteration 2089 | Cost: 0.4208785967440668 | Gradient: [[ 0.01116644]\n",
      " [-0.13556393]\n",
      " [ 0.1377026 ]]\n",
      "Iteration 2090 | Cost: 0.4208411360637753 | Gradient: [[ 0.01118617]\n",
      " [-0.13551004]\n",
      " [ 0.13770185]]\n",
      "Iteration 2091 | Cost: 0.42080368975089333 | Gradient: [[ 0.01120589]\n",
      " [-0.1354562 ]\n",
      " [ 0.1377011 ]]\n",
      "Iteration 2092 | Cost: 0.4207662577896307 | Gradient: [[ 0.01122558]\n",
      " [-0.13540241]\n",
      " [ 0.13770033]]\n",
      "Iteration 2093 | Cost: 0.4207288401642254 | Gradient: [[ 0.01124526]\n",
      " [-0.13534867]\n",
      " [ 0.13769955]]\n",
      "Iteration 2094 | Cost: 0.42069143685894406 | Gradient: [[ 0.01126492]\n",
      " [-0.13529497]\n",
      " [ 0.13769876]]\n",
      "Iteration 2095 | Cost: 0.42065404785808136 | Gradient: [[ 0.01128455]\n",
      " [-0.13524132]\n",
      " [ 0.13769795]]\n",
      "Iteration 2096 | Cost: 0.4206166731459605 | Gradient: [[ 0.01130417]\n",
      " [-0.13518772]\n",
      " [ 0.13769714]]\n",
      "Iteration 2097 | Cost: 0.4205793127069328 | Gradient: [[ 0.01132377]\n",
      " [-0.13513417]\n",
      " [ 0.13769631]]\n",
      "Iteration 2098 | Cost: 0.4205419665253777 | Gradient: [[ 0.01134334]\n",
      " [-0.13508066]\n",
      " [ 0.13769547]]\n",
      "Iteration 2099 | Cost: 0.42050463458570253 | Gradient: [[ 0.0113629 ]\n",
      " [-0.1350272 ]\n",
      " [ 0.13769462]]\n",
      "Iteration 2100 | Cost: 0.42046731687234307 | Gradient: [[ 0.01138244]\n",
      " [-0.13497379]\n",
      " [ 0.13769375]]\n",
      "Iteration 2101 | Cost: 0.4204300133697627 | Gradient: [[ 0.01140195]\n",
      " [-0.13492043]\n",
      " [ 0.13769287]]\n",
      "Iteration 2102 | Cost: 0.4203927240624528 | Gradient: [[ 0.01142145]\n",
      " [-0.13486711]\n",
      " [ 0.13769198]]\n",
      "Iteration 2103 | Cost: 0.42035544893493254 | Gradient: [[ 0.01144093]\n",
      " [-0.13481385]\n",
      " [ 0.13769108]]\n",
      "Iteration 2104 | Cost: 0.4203181879717489 | Gradient: [[ 0.01146038]\n",
      " [-0.13476063]\n",
      " [ 0.13769017]]\n",
      "Iteration 2105 | Cost: 0.4202809411574766 | Gradient: [[ 0.01147982]\n",
      " [-0.13470745]\n",
      " [ 0.13768924]]\n",
      "Iteration 2106 | Cost: 0.4202437084767179 | Gradient: [[ 0.01149924]\n",
      " [-0.13465433]\n",
      " [ 0.13768831]]\n",
      "Iteration 2107 | Cost: 0.4202064899141027 | Gradient: [[ 0.01151864]\n",
      " [-0.13460125]\n",
      " [ 0.13768736]]\n",
      "Iteration 2108 | Cost: 0.42016928545428855 | Gradient: [[ 0.01153802]\n",
      " [-0.13454822]\n",
      " [ 0.1376864 ]]\n",
      "Iteration 2109 | Cost: 0.4201320950819602 | Gradient: [[ 0.01155738]\n",
      " [-0.13449523]\n",
      " [ 0.13768542]]\n",
      "Iteration 2110 | Cost: 0.42009491878183003 | Gradient: [[ 0.01157672]\n",
      " [-0.13444229]\n",
      " [ 0.13768444]]\n",
      "Iteration 2111 | Cost: 0.4200577565386377 | Gradient: [[ 0.01159604]\n",
      " [-0.1343894 ]\n",
      " [ 0.13768344]]\n",
      "Iteration 2112 | Cost: 0.4200206083371501 | Gradient: [[ 0.01161534]\n",
      " [-0.13433656]\n",
      " [ 0.13768243]]\n",
      "Iteration 2113 | Cost: 0.41998347416216136 | Gradient: [[ 0.01163462]\n",
      " [-0.13428376]\n",
      " [ 0.13768141]]\n",
      "Iteration 2114 | Cost: 0.4199463539984929 | Gradient: [[ 0.01165388]\n",
      " [-0.13423101]\n",
      " [ 0.13768038]]\n",
      "Iteration 2115 | Cost: 0.419909247830993 | Gradient: [[ 0.01167313]\n",
      " [-0.13417831]\n",
      " [ 0.13767933]]\n",
      "Iteration 2116 | Cost: 0.4198721556445372 | Gradient: [[ 0.01169235]\n",
      " [-0.13412565]\n",
      " [ 0.13767828]]\n",
      "Iteration 2117 | Cost: 0.4198350774240281 | Gradient: [[ 0.01171155]\n",
      " [-0.13407304]\n",
      " [ 0.13767721]]\n",
      "Iteration 2118 | Cost: 0.41979801315439474 | Gradient: [[ 0.01173074]\n",
      " [-0.13402048]\n",
      " [ 0.13767613]]\n",
      "Iteration 2119 | Cost: 0.4197609628205938 | Gradient: [[ 0.0117499 ]\n",
      " [-0.13396796]\n",
      " [ 0.13767504]]\n",
      "Iteration 2120 | Cost: 0.4197239264076079 | Gradient: [[ 0.01176905]\n",
      " [-0.13391549]\n",
      " [ 0.13767393]]\n",
      "Iteration 2121 | Cost: 0.4196869039004472 | Gradient: [[ 0.01178817]\n",
      " [-0.13386307]\n",
      " [ 0.13767282]]\n",
      "Iteration 2122 | Cost: 0.419649895284148 | Gradient: [[ 0.01180728]\n",
      " [-0.13381069]\n",
      " [ 0.13767169]]\n",
      "Iteration 2123 | Cost: 0.41961290054377354 | Gradient: [[ 0.01182637]\n",
      " [-0.13375836]\n",
      " [ 0.13767055]]\n",
      "Iteration 2124 | Cost: 0.4195759196644134 | Gradient: [[ 0.01184543]\n",
      " [-0.13370607]\n",
      " [ 0.1376694 ]]\n",
      "Iteration 2125 | Cost: 0.4195389526311839 | Gradient: [[ 0.01186448]\n",
      " [-0.13365383]\n",
      " [ 0.13766824]]\n",
      "Iteration 2126 | Cost: 0.4195019994292278 | Gradient: [[ 0.01188351]\n",
      " [-0.13360164]\n",
      " [ 0.13766707]]\n",
      "Iteration 2127 | Cost: 0.4194650600437141 | Gradient: [[ 0.01190252]\n",
      " [-0.13354949]\n",
      " [ 0.13766588]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2128 | Cost: 0.4194281344598381 | Gradient: [[ 0.01192151]\n",
      " [-0.13349739]\n",
      " [ 0.13766468]]\n",
      "Iteration 2129 | Cost: 0.41939122266282186 | Gradient: [[ 0.01194049]\n",
      " [-0.13344534]\n",
      " [ 0.13766347]]\n",
      "Iteration 2130 | Cost: 0.41935432463791306 | Gradient: [[ 0.01195944]\n",
      " [-0.13339333]\n",
      " [ 0.13766225]]\n",
      "Iteration 2131 | Cost: 0.4193174403703858 | Gradient: [[ 0.01197837]\n",
      " [-0.13334137]\n",
      " [ 0.13766102]]\n",
      "Iteration 2132 | Cost: 0.4192805698455406 | Gradient: [[ 0.01199729]\n",
      " [-0.13328945]\n",
      " [ 0.13765978]]\n",
      "Iteration 2133 | Cost: 0.4192437130487034 | Gradient: [[ 0.01201618]\n",
      " [-0.13323758]\n",
      " [ 0.13765852]]\n",
      "Iteration 2134 | Cost: 0.4192068699652267 | Gradient: [[ 0.01203506]\n",
      " [-0.13318575]\n",
      " [ 0.13765726]]\n",
      "Iteration 2135 | Cost: 0.4191700405804887 | Gradient: [[ 0.01205392]\n",
      " [-0.13313397]\n",
      " [ 0.13765598]]\n",
      "Iteration 2136 | Cost: 0.41913322487989346 | Gradient: [[ 0.01207276]\n",
      " [-0.13308224]\n",
      " [ 0.13765469]]\n",
      "Iteration 2137 | Cost: 0.4190964228488711 | Gradient: [[ 0.01209158]\n",
      " [-0.13303055]\n",
      " [ 0.13765339]]\n",
      "Iteration 2138 | Cost: 0.4190596344728772 | Gradient: [[ 0.01211038]\n",
      " [-0.1329789 ]\n",
      " [ 0.13765208]]\n",
      "Iteration 2139 | Cost: 0.4190228597373933 | Gradient: [[ 0.01212916]\n",
      " [-0.1329273 ]\n",
      " [ 0.13765075]]\n",
      "Iteration 2140 | Cost: 0.41898609862792646 | Gradient: [[ 0.01214792]\n",
      " [-0.13287575]\n",
      " [ 0.13764942]]\n",
      "Iteration 2141 | Cost: 0.41894935113000953 | Gradient: [[ 0.01216667]\n",
      " [-0.13282424]\n",
      " [ 0.13764807]]\n",
      "Iteration 2142 | Cost: 0.4189126172292006 | Gradient: [[ 0.01218539]\n",
      " [-0.13277278]\n",
      " [ 0.13764671]]\n",
      "Iteration 2143 | Cost: 0.4188758969110835 | Gradient: [[ 0.0122041 ]\n",
      " [-0.13272136]\n",
      " [ 0.13764534]]\n",
      "Iteration 2144 | Cost: 0.41883919016126747 | Gradient: [[ 0.01222279]\n",
      " [-0.13266999]\n",
      " [ 0.13764396]]\n",
      "Iteration 2145 | Cost: 0.4188024969653871 | Gradient: [[ 0.01224146]\n",
      " [-0.13261866]\n",
      " [ 0.13764257]]\n",
      "Iteration 2146 | Cost: 0.41876581730910256 | Gradient: [[ 0.01226011]\n",
      " [-0.13256738]\n",
      " [ 0.13764116]]\n",
      "Iteration 2147 | Cost: 0.4187291511780986 | Gradient: [[ 0.01227874]\n",
      " [-0.13251614]\n",
      " [ 0.13763975]]\n",
      "Iteration 2148 | Cost: 0.41869249855808605 | Gradient: [[ 0.01229735]\n",
      " [-0.13246495]\n",
      " [ 0.13763832]]\n",
      "Iteration 2149 | Cost: 0.4186558594348004 | Gradient: [[ 0.01231595]\n",
      " [-0.1324138 ]\n",
      " [ 0.13763688]]\n",
      "Iteration 2150 | Cost: 0.4186192337940022 | Gradient: [[ 0.01233452]\n",
      " [-0.1323627 ]\n",
      " [ 0.13763543]]\n",
      "Iteration 2151 | Cost: 0.4185826216214773 | Gradient: [[ 0.01235308]\n",
      " [-0.13231164]\n",
      " [ 0.13763397]]\n",
      "Iteration 2152 | Cost: 0.41854602290303655 | Gradient: [[ 0.01237162]\n",
      " [-0.13226063]\n",
      " [ 0.1376325 ]]\n",
      "Iteration 2153 | Cost: 0.4185094376245156 | Gradient: [[ 0.01239013]\n",
      " [-0.13220966]\n",
      " [ 0.13763102]]\n",
      "Iteration 2154 | Cost: 0.4184728657717751 | Gradient: [[ 0.01240864]\n",
      " [-0.13215874]\n",
      " [ 0.13762952]]\n",
      "Iteration 2155 | Cost: 0.4184363073307005 | Gradient: [[ 0.01242712]\n",
      " [-0.13210786]\n",
      " [ 0.13762802]]\n",
      "Iteration 2156 | Cost: 0.418399762287202 | Gradient: [[ 0.01244558]\n",
      " [-0.13205702]\n",
      " [ 0.1376265 ]]\n",
      "Iteration 2157 | Cost: 0.41836323062721464 | Gradient: [[ 0.01246403]\n",
      " [-0.13200623]\n",
      " [ 0.13762497]]\n",
      "Iteration 2158 | Cost: 0.41832671233669794 | Gradient: [[ 0.01248245]\n",
      " [-0.13195549]\n",
      " [ 0.13762344]]\n",
      "Iteration 2159 | Cost: 0.41829020740163636 | Gradient: [[ 0.01250086]\n",
      " [-0.13190479]\n",
      " [ 0.13762188]]\n",
      "Iteration 2160 | Cost: 0.41825371580803866 | Gradient: [[ 0.01251925]\n",
      " [-0.13185413]\n",
      " [ 0.13762032]]\n",
      "Iteration 2161 | Cost: 0.4182172375419382 | Gradient: [[ 0.01253762]\n",
      " [-0.13180351]\n",
      " [ 0.13761875]]\n",
      "Iteration 2162 | Cost: 0.4181807725893929 | Gradient: [[ 0.01255598]\n",
      " [-0.13175295]\n",
      " [ 0.13761717]]\n",
      "Iteration 2163 | Cost: 0.41814432093648496 | Gradient: [[ 0.01257431]\n",
      " [-0.13170242]\n",
      " [ 0.13761557]]\n",
      "Iteration 2164 | Cost: 0.4181078825693211 | Gradient: [[ 0.01259263]\n",
      " [-0.13165194]\n",
      " [ 0.13761397]]\n",
      "Iteration 2165 | Cost: 0.4180714574740322 | Gradient: [[ 0.01261092]\n",
      " [-0.1316015 ]\n",
      " [ 0.13761235]]\n",
      "Iteration 2166 | Cost: 0.4180350456367733 | Gradient: [[ 0.0126292 ]\n",
      " [-0.13155111]\n",
      " [ 0.13761072]]\n",
      "Iteration 2167 | Cost: 0.41799864704372414 | Gradient: [[ 0.01264747]\n",
      " [-0.13150076]\n",
      " [ 0.13760908]]\n",
      "Iteration 2168 | Cost: 0.41796226168108797 | Gradient: [[ 0.01266571]\n",
      " [-0.13145045]\n",
      " [ 0.13760744]]\n",
      "Iteration 2169 | Cost: 0.4179258895350926 | Gradient: [[ 0.01268393]\n",
      " [-0.13140019]\n",
      " [ 0.13760577]]\n",
      "Iteration 2170 | Cost: 0.41788953059198947 | Gradient: [[ 0.01270214]\n",
      " [-0.13134998]\n",
      " [ 0.1376041 ]]\n",
      "Iteration 2171 | Cost: 0.4178531848380545 | Gradient: [[ 0.01272033]\n",
      " [-0.1312998 ]\n",
      " [ 0.13760242]]\n",
      "Iteration 2172 | Cost: 0.4178168522595874 | Gradient: [[ 0.0127385 ]\n",
      " [-0.13124967]\n",
      " [ 0.13760073]]\n",
      "Iteration 2173 | Cost: 0.4177805328429117 | Gradient: [[ 0.01275665]\n",
      " [-0.13119958]\n",
      " [ 0.13759902]]\n",
      "Iteration 2174 | Cost: 0.4177442265743747 | Gradient: [[ 0.01277478]\n",
      " [-0.13114954]\n",
      " [ 0.13759731]]\n",
      "Iteration 2175 | Cost: 0.41770793344034746 | Gradient: [[ 0.0127929 ]\n",
      " [-0.13109954]\n",
      " [ 0.13759558]]\n",
      "Iteration 2176 | Cost: 0.417671653427225 | Gradient: [[ 0.012811  ]\n",
      " [-0.13104958]\n",
      " [ 0.13759384]]\n",
      "Iteration 2177 | Cost: 0.4176353865214259 | Gradient: [[ 0.01282908]\n",
      " [-0.13099967]\n",
      " [ 0.13759209]]\n",
      "Iteration 2178 | Cost: 0.41759913270939253 | Gradient: [[ 0.01284714]\n",
      " [-0.1309498 ]\n",
      " [ 0.13759034]]\n",
      "Iteration 2179 | Cost: 0.4175628919775906 | Gradient: [[ 0.01286518]\n",
      " [-0.13089998]\n",
      " [ 0.13758857]]\n",
      "Iteration 2180 | Cost: 0.41752666431250945 | Gradient: [[ 0.01288321]\n",
      " [-0.13085019]\n",
      " [ 0.13758679]]\n",
      "Iteration 2181 | Cost: 0.417490449700662 | Gradient: [[ 0.01290121]\n",
      " [-0.13080045]\n",
      " [ 0.13758499]]\n",
      "Iteration 2182 | Cost: 0.4174542481285845 | Gradient: [[ 0.0129192 ]\n",
      " [-0.13075076]\n",
      " [ 0.13758319]]\n",
      "Iteration 2183 | Cost: 0.4174180595828367 | Gradient: [[ 0.01293717]\n",
      " [-0.1307011 ]\n",
      " [ 0.13758138]]\n",
      "Iteration 2184 | Cost: 0.41738188405000143 | Gradient: [[ 0.01295513]\n",
      " [-0.13065149]\n",
      " [ 0.13757955]]\n",
      "Iteration 2185 | Cost: 0.41734572151668514 | Gradient: [[ 0.01297306]\n",
      " [-0.13060192]\n",
      " [ 0.13757772]]\n",
      "Iteration 2186 | Cost: 0.4173095719695174 | Gradient: [[ 0.01299098]\n",
      " [-0.1305524 ]\n",
      " [ 0.13757588]]\n",
      "Iteration 2187 | Cost: 0.4172734353951509 | Gradient: [[ 0.01300888]\n",
      " [-0.13050292]\n",
      " [ 0.13757402]]\n",
      "Iteration 2188 | Cost: 0.41723731178026136 | Gradient: [[ 0.01302676]\n",
      " [-0.13045348]\n",
      " [ 0.13757215]]\n",
      "Iteration 2189 | Cost: 0.4172012011115479 | Gradient: [[ 0.01304463]\n",
      " [-0.13040408]\n",
      " [ 0.13757028]]\n",
      "Iteration 2190 | Cost: 0.4171651033757323 | Gradient: [[ 0.01306247]\n",
      " [-0.13035473]\n",
      " [ 0.13756839]]\n",
      "Iteration 2191 | Cost: 0.41712901855955986 | Gradient: [[ 0.0130803 ]\n",
      " [-0.13030542]\n",
      " [ 0.13756649]]\n",
      "Iteration 2192 | Cost: 0.4170929466497982 | Gradient: [[ 0.01309811]\n",
      " [-0.13025615]\n",
      " [ 0.13756458]]\n",
      "Iteration 2193 | Cost: 0.4170568876332382 | Gradient: [[ 0.0131159 ]\n",
      " [-0.13020692]\n",
      " [ 0.13756266]]\n",
      "Iteration 2194 | Cost: 0.41702084149669355 | Gradient: [[ 0.01313368]\n",
      " [-0.13015774]\n",
      " [ 0.13756073]]\n",
      "Iteration 2195 | Cost: 0.4169848082270007 | Gradient: [[ 0.01315144]\n",
      " [-0.1301086 ]\n",
      " [ 0.13755879]]\n",
      "Iteration 2196 | Cost: 0.41694878781101863 | Gradient: [[ 0.01316918]\n",
      " [-0.1300595 ]\n",
      " [ 0.13755684]]\n",
      "Iteration 2197 | Cost: 0.4169127802356295 | Gradient: [[ 0.0131869 ]\n",
      " [-0.13001044]\n",
      " [ 0.13755487]]\n",
      "Iteration 2198 | Cost: 0.4168767854877376 | Gradient: [[ 0.0132046 ]\n",
      " [-0.12996143]\n",
      " [ 0.1375529 ]]\n",
      "Iteration 2199 | Cost: 0.4168408035542702 | Gradient: [[ 0.01322229]\n",
      " [-0.12991246]\n",
      " [ 0.13755092]]\n",
      "Iteration 2200 | Cost: 0.4168048344221769 | Gradient: [[ 0.01323996]\n",
      " [-0.12986353]\n",
      " [ 0.13754892]]\n",
      "Iteration 2201 | Cost: 0.4167688780784299 | Gradient: [[ 0.01325761]\n",
      " [-0.12981464]\n",
      " [ 0.13754692]]\n",
      "Iteration 2202 | Cost: 0.4167329345100239 | Gradient: [[ 0.01327524]\n",
      " [-0.1297658 ]\n",
      " [ 0.1375449 ]]\n",
      "Iteration 2203 | Cost: 0.4166970037039758 | Gradient: [[ 0.01329286]\n",
      " [-0.129717  ]\n",
      " [ 0.13754288]]\n",
      "Iteration 2204 | Cost: 0.41666108564732507 | Gradient: [[ 0.01331046]\n",
      " [-0.12966823]\n",
      " [ 0.13754084]]\n",
      "Iteration 2205 | Cost: 0.4166251803271334 | Gradient: [[ 0.01332804]\n",
      " [-0.12961952]\n",
      " [ 0.1375388 ]]\n",
      "Iteration 2206 | Cost: 0.41658928773048465 | Gradient: [[ 0.01334561]\n",
      " [-0.12957084]\n",
      " [ 0.13753674]]\n",
      "Iteration 2207 | Cost: 0.41655340784448525 | Gradient: [[ 0.01336315]\n",
      " [-0.1295222 ]\n",
      " [ 0.13753467]]\n",
      "Iteration 2208 | Cost: 0.41651754065626345 | Gradient: [[ 0.01338068]\n",
      " [-0.12947361]\n",
      " [ 0.13753259]]\n",
      "Iteration 2209 | Cost: 0.4164816861529697 | Gradient: [[ 0.01339819]\n",
      " [-0.12942506]\n",
      " [ 0.13753051]]\n",
      "Iteration 2210 | Cost: 0.41644584432177656 | Gradient: [[ 0.01341569]\n",
      " [-0.12937655]\n",
      " [ 0.13752841]]\n",
      "Iteration 2211 | Cost: 0.4164100151498786 | Gradient: [[ 0.01343316]\n",
      " [-0.12932808]\n",
      " [ 0.1375263 ]]\n",
      "Iteration 2212 | Cost: 0.41637419862449243 | Gradient: [[ 0.01345062]\n",
      " [-0.12927966]\n",
      " [ 0.13752418]]\n",
      "Iteration 2213 | Cost: 0.41633839473285644 | Gradient: [[ 0.01346807]\n",
      " [-0.12923127]\n",
      " [ 0.13752205]]\n",
      "Iteration 2214 | Cost: 0.4163026034622312 | Gradient: [[ 0.01348549]\n",
      " [-0.12918293]\n",
      " [ 0.13751991]]\n",
      "Iteration 2215 | Cost: 0.41626682479989874 | Gradient: [[ 0.0135029 ]\n",
      " [-0.12913463]\n",
      " [ 0.13751776]]\n",
      "Iteration 2216 | Cost: 0.41623105873316324 | Gradient: [[ 0.01352029]\n",
      " [-0.12908637]\n",
      " [ 0.1375156 ]]\n",
      "Iteration 2217 | Cost: 0.41619530524935044 | Gradient: [[ 0.01353766]\n",
      " [-0.12903815]\n",
      " [ 0.13751343]]\n",
      "Iteration 2218 | Cost: 0.41615956433580775 | Gradient: [[ 0.01355502]\n",
      " [-0.12898997]\n",
      " [ 0.13751125]]\n",
      "Iteration 2219 | Cost: 0.41612383597990443 | Gradient: [[ 0.01357236]\n",
      " [-0.12894183]\n",
      " [ 0.13750906]]\n",
      "Iteration 2220 | Cost: 0.4160881201690311 | Gradient: [[ 0.01358968]\n",
      " [-0.12889374]\n",
      " [ 0.13750685]]\n",
      "Iteration 2221 | Cost: 0.4160524168906001 | Gradient: [[ 0.01360698]\n",
      " [-0.12884568]\n",
      " [ 0.13750464]]\n",
      "Iteration 2222 | Cost: 0.41601672613204527 | Gradient: [[ 0.01362427]\n",
      " [-0.12879767]\n",
      " [ 0.13750242]]\n",
      "Iteration 2223 | Cost: 0.4159810478808221 | Gradient: [[ 0.01364154]\n",
      " [-0.1287497 ]\n",
      " [ 0.13750019]]\n",
      "Iteration 2224 | Cost: 0.415945382124407 | Gradient: [[ 0.01365879]\n",
      " [-0.12870177]\n",
      " [ 0.13749795]]\n",
      "Iteration 2225 | Cost: 0.41590972885029825 | Gradient: [[ 0.01367603]\n",
      " [-0.12865388]\n",
      " [ 0.13749569]]\n",
      "Iteration 2226 | Cost: 0.41587408804601533 | Gradient: [[ 0.01369324]\n",
      " [-0.12860603]\n",
      " [ 0.13749343]]\n",
      "Iteration 2227 | Cost: 0.415838459699099 | Gradient: [[ 0.01371045]\n",
      " [-0.12855822]\n",
      " [ 0.13749116]]\n",
      "Iteration 2228 | Cost: 0.4158028437971113 | Gradient: [[ 0.01372763]\n",
      " [-0.12851046]\n",
      " [ 0.13748888]]\n",
      "Iteration 2229 | Cost: 0.41576724032763523 | Gradient: [[ 0.0137448 ]\n",
      " [-0.12846273]\n",
      " [ 0.13748658]]\n",
      "Iteration 2230 | Cost: 0.41573164927827533 | Gradient: [[ 0.01376195]\n",
      " [-0.12841504]\n",
      " [ 0.13748428]]\n",
      "Iteration 2231 | Cost: 0.4156960706366571 | Gradient: [[ 0.01377908]\n",
      " [-0.1283674 ]\n",
      " [ 0.13748197]]\n",
      "Iteration 2232 | Cost: 0.41566050439042695 | Gradient: [[ 0.0137962 ]\n",
      " [-0.1283198 ]\n",
      " [ 0.13747964]]\n",
      "Iteration 2233 | Cost: 0.4156249505272526 | Gradient: [[ 0.0138133 ]\n",
      " [-0.12827223]\n",
      " [ 0.13747731]]\n",
      "Iteration 2234 | Cost: 0.41558940903482244 | Gradient: [[ 0.01383038]\n",
      " [-0.12822471]\n",
      " [ 0.13747497]]\n",
      "Iteration 2235 | Cost: 0.415553879900846 | Gradient: [[ 0.01384745]\n",
      " [-0.12817723]\n",
      " [ 0.13747261]]\n",
      "Iteration 2236 | Cost: 0.4155183631130538 | Gradient: [[ 0.01386449]\n",
      " [-0.12812979]\n",
      " [ 0.13747025]]\n",
      "Iteration 2237 | Cost: 0.41548285865919693 | Gradient: [[ 0.01388153]\n",
      " [-0.12808238]\n",
      " [ 0.13746788]]\n",
      "Iteration 2238 | Cost: 0.4154473665270475 | Gradient: [[ 0.01389854]\n",
      " [-0.12803502]\n",
      " [ 0.13746549]]\n",
      "Iteration 2239 | Cost: 0.41541188670439827 | Gradient: [[ 0.01391554]\n",
      " [-0.1279877 ]\n",
      " [ 0.1374631 ]]\n",
      "Iteration 2240 | Cost: 0.41537641917906276 | Gradient: [[ 0.01393252]\n",
      " [-0.12794042]\n",
      " [ 0.1374607 ]]\n",
      "Iteration 2241 | Cost: 0.4153409639388751 | Gradient: [[ 0.01394949]\n",
      " [-0.12789318]\n",
      " [ 0.13745828]]\n",
      "Iteration 2242 | Cost: 0.4153055209716902 | Gradient: [[ 0.01396643]\n",
      " [-0.12784598]\n",
      " [ 0.13745586]]\n",
      "Iteration 2243 | Cost: 0.41527009026538336 | Gradient: [[ 0.01398337]\n",
      " [-0.12779882]\n",
      " [ 0.13745343]]\n",
      "Iteration 2244 | Cost: 0.4152346718078506 | Gradient: [[ 0.01400028]\n",
      " [-0.1277517 ]\n",
      " [ 0.13745098]]\n",
      "Iteration 2245 | Cost: 0.4151992655870083 | Gradient: [[ 0.01401718]\n",
      " [-0.12770462]\n",
      " [ 0.13744853]]\n",
      "Iteration 2246 | Cost: 0.41516387159079354 | Gradient: [[ 0.01403406]\n",
      " [-0.12765758]\n",
      " [ 0.13744607]]\n",
      "Iteration 2247 | Cost: 0.41512848980716344 | Gradient: [[ 0.01405092]\n",
      " [-0.12761058]\n",
      " [ 0.1374436 ]]\n",
      "Iteration 2248 | Cost: 0.4150931202240957 | Gradient: [[ 0.01406777]\n",
      " [-0.12756363]\n",
      " [ 0.13744111]]\n",
      "Iteration 2249 | Cost: 0.41505776282958834 | Gradient: [[ 0.0140846 ]\n",
      " [-0.12751671]\n",
      " [ 0.13743862]]\n",
      "Iteration 2250 | Cost: 0.41502241761165987 | Gradient: [[ 0.01410142]\n",
      " [-0.12746983]\n",
      " [ 0.13743612]]\n",
      "Iteration 2251 | Cost: 0.41498708455834854 | Gradient: [[ 0.01411821]\n",
      " [-0.12742299]\n",
      " [ 0.13743361]]\n",
      "Iteration 2252 | Cost: 0.41495176365771325 | Gradient: [[ 0.01413499]\n",
      " [-0.12737619]\n",
      " [ 0.13743108]]\n",
      "Iteration 2253 | Cost: 0.41491645489783285 | Gradient: [[ 0.01415176]\n",
      " [-0.12732942]\n",
      " [ 0.13742855]]\n",
      "Iteration 2254 | Cost: 0.4148811582668064 | Gradient: [[ 0.01416851]\n",
      " [-0.1272827 ]\n",
      " [ 0.13742601]]\n",
      "Iteration 2255 | Cost: 0.4148458737527529 | Gradient: [[ 0.01418524]\n",
      " [-0.12723602]\n",
      " [ 0.13742346]]\n",
      "Iteration 2256 | Cost: 0.41481060134381165 | Gradient: [[ 0.01420195]\n",
      " [-0.12718938]\n",
      " [ 0.1374209 ]]\n",
      "Iteration 2257 | Cost: 0.4147753410281417 | Gradient: [[ 0.01421865]\n",
      " [-0.12714278]\n",
      " [ 0.13741833]]\n",
      "Iteration 2258 | Cost: 0.414740092793922 | Gradient: [[ 0.01423533]\n",
      " [-0.12709621]\n",
      " [ 0.13741575]]\n",
      "Iteration 2259 | Cost: 0.4147048566293516 | Gradient: [[ 0.014252  ]\n",
      " [-0.12704969]\n",
      " [ 0.13741316]]\n",
      "Iteration 2260 | Cost: 0.41466963252264943 | Gradient: [[ 0.01426865]\n",
      " [-0.12700321]\n",
      " [ 0.13741056]]\n",
      "Iteration 2261 | Cost: 0.41463442046205395 | Gradient: [[ 0.01428528]\n",
      " [-0.12695676]\n",
      " [ 0.13740795]]\n",
      "Iteration 2262 | Cost: 0.4145992204358237 | Gradient: [[ 0.0143019 ]\n",
      " [-0.12691036]\n",
      " [ 0.13740533]]\n",
      "Iteration 2263 | Cost: 0.41456403243223694 | Gradient: [[ 0.0143185 ]\n",
      " [-0.12686399]\n",
      " [ 0.1374027 ]]\n",
      "Iteration 2264 | Cost: 0.4145288564395914 | Gradient: [[ 0.01433508]\n",
      " [-0.12681766]\n",
      " [ 0.13740006]]\n",
      "Iteration 2265 | Cost: 0.4144936924462048 | Gradient: [[ 0.01435165]\n",
      " [-0.12677137]\n",
      " [ 0.13739742]]\n",
      "Iteration 2266 | Cost: 0.41445854044041414 | Gradient: [[ 0.0143682 ]\n",
      " [-0.12672513]\n",
      " [ 0.13739476]]\n",
      "Iteration 2267 | Cost: 0.4144234004105763 | Gradient: [[ 0.01438474]\n",
      " [-0.12667892]\n",
      " [ 0.13739209]]\n",
      "Iteration 2268 | Cost: 0.4143882723450673 | Gradient: [[ 0.01440125]\n",
      " [-0.12663274]\n",
      " [ 0.13738941]]\n",
      "Iteration 2269 | Cost: 0.41435315623228314 | Gradient: [[ 0.01441776]\n",
      " [-0.12658661]\n",
      " [ 0.13738673]]\n",
      "Iteration 2270 | Cost: 0.41431805206063893 | Gradient: [[ 0.01443424]\n",
      " [-0.12654052]\n",
      " [ 0.13738403]]\n",
      "Iteration 2271 | Cost: 0.41428295981856933 | Gradient: [[ 0.01445071]\n",
      " [-0.12649447]\n",
      " [ 0.13738133]]\n",
      "Iteration 2272 | Cost: 0.4142478794945283 | Gradient: [[ 0.01446717]\n",
      " [-0.12644845]\n",
      " [ 0.13737861]]\n",
      "Iteration 2273 | Cost: 0.41421281107698915 | Gradient: [[ 0.0144836 ]\n",
      " [-0.12640247]\n",
      " [ 0.13737589]]\n",
      "Iteration 2274 | Cost: 0.4141777545544447 | Gradient: [[ 0.01450002]\n",
      " [-0.12635654]\n",
      " [ 0.13737315]]\n",
      "Iteration 2275 | Cost: 0.41414270991540664 | Gradient: [[ 0.01451643]\n",
      " [-0.12631064]\n",
      " [ 0.13737041]]\n",
      "Iteration 2276 | Cost: 0.41410767714840613 | Gradient: [[ 0.01453282]\n",
      " [-0.12626478]\n",
      " [ 0.13736766]]\n",
      "Iteration 2277 | Cost: 0.41407265624199346 | Gradient: [[ 0.01454919]\n",
      " [-0.12621896]\n",
      " [ 0.1373649 ]]\n",
      "Iteration 2278 | Cost: 0.41403764718473796 | Gradient: [[ 0.01456555]\n",
      " [-0.12617317]\n",
      " [ 0.13736212]]\n",
      "Iteration 2279 | Cost: 0.4140026499652282 | Gradient: [[ 0.01458189]\n",
      " [-0.12612743]\n",
      " [ 0.13735934]]\n",
      "Iteration 2280 | Cost: 0.4139676645720716 | Gradient: [[ 0.01459821]\n",
      " [-0.12608172]\n",
      " [ 0.13735655]]\n",
      "Iteration 2281 | Cost: 0.41393269099389474 | Gradient: [[ 0.01461452]\n",
      " [-0.12603605]\n",
      " [ 0.13735375]]\n",
      "Iteration 2282 | Cost: 0.4138977292193433 | Gradient: [[ 0.01463081]\n",
      " [-0.12599042]\n",
      " [ 0.13735094]]\n",
      "Iteration 2283 | Cost: 0.4138627792370816 | Gradient: [[ 0.01464709]\n",
      " [-0.12594483]\n",
      " [ 0.13734812]]\n",
      "Iteration 2284 | Cost: 0.413827841035793 | Gradient: [[ 0.01466335]\n",
      " [-0.12589928]\n",
      " [ 0.1373453 ]]\n",
      "Iteration 2285 | Cost: 0.41379291460417983 | Gradient: [[ 0.0146796 ]\n",
      " [-0.12585377]\n",
      " [ 0.13734246]]\n",
      "Iteration 2286 | Cost: 0.41375799993096307 | Gradient: [[ 0.01469582]\n",
      " [-0.12580829]\n",
      " [ 0.13733961]]\n",
      "Iteration 2287 | Cost: 0.41372309700488247 | Gradient: [[ 0.01471204]\n",
      " [-0.12576285]\n",
      " [ 0.13733675]]\n",
      "Iteration 2288 | Cost: 0.41368820581469656 | Gradient: [[ 0.01472823]\n",
      " [-0.12571745]\n",
      " [ 0.13733389]]\n",
      "Iteration 2289 | Cost: 0.4136533263491827 | Gradient: [[ 0.01474441]\n",
      " [-0.12567209]\n",
      " [ 0.13733101]]\n",
      "Iteration 2290 | Cost: 0.4136184585971368 | Gradient: [[ 0.01476058]\n",
      " [-0.12562676]\n",
      " [ 0.13732813]]\n",
      "Iteration 2291 | Cost: 0.4135836025473733 | Gradient: [[ 0.01477673]\n",
      " [-0.12558148]\n",
      " [ 0.13732524]]\n",
      "Iteration 2292 | Cost: 0.41354875818872533 | Gradient: [[ 0.01479286]\n",
      " [-0.12553623]\n",
      " [ 0.13732233]]\n",
      "Iteration 2293 | Cost: 0.4135139255100446 | Gradient: [[ 0.01480898]\n",
      " [-0.12549102]\n",
      " [ 0.13731942]]\n",
      "Iteration 2294 | Cost: 0.4134791045002013 | Gradient: [[ 0.01482508]\n",
      " [-0.12544585]\n",
      " [ 0.1373165 ]]\n",
      "Iteration 2295 | Cost: 0.413444295148084 | Gradient: [[ 0.01484117]\n",
      " [-0.12540071]\n",
      " [ 0.13731357]]\n",
      "Iteration 2296 | Cost: 0.4134094974425998 | Gradient: [[ 0.01485724]\n",
      " [-0.12535562]\n",
      " [ 0.13731063]]\n",
      "Iteration 2297 | Cost: 0.4133747113726741 | Gradient: [[ 0.01487329]\n",
      " [-0.12531056]\n",
      " [ 0.13730768]]\n",
      "Iteration 2298 | Cost: 0.41333993692725096 | Gradient: [[ 0.01488933]\n",
      " [-0.12526554]\n",
      " [ 0.13730472]]\n",
      "Iteration 2299 | Cost: 0.41330517409529216 | Gradient: [[ 0.01490535]\n",
      " [-0.12522055]\n",
      " [ 0.13730176]]\n",
      "Iteration 2300 | Cost: 0.41327042286577836 | Gradient: [[ 0.01492136]\n",
      " [-0.12517561]\n",
      " [ 0.13729878]]\n",
      "Iteration 2301 | Cost: 0.4132356832277081 | Gradient: [[ 0.01493735]\n",
      " [-0.1251307 ]\n",
      " [ 0.13729579]]\n",
      "Iteration 2302 | Cost: 0.41320095517009814 | Gradient: [[ 0.01495333]\n",
      " [-0.12508583]\n",
      " [ 0.1372928 ]]\n",
      "Iteration 2303 | Cost: 0.4131662386819838 | Gradient: [[ 0.01496929]\n",
      " [-0.12504099]\n",
      " [ 0.1372898 ]]\n",
      "Iteration 2304 | Cost: 0.4131315337524181 | Gradient: [[ 0.01498523]\n",
      " [-0.1249962 ]\n",
      " [ 0.13728678]]\n",
      "Iteration 2305 | Cost: 0.4130968403704723 | Gradient: [[ 0.01500116]\n",
      " [-0.12495144]\n",
      " [ 0.13728376]]\n",
      "Iteration 2306 | Cost: 0.4130621585252356 | Gradient: [[ 0.01501707]\n",
      " [-0.12490672]\n",
      " [ 0.13728073]]\n",
      "Iteration 2307 | Cost: 0.41302748820581536 | Gradient: [[ 0.01503297]\n",
      " [-0.12486203]\n",
      " [ 0.13727769]]\n",
      "Iteration 2308 | Cost: 0.41299282940133686 | Gradient: [[ 0.01504885]\n",
      " [-0.12481739]\n",
      " [ 0.13727464]]\n",
      "Iteration 2309 | Cost: 0.41295818210094337 | Gradient: [[ 0.01506472]\n",
      " [-0.12477278]\n",
      " [ 0.13727158]]\n",
      "Iteration 2310 | Cost: 0.412923546293796 | Gradient: [[ 0.01508057]\n",
      " [-0.12472821]\n",
      " [ 0.13726851]]\n",
      "Iteration 2311 | Cost: 0.41288892196907384 | Gradient: [[ 0.01509641]\n",
      " [-0.12468367]\n",
      " [ 0.13726544]]\n",
      "Iteration 2312 | Cost: 0.4128543091159737 | Gradient: [[ 0.01511223]\n",
      " [-0.12463917]\n",
      " [ 0.13726235]]\n",
      "Iteration 2313 | Cost: 0.4128197077237102 | Gradient: [[ 0.01512803]\n",
      " [-0.12459471]\n",
      " [ 0.13725926]]\n",
      "Iteration 2314 | Cost: 0.41278511778151555 | Gradient: [[ 0.01514382]\n",
      " [-0.12455029]\n",
      " [ 0.13725615]]\n",
      "Iteration 2315 | Cost: 0.41275053927864025 | Gradient: [[ 0.0151596 ]\n",
      " [-0.1245059 ]\n",
      " [ 0.13725304]]\n",
      "Iteration 2316 | Cost: 0.41271597220435174 | Gradient: [[ 0.01517535]\n",
      " [-0.12446155]\n",
      " [ 0.13724992]]\n",
      "Iteration 2317 | Cost: 0.41268141654793583 | Gradient: [[ 0.0151911 ]\n",
      " [-0.12441724]\n",
      " [ 0.13724679]]\n",
      "Iteration 2318 | Cost: 0.41264687229869523 | Gradient: [[ 0.01520682]\n",
      " [-0.12437296]\n",
      " [ 0.13724365]]\n",
      "Iteration 2319 | Cost: 0.4126123394459508 | Gradient: [[ 0.01522254]\n",
      " [-0.12432872]\n",
      " [ 0.1372405 ]]\n",
      "Iteration 2320 | Cost: 0.4125778179790408 | Gradient: [[ 0.01523823]\n",
      " [-0.12428452]\n",
      " [ 0.13723734]]\n",
      "Iteration 2321 | Cost: 0.4125433078873207 | Gradient: [[ 0.01525391]\n",
      " [-0.12424035]\n",
      " [ 0.13723418]]\n",
      "Iteration 2322 | Cost: 0.4125088091601638 | Gradient: [[ 0.01526958]\n",
      " [-0.12419622]\n",
      " [ 0.137231  ]]\n",
      "Iteration 2323 | Cost: 0.4124743217869606 | Gradient: [[ 0.01528523]\n",
      " [-0.12415213]\n",
      " [ 0.13722782]]\n",
      "Iteration 2324 | Cost: 0.41243984575711906 | Gradient: [[ 0.01530087]\n",
      " [-0.12410807]\n",
      " [ 0.13722463]]\n",
      "Iteration 2325 | Cost: 0.41240538106006475 | Gradient: [[ 0.01531649]\n",
      " [-0.12406406]\n",
      " [ 0.13722142]]\n",
      "Iteration 2326 | Cost: 0.41237092768524025 | Gradient: [[ 0.01533209]\n",
      " [-0.12402007]\n",
      " [ 0.13721821]]\n",
      "Iteration 2327 | Cost: 0.41233648562210545 | Gradient: [[ 0.01534768]\n",
      " [-0.12397613]\n",
      " [ 0.137215  ]]\n",
      "Iteration 2328 | Cost: 0.41230205486013755 | Gradient: [[ 0.01536326]\n",
      " [-0.12393222]\n",
      " [ 0.13721177]]\n",
      "Iteration 2329 | Cost: 0.41226763538883116 | Gradient: [[ 0.01537882]\n",
      " [-0.12388834]\n",
      " [ 0.13720853]]\n",
      "Iteration 2330 | Cost: 0.4122332271976977 | Gradient: [[ 0.01539436]\n",
      " [-0.1238445 ]\n",
      " [ 0.13720528]]\n",
      "Iteration 2331 | Cost: 0.41219883027626625 | Gradient: [[ 0.01540989]\n",
      " [-0.1238007 ]\n",
      " [ 0.13720203]]\n",
      "Iteration 2332 | Cost: 0.4121644446140824 | Gradient: [[ 0.0154254 ]\n",
      " [-0.12375694]\n",
      " [ 0.13719877]]\n",
      "Iteration 2333 | Cost: 0.41213007020070924 | Gradient: [[ 0.0154409 ]\n",
      " [-0.12371321]\n",
      " [ 0.13719549]]\n",
      "Iteration 2334 | Cost: 0.41209570702572684 | Gradient: [[ 0.01545639]\n",
      " [-0.12366952]\n",
      " [ 0.13719221]]\n",
      "Iteration 2335 | Cost: 0.4120613550787322 | Gradient: [[ 0.01547186]\n",
      " [-0.12362586]\n",
      " [ 0.13718892]]\n",
      "Iteration 2336 | Cost: 0.41202701434933925 | Gradient: [[ 0.01548731]\n",
      " [-0.12358224]\n",
      " [ 0.13718563]]\n",
      "Iteration 2337 | Cost: 0.4119926848271791 | Gradient: [[ 0.01550275]\n",
      " [-0.12353866]\n",
      " [ 0.13718232]]\n",
      "Iteration 2338 | Cost: 0.4119583665018995 | Gradient: [[ 0.01551817]\n",
      " [-0.12349511]\n",
      " [ 0.137179  ]]\n",
      "Iteration 2339 | Cost: 0.4119240593631651 | Gradient: [[ 0.01553358]\n",
      " [-0.1234516 ]\n",
      " [ 0.13717568]]\n",
      "Iteration 2340 | Cost: 0.4118897634006576 | Gradient: [[ 0.01554897]\n",
      " [-0.12340812]\n",
      " [ 0.13717235]]\n",
      "Iteration 2341 | Cost: 0.41185547860407523 | Gradient: [[ 0.01556435]\n",
      " [-0.12336468]\n",
      " [ 0.137169  ]]\n",
      "Iteration 2342 | Cost: 0.41182120496313324 | Gradient: [[ 0.01557972]\n",
      " [-0.12332127]\n",
      " [ 0.13716565]]\n",
      "Iteration 2343 | Cost: 0.41178694246756353 | Gradient: [[ 0.01559506]\n",
      " [-0.12327791]\n",
      " [ 0.13716229]]\n",
      "Iteration 2344 | Cost: 0.4117526911071144 | Gradient: [[ 0.0156104 ]\n",
      " [-0.12323457]\n",
      " [ 0.13715893]]\n",
      "Iteration 2345 | Cost: 0.4117184508715514 | Gradient: [[ 0.01562572]\n",
      " [-0.12319128]\n",
      " [ 0.13715555]]\n",
      "Iteration 2346 | Cost: 0.4116842217506564 | Gradient: [[ 0.01564102]\n",
      " [-0.12314801]\n",
      " [ 0.13715217]]\n",
      "Iteration 2347 | Cost: 0.41165000373422755 | Gradient: [[ 0.01565631]\n",
      " [-0.12310479]\n",
      " [ 0.13714877]]\n",
      "Iteration 2348 | Cost: 0.41161579681208005 | Gradient: [[ 0.01567158]\n",
      " [-0.1230616 ]\n",
      " [ 0.13714537]]\n",
      "Iteration 2349 | Cost: 0.4115816009740455 | Gradient: [[ 0.01568684]\n",
      " [-0.12301844]\n",
      " [ 0.13714196]]\n",
      "Iteration 2350 | Cost: 0.411547416209972 | Gradient: [[ 0.01570209]\n",
      " [-0.12297532]\n",
      " [ 0.13713854]]\n",
      "Iteration 2351 | Cost: 0.411513242509724 | Gradient: [[ 0.01571732]\n",
      " [-0.12293224]\n",
      " [ 0.13713511]]\n",
      "Iteration 2352 | Cost: 0.4114790798631824 | Gradient: [[ 0.01573253]\n",
      " [-0.12288919]\n",
      " [ 0.13713168]]\n",
      "Iteration 2353 | Cost: 0.4114449282602446 | Gradient: [[ 0.01574773]\n",
      " [-0.12284618]\n",
      " [ 0.13712823]]\n",
      "Iteration 2354 | Cost: 0.41141078769082434 | Gradient: [[ 0.01576291]\n",
      " [-0.1228032 ]\n",
      " [ 0.13712478]]\n",
      "Iteration 2355 | Cost: 0.4113766581448516 | Gradient: [[ 0.01577809]\n",
      " [-0.12276026]\n",
      " [ 0.13712132]]\n",
      "Iteration 2356 | Cost: 0.41134253961227285 | Gradient: [[ 0.01579324]\n",
      " [-0.12271735]\n",
      " [ 0.13711785]]\n",
      "Iteration 2357 | Cost: 0.4113084320830506 | Gradient: [[ 0.01580838]\n",
      " [-0.12267448]\n",
      " [ 0.13711437]]\n",
      "Iteration 2358 | Cost: 0.4112743355471637 | Gradient: [[ 0.01582351]\n",
      " [-0.12263165]\n",
      " [ 0.13711088]]\n",
      "Iteration 2359 | Cost: 0.4112402499946072 | Gradient: [[ 0.01583862]\n",
      " [-0.12258884]\n",
      " [ 0.13710738]]\n",
      "Iteration 2360 | Cost: 0.41120617541539217 | Gradient: [[ 0.01585372]\n",
      " [-0.12254608]\n",
      " [ 0.13710388]]\n",
      "Iteration 2361 | Cost: 0.41117211179954616 | Gradient: [[ 0.0158688 ]\n",
      " [-0.12250335]\n",
      " [ 0.13710037]]\n",
      "Iteration 2362 | Cost: 0.4111380591371125 | Gradient: [[ 0.01588387]\n",
      " [-0.12246065]\n",
      " [ 0.13709685]]\n",
      "Iteration 2363 | Cost: 0.41110401741815067 | Gradient: [[ 0.01589892]\n",
      " [-0.12241799]\n",
      " [ 0.13709332]]\n",
      "Iteration 2364 | Cost: 0.41106998663273625 | Gradient: [[ 0.01591396]\n",
      " [-0.12237537]\n",
      " [ 0.13708978]]\n",
      "Iteration 2365 | Cost: 0.41103596677096077 | Gradient: [[ 0.01592898]\n",
      " [-0.12233278]\n",
      " [ 0.13708623]]\n",
      "Iteration 2366 | Cost: 0.4110019578229318 | Gradient: [[ 0.01594399]\n",
      " [-0.12229022]\n",
      " [ 0.13708268]]\n",
      "Iteration 2367 | Cost: 0.4109679597787727 | Gradient: [[ 0.01595898]\n",
      " [-0.1222477 ]\n",
      " [ 0.13707911]]\n",
      "Iteration 2368 | Cost: 0.41093397262862275 | Gradient: [[ 0.01597396]\n",
      " [-0.12220521]\n",
      " [ 0.13707554]]\n",
      "Iteration 2369 | Cost: 0.41089999636263747 | Gradient: [[ 0.01598893]\n",
      " [-0.12216276]\n",
      " [ 0.13707196]]\n",
      "Iteration 2370 | Cost: 0.4108660309709876 | Gradient: [[ 0.01600388]\n",
      " [-0.12212034]\n",
      " [ 0.13706838]]\n",
      "Iteration 2371 | Cost: 0.4108320764438602 | Gradient: [[ 0.01601882]\n",
      " [-0.12207796]\n",
      " [ 0.13706478]]\n",
      "Iteration 2372 | Cost: 0.410798132771458 | Gradient: [[ 0.01603374]\n",
      " [-0.12203561]\n",
      " [ 0.13706117]]\n",
      "Iteration 2373 | Cost: 0.4107641999439991 | Gradient: [[ 0.01604864]\n",
      " [-0.1219933 ]\n",
      " [ 0.13705756]]\n",
      "Iteration 2374 | Cost: 0.410730277951718 | Gradient: [[ 0.01606354]\n",
      " [-0.12195102]\n",
      " [ 0.13705394]]\n",
      "Iteration 2375 | Cost: 0.4106963667848642 | Gradient: [[ 0.01607842]\n",
      " [-0.12190878]\n",
      " [ 0.13705031]]\n",
      "Iteration 2376 | Cost: 0.4106624664337033 | Gradient: [[ 0.01609328]\n",
      " [-0.12186657]\n",
      " [ 0.13704667]]\n",
      "Iteration 2377 | Cost: 0.41062857688851623 | Gradient: [[ 0.01610813]\n",
      " [-0.1218244 ]\n",
      " [ 0.13704303]]\n",
      "Iteration 2378 | Cost: 0.4105946981395999 | Gradient: [[ 0.01612296]\n",
      " [-0.12178226]\n",
      " [ 0.13703937]]\n",
      "Iteration 2379 | Cost: 0.4105608301772663 | Gradient: [[ 0.01613779]\n",
      " [-0.12174015]\n",
      " [ 0.13703571]]\n",
      "Iteration 2380 | Cost: 0.4105269729918433 | Gradient: [[ 0.01615259]\n",
      " [-0.12169808]\n",
      " [ 0.13703204]]\n",
      "Iteration 2381 | Cost: 0.4104931265736739 | Gradient: [[ 0.01616738]\n",
      " [-0.12165604]\n",
      " [ 0.13702836]]\n",
      "Iteration 2382 | Cost: 0.41045929091311717 | Gradient: [[ 0.01618216]\n",
      " [-0.12161404]\n",
      " [ 0.13702467]]\n",
      "Iteration 2383 | Cost: 0.41042546600054697 | Gradient: [[ 0.01619692]\n",
      " [-0.12157207]\n",
      " [ 0.13702098]]\n",
      "Iteration 2384 | Cost: 0.4103916518263528 | Gradient: [[ 0.01621167]\n",
      " [-0.12153014]\n",
      " [ 0.13701727]]\n",
      "Iteration 2385 | Cost: 0.41035784838093975 | Gradient: [[ 0.01622641]\n",
      " [-0.12148824]\n",
      " [ 0.13701356]]\n",
      "Iteration 2386 | Cost: 0.4103240556547279 | Gradient: [[ 0.01624113]\n",
      " [-0.12144637]\n",
      " [ 0.13700984]]\n",
      "Iteration 2387 | Cost: 0.4102902736381529 | Gradient: [[ 0.01625584]\n",
      " [-0.12140454]\n",
      " [ 0.13700611]]\n",
      "Iteration 2388 | Cost: 0.4102565023216654 | Gradient: [[ 0.01627053]\n",
      " [-0.12136274]\n",
      " [ 0.13700238]]\n",
      "Iteration 2389 | Cost: 0.4102227416957316 | Gradient: [[ 0.01628521]\n",
      " [-0.12132098]\n",
      " [ 0.13699863]]\n",
      "Iteration 2390 | Cost: 0.41018899175083284 | Gradient: [[ 0.01629987]\n",
      " [-0.12127925]\n",
      " [ 0.13699488]]\n",
      "Iteration 2391 | Cost: 0.41015525247746537 | Gradient: [[ 0.01631452]\n",
      " [-0.12123755]\n",
      " [ 0.13699112]]\n",
      "Iteration 2392 | Cost: 0.410121523866141 | Gradient: [[ 0.01632915]\n",
      " [-0.12119589]\n",
      " [ 0.13698735]]\n",
      "Iteration 2393 | Cost: 0.4100878059073863 | Gradient: [[ 0.01634378]\n",
      " [-0.12115426]\n",
      " [ 0.13698358]]\n",
      "Iteration 2394 | Cost: 0.4100540985917434 | Gradient: [[ 0.01635838]\n",
      " [-0.12111267]\n",
      " [ 0.13697979]]\n",
      "Iteration 2395 | Cost: 0.41002040190976885 | Gradient: [[ 0.01637298]\n",
      " [-0.12107111]\n",
      " [ 0.136976  ]]\n",
      "Iteration 2396 | Cost: 0.40998671585203483 | Gradient: [[ 0.01638755]\n",
      " [-0.12102958]\n",
      " [ 0.1369722 ]]\n",
      "Iteration 2397 | Cost: 0.4099530404091282 | Gradient: [[ 0.01640212]\n",
      " [-0.12098809]\n",
      " [ 0.13696839]]\n",
      "Iteration 2398 | Cost: 0.40991937557165087 | Gradient: [[ 0.01641667]\n",
      " [-0.12094663]\n",
      " [ 0.13696457]]\n",
      "Iteration 2399 | Cost: 0.40988572133021967 | Gradient: [[ 0.01643121]\n",
      " [-0.12090521]\n",
      " [ 0.13696075]]\n",
      "Iteration 2400 | Cost: 0.4098520776754664 | Gradient: [[ 0.01644573]\n",
      " [-0.12086381]\n",
      " [ 0.13695692]]\n",
      "Iteration 2401 | Cost: 0.4098184445980376 | Gradient: [[ 0.01646024]\n",
      " [-0.12082246]\n",
      " [ 0.13695308]]\n",
      "Iteration 2402 | Cost: 0.4097848220885949 | Gradient: [[ 0.01647473]\n",
      " [-0.12078113]\n",
      " [ 0.13694923]]\n",
      "Iteration 2403 | Cost: 0.4097512101378147 | Gradient: [[ 0.01648921]\n",
      " [-0.12073984]\n",
      " [ 0.13694537]]\n",
      "Iteration 2404 | Cost: 0.4097176087363879 | Gradient: [[ 0.01650368]\n",
      " [-0.12069858]\n",
      " [ 0.13694151]]\n",
      "Iteration 2405 | Cost: 0.40968401787502057 | Gradient: [[ 0.01651813]\n",
      " [-0.12065736]\n",
      " [ 0.13693763]]\n",
      "Iteration 2406 | Cost: 0.4096504375444332 | Gradient: [[ 0.01653257]\n",
      " [-0.12061617]\n",
      " [ 0.13693375]]\n",
      "Iteration 2407 | Cost: 0.4096168677353612 | Gradient: [[ 0.01654699]\n",
      " [-0.12057501]\n",
      " [ 0.13692986]]\n",
      "Iteration 2408 | Cost: 0.40958330843855456 | Gradient: [[ 0.01656141]\n",
      " [-0.12053389]\n",
      " [ 0.13692597]]\n",
      "Iteration 2409 | Cost: 0.40954975964477797 | Gradient: [[ 0.0165758 ]\n",
      " [-0.12049279]\n",
      " [ 0.13692206]]\n",
      "Iteration 2410 | Cost: 0.4095162213448106 | Gradient: [[ 0.01659019]\n",
      " [-0.12045174]\n",
      " [ 0.13691815]]\n",
      "Iteration 2411 | Cost: 0.40948269352944633 | Gradient: [[ 0.01660455]\n",
      " [-0.12041071]\n",
      " [ 0.13691423]]\n",
      "Iteration 2412 | Cost: 0.40944917618949367 | Gradient: [[ 0.01661891]\n",
      " [-0.12036972]\n",
      " [ 0.1369103 ]]\n",
      "Iteration 2413 | Cost: 0.4094156693157755 | Gradient: [[ 0.01663325]\n",
      " [-0.12032876]\n",
      " [ 0.13690637]]\n",
      "Iteration 2414 | Cost: 0.40938217289912915 | Gradient: [[ 0.01664758]\n",
      " [-0.12028784]\n",
      " [ 0.13690242]]\n",
      "Iteration 2415 | Cost: 0.40934868693040677 | Gradient: [[ 0.01666189]\n",
      " [-0.12024695]\n",
      " [ 0.13689847]]\n",
      "Iteration 2416 | Cost: 0.4093152114004746 | Gradient: [[ 0.01667619]\n",
      " [-0.12020609]\n",
      " [ 0.13689451]]\n",
      "Iteration 2417 | Cost: 0.40928174630021347 | Gradient: [[ 0.01669048]\n",
      " [-0.12016526]\n",
      " [ 0.13689055]]\n",
      "Iteration 2418 | Cost: 0.40924829162051835 | Gradient: [[ 0.01670475]\n",
      " [-0.12012447]\n",
      " [ 0.13688657]]\n",
      "Iteration 2419 | Cost: 0.40921484735229907 | Gradient: [[ 0.01671901]\n",
      " [-0.12008371]\n",
      " [ 0.13688259]]\n",
      "Iteration 2420 | Cost: 0.40918141348647935 | Gradient: [[ 0.01673325]\n",
      " [-0.12004298]\n",
      " [ 0.1368786 ]]\n",
      "Iteration 2421 | Cost: 0.40914799001399715 | Gradient: [[ 0.01674748]\n",
      " [-0.12000229]\n",
      " [ 0.1368746 ]]\n",
      "Iteration 2422 | Cost: 0.40911457692580533 | Gradient: [[ 0.0167617 ]\n",
      " [-0.11996162]\n",
      " [ 0.13687059]]\n",
      "Iteration 2423 | Cost: 0.4090811742128701 | Gradient: [[ 0.0167759 ]\n",
      " [-0.119921  ]\n",
      " [ 0.13686658]]\n",
      "Iteration 2424 | Cost: 0.4090477818661726 | Gradient: [[ 0.01679009]\n",
      " [-0.1198804 ]\n",
      " [ 0.13686256]]\n",
      "Iteration 2425 | Cost: 0.4090143998767079 | Gradient: [[ 0.01680427]\n",
      " [-0.11983984]\n",
      " [ 0.13685853]]\n",
      "Iteration 2426 | Cost: 0.4089810282354851 | Gradient: [[ 0.01681843]\n",
      " [-0.11979931]\n",
      " [ 0.13685449]]\n",
      "Iteration 2427 | Cost: 0.40894766693352774 | Gradient: [[ 0.01683258]\n",
      " [-0.11975881]\n",
      " [ 0.13685045]]\n",
      "Iteration 2428 | Cost: 0.40891431596187305 | Gradient: [[ 0.01684672]\n",
      " [-0.11971834]\n",
      " [ 0.1368464 ]]\n",
      "Iteration 2429 | Cost: 0.4088809753115728 | Gradient: [[ 0.01686084]\n",
      " [-0.11967791]\n",
      " [ 0.13684234]]\n",
      "Iteration 2430 | Cost: 0.40884764497369247 | Gradient: [[ 0.01687495]\n",
      " [-0.11963751]\n",
      " [ 0.13683827]]\n",
      "Iteration 2431 | Cost: 0.40881432493931175 | Gradient: [[ 0.01688904]\n",
      " [-0.11959714]\n",
      " [ 0.13683419]]\n",
      "Iteration 2432 | Cost: 0.40878101519952414 | Gradient: [[ 0.01690312]\n",
      " [-0.11955681]\n",
      " [ 0.13683011]]\n",
      "Iteration 2433 | Cost: 0.40874771574543717 | Gradient: [[ 0.01691719]\n",
      " [-0.1195165 ]\n",
      " [ 0.13682602]]\n",
      "Iteration 2434 | Cost: 0.40871442656817236 | Gradient: [[ 0.01693124]\n",
      " [-0.11947623]\n",
      " [ 0.13682192]]\n",
      "Iteration 2435 | Cost: 0.40868114765886526 | Gradient: [[ 0.01694528]\n",
      " [-0.11943599]\n",
      " [ 0.13681782]]\n",
      "Iteration 2436 | Cost: 0.40864787900866495 | Gradient: [[ 0.01695931]\n",
      " [-0.11939579]\n",
      " [ 0.1368137 ]]\n",
      "Iteration 2437 | Cost: 0.40861462060873477 | Gradient: [[ 0.01697332]\n",
      " [-0.11935561]\n",
      " [ 0.13680958]]\n",
      "Iteration 2438 | Cost: 0.4085813724502515 | Gradient: [[ 0.01698732]\n",
      " [-0.11931547]\n",
      " [ 0.13680545]]\n",
      "Iteration 2439 | Cost: 0.4085481345244059 | Gradient: [[ 0.01700131]\n",
      " [-0.11927536]\n",
      " [ 0.13680132]]\n",
      "Iteration 2440 | Cost: 0.40851490682240277 | Gradient: [[ 0.01701528]\n",
      " [-0.11923529]\n",
      " [ 0.13679717]]\n",
      "Iteration 2441 | Cost: 0.40848168933546003 | Gradient: [[ 0.01702924]\n",
      " [-0.11919524]\n",
      " [ 0.13679302]]\n",
      "Iteration 2442 | Cost: 0.40844848205481 | Gradient: [[ 0.01704319]\n",
      " [-0.11915523]\n",
      " [ 0.13678886]]\n",
      "Iteration 2443 | Cost: 0.4084152849716981 | Gradient: [[ 0.01705712]\n",
      " [-0.11911525]\n",
      " [ 0.1367847 ]]\n",
      "Iteration 2444 | Cost: 0.40838209807738396 | Gradient: [[ 0.01707104]\n",
      " [-0.1190753 ]\n",
      " [ 0.13678052]]\n",
      "Iteration 2445 | Cost: 0.4083489213631402 | Gradient: [[ 0.01708495]\n",
      " [-0.11903538]\n",
      " [ 0.13677634]]\n",
      "Iteration 2446 | Cost: 0.40831575482025373 | Gradient: [[ 0.01709884]\n",
      " [-0.1189955 ]\n",
      " [ 0.13677215]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2447 | Cost: 0.40828259844002457 | Gradient: [[ 0.01711272]\n",
      " [-0.11895564]\n",
      " [ 0.13676795]]\n",
      "Iteration 2448 | Cost: 0.4082494522137665 | Gradient: [[ 0.01712658]\n",
      " [-0.11891582]\n",
      " [ 0.13676375]]\n",
      "Iteration 2449 | Cost: 0.4082163161328067 | Gradient: [[ 0.01714044]\n",
      " [-0.11887603]\n",
      " [ 0.13675954]]\n",
      "Iteration 2450 | Cost: 0.40818319018848614 | Gradient: [[ 0.01715428]\n",
      " [-0.11883628]\n",
      " [ 0.13675532]]\n",
      "Iteration 2451 | Cost: 0.4081500743721588 | Gradient: [[ 0.0171681 ]\n",
      " [-0.11879655]\n",
      " [ 0.13675109]]\n",
      "Iteration 2452 | Cost: 0.4081169686751925 | Gradient: [[ 0.01718191]\n",
      " [-0.11875686]\n",
      " [ 0.13674686]]\n",
      "Iteration 2453 | Cost: 0.40808387308896826 | Gradient: [[ 0.01719571]\n",
      " [-0.11871719]\n",
      " [ 0.13674262]]\n",
      "Iteration 2454 | Cost: 0.4080507876048807 | Gradient: [[ 0.0172095 ]\n",
      " [-0.11867756]\n",
      " [ 0.13673837]]\n",
      "Iteration 2455 | Cost: 0.40801771221433764 | Gradient: [[ 0.01722327]\n",
      " [-0.11863797]\n",
      " [ 0.13673411]]\n",
      "Iteration 2456 | Cost: 0.40798464690876024 | Gradient: [[ 0.01723703]\n",
      " [-0.1185984 ]\n",
      " [ 0.13672985]]\n",
      "Iteration 2457 | Cost: 0.40795159167958317 | Gradient: [[ 0.01725078]\n",
      " [-0.11855886]\n",
      " [ 0.13672558]]\n",
      "Iteration 2458 | Cost: 0.407918546518254 | Gradient: [[ 0.01726451]\n",
      " [-0.11851936]\n",
      " [ 0.1367213 ]]\n",
      "Iteration 2459 | Cost: 0.407885511416234 | Gradient: [[ 0.01727823]\n",
      " [-0.11847989]\n",
      " [ 0.13671701]]\n",
      "Iteration 2460 | Cost: 0.4078524863649975 | Gradient: [[ 0.01729194]\n",
      " [-0.11844045]\n",
      " [ 0.13671272]]\n",
      "Iteration 2461 | Cost: 0.40781947135603197 | Gradient: [[ 0.01730563]\n",
      " [-0.11840104]\n",
      " [ 0.13670842]]\n",
      "Iteration 2462 | Cost: 0.4077864663808383 | Gradient: [[ 0.01731931]\n",
      " [-0.11836166]\n",
      " [ 0.13670411]]\n",
      "Iteration 2463 | Cost: 0.40775347143093 | Gradient: [[ 0.01733298]\n",
      " [-0.11832231]\n",
      " [ 0.1366998 ]]\n",
      "Iteration 2464 | Cost: 0.40772048649783443 | Gradient: [[ 0.01734664]\n",
      " [-0.118283  ]\n",
      " [ 0.13669547]]\n",
      "Iteration 2465 | Cost: 0.4076875115730916 | Gradient: [[ 0.01736028]\n",
      " [-0.11824371]\n",
      " [ 0.13669114]]\n",
      "Iteration 2466 | Cost: 0.4076545466482546 | Gradient: [[ 0.01737391]\n",
      " [-0.11820446]\n",
      " [ 0.13668681]]\n",
      "Iteration 2467 | Cost: 0.40762159171489 | Gradient: [[ 0.01738752]\n",
      " [-0.11816524]\n",
      " [ 0.13668246]]\n",
      "Iteration 2468 | Cost: 0.4075886467645768 | Gradient: [[ 0.01740112]\n",
      " [-0.11812605]\n",
      " [ 0.13667811]]\n",
      "Iteration 2469 | Cost: 0.40755571178890737 | Gradient: [[ 0.01741471]\n",
      " [-0.11808689]\n",
      " [ 0.13667375]]\n",
      "Iteration 2470 | Cost: 0.4075227867794871 | Gradient: [[ 0.01742829]\n",
      " [-0.11804776]\n",
      " [ 0.13666939]]\n",
      "Iteration 2471 | Cost: 0.4074898717279342 | Gradient: [[ 0.01744185]\n",
      " [-0.11800866]\n",
      " [ 0.13666501]]\n",
      "Iteration 2472 | Cost: 0.4074569666258797 | Gradient: [[ 0.0174554 ]\n",
      " [-0.1179696 ]\n",
      " [ 0.13666063]]\n",
      "Iteration 2473 | Cost: 0.40742407146496784 | Gradient: [[ 0.01746894]\n",
      " [-0.11793056]\n",
      " [ 0.13665624]]\n",
      "Iteration 2474 | Cost: 0.4073911862368555 | Gradient: [[ 0.01748246]\n",
      " [-0.11789156]\n",
      " [ 0.13665185]]\n",
      "Iteration 2475 | Cost: 0.40735831093321245 | Gradient: [[ 0.01749597]\n",
      " [-0.11785259]\n",
      " [ 0.13664745]]\n",
      "Iteration 2476 | Cost: 0.40732544554572153 | Gradient: [[ 0.01750947]\n",
      " [-0.11781364]\n",
      " [ 0.13664304]]\n",
      "Iteration 2477 | Cost: 0.4072925900660779 | Gradient: [[ 0.01752296]\n",
      " [-0.11777473]\n",
      " [ 0.13663862]]\n",
      "Iteration 2478 | Cost: 0.4072597444859899 | Gradient: [[ 0.01753643]\n",
      " [-0.11773585]\n",
      " [ 0.13663419]]\n",
      "Iteration 2479 | Cost: 0.4072269087971785 | Gradient: [[ 0.01754989]\n",
      " [-0.117697  ]\n",
      " [ 0.13662976]]\n",
      "Iteration 2480 | Cost: 0.40719408299137744 | Gradient: [[ 0.01756333]\n",
      " [-0.11765818]\n",
      " [ 0.13662533]]\n",
      "Iteration 2481 | Cost: 0.4071612670603331 | Gradient: [[ 0.01757677]\n",
      " [-0.1176194 ]\n",
      " [ 0.13662088]]\n",
      "Iteration 2482 | Cost: 0.4071284609958045 | Gradient: [[ 0.01759019]\n",
      " [-0.11758064]\n",
      " [ 0.13661643]]\n",
      "Iteration 2483 | Cost: 0.40709566478956355 | Gradient: [[ 0.0176036 ]\n",
      " [-0.11754191]\n",
      " [ 0.13661197]]\n",
      "Iteration 2484 | Cost: 0.4070628784333944 | Gradient: [[ 0.01761699]\n",
      " [-0.11750322]\n",
      " [ 0.1366075 ]]\n",
      "Iteration 2485 | Cost: 0.40703010191909417 | Gradient: [[ 0.01763037]\n",
      " [-0.11746455]\n",
      " [ 0.13660303]]\n",
      "Iteration 2486 | Cost: 0.4069973352384723 | Gradient: [[ 0.01764374]\n",
      " [-0.11742592]\n",
      " [ 0.13659854]]\n",
      "Iteration 2487 | Cost: 0.4069645783833511 | Gradient: [[ 0.0176571 ]\n",
      " [-0.11738732]\n",
      " [ 0.13659406]]\n",
      "Iteration 2488 | Cost: 0.40693183134556504 | Gradient: [[ 0.01767045]\n",
      " [-0.11734874]\n",
      " [ 0.13658956]]\n",
      "Iteration 2489 | Cost: 0.4068990941169613 | Gradient: [[ 0.01768378]\n",
      " [-0.1173102 ]\n",
      " [ 0.13658506]]\n",
      "Iteration 2490 | Cost: 0.4068663666893996 | Gradient: [[ 0.01769709]\n",
      " [-0.11727169]\n",
      " [ 0.13658055]]\n",
      "Iteration 2491 | Cost: 0.4068336490547518 | Gradient: [[ 0.0177104 ]\n",
      " [-0.11723321]\n",
      " [ 0.13657603]]\n",
      "Iteration 2492 | Cost: 0.4068009412049026 | Gradient: [[ 0.01772369]\n",
      " [-0.11719475]\n",
      " [ 0.13657151]]\n",
      "Iteration 2493 | Cost: 0.40676824313174903 | Gradient: [[ 0.01773697]\n",
      " [-0.11715633]\n",
      " [ 0.13656698]]\n",
      "Iteration 2494 | Cost: 0.40673555482720025 | Gradient: [[ 0.01775024]\n",
      " [-0.11711794]\n",
      " [ 0.13656244]]\n",
      "Iteration 2495 | Cost: 0.406702876283178 | Gradient: [[ 0.0177635 ]\n",
      " [-0.11707958]\n",
      " [ 0.13655789]]\n",
      "Iteration 2496 | Cost: 0.40667020749161636 | Gradient: [[ 0.01777674]\n",
      " [-0.11704125]\n",
      " [ 0.13655334]]\n",
      "Iteration 2497 | Cost: 0.4066375484444615 | Gradient: [[ 0.01778997]\n",
      " [-0.11700295]\n",
      " [ 0.13654878]]\n",
      "Iteration 2498 | Cost: 0.4066048991336721 | Gradient: [[ 0.01780318]\n",
      " [-0.11696468]\n",
      " [ 0.13654422]]\n",
      "Iteration 2499 | Cost: 0.4065722595512192 | Gradient: [[ 0.01781639]\n",
      " [-0.11692644]\n",
      " [ 0.13653964]]\n",
      "Iteration 2500 | Cost: 0.4065396296890857 | Gradient: [[ 0.01782958]\n",
      " [-0.11688823]\n",
      " [ 0.13653506]]\n",
      "Iteration 2501 | Cost: 0.40650700953926716 | Gradient: [[ 0.01784276]\n",
      " [-0.11685005]\n",
      " [ 0.13653048]]\n",
      "Iteration 2502 | Cost: 0.40647439909377103 | Gradient: [[ 0.01785593]\n",
      " [-0.11681191]\n",
      " [ 0.13652588]]\n",
      "Iteration 2503 | Cost: 0.40644179834461697 | Gradient: [[ 0.01786908]\n",
      " [-0.11677379]\n",
      " [ 0.13652128]]\n",
      "Iteration 2504 | Cost: 0.4064092072838369 | Gradient: [[ 0.01788222]\n",
      " [-0.1167357 ]\n",
      " [ 0.13651667]]\n",
      "Iteration 2505 | Cost: 0.4063766259034748 | Gradient: [[ 0.01789535]\n",
      " [-0.11669764]\n",
      " [ 0.13651206]]\n",
      "Iteration 2506 | Cost: 0.40634405419558683 | Gradient: [[ 0.01790847]\n",
      " [-0.11665961]\n",
      " [ 0.13650744]]\n",
      "Iteration 2507 | Cost: 0.40631149215224094 | Gradient: [[ 0.01792157]\n",
      " [-0.11662161]\n",
      " [ 0.13650281]]\n",
      "Iteration 2508 | Cost: 0.40627893976551765 | Gradient: [[ 0.01793466]\n",
      " [-0.11658364]\n",
      " [ 0.13649817]]\n",
      "Iteration 2509 | Cost: 0.406246397027509 | Gradient: [[ 0.01794774]\n",
      " [-0.1165457 ]\n",
      " [ 0.13649353]]\n",
      "Iteration 2510 | Cost: 0.4062138639303191 | Gradient: [[ 0.01796081]\n",
      " [-0.11650779]\n",
      " [ 0.13648888]]\n",
      "Iteration 2511 | Cost: 0.40618134046606463 | Gradient: [[ 0.01797386]\n",
      " [-0.11646991]\n",
      " [ 0.13648423]]\n",
      "Iteration 2512 | Cost: 0.4061488266268734 | Gradient: [[ 0.0179869 ]\n",
      " [-0.11643206]\n",
      " [ 0.13647956]]\n",
      "Iteration 2513 | Cost: 0.4061163224048858 | Gradient: [[ 0.01799993]\n",
      " [-0.11639424]\n",
      " [ 0.13647489]]\n",
      "Iteration 2514 | Cost: 0.4060838277922536 | Gradient: [[ 0.01801295]\n",
      " [-0.11635645]\n",
      " [ 0.13647022]]\n",
      "Iteration 2515 | Cost: 0.40605134278114097 | Gradient: [[ 0.01802595]\n",
      " [-0.11631869]\n",
      " [ 0.13646553]]\n",
      "Iteration 2516 | Cost: 0.40601886736372367 | Gradient: [[ 0.01803894]\n",
      " [-0.11628096]\n",
      " [ 0.13646084]]\n",
      "Iteration 2517 | Cost: 0.4059864015321892 | Gradient: [[ 0.01805192]\n",
      " [-0.11624326]\n",
      " [ 0.13645615]]\n",
      "Iteration 2518 | Cost: 0.4059539452787372 | Gradient: [[ 0.01806489]\n",
      " [-0.11620559]\n",
      " [ 0.13645144]]\n",
      "Iteration 2519 | Cost: 0.4059214985955789 | Gradient: [[ 0.01807784]\n",
      " [-0.11616794]\n",
      " [ 0.13644673]]\n",
      "Iteration 2520 | Cost: 0.40588906147493736 | Gradient: [[ 0.01809079]\n",
      " [-0.11613033]\n",
      " [ 0.13644201]]\n",
      "Iteration 2521 | Cost: 0.40585663390904736 | Gradient: [[ 0.01810372]\n",
      " [-0.11609275]\n",
      " [ 0.13643729]]\n",
      "Iteration 2522 | Cost: 0.40582421589015544 | Gradient: [[ 0.01811663]\n",
      " [-0.11605519]\n",
      " [ 0.13643256]]\n",
      "Iteration 2523 | Cost: 0.40579180741051973 | Gradient: [[ 0.01812954]\n",
      " [-0.11601767]\n",
      " [ 0.13642782]]\n",
      "Iteration 2524 | Cost: 0.40575940846241043 | Gradient: [[ 0.01814243]\n",
      " [-0.11598017]\n",
      " [ 0.13642308]]\n",
      "Iteration 2525 | Cost: 0.40572701903810887 | Gradient: [[ 0.01815531]\n",
      " [-0.11594271]\n",
      " [ 0.13641832]]\n",
      "Iteration 2526 | Cost: 0.40569463912990844 | Gradient: [[ 0.01816818]\n",
      " [-0.11590527]\n",
      " [ 0.13641357]]\n",
      "Iteration 2527 | Cost: 0.4056622687301139 | Gradient: [[ 0.01818104]\n",
      " [-0.11586786]\n",
      " [ 0.1364088 ]]\n",
      "Iteration 2528 | Cost: 0.40562990783104186 | Gradient: [[ 0.01819388]\n",
      " [-0.11583049]\n",
      " [ 0.13640403]]\n",
      "Iteration 2529 | Cost: 0.40559755642502 | Gradient: [[ 0.01820671]\n",
      " [-0.11579314]\n",
      " [ 0.13639925]]\n",
      "Iteration 2530 | Cost: 0.40556521450438826 | Gradient: [[ 0.01821953]\n",
      " [-0.11575582]\n",
      " [ 0.13639447]]\n",
      "Iteration 2531 | Cost: 0.4055328820614976 | Gradient: [[ 0.01823234]\n",
      " [-0.11571853]\n",
      " [ 0.13638968]]\n",
      "Iteration 2532 | Cost: 0.4055005590887106 | Gradient: [[ 0.01824513]\n",
      " [-0.11568127]\n",
      " [ 0.13638488]]\n",
      "Iteration 2533 | Cost: 0.4054682455784014 | Gradient: [[ 0.01825792]\n",
      " [-0.11564403]\n",
      " [ 0.13638007]]\n",
      "Iteration 2534 | Cost: 0.40543594152295537 | Gradient: [[ 0.01827069]\n",
      " [-0.11560683]\n",
      " [ 0.13637526]]\n",
      "Iteration 2535 | Cost: 0.40540364691476977 | Gradient: [[ 0.01828345]\n",
      " [-0.11556966]\n",
      " [ 0.13637044]]\n",
      "Iteration 2536 | Cost: 0.4053713617462529 | Gradient: [[ 0.01829619]\n",
      " [-0.11553251]\n",
      " [ 0.13636562]]\n",
      "Iteration 2537 | Cost: 0.40533908600982466 | Gradient: [[ 0.01830893]\n",
      " [-0.1154954 ]\n",
      " [ 0.13636078]]\n",
      "Iteration 2538 | Cost: 0.4053068196979161 | Gradient: [[ 0.01832165]\n",
      " [-0.11545831]\n",
      " [ 0.13635595]]\n",
      "Iteration 2539 | Cost: 0.4052745628029698 | Gradient: [[ 0.01833436]\n",
      " [-0.11542125]\n",
      " [ 0.1363511 ]]\n",
      "Iteration 2540 | Cost: 0.40524231531743965 | Gradient: [[ 0.01834706]\n",
      " [-0.11538422]\n",
      " [ 0.13634625]]\n",
      "Iteration 2541 | Cost: 0.40521007723379093 | Gradient: [[ 0.01835974]\n",
      " [-0.11534722]\n",
      " [ 0.13634139]]\n",
      "Iteration 2542 | Cost: 0.4051778485444999 | Gradient: [[ 0.01837242]\n",
      " [-0.11531025]\n",
      " [ 0.13633653]]\n",
      "Iteration 2543 | Cost: 0.40514562924205444 | Gradient: [[ 0.01838508]\n",
      " [-0.11527331]\n",
      " [ 0.13633166]]\n",
      "Iteration 2544 | Cost: 0.40511341931895356 | Gradient: [[ 0.01839773]\n",
      " [-0.11523639]\n",
      " [ 0.13632678]]\n",
      "Iteration 2545 | Cost: 0.40508121876770736 | Gradient: [[ 0.01841036]\n",
      " [-0.11519951]\n",
      " [ 0.13632189]]\n",
      "Iteration 2546 | Cost: 0.40504902758083733 | Gradient: [[ 0.01842299]\n",
      " [-0.11516265]\n",
      " [ 0.136317  ]]\n",
      "Iteration 2547 | Cost: 0.405016845750876 | Gradient: [[ 0.0184356 ]\n",
      " [-0.11512582]\n",
      " [ 0.13631211]]\n",
      "Iteration 2548 | Cost: 0.404984673270367 | Gradient: [[ 0.0184482 ]\n",
      " [-0.11508903]\n",
      " [ 0.1363072 ]]\n",
      "Iteration 2549 | Cost: 0.40495251013186556 | Gradient: [[ 0.01846079]\n",
      " [-0.11505225]\n",
      " [ 0.13630229]]\n",
      "Iteration 2550 | Cost: 0.4049203563279373 | Gradient: [[ 0.01847337]\n",
      " [-0.11501551]\n",
      " [ 0.13629737]]\n",
      "Iteration 2551 | Cost: 0.40488821185115953 | Gradient: [[ 0.01848594]\n",
      " [-0.1149788 ]\n",
      " [ 0.13629245]]\n",
      "Iteration 2552 | Cost: 0.40485607669412044 | Gradient: [[ 0.01849849]\n",
      " [-0.11494211]\n",
      " [ 0.13628752]]\n",
      "Iteration 2553 | Cost: 0.404823950849419 | Gradient: [[ 0.01851103]\n",
      " [-0.11490546]\n",
      " [ 0.13628258]]\n",
      "Iteration 2554 | Cost: 0.40479183430966575 | Gradient: [[ 0.01852356]\n",
      " [-0.11486883]\n",
      " [ 0.13627764]]\n",
      "Iteration 2555 | Cost: 0.40475972706748176 | Gradient: [[ 0.01853608]\n",
      " [-0.11483223]\n",
      " [ 0.13627269]]\n",
      "Iteration 2556 | Cost: 0.4047276291154993 | Gradient: [[ 0.01854859]\n",
      " [-0.11479566]\n",
      " [ 0.13626773]]\n",
      "Iteration 2557 | Cost: 0.40469554044636163 | Gradient: [[ 0.01856108]\n",
      " [-0.11475912]\n",
      " [ 0.13626277]]\n",
      "Iteration 2558 | Cost: 0.40466346105272305 | Gradient: [[ 0.01857356]\n",
      " [-0.1147226 ]\n",
      " [ 0.1362578 ]]\n",
      "Iteration 2559 | Cost: 0.40463139092724837 | Gradient: [[ 0.01858603]\n",
      " [-0.11468612]\n",
      " [ 0.13625283]]\n",
      "Iteration 2560 | Cost: 0.4045993300626137 | Gradient: [[ 0.01859849]\n",
      " [-0.11464966]\n",
      " [ 0.13624784]]\n",
      "Iteration 2561 | Cost: 0.40456727845150603 | Gradient: [[ 0.01861094]\n",
      " [-0.11461323]\n",
      " [ 0.13624286]]\n",
      "Iteration 2562 | Cost: 0.404535236086623 | Gradient: [[ 0.01862337]\n",
      " [-0.11457683]\n",
      " [ 0.13623786]]\n",
      "Iteration 2563 | Cost: 0.4045032029606732 | Gradient: [[ 0.0186358 ]\n",
      " [-0.11454046]\n",
      " [ 0.13623286]]\n",
      "Iteration 2564 | Cost: 0.404471179066376 | Gradient: [[ 0.01864821]\n",
      " [-0.11450411]\n",
      " [ 0.13622785]]\n",
      "Iteration 2565 | Cost: 0.4044391643964617 | Gradient: [[ 0.01866061]\n",
      " [-0.11446779]\n",
      " [ 0.13622284]]\n",
      "Iteration 2566 | Cost: 0.40440715894367124 | Gradient: [[ 0.018673  ]\n",
      " [-0.11443151]\n",
      " [ 0.13621782]]\n",
      "Iteration 2567 | Cost: 0.40437516270075635 | Gradient: [[ 0.01868537]\n",
      " [-0.11439525]\n",
      " [ 0.13621279]]\n",
      "Iteration 2568 | Cost: 0.40434317566047956 | Gradient: [[ 0.01869774]\n",
      " [-0.11435901]\n",
      " [ 0.13620776]]\n",
      "Iteration 2569 | Cost: 0.40431119781561414 | Gradient: [[ 0.01871009]\n",
      " [-0.11432281]\n",
      " [ 0.13620272]]\n",
      "Iteration 2570 | Cost: 0.404279229158944 | Gradient: [[ 0.01872243]\n",
      " [-0.11428663]\n",
      " [ 0.13619767]]\n",
      "Iteration 2571 | Cost: 0.4042472696832635 | Gradient: [[ 0.01873476]\n",
      " [-0.11425048]\n",
      " [ 0.13619262]]\n",
      "Iteration 2572 | Cost: 0.40421531938137817 | Gradient: [[ 0.01874708]\n",
      " [-0.11421436]\n",
      " [ 0.13618756]]\n",
      "Iteration 2573 | Cost: 0.4041833782461039 | Gradient: [[ 0.01875938]\n",
      " [-0.11417827]\n",
      " [ 0.1361825 ]]\n",
      "Iteration 2574 | Cost: 0.4041514462702669 | Gradient: [[ 0.01877168]\n",
      " [-0.11414221]\n",
      " [ 0.13617743]]\n",
      "Iteration 2575 | Cost: 0.4041195234467045 | Gradient: [[ 0.01878396]\n",
      " [-0.11410617]\n",
      " [ 0.13617235]]\n",
      "Iteration 2576 | Cost: 0.4040876097682643 | Gradient: [[ 0.01879623]\n",
      " [-0.11407016]\n",
      " [ 0.13616727]]\n",
      "Iteration 2577 | Cost: 0.40405570522780465 | Gradient: [[ 0.01880849]\n",
      " [-0.11403418]\n",
      " [ 0.13616218]]\n",
      "Iteration 2578 | Cost: 0.40402380981819425 | Gradient: [[ 0.01882074]\n",
      " [-0.11399823]\n",
      " [ 0.13615708]]\n",
      "Iteration 2579 | Cost: 0.4039919235323124 | Gradient: [[ 0.01883297]\n",
      " [-0.1139623 ]\n",
      " [ 0.13615198]]\n",
      "Iteration 2580 | Cost: 0.40396004636304894 | Gradient: [[ 0.0188452 ]\n",
      " [-0.1139264 ]\n",
      " [ 0.13614687]]\n",
      "Iteration 2581 | Cost: 0.4039281783033041 | Gradient: [[ 0.01885741]\n",
      " [-0.11389053]\n",
      " [ 0.13614175]]\n",
      "Iteration 2582 | Cost: 0.40389631934598863 | Gradient: [[ 0.01886961]\n",
      " [-0.11385469]\n",
      " [ 0.13613663]]\n",
      "Iteration 2583 | Cost: 0.40386446948402355 | Gradient: [[ 0.0188818 ]\n",
      " [-0.11381887]\n",
      " [ 0.1361315 ]]\n",
      "Iteration 2584 | Cost: 0.4038326287103407 | Gradient: [[ 0.01889398]\n",
      " [-0.11378309]\n",
      " [ 0.13612637]]\n",
      "Iteration 2585 | Cost: 0.4038007970178819 | Gradient: [[ 0.01890615]\n",
      " [-0.11374733]\n",
      " [ 0.13612123]]\n",
      "Iteration 2586 | Cost: 0.4037689743995996 | Gradient: [[ 0.0189183 ]\n",
      " [-0.11371159]\n",
      " [ 0.13611608]]\n",
      "Iteration 2587 | Cost: 0.4037371608484564 | Gradient: [[ 0.01893044]\n",
      " [-0.11367589]\n",
      " [ 0.13611093]]\n",
      "Iteration 2588 | Cost: 0.40370535635742555 | Gradient: [[ 0.01894258]\n",
      " [-0.11364021]\n",
      " [ 0.13610577]]\n",
      "Iteration 2589 | Cost: 0.40367356091949025 | Gradient: [[ 0.0189547 ]\n",
      " [-0.11360456]\n",
      " [ 0.13610061]]\n",
      "Iteration 2590 | Cost: 0.4036417745276443 | Gradient: [[ 0.01896681]\n",
      " [-0.11356894]\n",
      " [ 0.13609544]]\n",
      "Iteration 2591 | Cost: 0.40360999717489154 | Gradient: [[ 0.0189789 ]\n",
      " [-0.11353334]\n",
      " [ 0.13609026]]\n",
      "Iteration 2592 | Cost: 0.4035782288542464 | Gradient: [[ 0.01899099]\n",
      " [-0.11349778]\n",
      " [ 0.13608508]]\n",
      "Iteration 2593 | Cost: 0.4035464695587332 | Gradient: [[ 0.01900306]\n",
      " [-0.11346223]\n",
      " [ 0.13607989]]\n",
      "Iteration 2594 | Cost: 0.4035147192813866 | Gradient: [[ 0.01901513]\n",
      " [-0.11342672]\n",
      " [ 0.13607469]]\n",
      "Iteration 2595 | Cost: 0.4034829780152516 | Gradient: [[ 0.01902718]\n",
      " [-0.11339124]\n",
      " [ 0.13606949]]\n",
      "Iteration 2596 | Cost: 0.40345124575338326 | Gradient: [[ 0.01903922]\n",
      " [-0.11335578]\n",
      " [ 0.13606428]]\n",
      "Iteration 2597 | Cost: 0.40341952248884677 | Gradient: [[ 0.01905125]\n",
      " [-0.11332035]\n",
      " [ 0.13605907]]\n",
      "Iteration 2598 | Cost: 0.4033878082147176 | Gradient: [[ 0.01906327]\n",
      " [-0.11328494]\n",
      " [ 0.13605385]]\n",
      "Iteration 2599 | Cost: 0.40335610292408125 | Gradient: [[ 0.01907527]\n",
      " [-0.11324956]\n",
      " [ 0.13604862]]\n",
      "Iteration 2600 | Cost: 0.4033244066100332 | Gradient: [[ 0.01908727]\n",
      " [-0.11321421]\n",
      " [ 0.13604339]]\n",
      "Iteration 2601 | Cost: 0.40329271926567933 | Gradient: [[ 0.01909925]\n",
      " [-0.11317889]\n",
      " [ 0.13603815]]\n",
      "Iteration 2602 | Cost: 0.40326104088413556 | Gradient: [[ 0.01911122]\n",
      " [-0.1131436 ]\n",
      " [ 0.13603291]]\n",
      "Iteration 2603 | Cost: 0.4032293714585274 | Gradient: [[ 0.01912318]\n",
      " [-0.11310833]\n",
      " [ 0.13602766]]\n",
      "Iteration 2604 | Cost: 0.4031977109819909 | Gradient: [[ 0.01913513]\n",
      " [-0.11307308]\n",
      " [ 0.1360224 ]]\n",
      "Iteration 2605 | Cost: 0.403166059447672 | Gradient: [[ 0.01914707]\n",
      " [-0.11303787]\n",
      " [ 0.13601714]]\n",
      "Iteration 2606 | Cost: 0.40313441684872636 | Gradient: [[ 0.019159  ]\n",
      " [-0.11300268]\n",
      " [ 0.13601187]]\n",
      "Iteration 2607 | Cost: 0.40310278317832 | Gradient: [[ 0.01917091]\n",
      " [-0.11296752]\n",
      " [ 0.13600659]]\n",
      "Iteration 2608 | Cost: 0.4030711584296286 | Gradient: [[ 0.01918282]\n",
      " [-0.11293239]\n",
      " [ 0.13600131]]\n",
      "Iteration 2609 | Cost: 0.4030395425958381 | Gradient: [[ 0.01919471]\n",
      " [-0.11289728]\n",
      " [ 0.13599603]]\n",
      "Iteration 2610 | Cost: 0.40300793567014404 | Gradient: [[ 0.01920659]\n",
      " [-0.1128622 ]\n",
      " [ 0.13599073]]\n",
      "Iteration 2611 | Cost: 0.40297633764575197 | Gradient: [[ 0.01921846]\n",
      " [-0.11282715]\n",
      " [ 0.13598543]]\n",
      "Iteration 2612 | Cost: 0.4029447485158773 | Gradient: [[ 0.01923032]\n",
      " [-0.11279212]\n",
      " [ 0.13598013]]\n",
      "Iteration 2613 | Cost: 0.40291316827374546 | Gradient: [[ 0.01924217]\n",
      " [-0.11275712]\n",
      " [ 0.13597482]]\n",
      "Iteration 2614 | Cost: 0.40288159691259146 | Gradient: [[ 0.01925401]\n",
      " [-0.11272215]\n",
      " [ 0.1359695 ]]\n",
      "Iteration 2615 | Cost: 0.4028500344256605 | Gradient: [[ 0.01926583]\n",
      " [-0.1126872 ]\n",
      " [ 0.13596418]]\n",
      "Iteration 2616 | Cost: 0.402818480806207 | Gradient: [[ 0.01927765]\n",
      " [-0.11265228]\n",
      " [ 0.13595885]]\n",
      "Iteration 2617 | Cost: 0.40278693604749594 | Gradient: [[ 0.01928945]\n",
      " [-0.11261739]\n",
      " [ 0.13595352]]\n",
      "Iteration 2618 | Cost: 0.4027554001428015 | Gradient: [[ 0.01930124]\n",
      " [-0.11258252]\n",
      " [ 0.13594817]]\n",
      "Iteration 2619 | Cost: 0.4027238730854077 | Gradient: [[ 0.01931303]\n",
      " [-0.11254768]\n",
      " [ 0.13594283]]\n",
      "Iteration 2620 | Cost: 0.40269235486860844 | Gradient: [[ 0.0193248 ]\n",
      " [-0.11251287]\n",
      " [ 0.13593748]]\n",
      "Iteration 2621 | Cost: 0.40266084548570735 | Gradient: [[ 0.01933655]\n",
      " [-0.11247808]\n",
      " [ 0.13593212]]\n",
      "Iteration 2622 | Cost: 0.40262934493001756 | Gradient: [[ 0.0193483 ]\n",
      " [-0.11244332]\n",
      " [ 0.13592675]]\n",
      "Iteration 2623 | Cost: 0.402597853194862 | Gradient: [[ 0.01936004]\n",
      " [-0.11240859]\n",
      " [ 0.13592138]]\n",
      "Iteration 2624 | Cost: 0.4025663702735733 | Gradient: [[ 0.01937176]\n",
      " [-0.11237388]\n",
      " [ 0.13591601]]\n",
      "Iteration 2625 | Cost: 0.4025348961594937 | Gradient: [[ 0.01938348]\n",
      " [-0.1123392 ]\n",
      " [ 0.13591062]]\n",
      "Iteration 2626 | Cost: 0.4025034308459751 | Gradient: [[ 0.01939518]\n",
      " [-0.11230454]\n",
      " [ 0.13590524]]\n",
      "Iteration 2627 | Cost: 0.40247197432637893 | Gradient: [[ 0.01940688]\n",
      " [-0.11226992]\n",
      " [ 0.13589984]]\n",
      "Iteration 2628 | Cost: 0.40244052659407614 | Gradient: [[ 0.01941856]\n",
      " [-0.11223532]\n",
      " [ 0.13589444]]\n",
      "Iteration 2629 | Cost: 0.4024090876424475 | Gradient: [[ 0.01943023]\n",
      " [-0.11220074]\n",
      " [ 0.13588904]]\n",
      "Iteration 2630 | Cost: 0.4023776574648831 | Gradient: [[ 0.01944189]\n",
      " [-0.11216619]\n",
      " [ 0.13588363]]\n",
      "Iteration 2631 | Cost: 0.4023462360547827 | Gradient: [[ 0.01945353]\n",
      " [-0.11213167]\n",
      " [ 0.13587821]]\n",
      "Iteration 2632 | Cost: 0.4023148234055556 | Gradient: [[ 0.01946517]\n",
      " [-0.11209717]\n",
      " [ 0.13587279]]\n",
      "Iteration 2633 | Cost: 0.4022834195106204 | Gradient: [[ 0.0194768 ]\n",
      " [-0.1120627 ]\n",
      " [ 0.13586736]]\n",
      "Iteration 2634 | Cost: 0.40225202436340546 | Gradient: [[ 0.01948841]\n",
      " [-0.11202826]\n",
      " [ 0.13586192]]\n",
      "Iteration 2635 | Cost: 0.40222063795734836 | Gradient: [[ 0.01950002]\n",
      " [-0.11199384]\n",
      " [ 0.13585648]]\n",
      "Iteration 2636 | Cost: 0.40218926028589624 | Gradient: [[ 0.01951161]\n",
      " [-0.11195945]\n",
      " [ 0.13585104]]\n",
      "Iteration 2637 | Cost: 0.4021578913425056 | Gradient: [[ 0.01952319]\n",
      " [-0.11192508]\n",
      " [ 0.13584558]]\n",
      "Iteration 2638 | Cost: 0.4021265311206426 | Gradient: [[ 0.01953477]\n",
      " [-0.11189074]\n",
      " [ 0.13584012]]\n",
      "Iteration 2639 | Cost: 0.40209517961378244 | Gradient: [[ 0.01954633]\n",
      " [-0.11185643]\n",
      " [ 0.13583466]]\n",
      "Iteration 2640 | Cost: 0.4020638368154099 | Gradient: [[ 0.01955788]\n",
      " [-0.11182214]\n",
      " [ 0.13582919]]\n",
      "Iteration 2641 | Cost: 0.40203250271901914 | Gradient: [[ 0.01956942]\n",
      " [-0.11178788]\n",
      " [ 0.13582372]]\n",
      "Iteration 2642 | Cost: 0.4020011773181134 | Gradient: [[ 0.01958094]\n",
      " [-0.11175364]\n",
      " [ 0.13581824]]\n",
      "Iteration 2643 | Cost: 0.40196986060620576 | Gradient: [[ 0.01959246]\n",
      " [-0.11171943]\n",
      " [ 0.13581275]]\n",
      "Iteration 2644 | Cost: 0.40193855257681804 | Gradient: [[ 0.01960397]\n",
      " [-0.11168525]\n",
      " [ 0.13580726]]\n",
      "Iteration 2645 | Cost: 0.40190725322348175 | Gradient: [[ 0.01961546]\n",
      " [-0.11165109]\n",
      " [ 0.13580176]]\n",
      "Iteration 2646 | Cost: 0.40187596253973745 | Gradient: [[ 0.01962695]\n",
      " [-0.11161696]\n",
      " [ 0.13579625]]\n",
      "Iteration 2647 | Cost: 0.4018446805191351 | Gradient: [[ 0.01963842]\n",
      " [-0.11158285]\n",
      " [ 0.13579074]]\n",
      "Iteration 2648 | Cost: 0.40181340715523367 | Gradient: [[ 0.01964988]\n",
      " [-0.11154877]\n",
      " [ 0.13578523]]\n",
      "Iteration 2649 | Cost: 0.40178214244160165 | Gradient: [[ 0.01966134]\n",
      " [-0.11151472]\n",
      " [ 0.13577971]]\n",
      "Iteration 2650 | Cost: 0.4017508863718167 | Gradient: [[ 0.01967278]\n",
      " [-0.11148069]\n",
      " [ 0.13577418]]\n",
      "Iteration 2651 | Cost: 0.4017196389394653 | Gradient: [[ 0.01968421]\n",
      " [-0.11144669]\n",
      " [ 0.13576865]]\n",
      "Iteration 2652 | Cost: 0.4016884001381435 | Gradient: [[ 0.01969563]\n",
      " [-0.11141271]\n",
      " [ 0.13576311]]\n",
      "Iteration 2653 | Cost: 0.4016571699614563 | Gradient: [[ 0.01970704]\n",
      " [-0.11137876]\n",
      " [ 0.13575757]]\n",
      "Iteration 2654 | Cost: 0.40162594840301796 | Gradient: [[ 0.01971844]\n",
      " [-0.11134483]\n",
      " [ 0.13575202]]\n",
      "Iteration 2655 | Cost: 0.40159473545645186 | Gradient: [[ 0.01972982]\n",
      " [-0.11131093]\n",
      " [ 0.13574646]]\n",
      "Iteration 2656 | Cost: 0.40156353111539034 | Gradient: [[ 0.0197412 ]\n",
      " [-0.11127706]\n",
      " [ 0.1357409 ]]\n",
      "Iteration 2657 | Cost: 0.4015323353734748 | Gradient: [[ 0.01975257]\n",
      " [-0.11124321]\n",
      " [ 0.13573533]]\n",
      "Iteration 2658 | Cost: 0.401501148224356 | Gradient: [[ 0.01976392]\n",
      " [-0.11120939]\n",
      " [ 0.13572976]]\n",
      "Iteration 2659 | Cost: 0.40146996966169346 | Gradient: [[ 0.01977527]\n",
      " [-0.11117559]\n",
      " [ 0.13572418]]\n",
      "Iteration 2660 | Cost: 0.40143879967915586 | Gradient: [[ 0.0197866 ]\n",
      " [-0.11114182]\n",
      " [ 0.1357186 ]]\n",
      "Iteration 2661 | Cost: 0.4014076382704208 | Gradient: [[ 0.01979792]\n",
      " [-0.11110807]\n",
      " [ 0.13571301]]\n",
      "Iteration 2662 | Cost: 0.4013764854291751 | Gradient: [[ 0.01980924]\n",
      " [-0.11107435]\n",
      " [ 0.13570742]]\n",
      "Iteration 2663 | Cost: 0.40134534114911435 | Gradient: [[ 0.01982054]\n",
      " [-0.11104065]\n",
      " [ 0.13570182]]\n",
      "Iteration 2664 | Cost: 0.40131420542394314 | Gradient: [[ 0.01983183]\n",
      " [-0.11100698]\n",
      " [ 0.13569621]]\n",
      "Iteration 2665 | Cost: 0.40128307824737486 | Gradient: [[ 0.01984311]\n",
      " [-0.11097334]\n",
      " [ 0.1356906 ]]\n",
      "Iteration 2666 | Cost: 0.4012519596131325 | Gradient: [[ 0.01985438]\n",
      " [-0.11093972]\n",
      " [ 0.13568498]]\n",
      "Iteration 2667 | Cost: 0.40122084951494713 | Gradient: [[ 0.01986564]\n",
      " [-0.11090612]\n",
      " [ 0.13567936]]\n",
      "Iteration 2668 | Cost: 0.4011897479465592 | Gradient: [[ 0.01987689]\n",
      " [-0.11087255]\n",
      " [ 0.13567373]]\n",
      "Iteration 2669 | Cost: 0.4011586549017178 | Gradient: [[ 0.01988813]\n",
      " [-0.11083901]\n",
      " [ 0.1356681 ]]\n",
      "Iteration 2670 | Cost: 0.4011275703741811 | Gradient: [[ 0.01989935]\n",
      " [-0.11080549]\n",
      " [ 0.13566246]]\n",
      "Iteration 2671 | Cost: 0.40109649435771616 | Gradient: [[ 0.01991057]\n",
      " [-0.11077199]\n",
      " [ 0.13565681]]\n",
      "Iteration 2672 | Cost: 0.4010654268460986 | Gradient: [[ 0.01992178]\n",
      " [-0.11073853]\n",
      " [ 0.13565116]]\n",
      "Iteration 2673 | Cost: 0.40103436783311297 | Gradient: [[ 0.01993297]\n",
      " [-0.11070508]\n",
      " [ 0.13564551]]\n",
      "Iteration 2674 | Cost: 0.40100331731255284 | Gradient: [[ 0.01994416]\n",
      " [-0.11067166]\n",
      " [ 0.13563985]]\n",
      "Iteration 2675 | Cost: 0.4009722752782202 | Gradient: [[ 0.01995534]\n",
      " [-0.11063827]\n",
      " [ 0.13563418]]\n",
      "Iteration 2676 | Cost: 0.4009412417239261 | Gradient: [[ 0.0199665 ]\n",
      " [-0.1106049 ]\n",
      " [ 0.13562851]]\n",
      "Iteration 2677 | Cost: 0.40091021664349036 | Gradient: [[ 0.01997765]\n",
      " [-0.11057156]\n",
      " [ 0.13562283]]\n",
      "Iteration 2678 | Cost: 0.40087920003074123 | Gradient: [[ 0.0199888 ]\n",
      " [-0.11053824]\n",
      " [ 0.13561715]]\n",
      "Iteration 2679 | Cost: 0.4008481918795159 | Gradient: [[ 0.01999993]\n",
      " [-0.11050495]\n",
      " [ 0.13561146]]\n",
      "Iteration 2680 | Cost: 0.40081719218366024 | Gradient: [[ 0.02001105]\n",
      " [-0.11047168]\n",
      " [ 0.13560576]]\n",
      "Iteration 2681 | Cost: 0.400786200937029 | Gradient: [[ 0.02002216]\n",
      " [-0.11043844]\n",
      " [ 0.13560006]]\n",
      "Iteration 2682 | Cost: 0.4007552181334852 | Gradient: [[ 0.02003327]\n",
      " [-0.11040522]\n",
      " [ 0.13559436]]\n",
      "Iteration 2683 | Cost: 0.4007242437669008 | Gradient: [[ 0.02004436]\n",
      " [-0.11037203]\n",
      " [ 0.13558865]]\n",
      "Iteration 2684 | Cost: 0.40069327783115644 | Gradient: [[ 0.02005544]\n",
      " [-0.11033886]\n",
      " [ 0.13558293]]\n",
      "Iteration 2685 | Cost: 0.4006623203201411 | Gradient: [[ 0.02006651]\n",
      " [-0.11030572]\n",
      " [ 0.13557721]]\n",
      "Iteration 2686 | Cost: 0.40063137122775266 | Gradient: [[ 0.02007757]\n",
      " [-0.1102726 ]\n",
      " [ 0.13557148]]\n",
      "Iteration 2687 | Cost: 0.40060043054789746 | Gradient: [[ 0.02008862]\n",
      " [-0.1102395 ]\n",
      " [ 0.13556575]]\n",
      "Iteration 2688 | Cost: 0.4005694982744905 | Gradient: [[ 0.02009966]\n",
      " [-0.11020644]\n",
      " [ 0.13556001]]\n",
      "Iteration 2689 | Cost: 0.4005385744014553 | Gradient: [[ 0.02011069]\n",
      " [-0.11017339]\n",
      " [ 0.13555427]]\n",
      "Iteration 2690 | Cost: 0.40050765892272383 | Gradient: [[ 0.0201217 ]\n",
      " [-0.11014037]\n",
      " [ 0.13554852]]\n",
      "Iteration 2691 | Cost: 0.4004767518322367 | Gradient: [[ 0.02013271]\n",
      " [-0.11010738]\n",
      " [ 0.13554277]]\n",
      "Iteration 2692 | Cost: 0.400445853123943 | Gradient: [[ 0.02014371]\n",
      " [-0.11007441]\n",
      " [ 0.13553701]]\n",
      "Iteration 2693 | Cost: 0.40041496279180033 | Gradient: [[ 0.0201547 ]\n",
      " [-0.11004146]\n",
      " [ 0.13553125]]\n",
      "Iteration 2694 | Cost: 0.40038408082977506 | Gradient: [[ 0.02016567]\n",
      " [-0.11000854]\n",
      " [ 0.13552548]]\n",
      "Iteration 2695 | Cost: 0.4003532072318412 | Gradient: [[ 0.02017664]\n",
      " [-0.10997565]\n",
      " [ 0.1355197 ]]\n",
      "Iteration 2696 | Cost: 0.40032234199198224 | Gradient: [[ 0.0201876 ]\n",
      " [-0.10994277]\n",
      " [ 0.13551392]]\n",
      "Iteration 2697 | Cost: 0.4002914851041894 | Gradient: [[ 0.02019854]\n",
      " [-0.10990993]\n",
      " [ 0.13550813]]\n",
      "Iteration 2698 | Cost: 0.40026063656246264 | Gradient: [[ 0.02020948]\n",
      " [-0.1098771 ]\n",
      " [ 0.13550234]]\n",
      "Iteration 2699 | Cost: 0.4002297963608102 | Gradient: [[ 0.02022041]\n",
      " [-0.10984431]\n",
      " [ 0.13549655]]\n",
      "Iteration 2700 | Cost: 0.40019896449324877 | Gradient: [[ 0.02023132]\n",
      " [-0.10981153]\n",
      " [ 0.13549074]]\n",
      "Iteration 2701 | Cost: 0.4001681409538033 | Gradient: [[ 0.02024223]\n",
      " [-0.10977878]\n",
      " [ 0.13548494]]\n",
      "Iteration 2702 | Cost: 0.40013732573650734 | Gradient: [[ 0.02025312]\n",
      " [-0.10974606]\n",
      " [ 0.13547912]]\n",
      "Iteration 2703 | Cost: 0.40010651883540266 | Gradient: [[ 0.02026401]\n",
      " [-0.10971336]\n",
      " [ 0.1354733 ]]\n",
      "Iteration 2704 | Cost: 0.4000757202445393 | Gradient: [[ 0.02027488]\n",
      " [-0.10968068]\n",
      " [ 0.13546748]]\n",
      "Iteration 2705 | Cost: 0.4000449299579756 | Gradient: [[ 0.02028574]\n",
      " [-0.10964803]\n",
      " [ 0.13546165]]\n",
      "Iteration 2706 | Cost: 0.4000141479697782 | Gradient: [[ 0.0202966 ]\n",
      " [-0.10961541]\n",
      " [ 0.13545582]]\n",
      "Iteration 2707 | Cost: 0.3999833742740223 | Gradient: [[ 0.02030744]\n",
      " [-0.1095828 ]\n",
      " [ 0.13544998]]\n",
      "Iteration 2708 | Cost: 0.39995260886479095 | Gradient: [[ 0.02031828]\n",
      " [-0.10955022]\n",
      " [ 0.13544414]]\n",
      "Iteration 2709 | Cost: 0.3999218517361758 | Gradient: [[ 0.0203291 ]\n",
      " [-0.10951767]\n",
      " [ 0.13543829]]\n",
      "Iteration 2710 | Cost: 0.39989110288227653 | Gradient: [[ 0.02033991]\n",
      " [-0.10948514]\n",
      " [ 0.13543243]]\n",
      "Iteration 2711 | Cost: 0.3998603622972012 | Gradient: [[ 0.02035072]\n",
      " [-0.10945264]\n",
      " [ 0.13542657]]\n",
      "Iteration 2712 | Cost: 0.3998296299750657 | Gradient: [[ 0.02036151]\n",
      " [-0.10942015]\n",
      " [ 0.13542071]]\n",
      "Iteration 2713 | Cost: 0.3997989059099948 | Gradient: [[ 0.02037229]\n",
      " [-0.1093877 ]\n",
      " [ 0.13541484]]\n",
      "Iteration 2714 | Cost: 0.39976819009612086 | Gradient: [[ 0.02038306]\n",
      " [-0.10935526]\n",
      " [ 0.13540896]]\n",
      "Iteration 2715 | Cost: 0.39973748252758456 | Gradient: [[ 0.02039383]\n",
      " [-0.10932285]\n",
      " [ 0.13540308]]\n",
      "Iteration 2716 | Cost: 0.3997067831985349 | Gradient: [[ 0.02040458]\n",
      " [-0.10929047]\n",
      " [ 0.13539719]]\n",
      "Iteration 2717 | Cost: 0.39967609210312877 | Gradient: [[ 0.02041532]\n",
      " [-0.10925811]\n",
      " [ 0.1353913 ]]\n",
      "Iteration 2718 | Cost: 0.39964540923553143 | Gradient: [[ 0.02042605]\n",
      " [-0.10922577]\n",
      " [ 0.1353854 ]]\n",
      "Iteration 2719 | Cost: 0.3996147345899159 | Gradient: [[ 0.02043678]\n",
      " [-0.10919346]\n",
      " [ 0.1353795 ]]\n",
      "Iteration 2720 | Cost: 0.39958406816046366 | Gradient: [[ 0.02044749]\n",
      " [-0.10916117]\n",
      " [ 0.13537359]]\n",
      "Iteration 2721 | Cost: 0.39955340994136407 | Gradient: [[ 0.02045819]\n",
      " [-0.1091289 ]\n",
      " [ 0.13536768]]\n",
      "Iteration 2722 | Cost: 0.3995227599268146 | Gradient: [[ 0.02046888]\n",
      " [-0.10909666]\n",
      " [ 0.13536177]]\n",
      "Iteration 2723 | Cost: 0.39949211811102064 | Gradient: [[ 0.02047956]\n",
      " [-0.10906445]\n",
      " [ 0.13535584]]\n",
      "Iteration 2724 | Cost: 0.39946148448819596 | Gradient: [[ 0.02049024]\n",
      " [-0.10903225]\n",
      " [ 0.13534992]]\n",
      "Iteration 2725 | Cost: 0.3994308590525618 | Gradient: [[ 0.0205009 ]\n",
      " [-0.10900008]\n",
      " [ 0.13534398]]\n",
      "Iteration 2726 | Cost: 0.39940024179834804 | Gradient: [[ 0.02051155]\n",
      " [-0.10896794]\n",
      " [ 0.13533804]]\n",
      "Iteration 2727 | Cost: 0.39936963271979203 | Gradient: [[ 0.02052219]\n",
      " [-0.10893582]\n",
      " [ 0.1353321 ]]\n",
      "Iteration 2728 | Cost: 0.39933903181113917 | Gradient: [[ 0.02053282]\n",
      " [-0.10890372]\n",
      " [ 0.13532615]]\n",
      "Iteration 2729 | Cost: 0.3993084390666433 | Gradient: [[ 0.02054345]\n",
      " [-0.10887165]\n",
      " [ 0.1353202 ]]\n",
      "Iteration 2730 | Cost: 0.3992778544805655 | Gradient: [[ 0.02055406]\n",
      " [-0.1088396 ]\n",
      " [ 0.13531424]]\n",
      "Iteration 2731 | Cost: 0.39924727804717525 | Gradient: [[ 0.02056466]\n",
      " [-0.10880757]\n",
      " [ 0.13530828]]\n",
      "Iteration 2732 | Cost: 0.39921670976074985 | Gradient: [[ 0.02057525]\n",
      " [-0.10877557]\n",
      " [ 0.13530231]]\n",
      "Iteration 2733 | Cost: 0.3991861496155743 | Gradient: [[ 0.02058584]\n",
      " [-0.10874359]\n",
      " [ 0.13529634]]\n",
      "Iteration 2734 | Cost: 0.39915559760594194 | Gradient: [[ 0.02059641]\n",
      " [-0.10871163]\n",
      " [ 0.13529036]]\n",
      "Iteration 2735 | Cost: 0.3991250537261534 | Gradient: [[ 0.02060697]\n",
      " [-0.1086797 ]\n",
      " [ 0.13528437]]\n",
      "Iteration 2736 | Cost: 0.39909451797051754 | Gradient: [[ 0.02061752]\n",
      " [-0.10864779]\n",
      " [ 0.13527838]]\n",
      "Iteration 2737 | Cost: 0.39906399033335105 | Gradient: [[ 0.02062807]\n",
      " [-0.10861591]\n",
      " [ 0.13527239]]\n",
      "Iteration 2738 | Cost: 0.3990334708089784 | Gradient: [[ 0.0206386 ]\n",
      " [-0.10858405]\n",
      " [ 0.13526639]]\n",
      "Iteration 2739 | Cost: 0.39900295939173186 | Gradient: [[ 0.02064912]\n",
      " [-0.10855221]\n",
      " [ 0.13526039]]\n",
      "Iteration 2740 | Cost: 0.39897245607595133 | Gradient: [[ 0.02065964]\n",
      " [-0.10852039]\n",
      " [ 0.13525438]]\n",
      "Iteration 2741 | Cost: 0.398941960855985 | Gradient: [[ 0.02067014]\n",
      " [-0.1084886 ]\n",
      " [ 0.13524836]]\n",
      "Iteration 2742 | Cost: 0.39891147372618807 | Gradient: [[ 0.02068063]\n",
      " [-0.10845684]\n",
      " [ 0.13524234]]\n",
      "Iteration 2743 | Cost: 0.39888099468092436 | Gradient: [[ 0.02069112]\n",
      " [-0.10842509]\n",
      " [ 0.13523632]]\n",
      "Iteration 2744 | Cost: 0.39885052371456475 | Gradient: [[ 0.02070159]\n",
      " [-0.10839337]\n",
      " [ 0.13523029]]\n",
      "Iteration 2745 | Cost: 0.3988200608214882 | Gradient: [[ 0.02071205]\n",
      " [-0.10836168]\n",
      " [ 0.13522426]]\n",
      "Iteration 2746 | Cost: 0.39878960599608126 | Gradient: [[ 0.02072251]\n",
      " [-0.10833   ]\n",
      " [ 0.13521822]]\n",
      "Iteration 2747 | Cost: 0.3987591592327382 | Gradient: [[ 0.02073295]\n",
      " [-0.10829835]\n",
      " [ 0.13521217]]\n",
      "Iteration 2748 | Cost: 0.39872872052586106 | Gradient: [[ 0.02074339]\n",
      " [-0.10826673]\n",
      " [ 0.13520612]]\n",
      "Iteration 2749 | Cost: 0.39869828986985945 | Gradient: [[ 0.02075381]\n",
      " [-0.10823512]\n",
      " [ 0.13520007]]\n",
      "Iteration 2750 | Cost: 0.39866786725915054 | Gradient: [[ 0.02076423]\n",
      " [-0.10820354]\n",
      " [ 0.13519401]]\n",
      "Iteration 2751 | Cost: 0.3986374526881596 | Gradient: [[ 0.02077463]\n",
      " [-0.10817199]\n",
      " [ 0.13518795]]\n",
      "Iteration 2752 | Cost: 0.3986070461513191 | Gradient: [[ 0.02078503]\n",
      " [-0.10814045]\n",
      " [ 0.13518188]]\n",
      "Iteration 2753 | Cost: 0.3985766476430691 | Gradient: [[ 0.02079541]\n",
      " [-0.10810894]\n",
      " [ 0.1351758 ]]\n",
      "Iteration 2754 | Cost: 0.39854625715785763 | Gradient: [[ 0.02080579]\n",
      " [-0.10807746]\n",
      " [ 0.13516972]]\n",
      "Iteration 2755 | Cost: 0.39851587469014005 | Gradient: [[ 0.02081616]\n",
      " [-0.10804599]\n",
      " [ 0.13516364]]\n",
      "Iteration 2756 | Cost: 0.3984855002343792 | Gradient: [[ 0.02082651]\n",
      " [-0.10801455]\n",
      " [ 0.13515755]]\n",
      "Iteration 2757 | Cost: 0.39845513378504593 | Gradient: [[ 0.02083686]\n",
      " [-0.10798313]\n",
      " [ 0.13515146]]\n",
      "Iteration 2758 | Cost: 0.3984247753366179 | Gradient: [[ 0.0208472 ]\n",
      " [-0.10795174]\n",
      " [ 0.13514536]]\n",
      "Iteration 2759 | Cost: 0.39839442488358134 | Gradient: [[ 0.02085752]\n",
      " [-0.10792037]\n",
      " [ 0.13513925]]\n",
      "Iteration 2760 | Cost: 0.398364082420429 | Gradient: [[ 0.02086784]\n",
      " [-0.10788902]\n",
      " [ 0.13513315]]\n",
      "Iteration 2761 | Cost: 0.3983337479416616 | Gradient: [[ 0.02087815]\n",
      " [-0.10785769]\n",
      " [ 0.13512703]]\n",
      "Iteration 2762 | Cost: 0.39830342144178754 | Gradient: [[ 0.02088845]\n",
      " [-0.10782639]\n",
      " [ 0.13512091]]\n",
      "Iteration 2763 | Cost: 0.3982731029153223 | Gradient: [[ 0.02089874]\n",
      " [-0.10779511]\n",
      " [ 0.13511479]]\n",
      "Iteration 2764 | Cost: 0.398242792356789 | Gradient: [[ 0.02090902]\n",
      " [-0.10776385]\n",
      " [ 0.13510866]]\n",
      "Iteration 2765 | Cost: 0.3982124897607183 | Gradient: [[ 0.02091929]\n",
      " [-0.10773262]\n",
      " [ 0.13510253]]\n",
      "Iteration 2766 | Cost: 0.3981821951216483 | Gradient: [[ 0.02092955]\n",
      " [-0.10770141]\n",
      " [ 0.13509639]]\n",
      "Iteration 2767 | Cost: 0.39815190843412435 | Gradient: [[ 0.0209398 ]\n",
      " [-0.10767022]\n",
      " [ 0.13509025]]\n",
      "Iteration 2768 | Cost: 0.3981216296926993 | Gradient: [[ 0.02095004]\n",
      " [-0.10763906]\n",
      " [ 0.1350841 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2769 | Cost: 0.39809135889193364 | Gradient: [[ 0.02096027]\n",
      " [-0.10760792]\n",
      " [ 0.13507795]]\n",
      "Iteration 2770 | Cost: 0.39806109602639483 | Gradient: [[ 0.02097049]\n",
      " [-0.1075768 ]\n",
      " [ 0.13507179]]\n",
      "Iteration 2771 | Cost: 0.398030841090658 | Gradient: [[ 0.0209807 ]\n",
      " [-0.1075457 ]\n",
      " [ 0.13506563]]\n",
      "Iteration 2772 | Cost: 0.39800059407930555 | Gradient: [[ 0.02099091]\n",
      " [-0.10751463]\n",
      " [ 0.13505946]]\n",
      "Iteration 2773 | Cost: 0.39797035498692723 | Gradient: [[ 0.0210011 ]\n",
      " [-0.10748358]\n",
      " [ 0.13505329]]\n",
      "Iteration 2774 | Cost: 0.39794012380812016 | Gradient: [[ 0.02101128]\n",
      " [-0.10745255]\n",
      " [ 0.13504711]]\n",
      "Iteration 2775 | Cost: 0.39790990053748887 | Gradient: [[ 0.02102146]\n",
      " [-0.10742154]\n",
      " [ 0.13504093]]\n",
      "Iteration 2776 | Cost: 0.397879685169645 | Gradient: [[ 0.02103162]\n",
      " [-0.10739056]\n",
      " [ 0.13503475]]\n",
      "Iteration 2777 | Cost: 0.3978494776992076 | Gradient: [[ 0.02104178]\n",
      " [-0.1073596 ]\n",
      " [ 0.13502856]]\n",
      "Iteration 2778 | Cost: 0.3978192781208028 | Gradient: [[ 0.02105192]\n",
      " [-0.10732866]\n",
      " [ 0.13502236]]\n",
      "Iteration 2779 | Cost: 0.3977890864290646 | Gradient: [[ 0.02106206]\n",
      " [-0.10729775]\n",
      " [ 0.13501616]]\n",
      "Iteration 2780 | Cost: 0.3977589026186335 | Gradient: [[ 0.02107218]\n",
      " [-0.10726685]\n",
      " [ 0.13500995]]\n",
      "Iteration 2781 | Cost: 0.3977287266841577 | Gradient: [[ 0.0210823 ]\n",
      " [-0.10723599]\n",
      " [ 0.13500374]]\n",
      "Iteration 2782 | Cost: 0.3976985586202925 | Gradient: [[ 0.02109241]\n",
      " [-0.10720514]\n",
      " [ 0.13499753]]\n",
      "Iteration 2783 | Cost: 0.3976683984217007 | Gradient: [[ 0.02110251]\n",
      " [-0.10717431]\n",
      " [ 0.13499131]]\n",
      "Iteration 2784 | Cost: 0.3976382460830517 | Gradient: [[ 0.0211126 ]\n",
      " [-0.10714351]\n",
      " [ 0.13498509]]\n",
      "Iteration 2785 | Cost: 0.39760810159902266 | Gradient: [[ 0.02112268]\n",
      " [-0.10711273]\n",
      " [ 0.13497886]]\n",
      "Iteration 2786 | Cost: 0.3975779649642975 | Gradient: [[ 0.02113275]\n",
      " [-0.10708197]\n",
      " [ 0.13497262]]\n",
      "Iteration 2787 | Cost: 0.3975478361735678 | Gradient: [[ 0.02114281]\n",
      " [-0.10705124]\n",
      " [ 0.13496638]]\n",
      "Iteration 2788 | Cost: 0.39751771522153184 | Gradient: [[ 0.02115286]\n",
      " [-0.10702053]\n",
      " [ 0.13496014]]\n",
      "Iteration 2789 | Cost: 0.3974876021028953 | Gradient: [[ 0.0211629 ]\n",
      " [-0.10698984]\n",
      " [ 0.13495389]]\n",
      "Iteration 2790 | Cost: 0.39745749681237075 | Gradient: [[ 0.02117293]\n",
      " [-0.10695917]\n",
      " [ 0.13494764]]\n",
      "Iteration 2791 | Cost: 0.3974273993446782 | Gradient: [[ 0.02118295]\n",
      " [-0.10692853]\n",
      " [ 0.13494138]]\n",
      "Iteration 2792 | Cost: 0.39739730969454445 | Gradient: [[ 0.02119297]\n",
      " [-0.1068979 ]\n",
      " [ 0.13493512]]\n",
      "Iteration 2793 | Cost: 0.39736722785670375 | Gradient: [[ 0.02120297]\n",
      " [-0.1068673 ]\n",
      " [ 0.13492885]]\n",
      "Iteration 2794 | Cost: 0.39733715382589696 | Gradient: [[ 0.02121297]\n",
      " [-0.10683672]\n",
      " [ 0.13492258]]\n",
      "Iteration 2795 | Cost: 0.3973070875968725 | Gradient: [[ 0.02122295]\n",
      " [-0.10680617]\n",
      " [ 0.13491631]]\n",
      "Iteration 2796 | Cost: 0.39727702916438545 | Gradient: [[ 0.02123293]\n",
      " [-0.10677564]\n",
      " [ 0.13491002]]\n",
      "Iteration 2797 | Cost: 0.39724697852319824 | Gradient: [[ 0.0212429 ]\n",
      " [-0.10674512]\n",
      " [ 0.13490374]]\n",
      "Iteration 2798 | Cost: 0.3972169356680799 | Gradient: [[ 0.02125285]\n",
      " [-0.10671463]\n",
      " [ 0.13489745]]\n",
      "Iteration 2799 | Cost: 0.397186900593807 | Gradient: [[ 0.0212628 ]\n",
      " [-0.10668417]\n",
      " [ 0.13489115]]\n",
      "Iteration 2800 | Cost: 0.3971568732951628 | Gradient: [[ 0.02127274]\n",
      " [-0.10665372]\n",
      " [ 0.13488486]]\n",
      "Iteration 2801 | Cost: 0.3971268537669377 | Gradient: [[ 0.02128267]\n",
      " [-0.1066233 ]\n",
      " [ 0.13487855]]\n",
      "Iteration 2802 | Cost: 0.3970968420039288 | Gradient: [[ 0.02129259]\n",
      " [-0.1065929 ]\n",
      " [ 0.13487224]]\n",
      "Iteration 2803 | Cost: 0.39706683800094045 | Gradient: [[ 0.0213025 ]\n",
      " [-0.10656252]\n",
      " [ 0.13486593]]\n",
      "Iteration 2804 | Cost: 0.397036841752784 | Gradient: [[ 0.0213124 ]\n",
      " [-0.10653216]\n",
      " [ 0.13485961]]\n",
      "Iteration 2805 | Cost: 0.3970068532542775 | Gradient: [[ 0.0213223 ]\n",
      " [-0.10650183]\n",
      " [ 0.13485329]]\n",
      "Iteration 2806 | Cost: 0.39697687250024605 | Gradient: [[ 0.02133218]\n",
      " [-0.10647152]\n",
      " [ 0.13484696]]\n",
      "Iteration 2807 | Cost: 0.3969468994855215 | Gradient: [[ 0.02134205]\n",
      " [-0.10644123]\n",
      " [ 0.13484063]]\n",
      "Iteration 2808 | Cost: 0.396916934204943 | Gradient: [[ 0.02135192]\n",
      " [-0.10641096]\n",
      " [ 0.13483429]]\n",
      "Iteration 2809 | Cost: 0.39688697665335626 | Gradient: [[ 0.02136177]\n",
      " [-0.10638071]\n",
      " [ 0.13482795]]\n",
      "Iteration 2810 | Cost: 0.396857026825614 | Gradient: [[ 0.02137162]\n",
      " [-0.10635049]\n",
      " [ 0.13482161]]\n",
      "Iteration 2811 | Cost: 0.39682708471657563 | Gradient: [[ 0.02138146]\n",
      " [-0.10632029]\n",
      " [ 0.13481526]]\n",
      "Iteration 2812 | Cost: 0.39679715032110774 | Gradient: [[ 0.02139129]\n",
      " [-0.10629011]\n",
      " [ 0.1348089 ]]\n",
      "Iteration 2813 | Cost: 0.3967672236340834 | Gradient: [[ 0.0214011 ]\n",
      " [-0.10625995]\n",
      " [ 0.13480254]]\n",
      "Iteration 2814 | Cost: 0.39673730465038287 | Gradient: [[ 0.02141091]\n",
      " [-0.10622981]\n",
      " [ 0.13479618]]\n",
      "Iteration 2815 | Cost: 0.39670739336489297 | Gradient: [[ 0.02142071]\n",
      " [-0.10619969]\n",
      " [ 0.13478981]]\n",
      "Iteration 2816 | Cost: 0.3966774897725074 | Gradient: [[ 0.02143051]\n",
      " [-0.1061696 ]\n",
      " [ 0.13478344]]\n",
      "Iteration 2817 | Cost: 0.3966475938681266 | Gradient: [[ 0.02144029]\n",
      " [-0.10613953]\n",
      " [ 0.13477706]]\n",
      "Iteration 2818 | Cost: 0.3966177056466579 | Gradient: [[ 0.02145006]\n",
      " [-0.10610948]\n",
      " [ 0.13477068]]\n",
      "Iteration 2819 | Cost: 0.39658782510301543 | Gradient: [[ 0.02145983]\n",
      " [-0.10607945]\n",
      " [ 0.13476429]]\n",
      "Iteration 2820 | Cost: 0.39655795223212 | Gradient: [[ 0.02146958]\n",
      " [-0.10604945]\n",
      " [ 0.1347579 ]]\n",
      "Iteration 2821 | Cost: 0.3965280870288991 | Gradient: [[ 0.02147933]\n",
      " [-0.10601946]\n",
      " [ 0.1347515 ]]\n",
      "Iteration 2822 | Cost: 0.39649822948828695 | Gradient: [[ 0.02148906]\n",
      " [-0.1059895 ]\n",
      " [ 0.1347451 ]]\n",
      "Iteration 2823 | Cost: 0.39646837960522474 | Gradient: [[ 0.02149879]\n",
      " [-0.10595956]\n",
      " [ 0.1347387 ]]\n",
      "Iteration 2824 | Cost: 0.3964385373746602 | Gradient: [[ 0.02150851]\n",
      " [-0.10592964]\n",
      " [ 0.13473229]]\n",
      "Iteration 2825 | Cost: 0.3964087027915476 | Gradient: [[ 0.02151822]\n",
      " [-0.10589974]\n",
      " [ 0.13472588]]\n",
      "Iteration 2826 | Cost: 0.39637887585084813 | Gradient: [[ 0.02152792]\n",
      " [-0.10586986]\n",
      " [ 0.13471946]]\n",
      "Iteration 2827 | Cost: 0.3963490565475297 | Gradient: [[ 0.02153761]\n",
      " [-0.10584001]\n",
      " [ 0.13471304]]\n",
      "Iteration 2828 | Cost: 0.3963192448765666 | Gradient: [[ 0.02154729]\n",
      " [-0.10581018]\n",
      " [ 0.13470661]]\n",
      "Iteration 2829 | Cost: 0.39628944083294004 | Gradient: [[ 0.02155697]\n",
      " [-0.10578036]\n",
      " [ 0.13470018]]\n",
      "Iteration 2830 | Cost: 0.39625964441163775 | Gradient: [[ 0.02156663]\n",
      " [-0.10575057]\n",
      " [ 0.13469374]]\n",
      "Iteration 2831 | Cost: 0.39622985560765417 | Gradient: [[ 0.02157629]\n",
      " [-0.1057208 ]\n",
      " [ 0.1346873 ]]\n",
      "Iteration 2832 | Cost: 0.3962000744159901 | Gradient: [[ 0.02158593]\n",
      " [-0.10569106]\n",
      " [ 0.13468086]]\n",
      "Iteration 2833 | Cost: 0.39617030083165333 | Gradient: [[ 0.02159557]\n",
      " [-0.10566133]\n",
      " [ 0.13467441]]\n",
      "Iteration 2834 | Cost: 0.39614053484965794 | Gradient: [[ 0.0216052 ]\n",
      " [-0.10563163]\n",
      " [ 0.13466795]]\n",
      "Iteration 2835 | Cost: 0.39611077646502496 | Gradient: [[ 0.02161482]\n",
      " [-0.10560194]\n",
      " [ 0.1346615 ]]\n",
      "Iteration 2836 | Cost: 0.39608102567278136 | Gradient: [[ 0.02162443]\n",
      " [-0.10557228]\n",
      " [ 0.13465503]]\n",
      "Iteration 2837 | Cost: 0.3960512824679613 | Gradient: [[ 0.02163403]\n",
      " [-0.10554264]\n",
      " [ 0.13464857]]\n",
      "Iteration 2838 | Cost: 0.3960215468456052 | Gradient: [[ 0.02164362]\n",
      " [-0.10551302]\n",
      " [ 0.1346421 ]]\n",
      "Iteration 2839 | Cost: 0.39599181880076 | Gradient: [[ 0.0216532 ]\n",
      " [-0.10548343]\n",
      " [ 0.13463562]]\n",
      "Iteration 2840 | Cost: 0.3959620983284793 | Gradient: [[ 0.02166278]\n",
      " [-0.10545385]\n",
      " [ 0.13462914]]\n",
      "Iteration 2841 | Cost: 0.3959323854238229 | Gradient: [[ 0.02167234]\n",
      " [-0.1054243 ]\n",
      " [ 0.13462266]]\n",
      "Iteration 2842 | Cost: 0.3959026800818575 | Gradient: [[ 0.0216819 ]\n",
      " [-0.10539476]\n",
      " [ 0.13461617]]\n",
      "Iteration 2843 | Cost: 0.39587298229765633 | Gradient: [[ 0.02169145]\n",
      " [-0.10536525]\n",
      " [ 0.13460967]]\n",
      "Iteration 2844 | Cost: 0.3958432920662984 | Gradient: [[ 0.02170099]\n",
      " [-0.10533576]\n",
      " [ 0.13460318]]\n",
      "Iteration 2845 | Cost: 0.39581360938287014 | Gradient: [[ 0.02171052]\n",
      " [-0.10530629]\n",
      " [ 0.13459667]]\n",
      "Iteration 2846 | Cost: 0.3957839342424637 | Gradient: [[ 0.02172004]\n",
      " [-0.10527684]\n",
      " [ 0.13459017]]\n",
      "Iteration 2847 | Cost: 0.395754266640178 | Gradient: [[ 0.02172955]\n",
      " [-0.10524741]\n",
      " [ 0.13458366]]\n",
      "Iteration 2848 | Cost: 0.39572460657111835 | Gradient: [[ 0.02173905]\n",
      " [-0.10521801]\n",
      " [ 0.13457714]]\n",
      "Iteration 2849 | Cost: 0.3956949540303965 | Gradient: [[ 0.02174855]\n",
      " [-0.10518862]\n",
      " [ 0.13457062]]\n",
      "Iteration 2850 | Cost: 0.3956653090131305 | Gradient: [[ 0.02175803]\n",
      " [-0.10515926]\n",
      " [ 0.1345641 ]]\n",
      "Iteration 2851 | Cost: 0.395635671514445 | Gradient: [[ 0.02176751]\n",
      " [-0.10512991]\n",
      " [ 0.13455757]]\n",
      "Iteration 2852 | Cost: 0.3956060415294708 | Gradient: [[ 0.02177698]\n",
      " [-0.10510059]\n",
      " [ 0.13455104]]\n",
      "Iteration 2853 | Cost: 0.39557641905334523 | Gradient: [[ 0.02178644]\n",
      " [-0.10507129]\n",
      " [ 0.1345445 ]]\n",
      "Iteration 2854 | Cost: 0.39554680408121196 | Gradient: [[ 0.02179589]\n",
      " [-0.10504201]\n",
      " [ 0.13453796]]\n",
      "Iteration 2855 | Cost: 0.395517196608221 | Gradient: [[ 0.02180533]\n",
      " [-0.10501275]\n",
      " [ 0.13453141]]\n",
      "Iteration 2856 | Cost: 0.3954875966295287 | Gradient: [[ 0.02181476]\n",
      " [-0.10498351]\n",
      " [ 0.13452486]]\n",
      "Iteration 2857 | Cost: 0.3954580041402978 | Gradient: [[ 0.02182419]\n",
      " [-0.1049543 ]\n",
      " [ 0.13451831]]\n",
      "Iteration 2858 | Cost: 0.3954284191356972 | Gradient: [[ 0.0218336 ]\n",
      " [-0.1049251 ]\n",
      " [ 0.13451175]]\n",
      "Iteration 2859 | Cost: 0.39539884161090233 | Gradient: [[ 0.02184301]\n",
      " [-0.10489593]\n",
      " [ 0.13450519]]\n",
      "Iteration 2860 | Cost: 0.3953692715610947 | Gradient: [[ 0.0218524 ]\n",
      " [-0.10486677]\n",
      " [ 0.13449862]]\n",
      "Iteration 2861 | Cost: 0.39533970898146237 | Gradient: [[ 0.02186179]\n",
      " [-0.10483764]\n",
      " [ 0.13449205]]\n",
      "Iteration 2862 | Cost: 0.3953101538671993 | Gradient: [[ 0.02187117]\n",
      " [-0.10480852]\n",
      " [ 0.13448548]]\n",
      "Iteration 2863 | Cost: 0.3952806062135061 | Gradient: [[ 0.02188054]\n",
      " [-0.10477943]\n",
      " [ 0.1344789 ]]\n",
      "Iteration 2864 | Cost: 0.39525106601558946 | Gradient: [[ 0.02188991]\n",
      " [-0.10475036]\n",
      " [ 0.13447231]]\n",
      "Iteration 2865 | Cost: 0.3952215332686624 | Gradient: [[ 0.02189926]\n",
      " [-0.10472131]\n",
      " [ 0.13446572]]\n",
      "Iteration 2866 | Cost: 0.39519200796794385 | Gradient: [[ 0.02190861]\n",
      " [-0.10469228]\n",
      " [ 0.13445913]]\n",
      "Iteration 2867 | Cost: 0.3951624901086594 | Gradient: [[ 0.02191794]\n",
      " [-0.10466327]\n",
      " [ 0.13445253]]\n",
      "Iteration 2868 | Cost: 0.3951329796860407 | Gradient: [[ 0.02192727]\n",
      " [-0.10463429]\n",
      " [ 0.13444593]]\n",
      "Iteration 2869 | Cost: 0.3951034766953255 | Gradient: [[ 0.02193659]\n",
      " [-0.10460532]\n",
      " [ 0.13443933]]\n",
      "Iteration 2870 | Cost: 0.3950739811317577 | Gradient: [[ 0.0219459 ]\n",
      " [-0.10457637]\n",
      " [ 0.13443272]]\n",
      "Iteration 2871 | Cost: 0.39504449299058775 | Gradient: [[ 0.0219552 ]\n",
      " [-0.10454745]\n",
      " [ 0.13442611]]\n",
      "Iteration 2872 | Cost: 0.3950150122670717 | Gradient: [[ 0.02196449]\n",
      " [-0.10451854]\n",
      " [ 0.13441949]]\n",
      "Iteration 2873 | Cost: 0.3949855389564722 | Gradient: [[ 0.02197378]\n",
      " [-0.10448966]\n",
      " [ 0.13441287]]\n",
      "Iteration 2874 | Cost: 0.39495607305405794 | Gradient: [[ 0.02198305]\n",
      " [-0.10446079]\n",
      " [ 0.13440624]]\n",
      "Iteration 2875 | Cost: 0.39492661455510364 | Gradient: [[ 0.02199232]\n",
      " [-0.10443195]\n",
      " [ 0.13439961]]\n",
      "Iteration 2876 | Cost: 0.3948971634548903 | Gradient: [[ 0.02200158]\n",
      " [-0.10440313]\n",
      " [ 0.13439298]]\n",
      "Iteration 2877 | Cost: 0.3948677197487049 | Gradient: [[ 0.02201083]\n",
      " [-0.10437432]\n",
      " [ 0.13438634]]\n",
      "Iteration 2878 | Cost: 0.39483828343184046 | Gradient: [[ 0.02202007]\n",
      " [-0.10434554]\n",
      " [ 0.13437969]]\n",
      "Iteration 2879 | Cost: 0.3948088544995964 | Gradient: [[ 0.0220293 ]\n",
      " [-0.10431678]\n",
      " [ 0.13437305]]\n",
      "Iteration 2880 | Cost: 0.39477943294727796 | Gradient: [[ 0.02203853]\n",
      " [-0.10428804]\n",
      " [ 0.1343664 ]]\n",
      "Iteration 2881 | Cost: 0.3947500187701964 | Gradient: [[ 0.02204774]\n",
      " [-0.10425932]\n",
      " [ 0.13435974]]\n",
      "Iteration 2882 | Cost: 0.39472061196366937 | Gradient: [[ 0.02205695]\n",
      " [-0.10423062]\n",
      " [ 0.13435308]]\n",
      "Iteration 2883 | Cost: 0.39469121252302025 | Gradient: [[ 0.02206615]\n",
      " [-0.10420194]\n",
      " [ 0.13434642]]\n",
      "Iteration 2884 | Cost: 0.3946618204435784 | Gradient: [[ 0.02207534]\n",
      " [-0.10417328]\n",
      " [ 0.13433975]]\n",
      "Iteration 2885 | Cost: 0.39463243572067974 | Gradient: [[ 0.02208452]\n",
      " [-0.10414464]\n",
      " [ 0.13433308]]\n",
      "Iteration 2886 | Cost: 0.3946030583496656 | Gradient: [[ 0.02209369]\n",
      " [-0.10411603]\n",
      " [ 0.1343264 ]]\n",
      "Iteration 2887 | Cost: 0.39457368832588374 | Gradient: [[ 0.02210285]\n",
      " [-0.10408743]\n",
      " [ 0.13431972]]\n",
      "Iteration 2888 | Cost: 0.39454432564468755 | Gradient: [[ 0.02211201]\n",
      " [-0.10405885]\n",
      " [ 0.13431304]]\n",
      "Iteration 2889 | Cost: 0.39451497030143673 | Gradient: [[ 0.02212115]\n",
      " [-0.10403029]\n",
      " [ 0.13430635]]\n",
      "Iteration 2890 | Cost: 0.39448562229149686 | Gradient: [[ 0.02213029]\n",
      " [-0.10400176]\n",
      " [ 0.13429966]]\n",
      "Iteration 2891 | Cost: 0.3944562816102393 | Gradient: [[ 0.02213942]\n",
      " [-0.10397324]\n",
      " [ 0.13429296]]\n",
      "Iteration 2892 | Cost: 0.3944269482530418 | Gradient: [[ 0.02214854]\n",
      " [-0.10394474]\n",
      " [ 0.13428626]]\n",
      "Iteration 2893 | Cost: 0.39439762221528757 | Gradient: [[ 0.02215766]\n",
      " [-0.10391627]\n",
      " [ 0.13427955]]\n",
      "Iteration 2894 | Cost: 0.39436830349236607 | Gradient: [[ 0.02216676]\n",
      " [-0.10388781]\n",
      " [ 0.13427284]]\n",
      "Iteration 2895 | Cost: 0.3943389920796725 | Gradient: [[ 0.02217586]\n",
      " [-0.10385938]\n",
      " [ 0.13426613]]\n",
      "Iteration 2896 | Cost: 0.39430968797260807 | Gradient: [[ 0.02218494]\n",
      " [-0.10383096]\n",
      " [ 0.13425941]]\n",
      "Iteration 2897 | Cost: 0.39428039116658 | Gradient: [[ 0.02219402]\n",
      " [-0.10380257]\n",
      " [ 0.13425269]]\n",
      "Iteration 2898 | Cost: 0.3942511016570012 | Gradient: [[ 0.02220309]\n",
      " [-0.10377419]\n",
      " [ 0.13424597]]\n",
      "Iteration 2899 | Cost: 0.3942218194392905 | Gradient: [[ 0.02221216]\n",
      " [-0.10374584]\n",
      " [ 0.13423924]]\n",
      "Iteration 2900 | Cost: 0.3941925445088729 | Gradient: [[ 0.02222121]\n",
      " [-0.1037175 ]\n",
      " [ 0.13423251]]\n",
      "Iteration 2901 | Cost: 0.3941632768611788 | Gradient: [[ 0.02223025]\n",
      " [-0.10368919]\n",
      " [ 0.13422577]]\n",
      "Iteration 2902 | Cost: 0.39413401649164476 | Gradient: [[ 0.02223929]\n",
      " [-0.10366089]\n",
      " [ 0.13421903]]\n",
      "Iteration 2903 | Cost: 0.39410476339571304 | Gradient: [[ 0.02224832]\n",
      " [-0.10363262]\n",
      " [ 0.13421228]]\n",
      "Iteration 2904 | Cost: 0.3940755175688319 | Gradient: [[ 0.02225734]\n",
      " [-0.10360436]\n",
      " [ 0.13420553]]\n",
      "Iteration 2905 | Cost: 0.3940462790064553 | Gradient: [[ 0.02226635]\n",
      " [-0.10357613]\n",
      " [ 0.13419878]]\n",
      "Iteration 2906 | Cost: 0.394017047704043 | Gradient: [[ 0.02227535]\n",
      " [-0.10354791]\n",
      " [ 0.13419202]]\n",
      "Iteration 2907 | Cost: 0.39398782365706064 | Gradient: [[ 0.02228435]\n",
      " [-0.10351972]\n",
      " [ 0.13418526]]\n",
      "Iteration 2908 | Cost: 0.39395860686097955 | Gradient: [[ 0.02229334]\n",
      " [-0.10349154]\n",
      " [ 0.13417849]]\n",
      "Iteration 2909 | Cost: 0.39392939731127696 | Gradient: [[ 0.02230231]\n",
      " [-0.10346339]\n",
      " [ 0.13417172]]\n",
      "Iteration 2910 | Cost: 0.39390019500343576 | Gradient: [[ 0.02231128]\n",
      " [-0.10343525]\n",
      " [ 0.13416495]]\n",
      "Iteration 2911 | Cost: 0.39387099993294483 | Gradient: [[ 0.02232024]\n",
      " [-0.10340714]\n",
      " [ 0.13415817]]\n",
      "Iteration 2912 | Cost: 0.39384181209529845 | Gradient: [[ 0.0223292 ]\n",
      " [-0.10337904]\n",
      " [ 0.13415139]]\n",
      "Iteration 2913 | Cost: 0.39381263148599693 | Gradient: [[ 0.02233814]\n",
      " [-0.10335097]\n",
      " [ 0.13414461]]\n",
      "Iteration 2914 | Cost: 0.39378345810054627 | Gradient: [[ 0.02234708]\n",
      " [-0.10332291]\n",
      " [ 0.13413782]]\n",
      "Iteration 2915 | Cost: 0.3937542919344581 | Gradient: [[ 0.02235601]\n",
      " [-0.10329488]\n",
      " [ 0.13413102]]\n",
      "Iteration 2916 | Cost: 0.3937251329832496 | Gradient: [[ 0.02236493]\n",
      " [-0.10326686]\n",
      " [ 0.13412423]]\n",
      "Iteration 2917 | Cost: 0.3936959812424442 | Gradient: [[ 0.02237384]\n",
      " [-0.10323887]\n",
      " [ 0.13411743]]\n",
      "Iteration 2918 | Cost: 0.3936668367075706 | Gradient: [[ 0.02238274]\n",
      " [-0.10321089]\n",
      " [ 0.13411062]]\n",
      "Iteration 2919 | Cost: 0.39363769937416304 | Gradient: [[ 0.02239163]\n",
      " [-0.10318293]\n",
      " [ 0.13410381]]\n",
      "Iteration 2920 | Cost: 0.39360856923776183 | Gradient: [[ 0.02240052]\n",
      " [-0.103155  ]\n",
      " [ 0.134097  ]]\n",
      "Iteration 2921 | Cost: 0.3935794462939129 | Gradient: [[ 0.0224094 ]\n",
      " [-0.10312708]\n",
      " [ 0.13409018]]\n",
      "Iteration 2922 | Cost: 0.39355033053816757 | Gradient: [[ 0.02241827]\n",
      " [-0.10309918]\n",
      " [ 0.13408336]]\n",
      "Iteration 2923 | Cost: 0.39352122196608297 | Gradient: [[ 0.02242713]\n",
      " [-0.1030713 ]\n",
      " [ 0.13407654]]\n",
      "Iteration 2924 | Cost: 0.39349212057322186 | Gradient: [[ 0.02243598]\n",
      " [-0.10304345]\n",
      " [ 0.13406971]]\n",
      "Iteration 2925 | Cost: 0.39346302635515257 | Gradient: [[ 0.02244483]\n",
      " [-0.10301561]\n",
      " [ 0.13406287]]\n",
      "Iteration 2926 | Cost: 0.39343393930744924 | Gradient: [[ 0.02245367]\n",
      " [-0.10298779]\n",
      " [ 0.13405604]]\n",
      "Iteration 2927 | Cost: 0.3934048594256913 | Gradient: [[ 0.0224625 ]\n",
      " [-0.10295999]\n",
      " [ 0.1340492 ]]\n",
      "Iteration 2928 | Cost: 0.393375786705464 | Gradient: [[ 0.02247132]\n",
      " [-0.10293221]\n",
      " [ 0.13404235]]\n",
      "Iteration 2929 | Cost: 0.3933467211423582 | Gradient: [[ 0.02248013]\n",
      " [-0.10290445]\n",
      " [ 0.1340355 ]]\n",
      "Iteration 2930 | Cost: 0.3933176627319701 | Gradient: [[ 0.02248893]\n",
      " [-0.10287671]\n",
      " [ 0.13402865]]\n",
      "Iteration 2931 | Cost: 0.39328861146990185 | Gradient: [[ 0.02249773]\n",
      " [-0.10284899]\n",
      " [ 0.1340218 ]]\n",
      "Iteration 2932 | Cost: 0.3932595673517607 | Gradient: [[ 0.02250652]\n",
      " [-0.10282129]\n",
      " [ 0.13401494]]\n",
      "Iteration 2933 | Cost: 0.3932305303731599 | Gradient: [[ 0.0225153 ]\n",
      " [-0.1027936 ]\n",
      " [ 0.13400807]]\n",
      "Iteration 2934 | Cost: 0.3932015005297179 | Gradient: [[ 0.02252407]\n",
      " [-0.10276594]\n",
      " [ 0.1340012 ]]\n",
      "Iteration 2935 | Cost: 0.39317247781705894 | Gradient: [[ 0.02253283]\n",
      " [-0.1027383 ]\n",
      " [ 0.13399433]]\n",
      "Iteration 2936 | Cost: 0.3931434622308125 | Gradient: [[ 0.02254159]\n",
      " [-0.10271067]\n",
      " [ 0.13398746]]\n",
      "Iteration 2937 | Cost: 0.3931144537666138 | Gradient: [[ 0.02255033]\n",
      " [-0.10268307]\n",
      " [ 0.13398058]]\n",
      "Iteration 2938 | Cost: 0.3930854524201034 | Gradient: [[ 0.02255907]\n",
      " [-0.10265548]\n",
      " [ 0.13397369]]\n",
      "Iteration 2939 | Cost: 0.39305645818692764 | Gradient: [[ 0.0225678 ]\n",
      " [-0.10262792]\n",
      " [ 0.13396681]]\n",
      "Iteration 2940 | Cost: 0.39302747106273783 | Gradient: [[ 0.02257652]\n",
      " [-0.10260037]\n",
      " [ 0.13395992]]\n",
      "Iteration 2941 | Cost: 0.3929984910431914 | Gradient: [[ 0.02258524]\n",
      " [-0.10257284]\n",
      " [ 0.13395302]]\n",
      "Iteration 2942 | Cost: 0.3929695181239507 | Gradient: [[ 0.02259394]\n",
      " [-0.10254534]\n",
      " [ 0.13394612]]\n",
      "Iteration 2943 | Cost: 0.39294055230068375 | Gradient: [[ 0.02260264]\n",
      " [-0.10251785]\n",
      " [ 0.13393922]]\n",
      "Iteration 2944 | Cost: 0.39291159356906413 | Gradient: [[ 0.02261133]\n",
      " [-0.10249038]\n",
      " [ 0.13393232]]\n",
      "Iteration 2945 | Cost: 0.3928826419247706 | Gradient: [[ 0.02262002]\n",
      " [-0.10246293]\n",
      " [ 0.13392541]]\n",
      "Iteration 2946 | Cost: 0.3928536973634875 | Gradient: [[ 0.02262869]\n",
      " [-0.1024355 ]\n",
      " [ 0.13391849]]\n",
      "Iteration 2947 | Cost: 0.39282475988090476 | Gradient: [[ 0.02263736]\n",
      " [-0.10240809]\n",
      " [ 0.13391157]]\n",
      "Iteration 2948 | Cost: 0.39279582947271724 | Gradient: [[ 0.02264601]\n",
      " [-0.1023807 ]\n",
      " [ 0.13390465]]\n",
      "Iteration 2949 | Cost: 0.3927669061346256 | Gradient: [[ 0.02265466]\n",
      " [-0.10235332]\n",
      " [ 0.13389773]]\n",
      "Iteration 2950 | Cost: 0.392737989862336 | Gradient: [[ 0.0226633 ]\n",
      " [-0.10232597]\n",
      " [ 0.1338908 ]]\n",
      "Iteration 2951 | Cost: 0.39270908065155946 | Gradient: [[ 0.02267194]\n",
      " [-0.10229863]\n",
      " [ 0.13388387]]\n",
      "Iteration 2952 | Cost: 0.3926801784980129 | Gradient: [[ 0.02268056]\n",
      " [-0.10227132]\n",
      " [ 0.13387693]]\n",
      "Iteration 2953 | Cost: 0.39265128339741806 | Gradient: [[ 0.02268918]\n",
      " [-0.10224402]\n",
      " [ 0.13386999]]\n",
      "Iteration 2954 | Cost: 0.39262239534550264 | Gradient: [[ 0.02269779]\n",
      " [-0.10221674]\n",
      " [ 0.13386305]]\n",
      "Iteration 2955 | Cost: 0.3925935143379993 | Gradient: [[ 0.02270639]\n",
      " [-0.10218949]\n",
      " [ 0.1338561 ]]\n",
      "Iteration 2956 | Cost: 0.3925646403706462 | Gradient: [[ 0.02271499]\n",
      " [-0.10216225]\n",
      " [ 0.13384915]]\n",
      "Iteration 2957 | Cost: 0.3925357734391867 | Gradient: [[ 0.02272357]\n",
      " [-0.10213503]\n",
      " [ 0.13384219]]\n",
      "Iteration 2958 | Cost: 0.3925069135393694 | Gradient: [[ 0.02273215]\n",
      " [-0.10210783]\n",
      " [ 0.13383523]]\n",
      "Iteration 2959 | Cost: 0.3924780606669486 | Gradient: [[ 0.02274072]\n",
      " [-0.10208064]\n",
      " [ 0.13382827]]\n",
      "Iteration 2960 | Cost: 0.39244921481768336 | Gradient: [[ 0.02274928]\n",
      " [-0.10205348]\n",
      " [ 0.13382131]]\n",
      "Iteration 2961 | Cost: 0.3924203759873385 | Gradient: [[ 0.02275783]\n",
      " [-0.10202634]\n",
      " [ 0.13381434]]\n",
      "Iteration 2962 | Cost: 0.39239154417168387 | Gradient: [[ 0.02276638]\n",
      " [-0.10199921]\n",
      " [ 0.13380736]]\n",
      "Iteration 2963 | Cost: 0.39236271936649475 | Gradient: [[ 0.02277492]\n",
      " [-0.1019721 ]\n",
      " [ 0.13380038]]\n",
      "Iteration 2964 | Cost: 0.39233390156755127 | Gradient: [[ 0.02278345]\n",
      " [-0.10194502]\n",
      " [ 0.1337934 ]]\n",
      "Iteration 2965 | Cost: 0.3923050907706395 | Gradient: [[ 0.02279197]\n",
      " [-0.10191795]\n",
      " [ 0.13378642]]\n",
      "Iteration 2966 | Cost: 0.39227628697155026 | Gradient: [[ 0.02280048]\n",
      " [-0.1018909 ]\n",
      " [ 0.13377943]]\n",
      "Iteration 2967 | Cost: 0.3922474901660795 | Gradient: [[ 0.02280899]\n",
      " [-0.10186387]\n",
      " [ 0.13377244]]\n",
      "Iteration 2968 | Cost: 0.39221870035002904 | Gradient: [[ 0.02281749]\n",
      " [-0.10183686]\n",
      " [ 0.13376544]]\n",
      "Iteration 2969 | Cost: 0.3921899175192052 | Gradient: [[ 0.02282598]\n",
      " [-0.10180986]\n",
      " [ 0.13375844]]\n",
      "Iteration 2970 | Cost: 0.39216114166941984 | Gradient: [[ 0.02283446]\n",
      " [-0.10178289]\n",
      " [ 0.13375144]]\n",
      "Iteration 2971 | Cost: 0.39213237279649027 | Gradient: [[ 0.02284294]\n",
      " [-0.10175593]\n",
      " [ 0.13374443]]\n",
      "Iteration 2972 | Cost: 0.3921036108962383 | Gradient: [[ 0.0228514 ]\n",
      " [-0.101729  ]\n",
      " [ 0.13373742]]\n",
      "Iteration 2973 | Cost: 0.3920748559644916 | Gradient: [[ 0.02285986]\n",
      " [-0.10170208]\n",
      " [ 0.13373041]]\n",
      "Iteration 2974 | Cost: 0.39204610799708267 | Gradient: [[ 0.02286831]\n",
      " [-0.10167518]\n",
      " [ 0.13372339]]\n",
      "Iteration 2975 | Cost: 0.3920173669898493 | Gradient: [[ 0.02287675]\n",
      " [-0.1016483 ]\n",
      " [ 0.13371637]]\n",
      "Iteration 2976 | Cost: 0.39198863293863445 | Gradient: [[ 0.02288519]\n",
      " [-0.10162144]\n",
      " [ 0.13370934]]\n",
      "Iteration 2977 | Cost: 0.3919599058392861 | Gradient: [[ 0.02289362]\n",
      " [-0.10159459]\n",
      " [ 0.13370231]]\n",
      "Iteration 2978 | Cost: 0.3919311856876575 | Gradient: [[ 0.02290204]\n",
      " [-0.10156777]\n",
      " [ 0.13369528]]\n",
      "Iteration 2979 | Cost: 0.3919024724796068 | Gradient: [[ 0.02291045]\n",
      " [-0.10154096]\n",
      " [ 0.13368825]]\n",
      "Iteration 2980 | Cost: 0.39187376621099757 | Gradient: [[ 0.02291885]\n",
      " [-0.10151418]\n",
      " [ 0.13368121]]\n",
      "Iteration 2981 | Cost: 0.3918450668776985 | Gradient: [[ 0.02292725]\n",
      " [-0.10148741]\n",
      " [ 0.13367416]]\n",
      "Iteration 2982 | Cost: 0.39181637447558304 | Gradient: [[ 0.02293564]\n",
      " [-0.10146066]\n",
      " [ 0.13366712]]\n",
      "Iteration 2983 | Cost: 0.39178768900053007 | Gradient: [[ 0.02294402]\n",
      " [-0.10143393]\n",
      " [ 0.13366006]]\n",
      "Iteration 2984 | Cost: 0.3917590104484233 | Gradient: [[ 0.02295239]\n",
      " [-0.10140721]\n",
      " [ 0.13365301]]\n",
      "Iteration 2985 | Cost: 0.39173033881515185 | Gradient: [[ 0.02296075]\n",
      " [-0.10138052]\n",
      " [ 0.13364595]]\n",
      "Iteration 2986 | Cost: 0.3917016740966096 | Gradient: [[ 0.02296911]\n",
      " [-0.10135384]\n",
      " [ 0.13363889]]\n",
      "Iteration 2987 | Cost: 0.3916730162886956 | Gradient: [[ 0.02297746]\n",
      " [-0.10132719]\n",
      " [ 0.13363183]]\n",
      "Iteration 2988 | Cost: 0.3916443653873141 | Gradient: [[ 0.0229858 ]\n",
      " [-0.10130055]\n",
      " [ 0.13362476]]\n",
      "Iteration 2989 | Cost: 0.3916157213883741 | Gradient: [[ 0.02299414]\n",
      " [-0.10127393]\n",
      " [ 0.13361769]]\n",
      "Iteration 2990 | Cost: 0.39158708428778977 | Gradient: [[ 0.02300246]\n",
      " [-0.10124733]\n",
      " [ 0.13361061]]\n",
      "Iteration 2991 | Cost: 0.3915584540814804 | Gradient: [[ 0.02301078]\n",
      " [-0.10122074]\n",
      " [ 0.13360353]]\n",
      "Iteration 2992 | Cost: 0.3915298307653701 | Gradient: [[ 0.02301909]\n",
      " [-0.10119418]\n",
      " [ 0.13359645]]\n",
      "Iteration 2993 | Cost: 0.39150121433538837 | Gradient: [[ 0.02302739]\n",
      " [-0.10116763]\n",
      " [ 0.13358936]]\n",
      "Iteration 2994 | Cost: 0.3914726047874694 | Gradient: [[ 0.02303569]\n",
      " [-0.1011411 ]\n",
      " [ 0.13358227]]\n",
      "Iteration 2995 | Cost: 0.3914440021175522 | Gradient: [[ 0.02304398]\n",
      " [-0.10111459]\n",
      " [ 0.13357518]]\n",
      "Iteration 2996 | Cost: 0.3914154063215813 | Gradient: [[ 0.02305225]\n",
      " [-0.1010881 ]\n",
      " [ 0.13356808]]\n",
      "Iteration 2997 | Cost: 0.3913868173955056 | Gradient: [[ 0.02306053]\n",
      " [-0.10106163]\n",
      " [ 0.13356098]]\n",
      "Iteration 2998 | Cost: 0.39135823533527947 | Gradient: [[ 0.02306879]\n",
      " [-0.10103517]\n",
      " [ 0.13355388]]\n",
      "Iteration 2999 | Cost: 0.39132966013686193 | Gradient: [[ 0.02307705]\n",
      " [-0.10100874]\n",
      " [ 0.13354677]]\n",
      "Iteration 3000 | Cost: 0.3913010917962172 | Gradient: [[ 0.0230853 ]\n",
      " [-0.10098232]\n",
      " [ 0.13353966]]\n",
      "Iteration 3001 | Cost: 0.3912725303093142 | Gradient: [[ 0.02309354]\n",
      " [-0.10095592]\n",
      " [ 0.13353254]]\n",
      "Iteration 3002 | Cost: 0.391243975672127 | Gradient: [[ 0.02310177]\n",
      " [-0.10092954]\n",
      " [ 0.13352543]]\n",
      "Iteration 3003 | Cost: 0.39121542788063435 | Gradient: [[ 0.02311   ]\n",
      " [-0.10090317]\n",
      " [ 0.1335183 ]]\n",
      "Iteration 3004 | Cost: 0.39118688693082015 | Gradient: [[ 0.02311822]\n",
      " [-0.10087683]\n",
      " [ 0.13351118]]\n",
      "Iteration 3005 | Cost: 0.391158352818673 | Gradient: [[ 0.02312643]\n",
      " [-0.1008505 ]\n",
      " [ 0.13350405]]\n",
      "Iteration 3006 | Cost: 0.39112982554018666 | Gradient: [[ 0.02313463]\n",
      " [-0.10082419]\n",
      " [ 0.13349692]]\n",
      "Iteration 3007 | Cost: 0.3911013050913596 | Gradient: [[ 0.02314282]\n",
      " [-0.1007979 ]\n",
      " [ 0.13348978]]\n",
      "Iteration 3008 | Cost: 0.39107279146819524 | Gradient: [[ 0.02315101]\n",
      " [-0.10077163]\n",
      " [ 0.13348264]]\n",
      "Iteration 3009 | Cost: 0.39104428466670166 | Gradient: [[ 0.02315919]\n",
      " [-0.10074537]\n",
      " [ 0.1334755 ]]\n",
      "Iteration 3010 | Cost: 0.39101578468289233 | Gradient: [[ 0.02316736]\n",
      " [-0.10071914]\n",
      " [ 0.13346835]]\n",
      "Iteration 3011 | Cost: 0.39098729151278494 | Gradient: [[ 0.02317553]\n",
      " [-0.10069292]\n",
      " [ 0.13346121]]\n",
      "Iteration 3012 | Cost: 0.39095880515240256 | Gradient: [[ 0.02318369]\n",
      " [-0.10066672]\n",
      " [ 0.13345405]]\n",
      "Iteration 3013 | Cost: 0.3909303255977728 | Gradient: [[ 0.02319184]\n",
      " [-0.10064054]\n",
      " [ 0.1334469 ]]\n",
      "Iteration 3014 | Cost: 0.3909018528449283 | Gradient: [[ 0.02319998]\n",
      " [-0.10061437]\n",
      " [ 0.13343974]]\n",
      "Iteration 3015 | Cost: 0.39087338688990614 | Gradient: [[ 0.02320811]\n",
      " [-0.10058823]\n",
      " [ 0.13343257]]\n",
      "Iteration 3016 | Cost: 0.39084492772874885 | Gradient: [[ 0.02321624]\n",
      " [-0.1005621 ]\n",
      " [ 0.13342541]]\n",
      "Iteration 3017 | Cost: 0.3908164753575032 | Gradient: [[ 0.02322436]\n",
      " [-0.10053599]\n",
      " [ 0.13341824]]\n",
      "Iteration 3018 | Cost: 0.39078802977222116 | Gradient: [[ 0.02323247]\n",
      " [-0.1005099 ]\n",
      " [ 0.13341106]]\n",
      "Iteration 3019 | Cost: 0.3907595909689592 | Gradient: [[ 0.02324058]\n",
      " [-0.10048382]\n",
      " [ 0.13340388]]\n",
      "Iteration 3020 | Cost: 0.39073115894377863 | Gradient: [[ 0.02324867]\n",
      " [-0.10045777]\n",
      " [ 0.1333967 ]]\n",
      "Iteration 3021 | Cost: 0.39070273369274583 | Gradient: [[ 0.02325676]\n",
      " [-0.10043173]\n",
      " [ 0.13338952]]\n",
      "Iteration 3022 | Cost: 0.3906743152119316 | Gradient: [[ 0.02326484]\n",
      " [-0.10040571]\n",
      " [ 0.13338233]]\n",
      "Iteration 3023 | Cost: 0.39064590349741163 | Gradient: [[ 0.02327292]\n",
      " [-0.1003797 ]\n",
      " [ 0.13337514]]\n",
      "Iteration 3024 | Cost: 0.39061749854526645 | Gradient: [[ 0.02328098]\n",
      " [-0.10035372]\n",
      " [ 0.13336795]]\n",
      "Iteration 3025 | Cost: 0.39058910035158123 | Gradient: [[ 0.02328904]\n",
      " [-0.10032775]\n",
      " [ 0.13336075]]\n",
      "Iteration 3026 | Cost: 0.39056070891244593 | Gradient: [[ 0.0232971 ]\n",
      " [-0.1003018 ]\n",
      " [ 0.13335355]]\n",
      "Iteration 3027 | Cost: 0.3905323242239551 | Gradient: [[ 0.02330514]\n",
      " [-0.10027587]\n",
      " [ 0.13334634]]\n",
      "Iteration 3028 | Cost: 0.39050394628220836 | Gradient: [[ 0.02331318]\n",
      " [-0.10024996]\n",
      " [ 0.13333914]]\n",
      "Iteration 3029 | Cost: 0.39047557508330966 | Gradient: [[ 0.02332121]\n",
      " [-0.10022407]\n",
      " [ 0.13333193]]\n",
      "Iteration 3030 | Cost: 0.39044721062336785 | Gradient: [[ 0.02332923]\n",
      " [-0.10019819]\n",
      " [ 0.13332471]]\n",
      "Iteration 3031 | Cost: 0.3904188528984965 | Gradient: [[ 0.02333724]\n",
      " [-0.10017233]\n",
      " [ 0.13331749]]\n",
      "Iteration 3032 | Cost: 0.3903905019048138 | Gradient: [[ 0.02334525]\n",
      " [-0.10014649]\n",
      " [ 0.13331027]]\n",
      "Iteration 3033 | Cost: 0.3903621576384427 | Gradient: [[ 0.02335325]\n",
      " [-0.10012066]\n",
      " [ 0.13330305]]\n",
      "Iteration 3034 | Cost: 0.3903338200955106 | Gradient: [[ 0.02336124]\n",
      " [-0.10009485]\n",
      " [ 0.13329582]]\n",
      "Iteration 3035 | Cost: 0.3903054892721499 | Gradient: [[ 0.02336922]\n",
      " [-0.10006907]\n",
      " [ 0.13328859]]\n",
      "Iteration 3036 | Cost: 0.3902771651644977 | Gradient: [[ 0.0233772 ]\n",
      " [-0.10004329]\n",
      " [ 0.13328135]]\n",
      "Iteration 3037 | Cost: 0.3902488477686952 | Gradient: [[ 0.02338517]\n",
      " [-0.10001754]\n",
      " [ 0.13327411]]\n",
      "Iteration 3038 | Cost: 0.3902205370808887 | Gradient: [[ 0.02339313]\n",
      " [-0.0999918 ]\n",
      " [ 0.13326687]]\n",
      "Iteration 3039 | Cost: 0.39019223309722917 | Gradient: [[ 0.02340109]\n",
      " [-0.09996609]\n",
      " [ 0.13325963]]\n",
      "Iteration 3040 | Cost: 0.39016393581387204 | Gradient: [[ 0.02340904]\n",
      " [-0.09994039]\n",
      " [ 0.13325238]]\n",
      "Iteration 3041 | Cost: 0.39013564522697736 | Gradient: [[ 0.02341698]\n",
      " [-0.0999147 ]\n",
      " [ 0.13324513]]\n",
      "Iteration 3042 | Cost: 0.39010736133270985 | Gradient: [[ 0.02342491]\n",
      " [-0.09988904]\n",
      " [ 0.13323787]]\n",
      "Iteration 3043 | Cost: 0.39007908412723885 | Gradient: [[ 0.02343283]\n",
      " [-0.09986339]\n",
      " [ 0.13323062]]\n",
      "Iteration 3044 | Cost: 0.3900508136067384 | Gradient: [[ 0.02344075]\n",
      " [-0.09983776]\n",
      " [ 0.13322336]]\n",
      "Iteration 3045 | Cost: 0.3900225497673868 | Gradient: [[ 0.02344866]\n",
      " [-0.09981215]\n",
      " [ 0.13321609]]\n",
      "Iteration 3046 | Cost: 0.3899942926053673 | Gradient: [[ 0.02345657]\n",
      " [-0.09978655]\n",
      " [ 0.13320882]]\n",
      "Iteration 3047 | Cost: 0.3899660421168676 | Gradient: [[ 0.02346446]\n",
      " [-0.09976097]\n",
      " [ 0.13320155]]\n",
      "Iteration 3048 | Cost: 0.3899377982980797 | Gradient: [[ 0.02347235]\n",
      " [-0.09973541]\n",
      " [ 0.13319428]]\n",
      "Iteration 3049 | Cost: 0.38990956114520064 | Gradient: [[ 0.02348023]\n",
      " [-0.09970987]\n",
      " [ 0.133187  ]]\n",
      "Iteration 3050 | Cost: 0.38988133065443176 | Gradient: [[ 0.02348811]\n",
      " [-0.09968434]\n",
      " [ 0.13317972]]\n",
      "Iteration 3051 | Cost: 0.3898531068219788 | Gradient: [[ 0.02349597]\n",
      " [-0.09965883]\n",
      " [ 0.13317243]]\n",
      "Iteration 3052 | Cost: 0.3898248896440525 | Gradient: [[ 0.02350383]\n",
      " [-0.09963334]\n",
      " [ 0.13316515]]\n",
      "Iteration 3053 | Cost: 0.38979667911686755 | Gradient: [[ 0.02351168]\n",
      " [-0.09960787]\n",
      " [ 0.13315785]]\n",
      "Iteration 3054 | Cost: 0.38976847523664354 | Gradient: [[ 0.02351953]\n",
      " [-0.09958241]\n",
      " [ 0.13315056]]\n",
      "Iteration 3055 | Cost: 0.38974027799960453 | Gradient: [[ 0.02352737]\n",
      " [-0.09955698]\n",
      " [ 0.13314326]]\n",
      "Iteration 3056 | Cost: 0.38971208740197905 | Gradient: [[ 0.0235352 ]\n",
      " [-0.09953156]\n",
      " [ 0.13313596]]\n",
      "Iteration 3057 | Cost: 0.38968390344 | Gradient: [[ 0.02354302]\n",
      " [-0.09950615]\n",
      " [ 0.13312866]]\n",
      "Iteration 3058 | Cost: 0.38965572610990507 | Gradient: [[ 0.02355083]\n",
      " [-0.09948076]\n",
      " [ 0.13312135]]\n",
      "Iteration 3059 | Cost: 0.38962755540793603 | Gradient: [[ 0.02355864]\n",
      " [-0.0994554 ]\n",
      " [ 0.13311404]]\n",
      "Iteration 3060 | Cost: 0.3895993913303397 | Gradient: [[ 0.02356644]\n",
      " [-0.09943004]\n",
      " [ 0.13310673]]\n",
      "Iteration 3061 | Cost: 0.3895712338733668 | Gradient: [[ 0.02357424]\n",
      " [-0.09940471]\n",
      " [ 0.13309941]]\n",
      "Iteration 3062 | Cost: 0.38954308303327273 | Gradient: [[ 0.02358202]\n",
      " [-0.09937939]\n",
      " [ 0.13309209]]\n",
      "Iteration 3063 | Cost: 0.38951493880631743 | Gradient: [[ 0.0235898 ]\n",
      " [-0.09935409]\n",
      " [ 0.13308477]]\n",
      "Iteration 3064 | Cost: 0.3894868011887653 | Gradient: [[ 0.02359758]\n",
      " [-0.09932881]\n",
      " [ 0.13307744]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3065 | Cost: 0.3894586701768851 | Gradient: [[ 0.02360534]\n",
      " [-0.09930354]\n",
      " [ 0.13307011]]\n",
      "Iteration 3066 | Cost: 0.38943054576694985 | Gradient: [[ 0.0236131 ]\n",
      " [-0.09927829]\n",
      " [ 0.13306278]]\n",
      "Iteration 3067 | Cost: 0.3894024279552374 | Gradient: [[ 0.02362085]\n",
      " [-0.09925306]\n",
      " [ 0.13305544]]\n",
      "Iteration 3068 | Cost: 0.38937431673802964 | Gradient: [[ 0.02362859]\n",
      " [-0.09922785]\n",
      " [ 0.1330481 ]]\n",
      "Iteration 3069 | Cost: 0.38934621211161313 | Gradient: [[ 0.02363633]\n",
      " [-0.09920265]\n",
      " [ 0.13304076]]\n",
      "Iteration 3070 | Cost: 0.3893181140722786 | Gradient: [[ 0.02364406]\n",
      " [-0.09917747]\n",
      " [ 0.13303341]]\n",
      "Iteration 3071 | Cost: 0.3892900226163215 | Gradient: [[ 0.02365178]\n",
      " [-0.09915231]\n",
      " [ 0.13302606]]\n",
      "Iteration 3072 | Cost: 0.38926193774004136 | Gradient: [[ 0.02365949]\n",
      " [-0.09912716]\n",
      " [ 0.13301871]]\n",
      "Iteration 3073 | Cost: 0.3892338594397423 | Gradient: [[ 0.0236672 ]\n",
      " [-0.09910204]\n",
      " [ 0.13301136]]\n",
      "Iteration 3074 | Cost: 0.38920578771173275 | Gradient: [[ 0.0236749 ]\n",
      " [-0.09907692]\n",
      " [ 0.133004  ]]\n",
      "Iteration 3075 | Cost: 0.38917772255232536 | Gradient: [[ 0.02368259]\n",
      " [-0.09905183]\n",
      " [ 0.13299664]]\n",
      "Iteration 3076 | Cost: 0.38914966395783734 | Gradient: [[ 0.02369028]\n",
      " [-0.09902675]\n",
      " [ 0.13298927]]\n",
      "Iteration 3077 | Cost: 0.3891216119245903 | Gradient: [[ 0.02369796]\n",
      " [-0.09900169]\n",
      " [ 0.1329819 ]]\n",
      "Iteration 3078 | Cost: 0.38909356644890986 | Gradient: [[ 0.02370563]\n",
      " [-0.09897665]\n",
      " [ 0.13297453]]\n",
      "Iteration 3079 | Cost: 0.38906552752712653 | Gradient: [[ 0.02371329]\n",
      " [-0.09895162]\n",
      " [ 0.13296716]]\n",
      "Iteration 3080 | Cost: 0.38903749515557456 | Gradient: [[ 0.02372095]\n",
      " [-0.09892661]\n",
      " [ 0.13295978]]\n",
      "Iteration 3081 | Cost: 0.389009469330593 | Gradient: [[ 0.0237286 ]\n",
      " [-0.09890162]\n",
      " [ 0.1329524 ]]\n",
      "Iteration 3082 | Cost: 0.3889814500485247 | Gradient: [[ 0.02373624]\n",
      " [-0.09887664]\n",
      " [ 0.13294502]]\n",
      "Iteration 3083 | Cost: 0.38895343730571746 | Gradient: [[ 0.02374388]\n",
      " [-0.09885169]\n",
      " [ 0.13293763]]\n",
      "Iteration 3084 | Cost: 0.38892543109852307 | Gradient: [[ 0.02375151]\n",
      " [-0.09882674]\n",
      " [ 0.13293024]]\n",
      "Iteration 3085 | Cost: 0.3888974314232973 | Gradient: [[ 0.02375913]\n",
      " [-0.09880182]\n",
      " [ 0.13292285]]\n",
      "Iteration 3086 | Cost: 0.38886943827640086 | Gradient: [[ 0.02376674]\n",
      " [-0.09877691]\n",
      " [ 0.13291545]]\n",
      "Iteration 3087 | Cost: 0.38884145165419814 | Gradient: [[ 0.02377435]\n",
      " [-0.09875202]\n",
      " [ 0.13290805]]\n",
      "Iteration 3088 | Cost: 0.38881347155305834 | Gradient: [[ 0.02378195]\n",
      " [-0.09872715]\n",
      " [ 0.13290065]]\n",
      "Iteration 3089 | Cost: 0.3887854979693544 | Gradient: [[ 0.02378954]\n",
      " [-0.09870229]\n",
      " [ 0.13289324]]\n",
      "Iteration 3090 | Cost: 0.38875753089946397 | Gradient: [[ 0.02379713]\n",
      " [-0.09867745]\n",
      " [ 0.13288583]]\n",
      "Iteration 3091 | Cost: 0.38872957033976874 | Gradient: [[ 0.02380471]\n",
      " [-0.09865262]\n",
      " [ 0.13287842]]\n",
      "Iteration 3092 | Cost: 0.38870161628665456 | Gradient: [[ 0.02381228]\n",
      " [-0.09862782]\n",
      " [ 0.13287101]]\n",
      "Iteration 3093 | Cost: 0.38867366873651177 | Gradient: [[ 0.02381985]\n",
      " [-0.09860303]\n",
      " [ 0.13286359]]\n",
      "Iteration 3094 | Cost: 0.38864572768573474 | Gradient: [[ 0.0238274 ]\n",
      " [-0.09857825]\n",
      " [ 0.13285617]]\n",
      "Iteration 3095 | Cost: 0.38861779313072226 | Gradient: [[ 0.02383495]\n",
      " [-0.0985535 ]\n",
      " [ 0.13284874]]\n",
      "Iteration 3096 | Cost: 0.38858986506787696 | Gradient: [[ 0.0238425 ]\n",
      " [-0.09852876]\n",
      " [ 0.13284132]]\n",
      "Iteration 3097 | Cost: 0.38856194349360623 | Gradient: [[ 0.02385004]\n",
      " [-0.09850403]\n",
      " [ 0.13283389]]\n",
      "Iteration 3098 | Cost: 0.3885340284043214 | Gradient: [[ 0.02385757]\n",
      " [-0.09847933]\n",
      " [ 0.13282645]]\n",
      "Iteration 3099 | Cost: 0.38850611979643757 | Gradient: [[ 0.02386509]\n",
      " [-0.09845464]\n",
      " [ 0.13281902]]\n",
      "Iteration 3100 | Cost: 0.3884782176663749 | Gradient: [[ 0.0238726 ]\n",
      " [-0.09842996]\n",
      " [ 0.13281158]]\n",
      "Iteration 3101 | Cost: 0.3884503220105571 | Gradient: [[ 0.02388011]\n",
      " [-0.09840531]\n",
      " [ 0.13280413]]\n",
      "Iteration 3102 | Cost: 0.3884224328254123 | Gradient: [[ 0.02388762]\n",
      " [-0.09838067]\n",
      " [ 0.13279669]]\n",
      "Iteration 3103 | Cost: 0.38839455010737267 | Gradient: [[ 0.02389511]\n",
      " [-0.09835604]\n",
      " [ 0.13278924]]\n",
      "Iteration 3104 | Cost: 0.3883666738528746 | Gradient: [[ 0.0239026 ]\n",
      " [-0.09833144]\n",
      " [ 0.13278179]]\n",
      "Iteration 3105 | Cost: 0.38833880405835874 | Gradient: [[ 0.02391008]\n",
      " [-0.09830685]\n",
      " [ 0.13277433]]\n",
      "Iteration 3106 | Cost: 0.38831094072026967 | Gradient: [[ 0.02391755]\n",
      " [-0.09828227]\n",
      " [ 0.13276688]]\n",
      "Iteration 3107 | Cost: 0.38828308383505644 | Gradient: [[ 0.02392502]\n",
      " [-0.09825772]\n",
      " [ 0.13275942]]\n",
      "Iteration 3108 | Cost: 0.38825523339917206 | Gradient: [[ 0.02393248]\n",
      " [-0.09823318]\n",
      " [ 0.13275195]]\n",
      "Iteration 3109 | Cost: 0.3882273894090735 | Gradient: [[ 0.02393993]\n",
      " [-0.09820865]\n",
      " [ 0.13274448]]\n",
      "Iteration 3110 | Cost: 0.38819955186122207 | Gradient: [[ 0.02394738]\n",
      " [-0.09818414]\n",
      " [ 0.13273701]]\n",
      "Iteration 3111 | Cost: 0.3881717207520833 | Gradient: [[ 0.02395482]\n",
      " [-0.09815965]\n",
      " [ 0.13272954]]\n",
      "Iteration 3112 | Cost: 0.38814389607812644 | Gradient: [[ 0.02396225]\n",
      " [-0.09813518]\n",
      " [ 0.13272207]]\n",
      "Iteration 3113 | Cost: 0.3881160778358252 | Gradient: [[ 0.02396968]\n",
      " [-0.09811072]\n",
      " [ 0.13271459]]\n",
      "Iteration 3114 | Cost: 0.3880882660216573 | Gradient: [[ 0.0239771 ]\n",
      " [-0.09808628]\n",
      " [ 0.13270711]]\n",
      "Iteration 3115 | Cost: 0.38806046063210453 | Gradient: [[ 0.02398451]\n",
      " [-0.09806185]\n",
      " [ 0.13269962]]\n",
      "Iteration 3116 | Cost: 0.3880326616636527 | Gradient: [[ 0.02399191]\n",
      " [-0.09803745]\n",
      " [ 0.13269213]]\n",
      "Iteration 3117 | Cost: 0.38800486911279175 | Gradient: [[ 0.02399931]\n",
      " [-0.09801305]\n",
      " [ 0.13268464]]\n",
      "Iteration 3118 | Cost: 0.3879770829760158 | Gradient: [[ 0.0240067 ]\n",
      " [-0.09798868]\n",
      " [ 0.13267715]]\n",
      "Iteration 3119 | Cost: 0.3879493032498229 | Gradient: [[ 0.02401408]\n",
      " [-0.09796432]\n",
      " [ 0.13266965]]\n",
      "Iteration 3120 | Cost: 0.38792152993071505 | Gradient: [[ 0.02402146]\n",
      " [-0.09793998]\n",
      " [ 0.13266215]]\n",
      "Iteration 3121 | Cost: 0.3878937630151986 | Gradient: [[ 0.02402883]\n",
      " [-0.09791565]\n",
      " [ 0.13265465]]\n",
      "Iteration 3122 | Cost: 0.3878660024997837 | Gradient: [[ 0.0240362 ]\n",
      " [-0.09789134]\n",
      " [ 0.13264714]]\n",
      "Iteration 3123 | Cost: 0.3878382483809847 | Gradient: [[ 0.02404355]\n",
      " [-0.09786704]\n",
      " [ 0.13263963]]\n",
      "Iteration 3124 | Cost: 0.3878105006553199 | Gradient: [[ 0.0240509 ]\n",
      " [-0.09784277]\n",
      " [ 0.13263212]]\n",
      "Iteration 3125 | Cost: 0.38778275931931155 | Gradient: [[ 0.02405825]\n",
      " [-0.0978185 ]\n",
      " [ 0.13262461]]\n",
      "Iteration 3126 | Cost: 0.38775502436948595 | Gradient: [[ 0.02406558]\n",
      " [-0.09779426]\n",
      " [ 0.13261709]]\n",
      "Iteration 3127 | Cost: 0.38772729580237375 | Gradient: [[ 0.02407291]\n",
      " [-0.09777003]\n",
      " [ 0.13260957]]\n",
      "Iteration 3128 | Cost: 0.3876995736145091 | Gradient: [[ 0.02408023]\n",
      " [-0.09774582]\n",
      " [ 0.13260205]]\n",
      "Iteration 3129 | Cost: 0.3876718578024303 | Gradient: [[ 0.02408755]\n",
      " [-0.09772162]\n",
      " [ 0.13259452]]\n",
      "Iteration 3130 | Cost: 0.38764414836267985 | Gradient: [[ 0.02409486]\n",
      " [-0.09769744]\n",
      " [ 0.13258699]]\n",
      "Iteration 3131 | Cost: 0.38761644529180406 | Gradient: [[ 0.02410216]\n",
      " [-0.09767328]\n",
      " [ 0.13257946]]\n",
      "Iteration 3132 | Cost: 0.38758874858635317 | Gradient: [[ 0.02410945]\n",
      " [-0.09764913]\n",
      " [ 0.13257193]]\n",
      "Iteration 3133 | Cost: 0.3875610582428817 | Gradient: [[ 0.02411674]\n",
      " [-0.097625  ]\n",
      " [ 0.13256439]]\n",
      "Iteration 3134 | Cost: 0.3875333742579477 | Gradient: [[ 0.02412402]\n",
      " [-0.09760088]\n",
      " [ 0.13255685]]\n",
      "Iteration 3135 | Cost: 0.38750569662811346 | Gradient: [[ 0.0241313 ]\n",
      " [-0.09757678]\n",
      " [ 0.1325493 ]]\n",
      "Iteration 3136 | Cost: 0.38747802534994513 | Gradient: [[ 0.02413857]\n",
      " [-0.0975527 ]\n",
      " [ 0.13254176]]\n",
      "Iteration 3137 | Cost: 0.38745036042001296 | Gradient: [[ 0.02414583]\n",
      " [-0.09752863]\n",
      " [ 0.13253421]]\n",
      "Iteration 3138 | Cost: 0.38742270183489086 | Gradient: [[ 0.02415308]\n",
      " [-0.09750458]\n",
      " [ 0.13252665]]\n",
      "Iteration 3139 | Cost: 0.387395049591157 | Gradient: [[ 0.02416033]\n",
      " [-0.09748055]\n",
      " [ 0.1325191 ]]\n",
      "Iteration 3140 | Cost: 0.38736740368539313 | Gradient: [[ 0.02416757]\n",
      " [-0.09745653]\n",
      " [ 0.13251154]]\n",
      "Iteration 3141 | Cost: 0.38733976411418514 | Gradient: [[ 0.02417481]\n",
      " [-0.09743252]\n",
      " [ 0.13250398]]\n",
      "Iteration 3142 | Cost: 0.3873121308741229 | Gradient: [[ 0.02418203]\n",
      " [-0.09740854]\n",
      " [ 0.13249641]]\n",
      "Iteration 3143 | Cost: 0.38728450396180003 | Gradient: [[ 0.02418926]\n",
      " [-0.09738457]\n",
      " [ 0.13248885]]\n",
      "Iteration 3144 | Cost: 0.38725688337381414 | Gradient: [[ 0.02419647]\n",
      " [-0.09736061]\n",
      " [ 0.13248128]]\n",
      "Iteration 3145 | Cost: 0.38722926910676664 | Gradient: [[ 0.02420368]\n",
      " [-0.09733667]\n",
      " [ 0.13247371]]\n",
      "Iteration 3146 | Cost: 0.387201661157263 | Gradient: [[ 0.02421088]\n",
      " [-0.09731275]\n",
      " [ 0.13246613]]\n",
      "Iteration 3147 | Cost: 0.3871740595219123 | Gradient: [[ 0.02421807]\n",
      " [-0.09728884]\n",
      " [ 0.13245855]]\n",
      "Iteration 3148 | Cost: 0.38714646419732773 | Gradient: [[ 0.02422526]\n",
      " [-0.09726495]\n",
      " [ 0.13245097]]\n",
      "Iteration 3149 | Cost: 0.38711887518012644 | Gradient: [[ 0.02423244]\n",
      " [-0.09724108]\n",
      " [ 0.13244339]]\n",
      "Iteration 3150 | Cost: 0.3870912924669292 | Gradient: [[ 0.02423961]\n",
      " [-0.09721722]\n",
      " [ 0.1324358 ]]\n",
      "Iteration 3151 | Cost: 0.38706371605436063 | Gradient: [[ 0.02424678]\n",
      " [-0.09719337]\n",
      " [ 0.13242821]]\n",
      "Iteration 3152 | Cost: 0.3870361459390494 | Gradient: [[ 0.02425394]\n",
      " [-0.09716955]\n",
      " [ 0.13242062]]\n",
      "Iteration 3153 | Cost: 0.387008582117628 | Gradient: [[ 0.02426109]\n",
      " [-0.09714574]\n",
      " [ 0.13241302]]\n",
      "Iteration 3154 | Cost: 0.3869810245867326 | Gradient: [[ 0.02426824]\n",
      " [-0.09712194]\n",
      " [ 0.13240542]]\n",
      "Iteration 3155 | Cost: 0.3869534733430032 | Gradient: [[ 0.02427538]\n",
      " [-0.09709816]\n",
      " [ 0.13239782]]\n",
      "Iteration 3156 | Cost: 0.38692592838308393 | Gradient: [[ 0.02428252]\n",
      " [-0.0970744 ]\n",
      " [ 0.13239022]]\n",
      "Iteration 3157 | Cost: 0.38689838970362234 | Gradient: [[ 0.02428964]\n",
      " [-0.09705065]\n",
      " [ 0.13238261]]\n",
      "Iteration 3158 | Cost: 0.38687085730127024 | Gradient: [[ 0.02429676]\n",
      " [-0.09702692]\n",
      " [ 0.132375  ]]\n",
      "Iteration 3159 | Cost: 0.3868433311726827 | Gradient: [[ 0.02430388]\n",
      " [-0.0970032 ]\n",
      " [ 0.13236739]]\n",
      "Iteration 3160 | Cost: 0.38681581131451914 | Gradient: [[ 0.02431098]\n",
      " [-0.0969795 ]\n",
      " [ 0.13235978]]\n",
      "Iteration 3161 | Cost: 0.38678829772344236 | Gradient: [[ 0.02431809]\n",
      " [-0.09695581]\n",
      " [ 0.13235216]]\n",
      "Iteration 3162 | Cost: 0.38676079039611927 | Gradient: [[ 0.02432518]\n",
      " [-0.09693215]\n",
      " [ 0.13234454]]\n",
      "Iteration 3163 | Cost: 0.38673328932922024 | Gradient: [[ 0.02433227]\n",
      " [-0.09690849]\n",
      " [ 0.13233691]]\n",
      "Iteration 3164 | Cost: 0.3867057945194198 | Gradient: [[ 0.02433935]\n",
      " [-0.09688485]\n",
      " [ 0.13232929]]\n",
      "Iteration 3165 | Cost: 0.3866783059633959 | Gradient: [[ 0.02434642]\n",
      " [-0.09686123]\n",
      " [ 0.13232166]]\n",
      "Iteration 3166 | Cost: 0.3866508236578305 | Gradient: [[ 0.02435349]\n",
      " [-0.09683763]\n",
      " [ 0.13231403]]\n",
      "Iteration 3167 | Cost: 0.38662334759940903 | Gradient: [[ 0.02436055]\n",
      " [-0.09681404]\n",
      " [ 0.13230639]]\n",
      "Iteration 3168 | Cost: 0.38659587778482113 | Gradient: [[ 0.02436761]\n",
      " [-0.09679046]\n",
      " [ 0.13229875]]\n",
      "Iteration 3169 | Cost: 0.38656841421075977 | Gradient: [[ 0.02437465]\n",
      " [-0.0967669 ]\n",
      " [ 0.13229111]]\n",
      "Iteration 3170 | Cost: 0.38654095687392187 | Gradient: [[ 0.02438169]\n",
      " [-0.09674336]\n",
      " [ 0.13228347]]\n",
      "Iteration 3171 | Cost: 0.386513505771008 | Gradient: [[ 0.02438873]\n",
      " [-0.09671983]\n",
      " [ 0.13227583]]\n",
      "Iteration 3172 | Cost: 0.38648606089872256 | Gradient: [[ 0.02439576]\n",
      " [-0.09669632]\n",
      " [ 0.13226818]]\n",
      "Iteration 3173 | Cost: 0.38645862225377353 | Gradient: [[ 0.02440278]\n",
      " [-0.09667282]\n",
      " [ 0.13226053]]\n",
      "Iteration 3174 | Cost: 0.3864311898328727 | Gradient: [[ 0.02440979]\n",
      " [-0.09664934]\n",
      " [ 0.13225287]]\n",
      "Iteration 3175 | Cost: 0.3864037636327356 | Gradient: [[ 0.0244168 ]\n",
      " [-0.09662587]\n",
      " [ 0.13224521]]\n",
      "Iteration 3176 | Cost: 0.38637634365008156 | Gradient: [[ 0.0244238 ]\n",
      " [-0.09660242]\n",
      " [ 0.13223756]]\n",
      "Iteration 3177 | Cost: 0.38634892988163316 | Gradient: [[ 0.0244308 ]\n",
      " [-0.09657899]\n",
      " [ 0.13222989]]\n",
      "Iteration 3178 | Cost: 0.38632152232411726 | Gradient: [[ 0.02443779]\n",
      " [-0.09655557]\n",
      " [ 0.13222223]]\n",
      "Iteration 3179 | Cost: 0.386294120974264 | Gradient: [[ 0.02444477]\n",
      " [-0.09653217]\n",
      " [ 0.13221456]]\n",
      "Iteration 3180 | Cost: 0.38626672582880744 | Gradient: [[ 0.02445175]\n",
      " [-0.09650878]\n",
      " [ 0.13220689]]\n",
      "Iteration 3181 | Cost: 0.3862393368844852 | Gradient: [[ 0.02445872]\n",
      " [-0.09648541]\n",
      " [ 0.13219922]]\n",
      "Iteration 3182 | Cost: 0.3862119541380385 | Gradient: [[ 0.02446568]\n",
      " [-0.09646205]\n",
      " [ 0.13219154]]\n",
      "Iteration 3183 | Cost: 0.3861845775862125 | Gradient: [[ 0.02447264]\n",
      " [-0.09643871]\n",
      " [ 0.13218386]]\n",
      "Iteration 3184 | Cost: 0.3861572072257555 | Gradient: [[ 0.02447959]\n",
      " [-0.09641538]\n",
      " [ 0.13217618]]\n",
      "Iteration 3185 | Cost: 0.3861298430534202 | Gradient: [[ 0.02448653]\n",
      " [-0.09639207]\n",
      " [ 0.1321685 ]]\n",
      "Iteration 3186 | Cost: 0.3861024850659623 | Gradient: [[ 0.02449347]\n",
      " [-0.09636878]\n",
      " [ 0.13216081]]\n",
      "Iteration 3187 | Cost: 0.3860751332601415 | Gradient: [[ 0.0245004 ]\n",
      " [-0.0963455 ]\n",
      " [ 0.13215312]]\n",
      "Iteration 3188 | Cost: 0.38604778763272085 | Gradient: [[ 0.02450732]\n",
      " [-0.09632223]\n",
      " [ 0.13214543]]\n",
      "Iteration 3189 | Cost: 0.38602044818046727 | Gradient: [[ 0.02451424]\n",
      " [-0.09629898]\n",
      " [ 0.13213774]]\n",
      "Iteration 3190 | Cost: 0.3859931149001513 | Gradient: [[ 0.02452115]\n",
      " [-0.09627575]\n",
      " [ 0.13213004]]\n",
      "Iteration 3191 | Cost: 0.385965787788547 | Gradient: [[ 0.02452805]\n",
      " [-0.09625253]\n",
      " [ 0.13212234]]\n",
      "Iteration 3192 | Cost: 0.3859384668424321 | Gradient: [[ 0.02453495]\n",
      " [-0.09622933]\n",
      " [ 0.13211464]]\n",
      "Iteration 3193 | Cost: 0.3859111520585877 | Gradient: [[ 0.02454184]\n",
      " [-0.09620614]\n",
      " [ 0.13210693]]\n",
      "Iteration 3194 | Cost: 0.38588384343379895 | Gradient: [[ 0.02454873]\n",
      " [-0.09618297]\n",
      " [ 0.13209922]]\n",
      "Iteration 3195 | Cost: 0.3858565409648543 | Gradient: [[ 0.02455561]\n",
      " [-0.09615981]\n",
      " [ 0.13209151]]\n",
      "Iteration 3196 | Cost: 0.3858292446485458 | Gradient: [[ 0.02456248]\n",
      " [-0.09613667]\n",
      " [ 0.1320838 ]]\n",
      "Iteration 3197 | Cost: 0.3858019544816691 | Gradient: [[ 0.02456935]\n",
      " [-0.09611354]\n",
      " [ 0.13207608]]\n",
      "Iteration 3198 | Cost: 0.38577467046102354 | Gradient: [[ 0.02457621]\n",
      " [-0.09609043]\n",
      " [ 0.13206836]]\n",
      "Iteration 3199 | Cost: 0.38574739258341173 | Gradient: [[ 0.02458306]\n",
      " [-0.09606733]\n",
      " [ 0.13206064]]\n",
      "Iteration 3200 | Cost: 0.3857201208456404 | Gradient: [[ 0.02458991]\n",
      " [-0.09604425]\n",
      " [ 0.13205292]]\n",
      "Iteration 3201 | Cost: 0.3856928552445194 | Gradient: [[ 0.02459675]\n",
      " [-0.09602119]\n",
      " [ 0.13204519]]\n",
      "Iteration 3202 | Cost: 0.385665595776862 | Gradient: [[ 0.02460358]\n",
      " [-0.09599814]\n",
      " [ 0.13203746]]\n",
      "Iteration 3203 | Cost: 0.3856383424394856 | Gradient: [[ 0.02461041]\n",
      " [-0.0959751 ]\n",
      " [ 0.13202973]]\n",
      "Iteration 3204 | Cost: 0.38561109522921055 | Gradient: [[ 0.02461723]\n",
      " [-0.09595208]\n",
      " [ 0.132022  ]]\n",
      "Iteration 3205 | Cost: 0.3855838541428611 | Gradient: [[ 0.02462405]\n",
      " [-0.09592907]\n",
      " [ 0.13201426]]\n",
      "Iteration 3206 | Cost: 0.38555661917726497 | Gradient: [[ 0.02463086]\n",
      " [-0.09590608]\n",
      " [ 0.13200652]]\n",
      "Iteration 3207 | Cost: 0.38552939032925326 | Gradient: [[ 0.02463766]\n",
      " [-0.09588311]\n",
      " [ 0.13199878]]\n",
      "Iteration 3208 | Cost: 0.3855021675956608 | Gradient: [[ 0.02464445]\n",
      " [-0.09586015]\n",
      " [ 0.13199103]]\n",
      "Iteration 3209 | Cost: 0.38547495097332574 | Gradient: [[ 0.02465124]\n",
      " [-0.09583721]\n",
      " [ 0.13198328]]\n",
      "Iteration 3210 | Cost: 0.38544774045908986 | Gradient: [[ 0.02465803]\n",
      " [-0.09581428]\n",
      " [ 0.13197553]]\n",
      "Iteration 3211 | Cost: 0.3854205360497984 | Gradient: [[ 0.0246648 ]\n",
      " [-0.09579136]\n",
      " [ 0.13196778]]\n",
      "Iteration 3212 | Cost: 0.38539333774230033 | Gradient: [[ 0.02467157]\n",
      " [-0.09576846]\n",
      " [ 0.13196002]]\n",
      "Iteration 3213 | Cost: 0.3853661455334475 | Gradient: [[ 0.02467834]\n",
      " [-0.09574558]\n",
      " [ 0.13195227]]\n",
      "Iteration 3214 | Cost: 0.385338959420096 | Gradient: [[ 0.0246851 ]\n",
      " [-0.09572271]\n",
      " [ 0.13194451]]\n",
      "Iteration 3215 | Cost: 0.3853117793991048 | Gradient: [[ 0.02469185]\n",
      " [-0.09569985]\n",
      " [ 0.13193674]]\n",
      "Iteration 3216 | Cost: 0.3852846054673367 | Gradient: [[ 0.02469859]\n",
      " [-0.09567702]\n",
      " [ 0.13192898]]\n",
      "Iteration 3217 | Cost: 0.3852574376216579 | Gradient: [[ 0.02470533]\n",
      " [-0.09565419]\n",
      " [ 0.13192121]]\n",
      "Iteration 3218 | Cost: 0.3852302758589381 | Gradient: [[ 0.02471207]\n",
      " [-0.09563138]\n",
      " [ 0.13191344]]\n",
      "Iteration 3219 | Cost: 0.38520312017605024 | Gradient: [[ 0.02471879]\n",
      " [-0.09560859]\n",
      " [ 0.13190566]]\n",
      "Iteration 3220 | Cost: 0.38517597056987096 | Gradient: [[ 0.02472551]\n",
      " [-0.09558581]\n",
      " [ 0.13189789]]\n",
      "Iteration 3221 | Cost: 0.38514882703728015 | Gradient: [[ 0.02473223]\n",
      " [-0.09556304]\n",
      " [ 0.13189011]]\n",
      "Iteration 3222 | Cost: 0.38512168957516146 | Gradient: [[ 0.02473893]\n",
      " [-0.09554029]\n",
      " [ 0.13188233]]\n",
      "Iteration 3223 | Cost: 0.38509455818040156 | Gradient: [[ 0.02474563]\n",
      " [-0.09551756]\n",
      " [ 0.13187454]]\n",
      "Iteration 3224 | Cost: 0.3850674328498909 | Gradient: [[ 0.02475233]\n",
      " [-0.09549484]\n",
      " [ 0.13186676]]\n",
      "Iteration 3225 | Cost: 0.3850403135805232 | Gradient: [[ 0.02475902]\n",
      " [-0.09547213]\n",
      " [ 0.13185897]]\n",
      "Iteration 3226 | Cost: 0.3850132003691956 | Gradient: [[ 0.0247657 ]\n",
      " [-0.09544944]\n",
      " [ 0.13185118]]\n",
      "Iteration 3227 | Cost: 0.3849860932128087 | Gradient: [[ 0.02477238]\n",
      " [-0.09542677]\n",
      " [ 0.13184338]]\n",
      "Iteration 3228 | Cost: 0.38495899210826645 | Gradient: [[ 0.02477905]\n",
      " [-0.09540411]\n",
      " [ 0.13183559]]\n",
      "Iteration 3229 | Cost: 0.3849318970524763 | Gradient: [[ 0.02478571]\n",
      " [-0.09538146]\n",
      " [ 0.13182779]]\n",
      "Iteration 3230 | Cost: 0.3849048080423491 | Gradient: [[ 0.02479237]\n",
      " [-0.09535883]\n",
      " [ 0.13181999]]\n",
      "Iteration 3231 | Cost: 0.38487772507479895 | Gradient: [[ 0.02479902]\n",
      " [-0.09533622]\n",
      " [ 0.13181218]]\n",
      "Iteration 3232 | Cost: 0.3848506481467434 | Gradient: [[ 0.02480567]\n",
      " [-0.09531362]\n",
      " [ 0.13180438]]\n",
      "Iteration 3233 | Cost: 0.3848235772551036 | Gradient: [[ 0.02481231]\n",
      " [-0.09529103]\n",
      " [ 0.13179657]]\n",
      "Iteration 3234 | Cost: 0.3847965123968038 | Gradient: [[ 0.02481894]\n",
      " [-0.09526846]\n",
      " [ 0.13178876]]\n",
      "Iteration 3235 | Cost: 0.38476945356877174 | Gradient: [[ 0.02482556]\n",
      " [-0.0952459 ]\n",
      " [ 0.13178094]]\n",
      "Iteration 3236 | Cost: 0.3847424007679384 | Gradient: [[ 0.02483219]\n",
      " [-0.09522336]\n",
      " [ 0.13177313]]\n",
      "Iteration 3237 | Cost: 0.3847153539912384 | Gradient: [[ 0.0248388 ]\n",
      " [-0.09520083]\n",
      " [ 0.13176531]]\n",
      "Iteration 3238 | Cost: 0.38468831323560954 | Gradient: [[ 0.02484541]\n",
      " [-0.09517832]\n",
      " [ 0.13175748]]\n",
      "Iteration 3239 | Cost: 0.38466127849799286 | Gradient: [[ 0.02485201]\n",
      " [-0.09515582]\n",
      " [ 0.13174966]]\n",
      "Iteration 3240 | Cost: 0.38463424977533295 | Gradient: [[ 0.02485861]\n",
      " [-0.09513334]\n",
      " [ 0.13174183]]\n",
      "Iteration 3241 | Cost: 0.38460722706457773 | Gradient: [[ 0.02486519]\n",
      " [-0.09511087]\n",
      " [ 0.131734  ]]\n",
      "Iteration 3242 | Cost: 0.38458021036267837 | Gradient: [[ 0.02487178]\n",
      " [-0.09508842]\n",
      " [ 0.13172617]]\n",
      "Iteration 3243 | Cost: 0.3845531996665893 | Gradient: [[ 0.02487836]\n",
      " [-0.09506598]\n",
      " [ 0.13171834]]\n",
      "Iteration 3244 | Cost: 0.3845261949732685 | Gradient: [[ 0.02488493]\n",
      " [-0.09504355]\n",
      " [ 0.1317105 ]]\n",
      "Iteration 3245 | Cost: 0.384499196279677 | Gradient: [[ 0.02489149]\n",
      " [-0.09502114]\n",
      " [ 0.13170266]]\n",
      "Iteration 3246 | Cost: 0.3844722035827794 | Gradient: [[ 0.02489805]\n",
      " [-0.09499875]\n",
      " [ 0.13169482]]\n",
      "Iteration 3247 | Cost: 0.3844452168795436 | Gradient: [[ 0.0249046 ]\n",
      " [-0.09497637]\n",
      " [ 0.13168698]]\n",
      "Iteration 3248 | Cost: 0.38441823616694043 | Gradient: [[ 0.02491115]\n",
      " [-0.094954  ]\n",
      " [ 0.13167913]]\n",
      "Iteration 3249 | Cost: 0.3843912614419445 | Gradient: [[ 0.02491769]\n",
      " [-0.09493165]\n",
      " [ 0.13167128]]\n",
      "Iteration 3250 | Cost: 0.3843642927015335 | Gradient: [[ 0.02492422]\n",
      " [-0.09490931]\n",
      " [ 0.13166343]]\n",
      "Iteration 3251 | Cost: 0.3843373299426884 | Gradient: [[ 0.02493075]\n",
      " [-0.09488699]\n",
      " [ 0.13165558]]\n",
      "Iteration 3252 | Cost: 0.3843103731623933 | Gradient: [[ 0.02493727]\n",
      " [-0.09486468]\n",
      " [ 0.13164772]]\n",
      "Iteration 3253 | Cost: 0.384283422357636 | Gradient: [[ 0.02494379]\n",
      " [-0.09484239]\n",
      " [ 0.13163986]]\n",
      "Iteration 3254 | Cost: 0.38425647752540726 | Gradient: [[ 0.0249503 ]\n",
      " [-0.09482011]\n",
      " [ 0.131632  ]]\n",
      "Iteration 3255 | Cost: 0.3842295386627012 | Gradient: [[ 0.0249568 ]\n",
      " [-0.09479785]\n",
      " [ 0.13162414]]\n",
      "Iteration 3256 | Cost: 0.38420260576651516 | Gradient: [[ 0.0249633 ]\n",
      " [-0.0947756 ]\n",
      " [ 0.13161627]]\n",
      "Iteration 3257 | Cost: 0.3841756788338496 | Gradient: [[ 0.02496979]\n",
      " [-0.09475336]\n",
      " [ 0.1316084 ]]\n",
      "Iteration 3258 | Cost: 0.38414875786170866 | Gradient: [[ 0.02497628]\n",
      " [-0.09473114]\n",
      " [ 0.13160053]]\n",
      "Iteration 3259 | Cost: 0.3841218428470993 | Gradient: [[ 0.02498276]\n",
      " [-0.09470893]\n",
      " [ 0.13159266]]\n",
      "Iteration 3260 | Cost: 0.3840949337870321 | Gradient: [[ 0.02498923]\n",
      " [-0.09468674]\n",
      " [ 0.13158478]]\n",
      "Iteration 3261 | Cost: 0.38406803067852036 | Gradient: [[ 0.0249957 ]\n",
      " [-0.09466456]\n",
      " [ 0.13157691]]\n",
      "Iteration 3262 | Cost: 0.38404113351858116 | Gradient: [[ 0.02500216]\n",
      " [-0.0946424 ]\n",
      " [ 0.13156902]]\n",
      "Iteration 3263 | Cost: 0.3840142423042345 | Gradient: [[ 0.02500862]\n",
      " [-0.09462025]\n",
      " [ 0.13156114]]\n",
      "Iteration 3264 | Cost: 0.3839873570325036 | Gradient: [[ 0.02501507]\n",
      " [-0.09459812]\n",
      " [ 0.13155326]]\n",
      "Iteration 3265 | Cost: 0.383960477700415 | Gradient: [[ 0.02502151]\n",
      " [-0.094576  ]\n",
      " [ 0.13154537]]\n",
      "Iteration 3266 | Cost: 0.38393360430499857 | Gradient: [[ 0.02502795]\n",
      " [-0.09455389]\n",
      " [ 0.13153748]]\n",
      "Iteration 3267 | Cost: 0.383906736843287 | Gradient: [[ 0.02503438]\n",
      " [-0.0945318 ]\n",
      " [ 0.13152959]]\n",
      "Iteration 3268 | Cost: 0.38387987531231677 | Gradient: [[ 0.0250408 ]\n",
      " [-0.09450972]\n",
      " [ 0.13152169]]\n",
      "Iteration 3269 | Cost: 0.38385301970912683 | Gradient: [[ 0.02504722]\n",
      " [-0.09448766]\n",
      " [ 0.13151379]]\n",
      "Iteration 3270 | Cost: 0.38382617003075997 | Gradient: [[ 0.02505363]\n",
      " [-0.09446561]\n",
      " [ 0.13150589]]\n",
      "Iteration 3271 | Cost: 0.38379932627426183 | Gradient: [[ 0.02506004]\n",
      " [-0.09444358]\n",
      " [ 0.13149799]]\n",
      "Iteration 3272 | Cost: 0.3837724884366812 | Gradient: [[ 0.02506644]\n",
      " [-0.09442156]\n",
      " [ 0.13149009]]\n",
      "Iteration 3273 | Cost: 0.38374565651507037 | Gradient: [[ 0.02507284]\n",
      " [-0.09439955]\n",
      " [ 0.13148218]]\n",
      "Iteration 3274 | Cost: 0.3837188305064845 | Gradient: [[ 0.02507923]\n",
      " [-0.09437756]\n",
      " [ 0.13147427]]\n",
      "Iteration 3275 | Cost: 0.3836920104079819 | Gradient: [[ 0.02508561]\n",
      " [-0.09435558]\n",
      " [ 0.13146636]]\n",
      "Iteration 3276 | Cost: 0.38366519621662437 | Gradient: [[ 0.02509199]\n",
      " [-0.09433362]\n",
      " [ 0.13145845]]\n",
      "Iteration 3277 | Cost: 0.3836383879294766 | Gradient: [[ 0.02509836]\n",
      " [-0.09431167]\n",
      " [ 0.13145053]]\n",
      "Iteration 3278 | Cost: 0.38361158554360636 | Gradient: [[ 0.02510472]\n",
      " [-0.09428974]\n",
      " [ 0.13144261]]\n",
      "Iteration 3279 | Cost: 0.3835847890560847 | Gradient: [[ 0.02511108]\n",
      " [-0.09426782]\n",
      " [ 0.13143469]]\n",
      "Iteration 3280 | Cost: 0.38355799846398597 | Gradient: [[ 0.02511744]\n",
      " [-0.09424591]\n",
      " [ 0.13142677]]\n",
      "Iteration 3281 | Cost: 0.38353121376438737 | Gradient: [[ 0.02512378]\n",
      " [-0.09422402]\n",
      " [ 0.13141884]]\n",
      "Iteration 3282 | Cost: 0.38350443495436937 | Gradient: [[ 0.02513012]\n",
      " [-0.09420214]\n",
      " [ 0.13141091]]\n",
      "Iteration 3283 | Cost: 0.3834776620310156 | Gradient: [[ 0.02513646]\n",
      " [-0.09418028]\n",
      " [ 0.13140298]]\n",
      "Iteration 3284 | Cost: 0.38345089499141277 | Gradient: [[ 0.02514279]\n",
      " [-0.09415843]\n",
      " [ 0.13139505]]\n",
      "Iteration 3285 | Cost: 0.3834241338326508 | Gradient: [[ 0.02514911]\n",
      " [-0.09413659]\n",
      " [ 0.13138711]]\n",
      "Iteration 3286 | Cost: 0.3833973785518225 | Gradient: [[ 0.02515543]\n",
      " [-0.09411477]\n",
      " [ 0.13137918]]\n",
      "Iteration 3287 | Cost: 0.38337062914602393 | Gradient: [[ 0.02516174]\n",
      " [-0.09409296]\n",
      " [ 0.13137124]]\n",
      "Iteration 3288 | Cost: 0.3833438856123544 | Gradient: [[ 0.02516805]\n",
      " [-0.09407117]\n",
      " [ 0.1313633 ]]\n",
      "Iteration 3289 | Cost: 0.38331714794791594 | Gradient: [[ 0.02517435]\n",
      " [-0.09404939]\n",
      " [ 0.13135535]]\n",
      "Iteration 3290 | Cost: 0.3832904161498142 | Gradient: [[ 0.02518064]\n",
      " [-0.09402763]\n",
      " [ 0.1313474 ]]\n",
      "Iteration 3291 | Cost: 0.3832636902151574 | Gradient: [[ 0.02518693]\n",
      " [-0.09400588]\n",
      " [ 0.13133946]]\n",
      "Iteration 3292 | Cost: 0.38323697014105723 | Gradient: [[ 0.02519321]\n",
      " [-0.09398414]\n",
      " [ 0.1313315 ]]\n",
      "Iteration 3293 | Cost: 0.3832102559246282 | Gradient: [[ 0.02519949]\n",
      " [-0.09396242]\n",
      " [ 0.13132355]]\n",
      "Iteration 3294 | Cost: 0.383183547562988 | Gradient: [[ 0.02520576]\n",
      " [-0.09394071]\n",
      " [ 0.1313156 ]]\n",
      "Iteration 3295 | Cost: 0.38315684505325753 | Gradient: [[ 0.02521202]\n",
      " [-0.09391901]\n",
      " [ 0.13130764]]\n",
      "Iteration 3296 | Cost: 0.3831301483925605 | Gradient: [[ 0.02521828]\n",
      " [-0.09389733]\n",
      " [ 0.13129968]]\n",
      "Iteration 3297 | Cost: 0.38310345757802383 | Gradient: [[ 0.02522453]\n",
      " [-0.09387566]\n",
      " [ 0.13129171]]\n",
      "Iteration 3298 | Cost: 0.3830767726067774 | Gradient: [[ 0.02523078]\n",
      " [-0.09385401]\n",
      " [ 0.13128375]]\n",
      "Iteration 3299 | Cost: 0.3830500934759543 | Gradient: [[ 0.02523702]\n",
      " [-0.09383237]\n",
      " [ 0.13127578]]\n",
      "Iteration 3300 | Cost: 0.3830234201826906 | Gradient: [[ 0.02524326]\n",
      " [-0.09381075]\n",
      " [ 0.13126781]]\n",
      "Iteration 3301 | Cost: 0.38299675272412537 | Gradient: [[ 0.02524949]\n",
      " [-0.09378914]\n",
      " [ 0.13125984]]\n",
      "Iteration 3302 | Cost: 0.38297009109740066 | Gradient: [[ 0.02525571]\n",
      " [-0.09376754]\n",
      " [ 0.13125187]]\n",
      "Iteration 3303 | Cost: 0.3829434352996618 | Gradient: [[ 0.02526193]\n",
      " [-0.09374596]\n",
      " [ 0.13124389]]\n",
      "Iteration 3304 | Cost: 0.38291678532805684 | Gradient: [[ 0.02526814]\n",
      " [-0.09372439]\n",
      " [ 0.13123591]]\n",
      "Iteration 3305 | Cost: 0.382890141179737 | Gradient: [[ 0.02527435]\n",
      " [-0.09370283]\n",
      " [ 0.13122793]]\n",
      "Iteration 3306 | Cost: 0.3828635028518566 | Gradient: [[ 0.02528055]\n",
      " [-0.09368129]\n",
      " [ 0.13121995]]\n",
      "Iteration 3307 | Cost: 0.3828368703415729 | Gradient: [[ 0.02528674]\n",
      " [-0.09365976]\n",
      " [ 0.13121196]]\n",
      "Iteration 3308 | Cost: 0.382810243646046 | Gradient: [[ 0.02529293]\n",
      " [-0.09363825]\n",
      " [ 0.13120397]]\n",
      "Iteration 3309 | Cost: 0.3827836227624393 | Gradient: [[ 0.02529911]\n",
      " [-0.09361675]\n",
      " [ 0.13119598]]\n",
      "Iteration 3310 | Cost: 0.3827570076879191 | Gradient: [[ 0.02530529]\n",
      " [-0.09359526]\n",
      " [ 0.13118799]]\n",
      "Iteration 3311 | Cost: 0.3827303984196544 | Gradient: [[ 0.02531146]\n",
      " [-0.09357379]\n",
      " [ 0.13118   ]]\n",
      "Iteration 3312 | Cost: 0.3827037949548179 | Gradient: [[ 0.02531763]\n",
      " [-0.09355233]\n",
      " [ 0.131172  ]]\n",
      "Iteration 3313 | Cost: 0.38267719729058447 | Gradient: [[ 0.02532379]\n",
      " [-0.09353088]\n",
      " [ 0.131164  ]]\n",
      "Iteration 3314 | Cost: 0.3826506054241323 | Gradient: [[ 0.02532994]\n",
      " [-0.09350945]\n",
      " [ 0.131156  ]]\n",
      "Iteration 3315 | Cost: 0.38262401935264306 | Gradient: [[ 0.02533609]\n",
      " [-0.09348803]\n",
      " [ 0.131148  ]]\n",
      "Iteration 3316 | Cost: 0.3825974390733005 | Gradient: [[ 0.02534223]\n",
      " [-0.09346663]\n",
      " [ 0.13113999]]\n",
      "Iteration 3317 | Cost: 0.38257086458329176 | Gradient: [[ 0.02534837]\n",
      " [-0.09344524]\n",
      " [ 0.13113198]]\n",
      "Iteration 3318 | Cost: 0.38254429587980715 | Gradient: [[ 0.0253545 ]\n",
      " [-0.09342386]\n",
      " [ 0.13112397]]\n",
      "Iteration 3319 | Cost: 0.38251773296003955 | Gradient: [[ 0.02536062]\n",
      " [-0.0934025 ]\n",
      " [ 0.13111596]]\n",
      "Iteration 3320 | Cost: 0.38249117582118514 | Gradient: [[ 0.02536674]\n",
      " [-0.09338115]\n",
      " [ 0.13110795]]\n",
      "Iteration 3321 | Cost: 0.3824646244604428 | Gradient: [[ 0.02537286]\n",
      " [-0.09335981]\n",
      " [ 0.13109993]]\n",
      "Iteration 3322 | Cost: 0.3824380788750145 | Gradient: [[ 0.02537896]\n",
      " [-0.09333849]\n",
      " [ 0.13109191]]\n",
      "Iteration 3323 | Cost: 0.382411539062105 | Gradient: [[ 0.02538506]\n",
      " [-0.09331719]\n",
      " [ 0.13108389]]\n",
      "Iteration 3324 | Cost: 0.38238500501892225 | Gradient: [[ 0.02539116]\n",
      " [-0.09329589]\n",
      " [ 0.13107587]]\n",
      "Iteration 3325 | Cost: 0.38235847674267676 | Gradient: [[ 0.02539725]\n",
      " [-0.09327461]\n",
      " [ 0.13106784]]\n",
      "Iteration 3326 | Cost: 0.3823319542305823 | Gradient: [[ 0.02540334]\n",
      " [-0.09325334]\n",
      " [ 0.13105982]]\n",
      "Iteration 3327 | Cost: 0.3823054374798555 | Gradient: [[ 0.02540942]\n",
      " [-0.09323209]\n",
      " [ 0.13105179]]\n",
      "Iteration 3328 | Cost: 0.3822789264877157 | Gradient: [[ 0.02541549]\n",
      " [-0.09321085]\n",
      " [ 0.13104375]]\n",
      "Iteration 3329 | Cost: 0.38225242125138553 | Gradient: [[ 0.02542156]\n",
      " [-0.09318962]\n",
      " [ 0.13103572]]\n",
      "Iteration 3330 | Cost: 0.38222592176809006 | Gradient: [[ 0.02542762]\n",
      " [-0.09316841]\n",
      " [ 0.13102768]]\n",
      "Iteration 3331 | Cost: 0.38219942803505774 | Gradient: [[ 0.02543367]\n",
      " [-0.09314721]\n",
      " [ 0.13101965]]\n",
      "Iteration 3332 | Cost: 0.38217294004951946 | Gradient: [[ 0.02543973]\n",
      " [-0.09312602]\n",
      " [ 0.1310116 ]]\n",
      "Iteration 3333 | Cost: 0.3821464578087094 | Gradient: [[ 0.02544577]\n",
      " [-0.09310485]\n",
      " [ 0.13100356]]\n",
      "Iteration 3334 | Cost: 0.38211998130986446 | Gradient: [[ 0.02545181]\n",
      " [-0.09308369]\n",
      " [ 0.13099552]]\n",
      "Iteration 3335 | Cost: 0.38209351055022434 | Gradient: [[ 0.02545784]\n",
      " [-0.09306255]\n",
      " [ 0.13098747]]\n",
      "Iteration 3336 | Cost: 0.38206704552703186 | Gradient: [[ 0.02546387]\n",
      " [-0.09304142]\n",
      " [ 0.13097942]]\n",
      "Iteration 3337 | Cost: 0.38204058623753245 | Gradient: [[ 0.02546989]\n",
      " [-0.0930203 ]\n",
      " [ 0.13097137]]\n",
      "Iteration 3338 | Cost: 0.3820141326789746 | Gradient: [[ 0.02547591]\n",
      " [-0.09299919]\n",
      " [ 0.13096332]]\n",
      "Iteration 3339 | Cost: 0.38198768484860957 | Gradient: [[ 0.02548192]\n",
      " [-0.0929781 ]\n",
      " [ 0.13095526]]\n",
      "Iteration 3340 | Cost: 0.3819612427436916 | Gradient: [[ 0.02548793]\n",
      " [-0.09295702]\n",
      " [ 0.1309472 ]]\n",
      "Iteration 3341 | Cost: 0.38193480636147764 | Gradient: [[ 0.02549393]\n",
      " [-0.09293596]\n",
      " [ 0.13093914]]\n",
      "Iteration 3342 | Cost: 0.3819083756992276 | Gradient: [[ 0.02549992]\n",
      " [-0.09291491]\n",
      " [ 0.13093108]]\n",
      "Iteration 3343 | Cost: 0.3818819507542043 | Gradient: [[ 0.02550591]\n",
      " [-0.09289387]\n",
      " [ 0.13092302]]\n",
      "Iteration 3344 | Cost: 0.38185553152367324 | Gradient: [[ 0.02551189]\n",
      " [-0.09287285]\n",
      " [ 0.13091495]]\n",
      "Iteration 3345 | Cost: 0.3818291180049027 | Gradient: [[ 0.02551787]\n",
      " [-0.09285184]\n",
      " [ 0.13090688]]\n",
      "Iteration 3346 | Cost: 0.3818027101951643 | Gradient: [[ 0.02552384]\n",
      " [-0.09283084]\n",
      " [ 0.13089881]]\n",
      "Iteration 3347 | Cost: 0.3817763080917318 | Gradient: [[ 0.02552981]\n",
      " [-0.09280986]\n",
      " [ 0.13089074]]\n",
      "Iteration 3348 | Cost: 0.38174991169188227 | Gradient: [[ 0.02553577]\n",
      " [-0.09278888]\n",
      " [ 0.13088266]]\n",
      "Iteration 3349 | Cost: 0.38172352099289547 | Gradient: [[ 0.02554172]\n",
      " [-0.09276793]\n",
      " [ 0.13087459]]\n",
      "Iteration 3350 | Cost: 0.38169713599205396 | Gradient: [[ 0.02554767]\n",
      " [-0.09274698]\n",
      " [ 0.13086651]]\n",
      "Iteration 3351 | Cost: 0.38167075668664324 | Gradient: [[ 0.02555361]\n",
      " [-0.09272605]\n",
      " [ 0.13085843]]\n",
      "Iteration 3352 | Cost: 0.3816443830739513 | Gradient: [[ 0.02555955]\n",
      " [-0.09270514]\n",
      " [ 0.13085034]]\n",
      "Iteration 3353 | Cost: 0.38161801515126936 | Gradient: [[ 0.02556548]\n",
      " [-0.09268423]\n",
      " [ 0.13084226]]\n",
      "Iteration 3354 | Cost: 0.38159165291589114 | Gradient: [[ 0.02557141]\n",
      " [-0.09266334]\n",
      " [ 0.13083417]]\n",
      "Iteration 3355 | Cost: 0.3815652963651133 | Gradient: [[ 0.02557733]\n",
      " [-0.09264246]\n",
      " [ 0.13082608]]\n",
      "Iteration 3356 | Cost: 0.38153894549623524 | Gradient: [[ 0.02558325]\n",
      " [-0.0926216 ]\n",
      " [ 0.13081799]]\n",
      "Iteration 3357 | Cost: 0.381512600306559 | Gradient: [[ 0.02558916]\n",
      " [-0.09260075]\n",
      " [ 0.13080989]]\n",
      "Iteration 3358 | Cost: 0.3814862607933899 | Gradient: [[ 0.02559506]\n",
      " [-0.09257991]\n",
      " [ 0.1308018 ]]\n",
      "Iteration 3359 | Cost: 0.3814599269540354 | Gradient: [[ 0.02560096]\n",
      " [-0.09255909]\n",
      " [ 0.1307937 ]]\n",
      "Iteration 3360 | Cost: 0.38143359878580635 | Gradient: [[ 0.02560685]\n",
      " [-0.09253828]\n",
      " [ 0.1307856 ]]\n",
      "Iteration 3361 | Cost: 0.3814072762860159 | Gradient: [[ 0.02561274]\n",
      " [-0.09251748]\n",
      " [ 0.1307775 ]]\n",
      "Iteration 3362 | Cost: 0.38138095945198014 | Gradient: [[ 0.02561862]\n",
      " [-0.09249669]\n",
      " [ 0.13076939]]\n",
      "Iteration 3363 | Cost: 0.38135464828101806 | Gradient: [[ 0.0256245 ]\n",
      " [-0.09247592]\n",
      " [ 0.13076129]]\n",
      "Iteration 3364 | Cost: 0.38132834277045113 | Gradient: [[ 0.02563037]\n",
      " [-0.09245516]\n",
      " [ 0.13075318]]\n",
      "Iteration 3365 | Cost: 0.3813020429176038 | Gradient: [[ 0.02563623]\n",
      " [-0.09243442]\n",
      " [ 0.13074507]]\n",
      "Iteration 3366 | Cost: 0.38127574871980335 | Gradient: [[ 0.0256421 ]\n",
      " [-0.09241369]\n",
      " [ 0.13073696]]\n",
      "Iteration 3367 | Cost: 0.38124946017437944 | Gradient: [[ 0.02564795]\n",
      " [-0.09239297]\n",
      " [ 0.13072884]]\n",
      "Iteration 3368 | Cost: 0.3812231772786649 | Gradient: [[ 0.0256538 ]\n",
      " [-0.09237226]\n",
      " [ 0.13072073]]\n",
      "Iteration 3369 | Cost: 0.38119690002999496 | Gradient: [[ 0.02565964]\n",
      " [-0.09235157]\n",
      " [ 0.13071261]]\n",
      "Iteration 3370 | Cost: 0.38117062842570776 | Gradient: [[ 0.02566548]\n",
      " [-0.09233089]\n",
      " [ 0.13070449]]\n",
      "Iteration 3371 | Cost: 0.3811443624631442 | Gradient: [[ 0.02567131]\n",
      " [-0.09231022]\n",
      " [ 0.13069636]]\n",
      "Iteration 3372 | Cost: 0.38111810213964786 | Gradient: [[ 0.02567714]\n",
      " [-0.09228957]\n",
      " [ 0.13068824]]\n",
      "Iteration 3373 | Cost: 0.381091847452565 | Gradient: [[ 0.02568296]\n",
      " [-0.09226893]\n",
      " [ 0.13068011]]\n",
      "Iteration 3374 | Cost: 0.3810655983992446 | Gradient: [[ 0.02568878]\n",
      " [-0.0922483 ]\n",
      " [ 0.13067198]]\n",
      "Iteration 3375 | Cost: 0.38103935497703845 | Gradient: [[ 0.02569459]\n",
      " [-0.09222769]\n",
      " [ 0.13066385]]\n",
      "Iteration 3376 | Cost: 0.381013117183301 | Gradient: [[ 0.02570039]\n",
      " [-0.09220708]\n",
      " [ 0.13065572]]\n",
      "Iteration 3377 | Cost: 0.38098688501538935 | Gradient: [[ 0.02570619]\n",
      " [-0.0921865 ]\n",
      " [ 0.13064759]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3378 | Cost: 0.38096065847066346 | Gradient: [[ 0.02571199]\n",
      " [-0.09216592]\n",
      " [ 0.13063945]]\n",
      "Iteration 3379 | Cost: 0.3809344375464858 | Gradient: [[ 0.02571777]\n",
      " [-0.09214536]\n",
      " [ 0.13063131]]\n",
      "Iteration 3380 | Cost: 0.3809082222402216 | Gradient: [[ 0.02572356]\n",
      " [-0.09212481]\n",
      " [ 0.13062317]]\n",
      "Iteration 3381 | Cost: 0.3808820125492388 | Gradient: [[ 0.02572934]\n",
      " [-0.09210427]\n",
      " [ 0.13061503]]\n",
      "Iteration 3382 | Cost: 0.3808558084709081 | Gradient: [[ 0.02573511]\n",
      " [-0.09208375]\n",
      " [ 0.13060688]]\n",
      "Iteration 3383 | Cost: 0.38082961000260285 | Gradient: [[ 0.02574087]\n",
      " [-0.09206324]\n",
      " [ 0.13059873]]\n",
      "Iteration 3384 | Cost: 0.3808034171416989 | Gradient: [[ 0.02574664]\n",
      " [-0.09204274]\n",
      " [ 0.13059059]]\n",
      "Iteration 3385 | Cost: 0.38077722988557505 | Gradient: [[ 0.02575239]\n",
      " [-0.09202226]\n",
      " [ 0.13058244]]\n",
      "Iteration 3386 | Cost: 0.3807510482316126 | Gradient: [[ 0.02575814]\n",
      " [-0.09200179]\n",
      " [ 0.13057428]]\n",
      "Iteration 3387 | Cost: 0.3807248721771954 | Gradient: [[ 0.02576389]\n",
      " [-0.09198133]\n",
      " [ 0.13056613]]\n",
      "Iteration 3388 | Cost: 0.3806987017197104 | Gradient: [[ 0.02576963]\n",
      " [-0.09196088]\n",
      " [ 0.13055797]]\n",
      "Iteration 3389 | Cost: 0.3806725368565467 | Gradient: [[ 0.02577536]\n",
      " [-0.09194045]\n",
      " [ 0.13054981]]\n",
      "Iteration 3390 | Cost: 0.38064637758509634 | Gradient: [[ 0.02578109]\n",
      " [-0.09192003]\n",
      " [ 0.13054165]]\n",
      "Iteration 3391 | Cost: 0.38062022390275413 | Gradient: [[ 0.02578681]\n",
      " [-0.09189962]\n",
      " [ 0.13053349]]\n",
      "Iteration 3392 | Cost: 0.38059407580691695 | Gradient: [[ 0.02579253]\n",
      " [-0.09187923]\n",
      " [ 0.13052532]]\n",
      "Iteration 3393 | Cost: 0.38056793329498523 | Gradient: [[ 0.02579824]\n",
      " [-0.09185885]\n",
      " [ 0.13051716]]\n",
      "Iteration 3394 | Cost: 0.3805417963643612 | Gradient: [[ 0.02580395]\n",
      " [-0.09183848]\n",
      " [ 0.13050899]]\n",
      "Iteration 3395 | Cost: 0.38051566501245004 | Gradient: [[ 0.02580965]\n",
      " [-0.09181812]\n",
      " [ 0.13050082]]\n",
      "Iteration 3396 | Cost: 0.3804895392366597 | Gradient: [[ 0.02581535]\n",
      " [-0.09179778]\n",
      " [ 0.13049264]]\n",
      "Iteration 3397 | Cost: 0.3804634190344007 | Gradient: [[ 0.02582104]\n",
      " [-0.09177745]\n",
      " [ 0.13048447]]\n",
      "Iteration 3398 | Cost: 0.3804373044030858 | Gradient: [[ 0.02582673]\n",
      " [-0.09175713]\n",
      " [ 0.13047629]]\n",
      "Iteration 3399 | Cost: 0.3804111953401311 | Gradient: [[ 0.02583241]\n",
      " [-0.09173683]\n",
      " [ 0.13046811]]\n",
      "Iteration 3400 | Cost: 0.3803850918429547 | Gradient: [[ 0.02583808]\n",
      " [-0.09171654]\n",
      " [ 0.13045993]]\n",
      "Iteration 3401 | Cost: 0.3803589939089776 | Gradient: [[ 0.02584375]\n",
      " [-0.09169626]\n",
      " [ 0.13045175]]\n",
      "Iteration 3402 | Cost: 0.3803329015356232 | Gradient: [[ 0.02584942]\n",
      " [-0.09167599]\n",
      " [ 0.13044357]]\n",
      "Iteration 3403 | Cost: 0.3803068147203178 | Gradient: [[ 0.02585507]\n",
      " [-0.09165574]\n",
      " [ 0.13043538]]\n",
      "Iteration 3404 | Cost: 0.38028073346048996 | Gradient: [[ 0.02586073]\n",
      " [-0.0916355 ]\n",
      " [ 0.13042719]]\n",
      "Iteration 3405 | Cost: 0.38025465775357115 | Gradient: [[ 0.02586638]\n",
      " [-0.09161527]\n",
      " [ 0.130419  ]]\n",
      "Iteration 3406 | Cost: 0.38022858759699524 | Gradient: [[ 0.02587202]\n",
      " [-0.09159506]\n",
      " [ 0.13041081]]\n",
      "Iteration 3407 | Cost: 0.3802025229881987 | Gradient: [[ 0.02587766]\n",
      " [-0.09157485]\n",
      " [ 0.13040262]]\n",
      "Iteration 3408 | Cost: 0.3801764639246207 | Gradient: [[ 0.02588329]\n",
      " [-0.09155466]\n",
      " [ 0.13039442]]\n",
      "Iteration 3409 | Cost: 0.38015041040370284 | Gradient: [[ 0.02588892]\n",
      " [-0.09153449]\n",
      " [ 0.13038622]]\n",
      "Iteration 3410 | Cost: 0.3801243624228894 | Gradient: [[ 0.02589454]\n",
      " [-0.09151432]\n",
      " [ 0.13037802]]\n",
      "Iteration 3411 | Cost: 0.38009831997962723 | Gradient: [[ 0.02590015]\n",
      " [-0.09149417]\n",
      " [ 0.13036982]]\n",
      "Iteration 3412 | Cost: 0.38007228307136565 | Gradient: [[ 0.02590576]\n",
      " [-0.09147403]\n",
      " [ 0.13036162]]\n",
      "Iteration 3413 | Cost: 0.3800462516955566 | Gradient: [[ 0.02591137]\n",
      " [-0.09145391]\n",
      " [ 0.13035341]]\n",
      "Iteration 3414 | Cost: 0.38002022584965467 | Gradient: [[ 0.02591697]\n",
      " [-0.09143379]\n",
      " [ 0.13034521]]\n",
      "Iteration 3415 | Cost: 0.37999420553111696 | Gradient: [[ 0.02592257]\n",
      " [-0.09141369]\n",
      " [ 0.130337  ]]\n",
      "Iteration 3416 | Cost: 0.3799681907374029 | Gradient: [[ 0.02592816]\n",
      " [-0.0913936 ]\n",
      " [ 0.13032878]]\n",
      "Iteration 3417 | Cost: 0.3799421814659749 | Gradient: [[ 0.02593374]\n",
      " [-0.09137352]\n",
      " [ 0.13032057]]\n",
      "Iteration 3418 | Cost: 0.37991617771429753 | Gradient: [[ 0.02593932]\n",
      " [-0.09135346]\n",
      " [ 0.13031236]]\n",
      "Iteration 3419 | Cost: 0.37989017947983805 | Gradient: [[ 0.02594489]\n",
      " [-0.09133341]\n",
      " [ 0.13030414]]\n",
      "Iteration 3420 | Cost: 0.37986418676006634 | Gradient: [[ 0.02595046]\n",
      " [-0.09131337]\n",
      " [ 0.13029592]]\n",
      "Iteration 3421 | Cost: 0.3798381995524547 | Gradient: [[ 0.02595602]\n",
      " [-0.09129335]\n",
      " [ 0.1302877 ]]\n",
      "Iteration 3422 | Cost: 0.3798122178544779 | Gradient: [[ 0.02596158]\n",
      " [-0.09127333]\n",
      " [ 0.13027948]]\n",
      "Iteration 3423 | Cost: 0.3797862416636134 | Gradient: [[ 0.02596714]\n",
      " [-0.09125333]\n",
      " [ 0.13027125]]\n",
      "Iteration 3424 | Cost: 0.3797602709773411 | Gradient: [[ 0.02597268]\n",
      " [-0.09123334]\n",
      " [ 0.13026303]]\n",
      "Iteration 3425 | Cost: 0.3797343057931434 | Gradient: [[ 0.02597823]\n",
      " [-0.09121337]\n",
      " [ 0.1302548 ]]\n",
      "Iteration 3426 | Cost: 0.37970834610850535 | Gradient: [[ 0.02598376]\n",
      " [-0.0911934 ]\n",
      " [ 0.13024657]]\n",
      "Iteration 3427 | Cost: 0.37968239192091424 | Gradient: [[ 0.02598929]\n",
      " [-0.09117345]\n",
      " [ 0.13023834]]\n",
      "Iteration 3428 | Cost: 0.37965644322786013 | Gradient: [[ 0.02599482]\n",
      " [-0.09115352]\n",
      " [ 0.1302301 ]]\n",
      "Iteration 3429 | Cost: 0.37963050002683546 | Gradient: [[ 0.02600034]\n",
      " [-0.09113359]\n",
      " [ 0.13022187]]\n",
      "Iteration 3430 | Cost: 0.37960456231533524 | Gradient: [[ 0.02600586]\n",
      " [-0.09111368]\n",
      " [ 0.13021363]]\n",
      "Iteration 3431 | Cost: 0.37957863009085685 | Gradient: [[ 0.02601137]\n",
      " [-0.09109377]\n",
      " [ 0.13020539]]\n",
      "Iteration 3432 | Cost: 0.37955270335090024 | Gradient: [[ 0.02601687]\n",
      " [-0.09107389]\n",
      " [ 0.13019715]]\n",
      "Iteration 3433 | Cost: 0.3795267820929679 | Gradient: [[ 0.02602238]\n",
      " [-0.09105401]\n",
      " [ 0.13018891]]\n",
      "Iteration 3434 | Cost: 0.37950086631456476 | Gradient: [[ 0.02602787]\n",
      " [-0.09103415]\n",
      " [ 0.13018066]]\n",
      "Iteration 3435 | Cost: 0.37947495601319814 | Gradient: [[ 0.02603336]\n",
      " [-0.09101429]\n",
      " [ 0.13017241]]\n",
      "Iteration 3436 | Cost: 0.379449051186378 | Gradient: [[ 0.02603885]\n",
      " [-0.09099446]\n",
      " [ 0.13016417]]\n",
      "Iteration 3437 | Cost: 0.37942315183161673 | Gradient: [[ 0.02604432]\n",
      " [-0.09097463]\n",
      " [ 0.13015592]]\n",
      "Iteration 3438 | Cost: 0.3793972579464292 | Gradient: [[ 0.0260498 ]\n",
      " [-0.09095481]\n",
      " [ 0.13014766]]\n",
      "Iteration 3439 | Cost: 0.3793713695283325 | Gradient: [[ 0.02605527]\n",
      " [-0.09093501]\n",
      " [ 0.13013941]]\n",
      "Iteration 3440 | Cost: 0.3793454865748465 | Gradient: [[ 0.02606073]\n",
      " [-0.09091522]\n",
      " [ 0.13013115]]\n",
      "Iteration 3441 | Cost: 0.37931960908349344 | Gradient: [[ 0.02606619]\n",
      " [-0.09089545]\n",
      " [ 0.1301229 ]]\n",
      "Iteration 3442 | Cost: 0.3792937370517979 | Gradient: [[ 0.02607165]\n",
      " [-0.09087568]\n",
      " [ 0.13011464]]\n",
      "Iteration 3443 | Cost: 0.37926787047728716 | Gradient: [[ 0.02607709]\n",
      " [-0.09085593]\n",
      " [ 0.13010637]]\n",
      "Iteration 3444 | Cost: 0.3792420093574907 | Gradient: [[ 0.02608254]\n",
      " [-0.09083619]\n",
      " [ 0.13009811]]\n",
      "Iteration 3445 | Cost: 0.3792161536899405 | Gradient: [[ 0.02608798]\n",
      " [-0.09081646]\n",
      " [ 0.13008985]]\n",
      "Iteration 3446 | Cost: 0.3791903034721711 | Gradient: [[ 0.02609341]\n",
      " [-0.09079674]\n",
      " [ 0.13008158]]\n",
      "Iteration 3447 | Cost: 0.3791644587017193 | Gradient: [[ 0.02609884]\n",
      " [-0.09077704]\n",
      " [ 0.13007331]]\n",
      "Iteration 3448 | Cost: 0.3791386193761245 | Gradient: [[ 0.02610426]\n",
      " [-0.09075735]\n",
      " [ 0.13006504]]\n",
      "Iteration 3449 | Cost: 0.3791127854929284 | Gradient: [[ 0.02610968]\n",
      " [-0.09073767]\n",
      " [ 0.13005677]]\n",
      "Iteration 3450 | Cost: 0.3790869570496753 | Gradient: [[ 0.02611509]\n",
      " [-0.090718  ]\n",
      " [ 0.13004849]]\n",
      "Iteration 3451 | Cost: 0.3790611340439116 | Gradient: [[ 0.0261205 ]\n",
      " [-0.09069835]\n",
      " [ 0.13004022]]\n",
      "Iteration 3452 | Cost: 0.3790353164731865 | Gradient: [[ 0.0261259 ]\n",
      " [-0.09067871]\n",
      " [ 0.13003194]]\n",
      "Iteration 3453 | Cost: 0.3790095043350515 | Gradient: [[ 0.0261313 ]\n",
      " [-0.09065908]\n",
      " [ 0.13002366]]\n",
      "Iteration 3454 | Cost: 0.37898369762706025 | Gradient: [[ 0.02613669]\n",
      " [-0.09063946]\n",
      " [ 0.13001538]]\n",
      "Iteration 3455 | Cost: 0.3789578963467691 | Gradient: [[ 0.02614207]\n",
      " [-0.09061985]\n",
      " [ 0.1300071 ]]\n",
      "Iteration 3456 | Cost: 0.3789321004917366 | Gradient: [[ 0.02614746]\n",
      " [-0.09060026]\n",
      " [ 0.12999881]]\n",
      "Iteration 3457 | Cost: 0.37890631005952413 | Gradient: [[ 0.02615283]\n",
      " [-0.09058068]\n",
      " [ 0.12999052]]\n",
      "Iteration 3458 | Cost: 0.3788805250476948 | Gradient: [[ 0.0261582 ]\n",
      " [-0.09056111]\n",
      " [ 0.12998224]]\n",
      "Iteration 3459 | Cost: 0.3788547454538147 | Gradient: [[ 0.02616357]\n",
      " [-0.09054155]\n",
      " [ 0.12997395]]\n",
      "Iteration 3460 | Cost: 0.378828971275452 | Gradient: [[ 0.02616893]\n",
      " [-0.09052201]\n",
      " [ 0.12996565]]\n",
      "Iteration 3461 | Cost: 0.37880320251017735 | Gradient: [[ 0.02617429]\n",
      " [-0.09050248]\n",
      " [ 0.12995736]]\n",
      "Iteration 3462 | Cost: 0.37877743915556383 | Gradient: [[ 0.02617964]\n",
      " [-0.09048295]\n",
      " [ 0.12994907]]\n",
      "Iteration 3463 | Cost: 0.3787516812091867 | Gradient: [[ 0.02618499]\n",
      " [-0.09046345]\n",
      " [ 0.12994077]]\n",
      "Iteration 3464 | Cost: 0.3787259286686238 | Gradient: [[ 0.02619033]\n",
      " [-0.09044395]\n",
      " [ 0.12993247]]\n",
      "Iteration 3465 | Cost: 0.3787001815314553 | Gradient: [[ 0.02619566]\n",
      " [-0.09042447]\n",
      " [ 0.12992417]]\n",
      "Iteration 3466 | Cost: 0.3786744397952638 | Gradient: [[ 0.02620099]\n",
      " [-0.09040499]\n",
      " [ 0.12991587]]\n",
      "Iteration 3467 | Cost: 0.3786487034576339 | Gradient: [[ 0.02620632]\n",
      " [-0.09038553]\n",
      " [ 0.12990756]]\n",
      "Iteration 3468 | Cost: 0.3786229725161532 | Gradient: [[ 0.02621164]\n",
      " [-0.09036608]\n",
      " [ 0.12989926]]\n",
      "Iteration 3469 | Cost: 0.3785972469684111 | Gradient: [[ 0.02621696]\n",
      " [-0.09034665]\n",
      " [ 0.12989095]]\n",
      "Iteration 3470 | Cost: 0.3785715268119996 | Gradient: [[ 0.02622227]\n",
      " [-0.09032722]\n",
      " [ 0.12988264]]\n",
      "Iteration 3471 | Cost: 0.378545812044513 | Gradient: [[ 0.02622757]\n",
      " [-0.09030781]\n",
      " [ 0.12987433]]\n",
      "Iteration 3472 | Cost: 0.37852010266354796 | Gradient: [[ 0.02623287]\n",
      " [-0.09028841]\n",
      " [ 0.12986601]]\n",
      "Iteration 3473 | Cost: 0.3784943986667036 | Gradient: [[ 0.02623817]\n",
      " [-0.09026902]\n",
      " [ 0.1298577 ]]\n",
      "Iteration 3474 | Cost: 0.3784687000515811 | Gradient: [[ 0.02624346]\n",
      " [-0.09024965]\n",
      " [ 0.12984938]]\n",
      "Iteration 3475 | Cost: 0.3784430068157842 | Gradient: [[ 0.02624874]\n",
      " [-0.09023028]\n",
      " [ 0.12984106]]\n",
      "Iteration 3476 | Cost: 0.378417318956919 | Gradient: [[ 0.02625402]\n",
      " [-0.09021093]\n",
      " [ 0.12983275]]\n",
      "Iteration 3477 | Cost: 0.3783916364725938 | Gradient: [[ 0.0262593 ]\n",
      " [-0.09019159]\n",
      " [ 0.12982442]]\n",
      "Iteration 3478 | Cost: 0.3783659593604192 | Gradient: [[ 0.02626457]\n",
      " [-0.09017226]\n",
      " [ 0.1298161 ]]\n",
      "Iteration 3479 | Cost: 0.37834028761800836 | Gradient: [[ 0.02626983]\n",
      " [-0.09015295]\n",
      " [ 0.12980778]]\n",
      "Iteration 3480 | Cost: 0.37831462124297643 | Gradient: [[ 0.0262751 ]\n",
      " [-0.09013364]\n",
      " [ 0.12979945]]\n",
      "Iteration 3481 | Cost: 0.3782889602329412 | Gradient: [[ 0.02628035]\n",
      " [-0.09011435]\n",
      " [ 0.12979112]]\n",
      "Iteration 3482 | Cost: 0.3782633045855226 | Gradient: [[ 0.0262856 ]\n",
      " [-0.09009507]\n",
      " [ 0.12978279]]\n",
      "Iteration 3483 | Cost: 0.3782376542983428 | Gradient: [[ 0.02629085]\n",
      " [-0.0900758 ]\n",
      " [ 0.12977446]]\n",
      "Iteration 3484 | Cost: 0.37821200936902644 | Gradient: [[ 0.02629609]\n",
      " [-0.09005654]\n",
      " [ 0.12976612]]\n",
      "Iteration 3485 | Cost: 0.3781863697952003 | Gradient: [[ 0.02630132]\n",
      " [-0.0900373 ]\n",
      " [ 0.12975779]]\n",
      "Iteration 3486 | Cost: 0.3781607355744938 | Gradient: [[ 0.02630655]\n",
      " [-0.09001807]\n",
      " [ 0.12974945]]\n",
      "Iteration 3487 | Cost: 0.3781351067045382 | Gradient: [[ 0.02631178]\n",
      " [-0.08999885]\n",
      " [ 0.12974111]]\n",
      "Iteration 3488 | Cost: 0.3781094831829674 | Gradient: [[ 0.026317  ]\n",
      " [-0.08997964]\n",
      " [ 0.12973277]]\n",
      "Iteration 3489 | Cost: 0.3780838650074174 | Gradient: [[ 0.02632221]\n",
      " [-0.08996044]\n",
      " [ 0.12972443]]\n",
      "Iteration 3490 | Cost: 0.37805825217552647 | Gradient: [[ 0.02632742]\n",
      " [-0.08994125]\n",
      " [ 0.12971609]]\n",
      "Iteration 3491 | Cost: 0.37803264468493536 | Gradient: [[ 0.02633263]\n",
      " [-0.08992208]\n",
      " [ 0.12970774]]\n",
      "Iteration 3492 | Cost: 0.3780070425332869 | Gradient: [[ 0.02633783]\n",
      " [-0.08990292]\n",
      " [ 0.1296994 ]]\n",
      "Iteration 3493 | Cost: 0.3779814457182263 | Gradient: [[ 0.02634302]\n",
      " [-0.08988377]\n",
      " [ 0.12969105]]\n",
      "Iteration 3494 | Cost: 0.3779558542374011 | Gradient: [[ 0.02634822]\n",
      " [-0.08986463]\n",
      " [ 0.1296827 ]]\n",
      "Iteration 3495 | Cost: 0.37793026808846086 | Gradient: [[ 0.0263534 ]\n",
      " [-0.0898455 ]\n",
      " [ 0.12967434]]\n",
      "Iteration 3496 | Cost: 0.37790468726905774 | Gradient: [[ 0.02635858]\n",
      " [-0.08982639]\n",
      " [ 0.12966599]]\n",
      "Iteration 3497 | Cost: 0.3778791117768459 | Gradient: [[ 0.02636376]\n",
      " [-0.08980728]\n",
      " [ 0.12965763]]\n",
      "Iteration 3498 | Cost: 0.377853541609482 | Gradient: [[ 0.02636893]\n",
      " [-0.08978819]\n",
      " [ 0.12964928]]\n",
      "Iteration 3499 | Cost: 0.3778279767646246 | Gradient: [[ 0.02637409]\n",
      " [-0.08976911]\n",
      " [ 0.12964092]]\n",
      "Iteration 3500 | Cost: 0.3778024172399348 | Gradient: [[ 0.02637926]\n",
      " [-0.08975005]\n",
      " [ 0.12963256]]\n",
      "Iteration 3501 | Cost: 0.3777768630330761 | Gradient: [[ 0.02638441]\n",
      " [-0.08973099]\n",
      " [ 0.1296242 ]]\n",
      "Iteration 3502 | Cost: 0.3777513141417137 | Gradient: [[ 0.02638956]\n",
      " [-0.08971195]\n",
      " [ 0.12961583]]\n",
      "Iteration 3503 | Cost: 0.3777257705635156 | Gradient: [[ 0.02639471]\n",
      " [-0.08969291]\n",
      " [ 0.12960747]]\n",
      "Iteration 3504 | Cost: 0.3777002322961517 | Gradient: [[ 0.02639985]\n",
      " [-0.08967389]\n",
      " [ 0.1295991 ]]\n",
      "Iteration 3505 | Cost: 0.3776746993372943 | Gradient: [[ 0.02640499]\n",
      " [-0.08965488]\n",
      " [ 0.12959073]]\n",
      "Iteration 3506 | Cost: 0.3776491716846179 | Gradient: [[ 0.02641012]\n",
      " [-0.08963588]\n",
      " [ 0.12958236]]\n",
      "Iteration 3507 | Cost: 0.37762364933579906 | Gradient: [[ 0.02641524]\n",
      " [-0.0896169 ]\n",
      " [ 0.12957399]]\n",
      "Iteration 3508 | Cost: 0.377598132288517 | Gradient: [[ 0.02642037]\n",
      " [-0.08959792]\n",
      " [ 0.12956562]]\n",
      "Iteration 3509 | Cost: 0.3775726205404527 | Gradient: [[ 0.02642548]\n",
      " [-0.08957896]\n",
      " [ 0.12955724]]\n",
      "Iteration 3510 | Cost: 0.37754711408928965 | Gradient: [[ 0.02643059]\n",
      " [-0.08956001]\n",
      " [ 0.12954886]]\n",
      "Iteration 3511 | Cost: 0.3775216129327133 | Gradient: [[ 0.0264357 ]\n",
      " [-0.08954107]\n",
      " [ 0.12954049]]\n",
      "Iteration 3512 | Cost: 0.3774961170684115 | Gradient: [[ 0.0264408 ]\n",
      " [-0.08952214]\n",
      " [ 0.12953211]]\n",
      "Iteration 3513 | Cost: 0.37747062649407437 | Gradient: [[ 0.0264459 ]\n",
      " [-0.08950323]\n",
      " [ 0.12952372]]\n",
      "Iteration 3514 | Cost: 0.37744514120739414 | Gradient: [[ 0.02645099]\n",
      " [-0.08948432]\n",
      " [ 0.12951534]]\n",
      "Iteration 3515 | Cost: 0.37741966120606524 | Gradient: [[ 0.02645608]\n",
      " [-0.08946543]\n",
      " [ 0.12950696]]\n",
      "Iteration 3516 | Cost: 0.3773941864877843 | Gradient: [[ 0.02646116]\n",
      " [-0.08944655]\n",
      " [ 0.12949857]]\n",
      "Iteration 3517 | Cost: 0.37736871705025005 | Gradient: [[ 0.02646624]\n",
      " [-0.08942768]\n",
      " [ 0.12949018]]\n",
      "Iteration 3518 | Cost: 0.3773432528911636 | Gradient: [[ 0.02647132]\n",
      " [-0.08940882]\n",
      " [ 0.12948179]]\n",
      "Iteration 3519 | Cost: 0.37731779400822835 | Gradient: [[ 0.02647638]\n",
      " [-0.08938997]\n",
      " [ 0.1294734 ]]\n",
      "Iteration 3520 | Cost: 0.37729234039914955 | Gradient: [[ 0.02648145]\n",
      " [-0.08937114]\n",
      " [ 0.12946501]]\n",
      "Iteration 3521 | Cost: 0.3772668920616347 | Gradient: [[ 0.02648651]\n",
      " [-0.08935231]\n",
      " [ 0.12945661]]\n",
      "Iteration 3522 | Cost: 0.37724144899339385 | Gradient: [[ 0.02649156]\n",
      " [-0.0893335 ]\n",
      " [ 0.12944822]]\n",
      "Iteration 3523 | Cost: 0.3772160111921388 | Gradient: [[ 0.02649661]\n",
      " [-0.0893147 ]\n",
      " [ 0.12943982]]\n",
      "Iteration 3524 | Cost: 0.3771905786555837 | Gradient: [[ 0.02650165]\n",
      " [-0.08929591]\n",
      " [ 0.12943142]]\n",
      "Iteration 3525 | Cost: 0.37716515138144485 | Gradient: [[ 0.02650669]\n",
      " [-0.08927713]\n",
      " [ 0.12942302]]\n",
      "Iteration 3526 | Cost: 0.3771397293674407 | Gradient: [[ 0.02651172]\n",
      " [-0.08925837]\n",
      " [ 0.12941461]]\n",
      "Iteration 3527 | Cost: 0.3771143126112921 | Gradient: [[ 0.02651675]\n",
      " [-0.08923961]\n",
      " [ 0.12940621]]\n",
      "Iteration 3528 | Cost: 0.3770889011107216 | Gradient: [[ 0.02652178]\n",
      " [-0.08922087]\n",
      " [ 0.1293978 ]]\n",
      "Iteration 3529 | Cost: 0.37706349486345436 | Gradient: [[ 0.0265268 ]\n",
      " [-0.08920214]\n",
      " [ 0.1293894 ]]\n",
      "Iteration 3530 | Cost: 0.3770380938672173 | Gradient: [[ 0.02653181]\n",
      " [-0.08918342]\n",
      " [ 0.12938099]]\n",
      "Iteration 3531 | Cost: 0.3770126981197399 | Gradient: [[ 0.02653682]\n",
      " [-0.08916471]\n",
      " [ 0.12937258]]\n",
      "Iteration 3532 | Cost: 0.37698730761875354 | Gradient: [[ 0.02654183]\n",
      " [-0.08914601]\n",
      " [ 0.12936417]]\n",
      "Iteration 3533 | Cost: 0.37696192236199183 | Gradient: [[ 0.02654683]\n",
      " [-0.08912732]\n",
      " [ 0.12935575]]\n",
      "Iteration 3534 | Cost: 0.37693654234719043 | Gradient: [[ 0.02655183]\n",
      " [-0.08910865]\n",
      " [ 0.12934734]]\n",
      "Iteration 3535 | Cost: 0.3769111675720872 | Gradient: [[ 0.02655682]\n",
      " [-0.08908999]\n",
      " [ 0.12933892]]\n",
      "Iteration 3536 | Cost: 0.37688579803442224 | Gradient: [[ 0.0265618 ]\n",
      " [-0.08907133]\n",
      " [ 0.1293305 ]]\n",
      "Iteration 3537 | Cost: 0.3768604337319375 | Gradient: [[ 0.02656679]\n",
      " [-0.08905269]\n",
      " [ 0.12932208]]\n",
      "Iteration 3538 | Cost: 0.3768350746623775 | Gradient: [[ 0.02657176]\n",
      " [-0.08903406]\n",
      " [ 0.12931366]]\n",
      "Iteration 3539 | Cost: 0.3768097208234884 | Gradient: [[ 0.02657673]\n",
      " [-0.08901545]\n",
      " [ 0.12930524]]\n",
      "Iteration 3540 | Cost: 0.3767843722130189 | Gradient: [[ 0.0265817 ]\n",
      " [-0.08899684]\n",
      " [ 0.12929681]]\n",
      "Iteration 3541 | Cost: 0.3767590288287196 | Gradient: [[ 0.02658666]\n",
      " [-0.08897825]\n",
      " [ 0.12928839]]\n",
      "Iteration 3542 | Cost: 0.37673369066834317 | Gradient: [[ 0.02659162]\n",
      " [-0.08895966]\n",
      " [ 0.12927996]]\n",
      "Iteration 3543 | Cost: 0.3767083577296447 | Gradient: [[ 0.02659658]\n",
      " [-0.08894109]\n",
      " [ 0.12927153]]\n",
      "Iteration 3544 | Cost: 0.37668303001038095 | Gradient: [[ 0.02660152]\n",
      " [-0.08892253]\n",
      " [ 0.1292631 ]]\n",
      "Iteration 3545 | Cost: 0.37665770750831123 | Gradient: [[ 0.02660647]\n",
      " [-0.08890398]\n",
      " [ 0.12925467]]\n",
      "Iteration 3546 | Cost: 0.3766323902211967 | Gradient: [[ 0.02661141]\n",
      " [-0.08888544]\n",
      " [ 0.12924623]]\n",
      "Iteration 3547 | Cost: 0.3766070781468005 | Gradient: [[ 0.02661634]\n",
      " [-0.08886691]\n",
      " [ 0.1292378 ]]\n",
      "Iteration 3548 | Cost: 0.37658177128288844 | Gradient: [[ 0.02662127]\n",
      " [-0.0888484 ]\n",
      " [ 0.12922936]]\n",
      "Iteration 3549 | Cost: 0.37655646962722766 | Gradient: [[ 0.02662619]\n",
      " [-0.08882989]\n",
      " [ 0.12922092]]\n",
      "Iteration 3550 | Cost: 0.37653117317758794 | Gradient: [[ 0.02663111]\n",
      " [-0.0888114 ]\n",
      " [ 0.12921248]]\n",
      "Iteration 3551 | Cost: 0.376505881931741 | Gradient: [[ 0.02663603]\n",
      " [-0.08879291]\n",
      " [ 0.12920404]]\n",
      "Iteration 3552 | Cost: 0.3764805958874606 | Gradient: [[ 0.02664094]\n",
      " [-0.08877444]\n",
      " [ 0.1291956 ]]\n",
      "Iteration 3553 | Cost: 0.3764553150425226 | Gradient: [[ 0.02664585]\n",
      " [-0.08875598]\n",
      " [ 0.12918716]]\n",
      "Iteration 3554 | Cost: 0.37643003939470504 | Gradient: [[ 0.02665075]\n",
      " [-0.08873753]\n",
      " [ 0.12917871]]\n",
      "Iteration 3555 | Cost: 0.376404768941788 | Gradient: [[ 0.02665564]\n",
      " [-0.0887191 ]\n",
      " [ 0.12917026]]\n",
      "Iteration 3556 | Cost: 0.3763795036815534 | Gradient: [[ 0.02666053]\n",
      " [-0.08870067]\n",
      " [ 0.12916181]]\n",
      "Iteration 3557 | Cost: 0.3763542436117856 | Gradient: [[ 0.02666542]\n",
      " [-0.08868226]\n",
      " [ 0.12915336]]\n",
      "Iteration 3558 | Cost: 0.3763289887302709 | Gradient: [[ 0.0266703 ]\n",
      " [-0.08866385]\n",
      " [ 0.12914491]]\n",
      "Iteration 3559 | Cost: 0.3763037390347976 | Gradient: [[ 0.02667518]\n",
      " [-0.08864546]\n",
      " [ 0.12913646]]\n",
      "Iteration 3560 | Cost: 0.3762784945231559 | Gradient: [[ 0.02668005]\n",
      " [-0.08862708]\n",
      " [ 0.129128  ]]\n",
      "Iteration 3561 | Cost: 0.3762532551931386 | Gradient: [[ 0.02668492]\n",
      " [-0.08860871]\n",
      " [ 0.12911955]]\n",
      "Iteration 3562 | Cost: 0.3762280210425401 | Gradient: [[ 0.02668979]\n",
      " [-0.08859035]\n",
      " [ 0.12911109]]\n",
      "Iteration 3563 | Cost: 0.37620279206915685 | Gradient: [[ 0.02669464]\n",
      " [-0.088572  ]\n",
      " [ 0.12910263]]\n",
      "Iteration 3564 | Cost: 0.37617756827078763 | Gradient: [[ 0.0266995 ]\n",
      " [-0.08855366]\n",
      " [ 0.12909417]]\n",
      "Iteration 3565 | Cost: 0.37615234964523314 | Gradient: [[ 0.02670435]\n",
      " [-0.08853534]\n",
      " [ 0.12908571]]\n",
      "Iteration 3566 | Cost: 0.3761271361902959 | Gradient: [[ 0.02670919]\n",
      " [-0.08851702]\n",
      " [ 0.12907724]]\n",
      "Iteration 3567 | Cost: 0.37610192790378094 | Gradient: [[ 0.02671403]\n",
      " [-0.08849872]\n",
      " [ 0.12906878]]\n",
      "Iteration 3568 | Cost: 0.376076724783495 | Gradient: [[ 0.02671887]\n",
      " [-0.08848042]\n",
      " [ 0.12906031]]\n",
      "Iteration 3569 | Cost: 0.37605152682724696 | Gradient: [[ 0.0267237 ]\n",
      " [-0.08846214]\n",
      " [ 0.12905184]]\n",
      "Iteration 3570 | Cost: 0.3760263340328477 | Gradient: [[ 0.02672853]\n",
      " [-0.08844387]\n",
      " [ 0.12904337]]\n",
      "Iteration 3571 | Cost: 0.37600114639811 | Gradient: [[ 0.02673335]\n",
      " [-0.08842561]\n",
      " [ 0.1290349 ]]\n",
      "Iteration 3572 | Cost: 0.37597596392084887 | Gradient: [[ 0.02673817]\n",
      " [-0.08840736]\n",
      " [ 0.12902643]]\n",
      "Iteration 3573 | Cost: 0.3759507865988814 | Gradient: [[ 0.02674298]\n",
      " [-0.08838913]\n",
      " [ 0.12901795]]\n",
      "Iteration 3574 | Cost: 0.3759256144300267 | Gradient: [[ 0.02674779]\n",
      " [-0.0883709 ]\n",
      " [ 0.12900948]]\n",
      "Iteration 3575 | Cost: 0.37590044741210554 | Gradient: [[ 0.02675259]\n",
      " [-0.08835268]\n",
      " [ 0.129001  ]]\n",
      "Iteration 3576 | Cost: 0.3758752855429411 | Gradient: [[ 0.02675739]\n",
      " [-0.08833448]\n",
      " [ 0.12899252]]\n",
      "Iteration 3577 | Cost: 0.37585012882035834 | Gradient: [[ 0.02676218]\n",
      " [-0.08831629]\n",
      " [ 0.12898404]]\n",
      "Iteration 3578 | Cost: 0.37582497724218444 | Gradient: [[ 0.02676697]\n",
      " [-0.0882981 ]\n",
      " [ 0.12897556]]\n",
      "Iteration 3579 | Cost: 0.37579983080624846 | Gradient: [[ 0.02677175]\n",
      " [-0.08827993]\n",
      " [ 0.12896708]]\n",
      "Iteration 3580 | Cost: 0.37577468951038157 | Gradient: [[ 0.02677653]\n",
      " [-0.08826177]\n",
      " [ 0.12895859]]\n",
      "Iteration 3581 | Cost: 0.37574955335241667 | Gradient: [[ 0.02678131]\n",
      " [-0.08824362]\n",
      " [ 0.12895011]]\n",
      "Iteration 3582 | Cost: 0.375724422330189 | Gradient: [[ 0.02678608]\n",
      " [-0.08822548]\n",
      " [ 0.12894162]]\n",
      "Iteration 3583 | Cost: 0.37569929644153566 | Gradient: [[ 0.02679085]\n",
      " [-0.08820736]\n",
      " [ 0.12893313]]\n",
      "Iteration 3584 | Cost: 0.3756741756842956 | Gradient: [[ 0.02679561]\n",
      " [-0.08818924]\n",
      " [ 0.12892464]]\n",
      "Iteration 3585 | Cost: 0.3756490600563101 | Gradient: [[ 0.02680037]\n",
      " [-0.08817113]\n",
      " [ 0.12891615]]\n",
      "Iteration 3586 | Cost: 0.3756239495554221 | Gradient: [[ 0.02680512]\n",
      " [-0.08815304]\n",
      " [ 0.12890766]]\n",
      "Iteration 3587 | Cost: 0.3755988441794766 | Gradient: [[ 0.02680987]\n",
      " [-0.08813496]\n",
      " [ 0.12889916]]\n",
      "Iteration 3588 | Cost: 0.3755737439263208 | Gradient: [[ 0.02681461]\n",
      " [-0.08811688]\n",
      " [ 0.12889067]]\n",
      "Iteration 3589 | Cost: 0.3755486487938036 | Gradient: [[ 0.02681935]\n",
      " [-0.08809882]\n",
      " [ 0.12888217]]\n",
      "Iteration 3590 | Cost: 0.37552355877977606 | Gradient: [[ 0.02682408]\n",
      " [-0.08808077]\n",
      " [ 0.12887367]]\n",
      "Iteration 3591 | Cost: 0.3754984738820912 | Gradient: [[ 0.02682881]\n",
      " [-0.08806273]\n",
      " [ 0.12886517]]\n",
      "Iteration 3592 | Cost: 0.3754733940986038 | Gradient: [[ 0.02683354]\n",
      " [-0.0880447 ]\n",
      " [ 0.12885667]]\n",
      "Iteration 3593 | Cost: 0.3754483194271709 | Gradient: [[ 0.02683826]\n",
      " [-0.08802668]\n",
      " [ 0.12884817]]\n",
      "Iteration 3594 | Cost: 0.37542324986565145 | Gradient: [[ 0.02684297]\n",
      " [-0.08800867]\n",
      " [ 0.12883966]]\n",
      "Iteration 3595 | Cost: 0.3753981854119061 | Gradient: [[ 0.02684769]\n",
      " [-0.08799068]\n",
      " [ 0.12883116]]\n",
      "Iteration 3596 | Cost: 0.37537312606379786 | Gradient: [[ 0.02685239]\n",
      " [-0.08797269]\n",
      " [ 0.12882265]]\n",
      "Iteration 3597 | Cost: 0.37534807181919144 | Gradient: [[ 0.0268571 ]\n",
      " [-0.08795472]\n",
      " [ 0.12881414]]\n",
      "Iteration 3598 | Cost: 0.37532302267595347 | Gradient: [[ 0.02686179]\n",
      " [-0.08793675]\n",
      " [ 0.12880563]]\n",
      "Iteration 3599 | Cost: 0.3752979786319528 | Gradient: [[ 0.02686649]\n",
      " [-0.0879188 ]\n",
      " [ 0.12879712]]\n",
      "Iteration 3600 | Cost: 0.37527293968505976 | Gradient: [[ 0.02687117]\n",
      " [-0.08790085]\n",
      " [ 0.12878861]]\n",
      "Iteration 3601 | Cost: 0.3752479058331473 | Gradient: [[ 0.02687586]\n",
      " [-0.08788292]\n",
      " [ 0.12878009]]\n",
      "Iteration 3602 | Cost: 0.3752228770740897 | Gradient: [[ 0.02688054]\n",
      " [-0.087865  ]\n",
      " [ 0.12877158]]\n",
      "Iteration 3603 | Cost: 0.37519785340576345 | Gradient: [[ 0.02688521]\n",
      " [-0.08784709]\n",
      " [ 0.12876306]]\n",
      "Iteration 3604 | Cost: 0.375172834826047 | Gradient: [[ 0.02688988]\n",
      " [-0.08782919]\n",
      " [ 0.12875454]]\n",
      "Iteration 3605 | Cost: 0.37514782133282065 | Gradient: [[ 0.02689455]\n",
      " [-0.0878113 ]\n",
      " [ 0.12874602]]\n",
      "Iteration 3606 | Cost: 0.3751228129239667 | Gradient: [[ 0.02689921]\n",
      " [-0.08779342]\n",
      " [ 0.1287375 ]]\n",
      "Iteration 3607 | Cost: 0.37509780959736927 | Gradient: [[ 0.02690387]\n",
      " [-0.08777556]\n",
      " [ 0.12872898]]\n",
      "Iteration 3608 | Cost: 0.37507281135091464 | Gradient: [[ 0.02690852]\n",
      " [-0.0877577 ]\n",
      " [ 0.12872045]]\n",
      "Iteration 3609 | Cost: 0.3750478181824908 | Gradient: [[ 0.02691317]\n",
      " [-0.08773985]\n",
      " [ 0.12871193]]\n",
      "Iteration 3610 | Cost: 0.3750228300899876 | Gradient: [[ 0.02691781]\n",
      " [-0.08772202]\n",
      " [ 0.1287034 ]]\n",
      "Iteration 3611 | Cost: 0.37499784707129713 | Gradient: [[ 0.02692245]\n",
      " [-0.08770419]\n",
      " [ 0.12869487]]\n",
      "Iteration 3612 | Cost: 0.3749728691243131 | Gradient: [[ 0.02692709]\n",
      " [-0.08768638]\n",
      " [ 0.12868635]]\n",
      "Iteration 3613 | Cost: 0.3749478962469312 | Gradient: [[ 0.02693172]\n",
      " [-0.08766857]\n",
      " [ 0.12867781]]\n",
      "Iteration 3614 | Cost: 0.37492292843704916 | Gradient: [[ 0.02693634]\n",
      " [-0.08765078]\n",
      " [ 0.12866928]]\n",
      "Iteration 3615 | Cost: 0.37489796569256645 | Gradient: [[ 0.02694097]\n",
      " [-0.087633  ]\n",
      " [ 0.12866075]]\n",
      "Iteration 3616 | Cost: 0.37487300801138457 | Gradient: [[ 0.02694558]\n",
      " [-0.08761523]\n",
      " [ 0.12865221]]\n",
      "Iteration 3617 | Cost: 0.3748480553914069 | Gradient: [[ 0.02695019]\n",
      " [-0.08759747]\n",
      " [ 0.12864368]]\n",
      "Iteration 3618 | Cost: 0.3748231078305388 | Gradient: [[ 0.0269548 ]\n",
      " [-0.08757972]\n",
      " [ 0.12863514]]\n",
      "Iteration 3619 | Cost: 0.3747981653266871 | Gradient: [[ 0.02695941]\n",
      " [-0.08756198]\n",
      " [ 0.1286266 ]]\n",
      "Iteration 3620 | Cost: 0.3747732278777611 | Gradient: [[ 0.026964  ]\n",
      " [-0.08754425]\n",
      " [ 0.12861806]]\n",
      "Iteration 3621 | Cost: 0.3747482954816717 | Gradient: [[ 0.0269686 ]\n",
      " [-0.08752653]\n",
      " [ 0.12860952]]\n",
      "Iteration 3622 | Cost: 0.37472336813633184 | Gradient: [[ 0.02697319]\n",
      " [-0.08750882]\n",
      " [ 0.12860098]]\n",
      "Iteration 3623 | Cost: 0.374698445839656 | Gradient: [[ 0.02697778]\n",
      " [-0.08749113]\n",
      " [ 0.12859243]]\n",
      "Iteration 3624 | Cost: 0.374673528589561 | Gradient: [[ 0.02698236]\n",
      " [-0.08747344]\n",
      " [ 0.12858389]]\n",
      "Iteration 3625 | Cost: 0.37464861638396524 | Gradient: [[ 0.02698693]\n",
      " [-0.08745576]\n",
      " [ 0.12857534]]\n",
      "Iteration 3626 | Cost: 0.37462370922078914 | Gradient: [[ 0.02699151]\n",
      " [-0.0874381 ]\n",
      " [ 0.12856679]]\n",
      "Iteration 3627 | Cost: 0.37459880709795496 | Gradient: [[ 0.02699607]\n",
      " [-0.08742044]\n",
      " [ 0.12855824]]\n",
      "Iteration 3628 | Cost: 0.3745739100133866 | Gradient: [[ 0.02700064]\n",
      " [-0.0874028 ]\n",
      " [ 0.12854969]]\n",
      "Iteration 3629 | Cost: 0.3745490179650104 | Gradient: [[ 0.0270052 ]\n",
      " [-0.08738517]\n",
      " [ 0.12854114]]\n",
      "Iteration 3630 | Cost: 0.3745241309507539 | Gradient: [[ 0.02700975]\n",
      " [-0.08736754]\n",
      " [ 0.12853259]]\n",
      "Iteration 3631 | Cost: 0.3744992489685471 | Gradient: [[ 0.0270143 ]\n",
      " [-0.08734993]\n",
      " [ 0.12852403]]\n",
      "Iteration 3632 | Cost: 0.3744743720163214 | Gradient: [[ 0.02701885]\n",
      " [-0.08733233]\n",
      " [ 0.12851548]]\n",
      "Iteration 3633 | Cost: 0.37444950009201033 | Gradient: [[ 0.02702339]\n",
      " [-0.08731474]\n",
      " [ 0.12850692]]\n",
      "Iteration 3634 | Cost: 0.3744246331935492 | Gradient: [[ 0.02702792]\n",
      " [-0.08729715]\n",
      " [ 0.12849836]]\n",
      "Iteration 3635 | Cost: 0.3743997713188752 | Gradient: [[ 0.02703246]\n",
      " [-0.08727958]\n",
      " [ 0.1284898 ]]\n",
      "Iteration 3636 | Cost: 0.37437491446592724 | Gradient: [[ 0.02703699]\n",
      " [-0.08726202]\n",
      " [ 0.12848124]]\n",
      "Iteration 3637 | Cost: 0.3743500626326463 | Gradient: [[ 0.02704151]\n",
      " [-0.08724447]\n",
      " [ 0.12847268]]\n",
      "Iteration 3638 | Cost: 0.3743252158169751 | Gradient: [[ 0.02704603]\n",
      " [-0.08722693]\n",
      " [ 0.12846411]]\n",
      "Iteration 3639 | Cost: 0.37430037401685806 | Gradient: [[ 0.02705054]\n",
      " [-0.08720941]\n",
      " [ 0.12845555]]\n",
      "Iteration 3640 | Cost: 0.3742755372302418 | Gradient: [[ 0.02705505]\n",
      " [-0.08719189]\n",
      " [ 0.12844698]]\n",
      "Iteration 3641 | Cost: 0.37425070545507433 | Gradient: [[ 0.02705956]\n",
      " [-0.08717438]\n",
      " [ 0.12843841]]\n",
      "Iteration 3642 | Cost: 0.374225878689306 | Gradient: [[ 0.02706406]\n",
      " [-0.08715688]\n",
      " [ 0.12842984]]\n",
      "Iteration 3643 | Cost: 0.3742010569308885 | Gradient: [[ 0.02706856]\n",
      " [-0.08713939]\n",
      " [ 0.12842127]]\n",
      "Iteration 3644 | Cost: 0.3741762401777757 | Gradient: [[ 0.02707305]\n",
      " [-0.08712192]\n",
      " [ 0.1284127 ]]\n",
      "Iteration 3645 | Cost: 0.37415142842792315 | Gradient: [[ 0.02707754]\n",
      " [-0.08710445]\n",
      " [ 0.12840413]]\n",
      "Iteration 3646 | Cost: 0.3741266216792882 | Gradient: [[ 0.02708203]\n",
      " [-0.087087  ]\n",
      " [ 0.12839555]]\n",
      "Iteration 3647 | Cost: 0.37410181992983016 | Gradient: [[ 0.02708651]\n",
      " [-0.08706955]\n",
      " [ 0.12838698]]\n",
      "Iteration 3648 | Cost: 0.3740770231775101 | Gradient: [[ 0.02709098]\n",
      " [-0.08705211]\n",
      " [ 0.1283784 ]]\n",
      "Iteration 3649 | Cost: 0.37405223142029076 | Gradient: [[ 0.02709545]\n",
      " [-0.08703469]\n",
      " [ 0.12836982]]\n",
      "Iteration 3650 | Cost: 0.374027444656137 | Gradient: [[ 0.02709992]\n",
      " [-0.08701728]\n",
      " [ 0.12836124]]\n",
      "Iteration 3651 | Cost: 0.3740026628830152 | Gradient: [[ 0.02710438]\n",
      " [-0.08699987]\n",
      " [ 0.12835266]]\n",
      "Iteration 3652 | Cost: 0.3739778860988938 | Gradient: [[ 0.02710884]\n",
      " [-0.08698248]\n",
      " [ 0.12834408]]\n",
      "Iteration 3653 | Cost: 0.3739531143017427 | Gradient: [[ 0.0271133 ]\n",
      " [-0.08696509]\n",
      " [ 0.1283355 ]]\n",
      "Iteration 3654 | Cost: 0.3739283474895341 | Gradient: [[ 0.02711775]\n",
      " [-0.08694772]\n",
      " [ 0.12832691]]\n",
      "Iteration 3655 | Cost: 0.37390358566024157 | Gradient: [[ 0.02712219]\n",
      " [-0.08693036]\n",
      " [ 0.12831833]]\n",
      "Iteration 3656 | Cost: 0.3738788288118407 | Gradient: [[ 0.02712663]\n",
      " [-0.08691301]\n",
      " [ 0.12830974]]\n",
      "Iteration 3657 | Cost: 0.3738540769423088 | Gradient: [[ 0.02713107]\n",
      " [-0.08689566]\n",
      " [ 0.12830115]]\n",
      "Iteration 3658 | Cost: 0.37382933004962515 | Gradient: [[ 0.0271355 ]\n",
      " [-0.08687833]\n",
      " [ 0.12829256]]\n",
      "Iteration 3659 | Cost: 0.3738045881317704 | Gradient: [[ 0.02713993]\n",
      " [-0.08686101]\n",
      " [ 0.12828397]]\n",
      "Iteration 3660 | Cost: 0.3737798511867275 | Gradient: [[ 0.02714435]\n",
      " [-0.0868437 ]\n",
      " [ 0.12827538]]\n",
      "Iteration 3661 | Cost: 0.37375511921248084 | Gradient: [[ 0.02714877]\n",
      " [-0.0868264 ]\n",
      " [ 0.12826679]]\n",
      "Iteration 3662 | Cost: 0.37373039220701687 | Gradient: [[ 0.02715319]\n",
      " [-0.08680911]\n",
      " [ 0.12825819]]\n",
      "Iteration 3663 | Cost: 0.3737056701683234 | Gradient: [[ 0.0271576 ]\n",
      " [-0.08679183]\n",
      " [ 0.12824959]]\n",
      "Iteration 3664 | Cost: 0.3736809530943905 | Gradient: [[ 0.02716201]\n",
      " [-0.08677456]\n",
      " [ 0.128241  ]]\n",
      "Iteration 3665 | Cost: 0.3736562409832098 | Gradient: [[ 0.02716641]\n",
      " [-0.0867573 ]\n",
      " [ 0.1282324 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3666 | Cost: 0.3736315338327747 | Gradient: [[ 0.02717081]\n",
      " [-0.08674005]\n",
      " [ 0.1282238 ]]\n",
      "Iteration 3667 | Cost: 0.3736068316410804 | Gradient: [[ 0.0271752 ]\n",
      " [-0.08672281]\n",
      " [ 0.1282152 ]]\n",
      "Iteration 3668 | Cost: 0.37358213440612364 | Gradient: [[ 0.02717959]\n",
      " [-0.08670558]\n",
      " [ 0.1282066 ]]\n",
      "Iteration 3669 | Cost: 0.3735574421259035 | Gradient: [[ 0.02718397]\n",
      " [-0.08668836]\n",
      " [ 0.12819799]]\n",
      "Iteration 3670 | Cost: 0.37353275479842035 | Gradient: [[ 0.02718836]\n",
      " [-0.08667115]\n",
      " [ 0.12818939]]\n",
      "Iteration 3671 | Cost: 0.37350807242167633 | Gradient: [[ 0.02719273]\n",
      " [-0.08665395]\n",
      " [ 0.12818078]]\n",
      "Iteration 3672 | Cost: 0.3734833949936756 | Gradient: [[ 0.0271971 ]\n",
      " [-0.08663676]\n",
      " [ 0.12817218]]\n",
      "Iteration 3673 | Cost: 0.3734587225124239 | Gradient: [[ 0.02720147]\n",
      " [-0.08661958]\n",
      " [ 0.12816357]]\n",
      "Iteration 3674 | Cost: 0.3734340549759288 | Gradient: [[ 0.02720584]\n",
      " [-0.08660241]\n",
      " [ 0.12815496]]\n",
      "Iteration 3675 | Cost: 0.3734093923821995 | Gradient: [[ 0.0272102 ]\n",
      " [-0.08658526]\n",
      " [ 0.12814635]]\n",
      "Iteration 3676 | Cost: 0.37338473472924716 | Gradient: [[ 0.02721455]\n",
      " [-0.08656811]\n",
      " [ 0.12813774]]\n",
      "Iteration 3677 | Cost: 0.3733600820150846 | Gradient: [[ 0.0272189 ]\n",
      " [-0.08655097]\n",
      " [ 0.12812912]]\n",
      "Iteration 3678 | Cost: 0.3733354342377262 | Gradient: [[ 0.02722325]\n",
      " [-0.08653384]\n",
      " [ 0.12812051]]\n",
      "Iteration 3679 | Cost: 0.37331079139518847 | Gradient: [[ 0.02722759]\n",
      " [-0.08651672]\n",
      " [ 0.12811189]]\n",
      "Iteration 3680 | Cost: 0.37328615348548927 | Gradient: [[ 0.02723193]\n",
      " [-0.08649962]\n",
      " [ 0.12810328]]\n",
      "Iteration 3681 | Cost: 0.3732615205066484 | Gradient: [[ 0.02723626]\n",
      " [-0.08648252]\n",
      " [ 0.12809466]]\n",
      "Iteration 3682 | Cost: 0.3732368924566874 | Gradient: [[ 0.02724059]\n",
      " [-0.08646543]\n",
      " [ 0.12808604]]\n",
      "Iteration 3683 | Cost: 0.3732122693336295 | Gradient: [[ 0.02724492]\n",
      " [-0.08644835]\n",
      " [ 0.12807742]]\n",
      "Iteration 3684 | Cost: 0.3731876511354997 | Gradient: [[ 0.02724924]\n",
      " [-0.08643129]\n",
      " [ 0.1280688 ]]\n",
      "Iteration 3685 | Cost: 0.3731630378603247 | Gradient: [[ 0.02725356]\n",
      " [-0.08641423]\n",
      " [ 0.12806018]]\n",
      "Iteration 3686 | Cost: 0.37313842950613285 | Gradient: [[ 0.02725787]\n",
      " [-0.08639718]\n",
      " [ 0.12805155]]\n",
      "Iteration 3687 | Cost: 0.37311382607095445 | Gradient: [[ 0.02726218]\n",
      " [-0.08638015]\n",
      " [ 0.12804293]]\n",
      "Iteration 3688 | Cost: 0.37308922755282137 | Gradient: [[ 0.02726649]\n",
      " [-0.08636312]\n",
      " [ 0.1280343 ]]\n",
      "Iteration 3689 | Cost: 0.3730646339497671 | Gradient: [[ 0.02727079]\n",
      " [-0.0863461 ]\n",
      " [ 0.12802567]]\n",
      "Iteration 3690 | Cost: 0.37304004525982704 | Gradient: [[ 0.02727508]\n",
      " [-0.0863291 ]\n",
      " [ 0.12801704]]\n",
      "Iteration 3691 | Cost: 0.37301546148103815 | Gradient: [[ 0.02727937]\n",
      " [-0.0863121 ]\n",
      " [ 0.12800841]]\n",
      "Iteration 3692 | Cost: 0.37299088261143926 | Gradient: [[ 0.02728366]\n",
      " [-0.08629511]\n",
      " [ 0.12799978]]\n",
      "Iteration 3693 | Cost: 0.3729663086490708 | Gradient: [[ 0.02728795]\n",
      " [-0.08627813]\n",
      " [ 0.12799115]]\n",
      "Iteration 3694 | Cost: 0.3729417395919749 | Gradient: [[ 0.02729222]\n",
      " [-0.08626117]\n",
      " [ 0.12798252]]\n",
      "Iteration 3695 | Cost: 0.37291717543819564 | Gradient: [[ 0.0272965 ]\n",
      " [-0.08624421]\n",
      " [ 0.12797388]]\n",
      "Iteration 3696 | Cost: 0.37289261618577835 | Gradient: [[ 0.02730077]\n",
      " [-0.08622726]\n",
      " [ 0.12796525]]\n",
      "Iteration 3697 | Cost: 0.37286806183277044 | Gradient: [[ 0.02730504]\n",
      " [-0.08621033]\n",
      " [ 0.12795661]]\n",
      "Iteration 3698 | Cost: 0.3728435123772209 | Gradient: [[ 0.0273093 ]\n",
      " [-0.0861934 ]\n",
      " [ 0.12794797]]\n",
      "Iteration 3699 | Cost: 0.3728189678171802 | Gradient: [[ 0.02731356]\n",
      " [-0.08617648]\n",
      " [ 0.12793933]]\n",
      "Iteration 3700 | Cost: 0.372794428150701 | Gradient: [[ 0.02731781]\n",
      " [-0.08615957]\n",
      " [ 0.12793069]]\n",
      "Iteration 3701 | Cost: 0.3727698933758373 | Gradient: [[ 0.02732206]\n",
      " [-0.08614268]\n",
      " [ 0.12792205]]\n",
      "Iteration 3702 | Cost: 0.3727453634906448 | Gradient: [[ 0.02732631]\n",
      " [-0.08612579]\n",
      " [ 0.12791341]]\n",
      "Iteration 3703 | Cost: 0.37272083849318083 | Gradient: [[ 0.02733055]\n",
      " [-0.08610891]\n",
      " [ 0.12790477]]\n",
      "Iteration 3704 | Cost: 0.3726963183815048 | Gradient: [[ 0.02733479]\n",
      " [-0.08609205]\n",
      " [ 0.12789612]]\n",
      "Iteration 3705 | Cost: 0.37267180315367726 | Gradient: [[ 0.02733902]\n",
      " [-0.08607519]\n",
      " [ 0.12788747]]\n",
      "Iteration 3706 | Cost: 0.3726472928077609 | Gradient: [[ 0.02734325]\n",
      " [-0.08605834]\n",
      " [ 0.12787883]]\n",
      "Iteration 3707 | Cost: 0.37262278734181964 | Gradient: [[ 0.02734748]\n",
      " [-0.0860415 ]\n",
      " [ 0.12787018]]\n",
      "Iteration 3708 | Cost: 0.3725982867539196 | Gradient: [[ 0.0273517 ]\n",
      " [-0.08602467]\n",
      " [ 0.12786153]]\n",
      "Iteration 3709 | Cost: 0.372573791042128 | Gradient: [[ 0.02735592]\n",
      " [-0.08600786]\n",
      " [ 0.12785288]]\n",
      "Iteration 3710 | Cost: 0.3725493002045143 | Gradient: [[ 0.02736013]\n",
      " [-0.08599105]\n",
      " [ 0.12784423]]\n",
      "Iteration 3711 | Cost: 0.37252481423914924 | Gradient: [[ 0.02736434]\n",
      " [-0.08597425]\n",
      " [ 0.12783557]]\n",
      "Iteration 3712 | Cost: 0.37250033314410547 | Gradient: [[ 0.02736854]\n",
      " [-0.08595746]\n",
      " [ 0.12782692]]\n",
      "Iteration 3713 | Cost: 0.372475856917457 | Gradient: [[ 0.02737274]\n",
      " [-0.08594068]\n",
      " [ 0.12781826]]\n",
      "Iteration 3714 | Cost: 0.37245138555727975 | Gradient: [[ 0.02737694]\n",
      " [-0.08592391]\n",
      " [ 0.12780961]]\n",
      "Iteration 3715 | Cost: 0.37242691906165126 | Gradient: [[ 0.02738113]\n",
      " [-0.08590715]\n",
      " [ 0.12780095]]\n",
      "Iteration 3716 | Cost: 0.3724024574286508 | Gradient: [[ 0.02738532]\n",
      " [-0.08589041]\n",
      " [ 0.12779229]]\n",
      "Iteration 3717 | Cost: 0.37237800065635895 | Gradient: [[ 0.0273895 ]\n",
      " [-0.08587367]\n",
      " [ 0.12778363]]\n",
      "Iteration 3718 | Cost: 0.37235354874285825 | Gradient: [[ 0.02739368]\n",
      " [-0.08585694]\n",
      " [ 0.12777497]]\n",
      "Iteration 3719 | Cost: 0.37232910168623307 | Gradient: [[ 0.02739786]\n",
      " [-0.08584022]\n",
      " [ 0.12776631]]\n",
      "Iteration 3720 | Cost: 0.3723046594845689 | Gradient: [[ 0.02740203]\n",
      " [-0.08582351]\n",
      " [ 0.12775765]]\n",
      "Iteration 3721 | Cost: 0.37228022213595335 | Gradient: [[ 0.0274062 ]\n",
      " [-0.08580681]\n",
      " [ 0.12774898]]\n",
      "Iteration 3722 | Cost: 0.37225578963847533 | Gradient: [[ 0.02741036]\n",
      " [-0.08579012]\n",
      " [ 0.12774032]]\n",
      "Iteration 3723 | Cost: 0.37223136199022566 | Gradient: [[ 0.02741452]\n",
      " [-0.08577344]\n",
      " [ 0.12773165]]\n",
      "Iteration 3724 | Cost: 0.3722069391892967 | Gradient: [[ 0.02741868]\n",
      " [-0.08575676]\n",
      " [ 0.12772298]]\n",
      "Iteration 3725 | Cost: 0.3721825212337823 | Gradient: [[ 0.02742283]\n",
      " [-0.0857401 ]\n",
      " [ 0.12771431]]\n",
      "Iteration 3726 | Cost: 0.3721581081217783 | Gradient: [[ 0.02742697]\n",
      " [-0.08572345]\n",
      " [ 0.12770564]]\n",
      "Iteration 3727 | Cost: 0.37213369985138184 | Gradient: [[ 0.02743112]\n",
      " [-0.08570681]\n",
      " [ 0.12769697]]\n",
      "Iteration 3728 | Cost: 0.3721092964206917 | Gradient: [[ 0.02743526]\n",
      " [-0.08569018]\n",
      " [ 0.1276883 ]]\n",
      "Iteration 3729 | Cost: 0.37208489782780857 | Gradient: [[ 0.02743939]\n",
      " [-0.08567356]\n",
      " [ 0.12767963]]\n",
      "Iteration 3730 | Cost: 0.3720605040708344 | Gradient: [[ 0.02744352]\n",
      " [-0.08565694]\n",
      " [ 0.12767095]]\n",
      "Iteration 3731 | Cost: 0.37203611514787316 | Gradient: [[ 0.02744765]\n",
      " [-0.08564034]\n",
      " [ 0.12766228]]\n",
      "Iteration 3732 | Cost: 0.37201173105703006 | Gradient: [[ 0.02745177]\n",
      " [-0.08562375]\n",
      " [ 0.1276536 ]]\n",
      "Iteration 3733 | Cost: 0.3719873517964122 | Gradient: [[ 0.02745589]\n",
      " [-0.08560716]\n",
      " [ 0.12764492]]\n",
      "Iteration 3734 | Cost: 0.37196297736412803 | Gradient: [[ 0.02746   ]\n",
      " [-0.08559059]\n",
      " [ 0.12763625]]\n",
      "Iteration 3735 | Cost: 0.37193860775828813 | Gradient: [[ 0.02746412]\n",
      " [-0.08557403]\n",
      " [ 0.12762757]]\n",
      "Iteration 3736 | Cost: 0.37191424297700404 | Gradient: [[ 0.02746822]\n",
      " [-0.08555747]\n",
      " [ 0.12761889]]\n",
      "Iteration 3737 | Cost: 0.3718898830183894 | Gradient: [[ 0.02747232]\n",
      " [-0.08554093]\n",
      " [ 0.1276102 ]]\n",
      "Iteration 3738 | Cost: 0.371865527880559 | Gradient: [[ 0.02747642]\n",
      " [-0.08552439]\n",
      " [ 0.12760152]]\n",
      "Iteration 3739 | Cost: 0.3718411775616299 | Gradient: [[ 0.02748052]\n",
      " [-0.08550787]\n",
      " [ 0.12759284]]\n",
      "Iteration 3740 | Cost: 0.37181683205972005 | Gradient: [[ 0.02748461]\n",
      " [-0.08549135]\n",
      " [ 0.12758415]]\n",
      "Iteration 3741 | Cost: 0.37179249137294956 | Gradient: [[ 0.02748869]\n",
      " [-0.08547484]\n",
      " [ 0.12757547]]\n",
      "Iteration 3742 | Cost: 0.37176815549943976 | Gradient: [[ 0.02749278]\n",
      " [-0.08545835]\n",
      " [ 0.12756678]]\n",
      "Iteration 3743 | Cost: 0.3717438244373137 | Gradient: [[ 0.02749685]\n",
      " [-0.08544186]\n",
      " [ 0.12755809]]\n",
      "Iteration 3744 | Cost: 0.37171949818469613 | Gradient: [[ 0.02750093]\n",
      " [-0.08542538]\n",
      " [ 0.1275494 ]]\n",
      "Iteration 3745 | Cost: 0.3716951767397133 | Gradient: [[ 0.027505  ]\n",
      " [-0.08540891]\n",
      " [ 0.12754071]]\n",
      "Iteration 3746 | Cost: 0.3716708601004931 | Gradient: [[ 0.02750907]\n",
      " [-0.08539246]\n",
      " [ 0.12753202]]\n",
      "Iteration 3747 | Cost: 0.37164654826516486 | Gradient: [[ 0.02751313]\n",
      " [-0.08537601]\n",
      " [ 0.12752333]]\n",
      "Iteration 3748 | Cost: 0.37162224123185966 | Gradient: [[ 0.02751719]\n",
      " [-0.08535957]\n",
      " [ 0.12751463]]\n",
      "Iteration 3749 | Cost: 0.37159793899871013 | Gradient: [[ 0.02752124]\n",
      " [-0.08534314]\n",
      " [ 0.12750594]]\n",
      "Iteration 3750 | Cost: 0.3715736415638505 | Gradient: [[ 0.02752529]\n",
      " [-0.08532672]\n",
      " [ 0.12749724]]\n",
      "Iteration 3751 | Cost: 0.3715493489254164 | Gradient: [[ 0.02752934]\n",
      " [-0.08531031]\n",
      " [ 0.12748855]]\n",
      "Iteration 3752 | Cost: 0.37152506108154537 | Gradient: [[ 0.02753338]\n",
      " [-0.08529391]\n",
      " [ 0.12747985]]\n",
      "Iteration 3753 | Cost: 0.3715007780303761 | Gradient: [[ 0.02753742]\n",
      " [-0.08527752]\n",
      " [ 0.12747115]]\n",
      "Iteration 3754 | Cost: 0.3714764997700494 | Gradient: [[ 0.02754145]\n",
      " [-0.08526113]\n",
      " [ 0.12746245]]\n",
      "Iteration 3755 | Cost: 0.3714522262987071 | Gradient: [[ 0.02754548]\n",
      " [-0.08524476]\n",
      " [ 0.12745375]]\n",
      "Iteration 3756 | Cost: 0.3714279576144929 | Gradient: [[ 0.02754951]\n",
      " [-0.0852284 ]\n",
      " [ 0.12744505]]\n",
      "Iteration 3757 | Cost: 0.371403693715552 | Gradient: [[ 0.02755353]\n",
      " [-0.08521204]\n",
      " [ 0.12743634]]\n",
      "Iteration 3758 | Cost: 0.37137943460003126 | Gradient: [[ 0.02755755]\n",
      " [-0.0851957 ]\n",
      " [ 0.12742764]]\n",
      "Iteration 3759 | Cost: 0.37135518026607883 | Gradient: [[ 0.02756156]\n",
      " [-0.08517937]\n",
      " [ 0.12741893]]\n",
      "Iteration 3760 | Cost: 0.37133093071184475 | Gradient: [[ 0.02756557]\n",
      " [-0.08516304]\n",
      " [ 0.12741023]]\n",
      "Iteration 3761 | Cost: 0.3713066859354805 | Gradient: [[ 0.02756958]\n",
      " [-0.08514673]\n",
      " [ 0.12740152]]\n",
      "Iteration 3762 | Cost: 0.371282445935139 | Gradient: [[ 0.02757358]\n",
      " [-0.08513042]\n",
      " [ 0.12739281]]\n",
      "Iteration 3763 | Cost: 0.3712582107089749 | Gradient: [[ 0.02757758]\n",
      " [-0.08511412]\n",
      " [ 0.1273841 ]]\n",
      "Iteration 3764 | Cost: 0.3712339802551442 | Gradient: [[ 0.02758157]\n",
      " [-0.08509784]\n",
      " [ 0.12737539]]\n",
      "Iteration 3765 | Cost: 0.37120975457180466 | Gradient: [[ 0.02758556]\n",
      " [-0.08508156]\n",
      " [ 0.12736668]]\n",
      "Iteration 3766 | Cost: 0.3711855336571154 | Gradient: [[ 0.02758955]\n",
      " [-0.08506529]\n",
      " [ 0.12735797]]\n",
      "Iteration 3767 | Cost: 0.37116131750923725 | Gradient: [[ 0.02759353]\n",
      " [-0.08504903]\n",
      " [ 0.12734926]]\n",
      "Iteration 3768 | Cost: 0.3711371061263326 | Gradient: [[ 0.02759751]\n",
      " [-0.08503278]\n",
      " [ 0.12734054]]\n",
      "Iteration 3769 | Cost: 0.3711128995065651 | Gradient: [[ 0.02760149]\n",
      " [-0.08501654]\n",
      " [ 0.12733183]]\n",
      "Iteration 3770 | Cost: 0.3710886976481003 | Gradient: [[ 0.02760546]\n",
      " [-0.08500031]\n",
      " [ 0.12732311]]\n",
      "Iteration 3771 | Cost: 0.37106450054910517 | Gradient: [[ 0.02760943]\n",
      " [-0.08498409]\n",
      " [ 0.12731439]]\n",
      "Iteration 3772 | Cost: 0.3710403082077479 | Gradient: [[ 0.02761339]\n",
      " [-0.08496788]\n",
      " [ 0.12730567]]\n",
      "Iteration 3773 | Cost: 0.3710161206221987 | Gradient: [[ 0.02761735]\n",
      " [-0.08495167]\n",
      " [ 0.12729696]]\n",
      "Iteration 3774 | Cost: 0.37099193779062906 | Gradient: [[ 0.0276213 ]\n",
      " [-0.08493548]\n",
      " [ 0.12728824]]\n",
      "Iteration 3775 | Cost: 0.37096775971121193 | Gradient: [[ 0.02762525]\n",
      " [-0.0849193 ]\n",
      " [ 0.12727951]]\n",
      "Iteration 3776 | Cost: 0.37094358638212205 | Gradient: [[ 0.0276292 ]\n",
      " [-0.08490312]\n",
      " [ 0.12727079]]\n",
      "Iteration 3777 | Cost: 0.3709194178015354 | Gradient: [[ 0.02763314]\n",
      " [-0.08488696]\n",
      " [ 0.12726207]]\n",
      "Iteration 3778 | Cost: 0.3708952539676296 | Gradient: [[ 0.02763708]\n",
      " [-0.0848708 ]\n",
      " [ 0.12725334]]\n",
      "Iteration 3779 | Cost: 0.37087109487858394 | Gradient: [[ 0.02764102]\n",
      " [-0.08485466]\n",
      " [ 0.12724462]]\n",
      "Iteration 3780 | Cost: 0.370846940532579 | Gradient: [[ 0.02764495]\n",
      " [-0.08483852]\n",
      " [ 0.12723589]]\n",
      "Iteration 3781 | Cost: 0.37082279092779696 | Gradient: [[ 0.02764888]\n",
      " [-0.08482239]\n",
      " [ 0.12722716]]\n",
      "Iteration 3782 | Cost: 0.37079864606242147 | Gradient: [[ 0.0276528 ]\n",
      " [-0.08480627]\n",
      " [ 0.12721844]]\n",
      "Iteration 3783 | Cost: 0.37077450593463784 | Gradient: [[ 0.02765672]\n",
      " [-0.08479016]\n",
      " [ 0.12720971]]\n",
      "Iteration 3784 | Cost: 0.3707503705426327 | Gradient: [[ 0.02766064]\n",
      " [-0.08477406]\n",
      " [ 0.12720098]]\n",
      "Iteration 3785 | Cost: 0.3707262398845943 | Gradient: [[ 0.02766455]\n",
      " [-0.08475797]\n",
      " [ 0.12719225]]\n",
      "Iteration 3786 | Cost: 0.37070211395871244 | Gradient: [[ 0.02766846]\n",
      " [-0.08474189]\n",
      " [ 0.12718351]]\n",
      "Iteration 3787 | Cost: 0.37067799276317837 | Gradient: [[ 0.02767236]\n",
      " [-0.08472582]\n",
      " [ 0.12717478]]\n",
      "Iteration 3788 | Cost: 0.3706538762961846 | Gradient: [[ 0.02767626]\n",
      " [-0.08470976]\n",
      " [ 0.12716605]]\n",
      "Iteration 3789 | Cost: 0.37062976455592583 | Gradient: [[ 0.02768016]\n",
      " [-0.0846937 ]\n",
      " [ 0.12715731]]\n",
      "Iteration 3790 | Cost: 0.37060565754059743 | Gradient: [[ 0.02768405]\n",
      " [-0.08467766]\n",
      " [ 0.12714857]]\n",
      "Iteration 3791 | Cost: 0.37058155524839675 | Gradient: [[ 0.02768794]\n",
      " [-0.08466162]\n",
      " [ 0.12713984]]\n",
      "Iteration 3792 | Cost: 0.37055745767752246 | Gradient: [[ 0.02769183]\n",
      " [-0.0846456 ]\n",
      " [ 0.1271311 ]]\n",
      "Iteration 3793 | Cost: 0.37053336482617494 | Gradient: [[ 0.02769571]\n",
      " [-0.08462958]\n",
      " [ 0.12712236]]\n",
      "Iteration 3794 | Cost: 0.3705092766925558 | Gradient: [[ 0.02769959]\n",
      " [-0.08461357]\n",
      " [ 0.12711362]]\n",
      "Iteration 3795 | Cost: 0.3704851932748683 | Gradient: [[ 0.02770346]\n",
      " [-0.08459758]\n",
      " [ 0.12710488]]\n",
      "Iteration 3796 | Cost: 0.370461114571317 | Gradient: [[ 0.02770733]\n",
      " [-0.08458159]\n",
      " [ 0.12709614]]\n",
      "Iteration 3797 | Cost: 0.37043704058010823 | Gradient: [[ 0.02771119]\n",
      " [-0.08456561]\n",
      " [ 0.12708739]]\n",
      "Iteration 3798 | Cost: 0.3704129712994496 | Gradient: [[ 0.02771506]\n",
      " [-0.08454964]\n",
      " [ 0.12707865]]\n",
      "Iteration 3799 | Cost: 0.3703889067275503 | Gradient: [[ 0.02771891]\n",
      " [-0.08453368]\n",
      " [ 0.12706991]]\n",
      "Iteration 3800 | Cost: 0.3703648468626209 | Gradient: [[ 0.02772277]\n",
      " [-0.08451772]\n",
      " [ 0.12706116]]\n",
      "Iteration 3801 | Cost: 0.3703407917028734 | Gradient: [[ 0.02772662]\n",
      " [-0.08450178]\n",
      " [ 0.12705241]]\n",
      "Iteration 3802 | Cost: 0.3703167412465214 | Gradient: [[ 0.02773047]\n",
      " [-0.08448585]\n",
      " [ 0.12704367]]\n",
      "Iteration 3803 | Cost: 0.3702926954917801 | Gradient: [[ 0.02773431]\n",
      " [-0.08446992]\n",
      " [ 0.12703492]]\n",
      "Iteration 3804 | Cost: 0.37026865443686596 | Gradient: [[ 0.02773815]\n",
      " [-0.08445401]\n",
      " [ 0.12702617]]\n",
      "Iteration 3805 | Cost: 0.3702446180799969 | Gradient: [[ 0.02774198]\n",
      " [-0.0844381 ]\n",
      " [ 0.12701742]]\n",
      "Iteration 3806 | Cost: 0.37022058641939243 | Gradient: [[ 0.02774581]\n",
      " [-0.0844222 ]\n",
      " [ 0.12700867]]\n",
      "Iteration 3807 | Cost: 0.37019655945327334 | Gradient: [[ 0.02774964]\n",
      " [-0.08440631]\n",
      " [ 0.12699991]]\n",
      "Iteration 3808 | Cost: 0.3701725371798621 | Gradient: [[ 0.02775346]\n",
      " [-0.08439044]\n",
      " [ 0.12699116]]\n",
      "Iteration 3809 | Cost: 0.3701485195973826 | Gradient: [[ 0.02775728]\n",
      " [-0.08437457]\n",
      " [ 0.12698241]]\n",
      "Iteration 3810 | Cost: 0.37012450670405994 | Gradient: [[ 0.0277611 ]\n",
      " [-0.0843587 ]\n",
      " [ 0.12697365]]\n",
      "Iteration 3811 | Cost: 0.37010049849812104 | Gradient: [[ 0.02776491]\n",
      " [-0.08434285]\n",
      " [ 0.12696489]]\n",
      "Iteration 3812 | Cost: 0.37007649497779416 | Gradient: [[ 0.02776872]\n",
      " [-0.08432701]\n",
      " [ 0.12695614]]\n",
      "Iteration 3813 | Cost: 0.3700524961413089 | Gradient: [[ 0.02777253]\n",
      " [-0.08431118]\n",
      " [ 0.12694738]]\n",
      "Iteration 3814 | Cost: 0.3700285019868962 | Gradient: [[ 0.02777633]\n",
      " [-0.08429535]\n",
      " [ 0.12693862]]\n",
      "Iteration 3815 | Cost: 0.37000451251278876 | Gradient: [[ 0.02778012]\n",
      " [-0.08427954]\n",
      " [ 0.12692986]]\n",
      "Iteration 3816 | Cost: 0.3699805277172206 | Gradient: [[ 0.02778392]\n",
      " [-0.08426373]\n",
      " [ 0.1269211 ]]\n",
      "Iteration 3817 | Cost: 0.3699565475984273 | Gradient: [[ 0.02778771]\n",
      " [-0.08424793]\n",
      " [ 0.12691234]]\n",
      "Iteration 3818 | Cost: 0.36993257215464553 | Gradient: [[ 0.02779149]\n",
      " [-0.08423214]\n",
      " [ 0.12690358]]\n",
      "Iteration 3819 | Cost: 0.3699086013841136 | Gradient: [[ 0.02779527]\n",
      " [-0.08421637]\n",
      " [ 0.12689481]]\n",
      "Iteration 3820 | Cost: 0.3698846352850715 | Gradient: [[ 0.02779905]\n",
      " [-0.0842006 ]\n",
      " [ 0.12688605]]\n",
      "Iteration 3821 | Cost: 0.3698606738557604 | Gradient: [[ 0.02780283]\n",
      " [-0.08418483]\n",
      " [ 0.12687728]]\n",
      "Iteration 3822 | Cost: 0.3698367170944228 | Gradient: [[ 0.0278066 ]\n",
      " [-0.08416908]\n",
      " [ 0.12686852]]\n",
      "Iteration 3823 | Cost: 0.3698127649993029 | Gradient: [[ 0.02781036]\n",
      " [-0.08415334]\n",
      " [ 0.12685975]]\n",
      "Iteration 3824 | Cost: 0.36978881756864623 | Gradient: [[ 0.02781413]\n",
      " [-0.0841376 ]\n",
      " [ 0.12685098]]\n",
      "Iteration 3825 | Cost: 0.3697648748006996 | Gradient: [[ 0.02781788]\n",
      " [-0.08412188]\n",
      " [ 0.12684221]]\n",
      "Iteration 3826 | Cost: 0.36974093669371155 | Gradient: [[ 0.02782164]\n",
      " [-0.08410616]\n",
      " [ 0.12683344]]\n",
      "Iteration 3827 | Cost: 0.36971700324593176 | Gradient: [[ 0.02782539]\n",
      " [-0.08409046]\n",
      " [ 0.12682467]]\n",
      "Iteration 3828 | Cost: 0.3696930744556115 | Gradient: [[ 0.02782914]\n",
      " [-0.08407476]\n",
      " [ 0.1268159 ]]\n",
      "Iteration 3829 | Cost: 0.3696691503210035 | Gradient: [[ 0.02783288]\n",
      " [-0.08405907]\n",
      " [ 0.12680713]]\n",
      "Iteration 3830 | Cost: 0.3696452308403617 | Gradient: [[ 0.02783662]\n",
      " [-0.08404339]\n",
      " [ 0.12679835]]\n",
      "Iteration 3831 | Cost: 0.36962131601194154 | Gradient: [[ 0.02784036]\n",
      " [-0.08402772]\n",
      " [ 0.12678958]]\n",
      "Iteration 3832 | Cost: 0.36959740583400014 | Gradient: [[ 0.02784409]\n",
      " [-0.08401205]\n",
      " [ 0.1267808 ]]\n",
      "Iteration 3833 | Cost: 0.3695735003047956 | Gradient: [[ 0.02784782]\n",
      " [-0.0839964 ]\n",
      " [ 0.12677203]]\n",
      "Iteration 3834 | Cost: 0.36954959942258775 | Gradient: [[ 0.02785155]\n",
      " [-0.08398076]\n",
      " [ 0.12676325]]\n",
      "Iteration 3835 | Cost: 0.36952570318563766 | Gradient: [[ 0.02785527]\n",
      " [-0.08396512]\n",
      " [ 0.12675447]]\n",
      "Iteration 3836 | Cost: 0.36950181159220796 | Gradient: [[ 0.02785899]\n",
      " [-0.08394949]\n",
      " [ 0.12674569]]\n",
      "Iteration 3837 | Cost: 0.36947792464056256 | Gradient: [[ 0.0278627 ]\n",
      " [-0.08393388]\n",
      " [ 0.12673691]]\n",
      "Iteration 3838 | Cost: 0.36945404232896695 | Gradient: [[ 0.02786641]\n",
      " [-0.08391827]\n",
      " [ 0.12672813]]\n",
      "Iteration 3839 | Cost: 0.36943016465568757 | Gradient: [[ 0.02787012]\n",
      " [-0.08390267]\n",
      " [ 0.12671935]]\n",
      "Iteration 3840 | Cost: 0.3694062916189929 | Gradient: [[ 0.02787382]\n",
      " [-0.08388708]\n",
      " [ 0.12671057]]\n",
      "Iteration 3841 | Cost: 0.36938242321715237 | Gradient: [[ 0.02787752]\n",
      " [-0.08387149]\n",
      " [ 0.12670179]]\n",
      "Iteration 3842 | Cost: 0.369358559448437 | Gradient: [[ 0.02788122]\n",
      " [-0.08385592]\n",
      " [ 0.126693  ]]\n",
      "Iteration 3843 | Cost: 0.3693347003111191 | Gradient: [[ 0.02788491]\n",
      " [-0.08384036]\n",
      " [ 0.12668422]]\n",
      "Iteration 3844 | Cost: 0.36931084580347245 | Gradient: [[ 0.0278886 ]\n",
      " [-0.0838248 ]\n",
      " [ 0.12667543]]\n",
      "Iteration 3845 | Cost: 0.36928699592377223 | Gradient: [[ 0.02789228]\n",
      " [-0.08380925]\n",
      " [ 0.12666665]]\n",
      "Iteration 3846 | Cost: 0.36926315067029486 | Gradient: [[ 0.02789596]\n",
      " [-0.08379372]\n",
      " [ 0.12665786]]\n",
      "Iteration 3847 | Cost: 0.3692393100413184 | Gradient: [[ 0.02789964]\n",
      " [-0.08377819]\n",
      " [ 0.12664907]]\n",
      "Iteration 3848 | Cost: 0.36921547403512206 | Gradient: [[ 0.02790331]\n",
      " [-0.08376267]\n",
      " [ 0.12664028]]\n",
      "Iteration 3849 | Cost: 0.36919164264998655 | Gradient: [[ 0.02790698]\n",
      " [-0.08374716]\n",
      " [ 0.12663149]]\n",
      "Iteration 3850 | Cost: 0.369167815884194 | Gradient: [[ 0.02791065]\n",
      " [-0.08373165]\n",
      " [ 0.1266227 ]]\n",
      "Iteration 3851 | Cost: 0.36914399373602796 | Gradient: [[ 0.02791431]\n",
      " [-0.08371616]\n",
      " [ 0.12661391]]\n",
      "Iteration 3852 | Cost: 0.36912017620377297 | Gradient: [[ 0.02791797]\n",
      " [-0.08370067]\n",
      " [ 0.12660512]]\n",
      "Iteration 3853 | Cost: 0.36909636328571555 | Gradient: [[ 0.02792162]\n",
      " [-0.0836852 ]\n",
      " [ 0.12659632]]\n",
      "Iteration 3854 | Cost: 0.36907255498014313 | Gradient: [[ 0.02792528]\n",
      " [-0.08366973]\n",
      " [ 0.12658753]]\n",
      "Iteration 3855 | Cost: 0.36904875128534487 | Gradient: [[ 0.02792892]\n",
      " [-0.08365427]\n",
      " [ 0.12657873]]\n",
      "Iteration 3856 | Cost: 0.3690249521996108 | Gradient: [[ 0.02793257]\n",
      " [-0.08363882]\n",
      " [ 0.12656994]]\n",
      "Iteration 3857 | Cost: 0.3690011577212329 | Gradient: [[ 0.02793621]\n",
      " [-0.08362338]\n",
      " [ 0.12656114]]\n",
      "Iteration 3858 | Cost: 0.3689773678485041 | Gradient: [[ 0.02793984]\n",
      " [-0.08360795]\n",
      " [ 0.12655234]]\n",
      "Iteration 3859 | Cost: 0.3689535825797189 | Gradient: [[ 0.02794348]\n",
      " [-0.08359253]\n",
      " [ 0.12654354]]\n",
      "Iteration 3860 | Cost: 0.36892980191317315 | Gradient: [[ 0.02794711]\n",
      " [-0.08357711]\n",
      " [ 0.12653474]]\n",
      "Iteration 3861 | Cost: 0.368906025847164 | Gradient: [[ 0.02795073]\n",
      " [-0.08356171]\n",
      " [ 0.12652594]]\n",
      "Iteration 3862 | Cost: 0.36888225437998984 | Gradient: [[ 0.02795435]\n",
      " [-0.08354631]\n",
      " [ 0.12651714]]\n",
      "Iteration 3863 | Cost: 0.36885848750995087 | Gradient: [[ 0.02795797]\n",
      " [-0.08353092]\n",
      " [ 0.12650834]]\n",
      "Iteration 3864 | Cost: 0.36883472523534805 | Gradient: [[ 0.02796159]\n",
      " [-0.08351554]\n",
      " [ 0.12649954]]\n",
      "Iteration 3865 | Cost: 0.3688109675544841 | Gradient: [[ 0.0279652 ]\n",
      " [-0.08350017]\n",
      " [ 0.12649074]]\n",
      "Iteration 3866 | Cost: 0.368787214465663 | Gradient: [[ 0.02796881]\n",
      " [-0.08348481]\n",
      " [ 0.12648193]]\n",
      "Iteration 3867 | Cost: 0.36876346596719006 | Gradient: [[ 0.02797241]\n",
      " [-0.08346945]\n",
      " [ 0.12647313]]\n",
      "Iteration 3868 | Cost: 0.36873972205737204 | Gradient: [[ 0.02797601]\n",
      " [-0.08345411]\n",
      " [ 0.12646432]]\n",
      "Iteration 3869 | Cost: 0.3687159827345167 | Gradient: [[ 0.02797961]\n",
      " [-0.08343877]\n",
      " [ 0.12645551]]\n",
      "Iteration 3870 | Cost: 0.3686922479969337 | Gradient: [[ 0.0279832 ]\n",
      " [-0.08342344]\n",
      " [ 0.12644671]]\n",
      "Iteration 3871 | Cost: 0.36866851784293353 | Gradient: [[ 0.02798679]\n",
      " [-0.08340812]\n",
      " [ 0.1264379 ]]\n",
      "Iteration 3872 | Cost: 0.36864479227082836 | Gradient: [[ 0.02799037]\n",
      " [-0.08339281]\n",
      " [ 0.12642909]]\n",
      "Iteration 3873 | Cost: 0.36862107127893146 | Gradient: [[ 0.02799395]\n",
      " [-0.08337751]\n",
      " [ 0.12642028]]\n",
      "Iteration 3874 | Cost: 0.3685973548655577 | Gradient: [[ 0.02799753]\n",
      " [-0.08336222]\n",
      " [ 0.12641147]]\n",
      "Iteration 3875 | Cost: 0.3685736430290233 | Gradient: [[ 0.02800111]\n",
      " [-0.08334693]\n",
      " [ 0.12640266]]\n",
      "Iteration 3876 | Cost: 0.36854993576764516 | Gradient: [[ 0.02800468]\n",
      " [-0.08333166]\n",
      " [ 0.12639384]]\n",
      "Iteration 3877 | Cost: 0.36852623307974247 | Gradient: [[ 0.02800825]\n",
      " [-0.08331639]\n",
      " [ 0.12638503]]\n",
      "Iteration 3878 | Cost: 0.3685025349636351 | Gradient: [[ 0.02801181]\n",
      " [-0.08330113]\n",
      " [ 0.12637622]]\n",
      "Iteration 3879 | Cost: 0.36847884141764464 | Gradient: [[ 0.02801537]\n",
      " [-0.08328588]\n",
      " [ 0.1263674 ]]\n",
      "Iteration 3880 | Cost: 0.36845515244009364 | Gradient: [[ 0.02801893]\n",
      " [-0.08327064]\n",
      " [ 0.12635859]]\n",
      "Iteration 3881 | Cost: 0.3684314680293062 | Gradient: [[ 0.02802248]\n",
      " [-0.08325541]\n",
      " [ 0.12634977]]\n",
      "Iteration 3882 | Cost: 0.3684077881836078 | Gradient: [[ 0.02802603]\n",
      " [-0.08324019]\n",
      " [ 0.12634095]]\n",
      "Iteration 3883 | Cost: 0.36838411290132517 | Gradient: [[ 0.02802958]\n",
      " [-0.08322497]\n",
      " [ 0.12633213]]\n",
      "Iteration 3884 | Cost: 0.3683604421807862 | Gradient: [[ 0.02803312]\n",
      " [-0.08320976]\n",
      " [ 0.12632331]]\n",
      "Iteration 3885 | Cost: 0.36833677602032033 | Gradient: [[ 0.02803666]\n",
      " [-0.08319457]\n",
      " [ 0.12631449]]\n",
      "Iteration 3886 | Cost: 0.36831311441825826 | Gradient: [[ 0.02804019]\n",
      " [-0.08317938]\n",
      " [ 0.12630567]]\n",
      "Iteration 3887 | Cost: 0.3682894573729319 | Gradient: [[ 0.02804372]\n",
      " [-0.08316419]\n",
      " [ 0.12629685]]\n",
      "Iteration 3888 | Cost: 0.3682658048826747 | Gradient: [[ 0.02804725]\n",
      " [-0.08314902]\n",
      " [ 0.12628803]]\n",
      "Iteration 3889 | Cost: 0.3682421569458211 | Gradient: [[ 0.02805078]\n",
      " [-0.08313386]\n",
      " [ 0.12627921]]\n",
      "Iteration 3890 | Cost: 0.3682185135607073 | Gradient: [[ 0.0280543 ]\n",
      " [-0.0831187 ]\n",
      " [ 0.12627038]]\n",
      "Iteration 3891 | Cost: 0.36819487472567025 | Gradient: [[ 0.02805781]\n",
      " [-0.08310356]\n",
      " [ 0.12626156]]\n",
      "Iteration 3892 | Cost: 0.3681712404390487 | Gradient: [[ 0.02806133]\n",
      " [-0.08308842]\n",
      " [ 0.12625274]]\n",
      "Iteration 3893 | Cost: 0.36814761069918245 | Gradient: [[ 0.02806484]\n",
      " [-0.08307329]\n",
      " [ 0.12624391]]\n",
      "Iteration 3894 | Cost: 0.3681239855044128 | Gradient: [[ 0.02806834]\n",
      " [-0.08305817]\n",
      " [ 0.12623508]]\n",
      "Iteration 3895 | Cost: 0.36810036485308195 | Gradient: [[ 0.02807185]\n",
      " [-0.08304305]\n",
      " [ 0.12622626]]\n",
      "Iteration 3896 | Cost: 0.3680767487435339 | Gradient: [[ 0.02807535]\n",
      " [-0.08302795]\n",
      " [ 0.12621743]]\n",
      "Iteration 3897 | Cost: 0.36805313717411364 | Gradient: [[ 0.02807884]\n",
      " [-0.08301285]\n",
      " [ 0.1262086 ]]\n",
      "Iteration 3898 | Cost: 0.3680295301431676 | Gradient: [[ 0.02808233]\n",
      " [-0.08299777]\n",
      " [ 0.12619977]]\n",
      "Iteration 3899 | Cost: 0.3680059276490434 | Gradient: [[ 0.02808582]\n",
      " [-0.08298269]\n",
      " [ 0.12619094]]\n",
      "Iteration 3900 | Cost: 0.36798232969009 | Gradient: [[ 0.02808931]\n",
      " [-0.08296762]\n",
      " [ 0.12618211]]\n",
      "Iteration 3901 | Cost: 0.3679587362646575 | Gradient: [[ 0.02809279]\n",
      " [-0.08295255]\n",
      " [ 0.12617327]]\n",
      "Iteration 3902 | Cost: 0.3679351473710979 | Gradient: [[ 0.02809627]\n",
      " [-0.0829375 ]\n",
      " [ 0.12616444]]\n",
      "Iteration 3903 | Cost: 0.3679115630077637 | Gradient: [[ 0.02809974]\n",
      " [-0.08292246]\n",
      " [ 0.12615561]]\n",
      "Iteration 3904 | Cost: 0.367887983173009 | Gradient: [[ 0.02810321]\n",
      " [-0.08290742]\n",
      " [ 0.12614677]]\n",
      "Iteration 3905 | Cost: 0.36786440786518937 | Gradient: [[ 0.02810668]\n",
      " [-0.08289239]\n",
      " [ 0.12613794]]\n",
      "Iteration 3906 | Cost: 0.3678408370826615 | Gradient: [[ 0.02811015]\n",
      " [-0.08287737]\n",
      " [ 0.1261291 ]]\n",
      "Iteration 3907 | Cost: 0.36781727082378335 | Gradient: [[ 0.02811361]\n",
      " [-0.08286236]\n",
      " [ 0.12612027]]\n",
      "Iteration 3908 | Cost: 0.36779370908691406 | Gradient: [[ 0.02811706]\n",
      " [-0.08284736]\n",
      " [ 0.12611143]]\n",
      "Iteration 3909 | Cost: 0.3677701518704144 | Gradient: [[ 0.02812052]\n",
      " [-0.08283236]\n",
      " [ 0.12610259]]\n",
      "Iteration 3910 | Cost: 0.367746599172646 | Gradient: [[ 0.02812397]\n",
      " [-0.08281738]\n",
      " [ 0.12609375]]\n",
      "Iteration 3911 | Cost: 0.3677230509919721 | Gradient: [[ 0.02812741]\n",
      " [-0.0828024 ]\n",
      " [ 0.12608491]]\n",
      "Iteration 3912 | Cost: 0.36769950732675705 | Gradient: [[ 0.02813086]\n",
      " [-0.08278743]\n",
      " [ 0.12607607]]\n",
      "Iteration 3913 | Cost: 0.3676759681753664 | Gradient: [[ 0.0281343 ]\n",
      " [-0.08277247]\n",
      " [ 0.12606723]]\n",
      "Iteration 3914 | Cost: 0.3676524335361672 | Gradient: [[ 0.02813773]\n",
      " [-0.08275752]\n",
      " [ 0.12605839]]\n",
      "Iteration 3915 | Cost: 0.3676289034075276 | Gradient: [[ 0.02814116]\n",
      " [-0.08274257]\n",
      " [ 0.12604955]]\n",
      "Iteration 3916 | Cost: 0.36760537778781704 | Gradient: [[ 0.02814459]\n",
      " [-0.08272764]\n",
      " [ 0.1260407 ]]\n",
      "Iteration 3917 | Cost: 0.3675818566754062 | Gradient: [[ 0.02814802]\n",
      " [-0.08271271]\n",
      " [ 0.12603186]]\n",
      "Iteration 3918 | Cost: 0.3675583400686672 | Gradient: [[ 0.02815144]\n",
      " [-0.08269779]\n",
      " [ 0.12602301]]\n",
      "Iteration 3919 | Cost: 0.36753482796597337 | Gradient: [[ 0.02815486]\n",
      " [-0.08268288]\n",
      " [ 0.12601417]]\n",
      "Iteration 3920 | Cost: 0.367511320365699 | Gradient: [[ 0.02815827]\n",
      " [-0.08266798]\n",
      " [ 0.12600532]]\n",
      "Iteration 3921 | Cost: 0.36748781726621993 | Gradient: [[ 0.02816168]\n",
      " [-0.08265309]\n",
      " [ 0.12599648]]\n",
      "Iteration 3922 | Cost: 0.36746431866591317 | Gradient: [[ 0.02816509]\n",
      " [-0.0826382 ]\n",
      " [ 0.12598763]]\n",
      "Iteration 3923 | Cost: 0.36744082456315724 | Gradient: [[ 0.0281685 ]\n",
      " [-0.08262332]\n",
      " [ 0.12597878]]\n",
      "Iteration 3924 | Cost: 0.36741733495633155 | Gradient: [[ 0.0281719 ]\n",
      " [-0.08260845]\n",
      " [ 0.12596993]]\n",
      "Iteration 3925 | Cost: 0.36739384984381684 | Gradient: [[ 0.0281753 ]\n",
      " [-0.08259359]\n",
      " [ 0.12596108]]\n",
      "Iteration 3926 | Cost: 0.3673703692239952 | Gradient: [[ 0.02817869]\n",
      " [-0.08257874]\n",
      " [ 0.12595223]]\n",
      "Iteration 3927 | Cost: 0.36734689309525004 | Gradient: [[ 0.02818208]\n",
      " [-0.0825639 ]\n",
      " [ 0.12594338]]\n",
      "Iteration 3928 | Cost: 0.36732342145596575 | Gradient: [[ 0.02818547]\n",
      " [-0.08254906]\n",
      " [ 0.12593453]]\n",
      "Iteration 3929 | Cost: 0.3672999543045282 | Gradient: [[ 0.02818885]\n",
      " [-0.08253423]\n",
      " [ 0.12592567]]\n",
      "Iteration 3930 | Cost: 0.36727649163932463 | Gradient: [[ 0.02819223]\n",
      " [-0.08251941]\n",
      " [ 0.12591682]]\n",
      "Iteration 3931 | Cost: 0.36725303345874305 | Gradient: [[ 0.02819561]\n",
      " [-0.0825046 ]\n",
      " [ 0.12590797]]\n",
      "Iteration 3932 | Cost: 0.36722957976117304 | Gradient: [[ 0.02819898]\n",
      " [-0.0824898 ]\n",
      " [ 0.12589911]]\n",
      "Iteration 3933 | Cost: 0.3672061305450056 | Gradient: [[ 0.02820235]\n",
      " [-0.08247501]\n",
      " [ 0.12589026]]\n",
      "Iteration 3934 | Cost: 0.36718268580863256 | Gradient: [[ 0.02820572]\n",
      " [-0.08246022]\n",
      " [ 0.1258814 ]]\n",
      "Iteration 3935 | Cost: 0.36715924555044727 | Gradient: [[ 0.02820908]\n",
      " [-0.08244544]\n",
      " [ 0.12587254]]\n",
      "Iteration 3936 | Cost: 0.36713580976884413 | Gradient: [[ 0.02821244]\n",
      " [-0.08243067]\n",
      " [ 0.12586369]]\n",
      "Iteration 3937 | Cost: 0.367112378462219 | Gradient: [[ 0.0282158 ]\n",
      " [-0.08241591]\n",
      " [ 0.12585483]]\n",
      "Iteration 3938 | Cost: 0.36708895162896865 | Gradient: [[ 0.02821915]\n",
      " [-0.08240116]\n",
      " [ 0.12584597]]\n",
      "Iteration 3939 | Cost: 0.3670655292674915 | Gradient: [[ 0.0282225 ]\n",
      " [-0.08238641]\n",
      " [ 0.12583711]]\n",
      "Iteration 3940 | Cost: 0.3670421113761867 | Gradient: [[ 0.02822584]\n",
      " [-0.08237168]\n",
      " [ 0.12582825]]\n",
      "Iteration 3941 | Cost: 0.3670186979534551 | Gradient: [[ 0.02822919]\n",
      " [-0.08235695]\n",
      " [ 0.12581939]]\n",
      "Iteration 3942 | Cost: 0.3669952889976985 | Gradient: [[ 0.02823252]\n",
      " [-0.08234223]\n",
      " [ 0.12581053]]\n",
      "Iteration 3943 | Cost: 0.36697188450732005 | Gradient: [[ 0.02823586]\n",
      " [-0.08232752]\n",
      " [ 0.12580166]]\n",
      "Iteration 3944 | Cost: 0.36694848448072415 | Gradient: [[ 0.02823919]\n",
      " [-0.08231281]\n",
      " [ 0.1257928 ]]\n",
      "Iteration 3945 | Cost: 0.3669250889163162 | Gradient: [[ 0.02824252]\n",
      " [-0.08229812]\n",
      " [ 0.12578394]]\n",
      "Iteration 3946 | Cost: 0.3669016978125029 | Gradient: [[ 0.02824585]\n",
      " [-0.08228343]\n",
      " [ 0.12577507]]\n",
      "Iteration 3947 | Cost: 0.3668783111676925 | Gradient: [[ 0.02824917]\n",
      " [-0.08226875]\n",
      " [ 0.12576621]]\n",
      "Iteration 3948 | Cost: 0.3668549289802939 | Gradient: [[ 0.02825249]\n",
      " [-0.08225408]\n",
      " [ 0.12575734]]\n",
      "Iteration 3949 | Cost: 0.36683155124871786 | Gradient: [[ 0.0282558 ]\n",
      " [-0.08223942]\n",
      " [ 0.12574847]]\n",
      "Iteration 3950 | Cost: 0.3668081779713757 | Gradient: [[ 0.02825911]\n",
      " [-0.08222476]\n",
      " [ 0.12573961]]\n",
      "Iteration 3951 | Cost: 0.36678480914668043 | Gradient: [[ 0.02826242]\n",
      " [-0.08221012]\n",
      " [ 0.12573074]]\n",
      "Iteration 3952 | Cost: 0.3667614447730462 | Gradient: [[ 0.02826572]\n",
      " [-0.08219548]\n",
      " [ 0.12572187]]\n",
      "Iteration 3953 | Cost: 0.3667380848488879 | Gradient: [[ 0.02826903]\n",
      " [-0.08218085]\n",
      " [ 0.125713  ]]\n",
      "Iteration 3954 | Cost: 0.36671472937262234 | Gradient: [[ 0.02827232]\n",
      " [-0.08216622]\n",
      " [ 0.12570413]]\n",
      "Iteration 3955 | Cost: 0.3666913783426672 | Gradient: [[ 0.02827562]\n",
      " [-0.08215161]\n",
      " [ 0.12569526]]\n",
      "Iteration 3956 | Cost: 0.3666680317574412 | Gradient: [[ 0.02827891]\n",
      " [-0.082137  ]\n",
      " [ 0.12568639]]\n",
      "Iteration 3957 | Cost: 0.36664468961536456 | Gradient: [[ 0.0282822 ]\n",
      " [-0.08212241]\n",
      " [ 0.12567752]]\n",
      "Iteration 3958 | Cost: 0.36662135191485856 | Gradient: [[ 0.02828548]\n",
      " [-0.08210782]\n",
      " [ 0.12566864]]\n",
      "Iteration 3959 | Cost: 0.36659801865434555 | Gradient: [[ 0.02828876]\n",
      " [-0.08209324]\n",
      " [ 0.12565977]]\n",
      "Iteration 3960 | Cost: 0.3665746898322494 | Gradient: [[ 0.02829204]\n",
      " [-0.08207866]\n",
      " [ 0.1256509 ]]\n",
      "Iteration 3961 | Cost: 0.36655136544699485 | Gradient: [[ 0.02829531]\n",
      " [-0.0820641 ]\n",
      " [ 0.12564202]]\n",
      "Iteration 3962 | Cost: 0.36652804549700807 | Gradient: [[ 0.02829859]\n",
      " [-0.08204954]\n",
      " [ 0.12563315]]\n",
      "Iteration 3963 | Cost: 0.36650472998071637 | Gradient: [[ 0.02830185]\n",
      " [-0.08203499]\n",
      " [ 0.12562427]]\n",
      "Iteration 3964 | Cost: 0.3664814188965481 | Gradient: [[ 0.02830512]\n",
      " [-0.08202045]\n",
      " [ 0.1256154 ]]\n",
      "Iteration 3965 | Cost: 0.36645811224293307 | Gradient: [[ 0.02830838]\n",
      " [-0.08200591]\n",
      " [ 0.12560652]]\n",
      "Iteration 3966 | Cost: 0.36643481001830197 | Gradient: [[ 0.02831164]\n",
      " [-0.08199139]\n",
      " [ 0.12559764]]\n",
      "Iteration 3967 | Cost: 0.3664115122210869 | Gradient: [[ 0.02831489]\n",
      " [-0.08197687]\n",
      " [ 0.12558876]]\n",
      "Iteration 3968 | Cost: 0.36638821884972117 | Gradient: [[ 0.02831814]\n",
      " [-0.08196236]\n",
      " [ 0.12557988]]\n",
      "Iteration 3969 | Cost: 0.36636492990263914 | Gradient: [[ 0.02832139]\n",
      " [-0.08194786]\n",
      " [ 0.125571  ]]\n",
      "Iteration 3970 | Cost: 0.36634164537827635 | Gradient: [[ 0.02832463]\n",
      " [-0.08193337]\n",
      " [ 0.12556212]]\n",
      "Iteration 3971 | Cost: 0.3663183652750696 | Gradient: [[ 0.02832787]\n",
      " [-0.08191888]\n",
      " [ 0.12555324]]\n",
      "Iteration 3972 | Cost: 0.36629508959145685 | Gradient: [[ 0.02833111]\n",
      " [-0.08190441]\n",
      " [ 0.12554436]]\n",
      "Iteration 3973 | Cost: 0.36627181832587724 | Gradient: [[ 0.02833434]\n",
      " [-0.08188994]\n",
      " [ 0.12553548]]\n",
      "Iteration 3974 | Cost: 0.36624855147677104 | Gradient: [[ 0.02833757]\n",
      " [-0.08187548]\n",
      " [ 0.12552659]]\n",
      "Iteration 3975 | Cost: 0.3662252890425799 | Gradient: [[ 0.0283408 ]\n",
      " [-0.08186102]\n",
      " [ 0.12551771]]\n",
      "Iteration 3976 | Cost: 0.36620203102174625 | Gradient: [[ 0.02834402]\n",
      " [-0.08184658]\n",
      " [ 0.12550883]]\n",
      "Iteration 3977 | Cost: 0.3661787774127141 | Gradient: [[ 0.02834725]\n",
      " [-0.08183214]\n",
      " [ 0.12549994]]\n",
      "Iteration 3978 | Cost: 0.3661555282139283 | Gradient: [[ 0.02835046]\n",
      " [-0.08181771]\n",
      " [ 0.12549106]]\n",
      "Iteration 3979 | Cost: 0.36613228342383525 | Gradient: [[ 0.02835368]\n",
      " [-0.08180329]\n",
      " [ 0.12548217]]\n",
      "Iteration 3980 | Cost: 0.36610904304088215 | Gradient: [[ 0.02835689]\n",
      " [-0.08178888]\n",
      " [ 0.12547328]]\n",
      "Iteration 3981 | Cost: 0.36608580706351757 | Gradient: [[ 0.02836009]\n",
      " [-0.08177447]\n",
      " [ 0.1254644 ]]\n",
      "Iteration 3982 | Cost: 0.36606257549019106 | Gradient: [[ 0.0283633 ]\n",
      " [-0.08176008]\n",
      " [ 0.12545551]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3983 | Cost: 0.36603934831935353 | Gradient: [[ 0.0283665 ]\n",
      " [-0.08174569]\n",
      " [ 0.12544662]]\n",
      "Iteration 3984 | Cost: 0.36601612554945706 | Gradient: [[ 0.0283697 ]\n",
      " [-0.08173131]\n",
      " [ 0.12543773]]\n",
      "Iteration 3985 | Cost: 0.3659929071789548 | Gradient: [[ 0.02837289]\n",
      " [-0.08171693]\n",
      " [ 0.12542884]]\n",
      "Iteration 3986 | Cost: 0.3659696932063009 | Gradient: [[ 0.02837608]\n",
      " [-0.08170257]\n",
      " [ 0.12541995]]\n",
      "Iteration 3987 | Cost: 0.365946483629951 | Gradient: [[ 0.02837927]\n",
      " [-0.08168821]\n",
      " [ 0.12541106]]\n",
      "Iteration 3988 | Cost: 0.36592327844836187 | Gradient: [[ 0.02838245]\n",
      " [-0.08167386]\n",
      " [ 0.12540217]]\n",
      "Iteration 3989 | Cost: 0.3659000776599911 | Gradient: [[ 0.02838563]\n",
      " [-0.08165952]\n",
      " [ 0.12539327]]\n",
      "Iteration 3990 | Cost: 0.36587688126329765 | Gradient: [[ 0.02838881]\n",
      " [-0.08164518]\n",
      " [ 0.12538438]]\n",
      "Iteration 3991 | Cost: 0.3658536892567416 | Gradient: [[ 0.02839198]\n",
      " [-0.08163086]\n",
      " [ 0.12537549]]\n",
      "Iteration 3992 | Cost: 0.3658305016387845 | Gradient: [[ 0.02839516]\n",
      " [-0.08161654]\n",
      " [ 0.12536659]]\n",
      "Iteration 3993 | Cost: 0.3658073184078884 | Gradient: [[ 0.02839832]\n",
      " [-0.08160223]\n",
      " [ 0.1253577 ]]\n",
      "Iteration 3994 | Cost: 0.365784139562517 | Gradient: [[ 0.02840149]\n",
      " [-0.08158793]\n",
      " [ 0.1253488 ]]\n",
      "Iteration 3995 | Cost: 0.3657609651011349 | Gradient: [[ 0.02840465]\n",
      " [-0.08157363]\n",
      " [ 0.12533991]]\n",
      "Iteration 3996 | Cost: 0.36573779502220805 | Gradient: [[ 0.02840781]\n",
      " [-0.08155935]\n",
      " [ 0.12533101]]\n",
      "Iteration 3997 | Cost: 0.36571462932420346 | Gradient: [[ 0.02841096]\n",
      " [-0.08154507]\n",
      " [ 0.12532211]]\n",
      "Iteration 3998 | Cost: 0.3656914680055891 | Gradient: [[ 0.02841411]\n",
      " [-0.0815308 ]\n",
      " [ 0.12531322]]\n",
      "Iteration 3999 | Cost: 0.36566831106483444 | Gradient: [[ 0.02841726]\n",
      " [-0.08151654]\n",
      " [ 0.12530432]]\n",
      "Iteration 4000 | Cost: 0.3656451585004097 | Gradient: [[ 0.0284204 ]\n",
      " [-0.08150228]\n",
      " [ 0.12529542]]\n",
      "Iteration 4001 | Cost: 0.3656220103107865 | Gradient: [[ 0.02842355]\n",
      " [-0.08148803]\n",
      " [ 0.12528652]]\n",
      "Iteration 4002 | Cost: 0.3655988664944376 | Gradient: [[ 0.02842668]\n",
      " [-0.08147379]\n",
      " [ 0.12527762]]\n",
      "Iteration 4003 | Cost: 0.36557572704983676 | Gradient: [[ 0.02842982]\n",
      " [-0.08145956]\n",
      " [ 0.12526872]]\n",
      "Iteration 4004 | Cost: 0.36555259197545886 | Gradient: [[ 0.02843295]\n",
      " [-0.08144534]\n",
      " [ 0.12525982]]\n",
      "Iteration 4005 | Cost: 0.3655294612697801 | Gradient: [[ 0.02843608]\n",
      " [-0.08143112]\n",
      " [ 0.12525092]]\n",
      "Iteration 4006 | Cost: 0.36550633493127754 | Gradient: [[ 0.0284392 ]\n",
      " [-0.08141691]\n",
      " [ 0.12524201]]\n",
      "Iteration 4007 | Cost: 0.3654832129584297 | Gradient: [[ 0.02844233]\n",
      " [-0.08140271]\n",
      " [ 0.12523311]]\n",
      "Iteration 4008 | Cost: 0.36546009534971596 | Gradient: [[ 0.02844544]\n",
      " [-0.08138852]\n",
      " [ 0.12522421]]\n",
      "Iteration 4009 | Cost: 0.3654369821036169 | Gradient: [[ 0.02844856]\n",
      " [-0.08137434]\n",
      " [ 0.1252153 ]]\n",
      "Iteration 4010 | Cost: 0.3654138732186143 | Gradient: [[ 0.02845167]\n",
      " [-0.08136016]\n",
      " [ 0.1252064 ]]\n",
      "Iteration 4011 | Cost: 0.3653907686931909 | Gradient: [[ 0.02845478]\n",
      " [-0.08134599]\n",
      " [ 0.12519749]]\n",
      "Iteration 4012 | Cost: 0.3653676685258308 | Gradient: [[ 0.02845789]\n",
      " [-0.08133183]\n",
      " [ 0.12518859]]\n",
      "Iteration 4013 | Cost: 0.365344572715019 | Gradient: [[ 0.02846099]\n",
      " [-0.08131768]\n",
      " [ 0.12517968]]\n",
      "Iteration 4014 | Cost: 0.3653214812592419 | Gradient: [[ 0.02846409]\n",
      " [-0.08130353]\n",
      " [ 0.12517077]]\n",
      "Iteration 4015 | Cost: 0.3652983941569865 | Gradient: [[ 0.02846718]\n",
      " [-0.08128939]\n",
      " [ 0.12516186]]\n",
      "Iteration 4016 | Cost: 0.36527531140674135 | Gradient: [[ 0.02847028]\n",
      " [-0.08127526]\n",
      " [ 0.12515296]]\n",
      "Iteration 4017 | Cost: 0.3652522330069962 | Gradient: [[ 0.02847336]\n",
      " [-0.08126114]\n",
      " [ 0.12514405]]\n",
      "Iteration 4018 | Cost: 0.3652291589562416 | Gradient: [[ 0.02847645]\n",
      " [-0.08124702]\n",
      " [ 0.12513514]]\n",
      "Iteration 4019 | Cost: 0.3652060892529692 | Gradient: [[ 0.02847953]\n",
      " [-0.08123292]\n",
      " [ 0.12512623]]\n",
      "Iteration 4020 | Cost: 0.3651830238956721 | Gradient: [[ 0.02848261]\n",
      " [-0.08121882]\n",
      " [ 0.12511732]]\n",
      "Iteration 4021 | Cost: 0.3651599628828442 | Gradient: [[ 0.02848569]\n",
      " [-0.08120473]\n",
      " [ 0.12510841]]\n",
      "Iteration 4022 | Cost: 0.36513690621298067 | Gradient: [[ 0.02848876]\n",
      " [-0.08119064]\n",
      " [ 0.12509949]]\n",
      "Iteration 4023 | Cost: 0.36511385388457757 | Gradient: [[ 0.02849183]\n",
      " [-0.08117657]\n",
      " [ 0.12509058]]\n",
      "Iteration 4024 | Cost: 0.36509080589613246 | Gradient: [[ 0.0284949 ]\n",
      " [-0.0811625 ]\n",
      " [ 0.12508167]]\n",
      "Iteration 4025 | Cost: 0.3650677622461436 | Gradient: [[ 0.02849796]\n",
      " [-0.08114844]\n",
      " [ 0.12507276]]\n",
      "Iteration 4026 | Cost: 0.3650447229331105 | Gradient: [[ 0.02850102]\n",
      " [-0.08113438]\n",
      " [ 0.12506384]]\n",
      "Iteration 4027 | Cost: 0.3650216879555341 | Gradient: [[ 0.02850408]\n",
      " [-0.08112034]\n",
      " [ 0.12505493]]\n",
      "Iteration 4028 | Cost: 0.3649986573119157 | Gradient: [[ 0.02850713]\n",
      " [-0.0811063 ]\n",
      " [ 0.12504601]]\n",
      "Iteration 4029 | Cost: 0.3649756310007584 | Gradient: [[ 0.02851019]\n",
      " [-0.08109227]\n",
      " [ 0.1250371 ]]\n",
      "Iteration 4030 | Cost: 0.36495260902056603 | Gradient: [[ 0.02851323]\n",
      " [-0.08107825]\n",
      " [ 0.12502818]]\n",
      "Iteration 4031 | Cost: 0.3649295913698437 | Gradient: [[ 0.02851628]\n",
      " [-0.08106423]\n",
      " [ 0.12501927]]\n",
      "Iteration 4032 | Cost: 0.3649065780470975 | Gradient: [[ 0.02851932]\n",
      " [-0.08105022]\n",
      " [ 0.12501035]]\n",
      "Iteration 4033 | Cost: 0.3648835690508345 | Gradient: [[ 0.02852236]\n",
      " [-0.08103623]\n",
      " [ 0.12500143]]\n",
      "Iteration 4034 | Cost: 0.36486056437956327 | Gradient: [[ 0.02852539]\n",
      " [-0.08102223]\n",
      " [ 0.12499251]]\n",
      "Iteration 4035 | Cost: 0.3648375640317929 | Gradient: [[ 0.02852842]\n",
      " [-0.08100825]\n",
      " [ 0.12498359]]\n",
      "Iteration 4036 | Cost: 0.36481456800603407 | Gradient: [[ 0.02853145]\n",
      " [-0.08099427]\n",
      " [ 0.12497467]]\n",
      "Iteration 4037 | Cost: 0.36479157630079845 | Gradient: [[ 0.02853448]\n",
      " [-0.0809803 ]\n",
      " [ 0.12496575]]\n",
      "Iteration 4038 | Cost: 0.3647685889145984 | Gradient: [[ 0.0285375 ]\n",
      " [-0.08096634]\n",
      " [ 0.12495683]]\n",
      "Iteration 4039 | Cost: 0.3647456058459478 | Gradient: [[ 0.02854052]\n",
      " [-0.08095239]\n",
      " [ 0.12494791]]\n",
      "Iteration 4040 | Cost: 0.36472262709336156 | Gradient: [[ 0.02854353]\n",
      " [-0.08093844]\n",
      " [ 0.12493899]]\n",
      "Iteration 4041 | Cost: 0.36469965265535553 | Gradient: [[ 0.02854655]\n",
      " [-0.0809245 ]\n",
      " [ 0.12493007]]\n",
      "Iteration 4042 | Cost: 0.3646766825304466 | Gradient: [[ 0.02854956]\n",
      " [-0.08091057]\n",
      " [ 0.12492115]]\n",
      "Iteration 4043 | Cost: 0.3646537167171529 | Gradient: [[ 0.02855256]\n",
      " [-0.08089665]\n",
      " [ 0.12491222]]\n",
      "Iteration 4044 | Cost: 0.3646307552139937 | Gradient: [[ 0.02855556]\n",
      " [-0.08088273]\n",
      " [ 0.1249033 ]]\n",
      "Iteration 4045 | Cost: 0.36460779801948906 | Gradient: [[ 0.02855856]\n",
      " [-0.08086883]\n",
      " [ 0.12489438]]\n",
      "Iteration 4046 | Cost: 0.3645848451321603 | Gradient: [[ 0.02856156]\n",
      " [-0.08085492]\n",
      " [ 0.12488545]]\n",
      "Iteration 4047 | Cost: 0.3645618965505299 | Gradient: [[ 0.02856456]\n",
      " [-0.08084103]\n",
      " [ 0.12487653]]\n",
      "Iteration 4048 | Cost: 0.36453895227312116 | Gradient: [[ 0.02856755]\n",
      " [-0.08082715]\n",
      " [ 0.1248676 ]]\n",
      "Iteration 4049 | Cost: 0.3645160122984587 | Gradient: [[ 0.02857053]\n",
      " [-0.08081327]\n",
      " [ 0.12485868]]\n",
      "Iteration 4050 | Cost: 0.3644930766250682 | Gradient: [[ 0.02857352]\n",
      " [-0.0807994 ]\n",
      " [ 0.12484975]]\n",
      "Iteration 4051 | Cost: 0.364470145251476 | Gradient: [[ 0.0285765 ]\n",
      " [-0.08078553]\n",
      " [ 0.12484082]]\n",
      "Iteration 4052 | Cost: 0.36444721817621 | Gradient: [[ 0.02857948]\n",
      " [-0.08077168]\n",
      " [ 0.12483189]]\n",
      "Iteration 4053 | Cost: 0.36442429539779914 | Gradient: [[ 0.02858245]\n",
      " [-0.08075783]\n",
      " [ 0.12482297]]\n",
      "Iteration 4054 | Cost: 0.3644013769147731 | Gradient: [[ 0.02858542]\n",
      " [-0.08074399]\n",
      " [ 0.12481404]]\n",
      "Iteration 4055 | Cost: 0.36437846272566277 | Gradient: [[ 0.02858839]\n",
      " [-0.08073016]\n",
      " [ 0.12480511]]\n",
      "Iteration 4056 | Cost: 0.36435555282900023 | Gradient: [[ 0.02859136]\n",
      " [-0.08071633]\n",
      " [ 0.12479618]]\n",
      "Iteration 4057 | Cost: 0.36433264722331843 | Gradient: [[ 0.02859432]\n",
      " [-0.08070252]\n",
      " [ 0.12478725]]\n",
      "Iteration 4058 | Cost: 0.3643097459071516 | Gradient: [[ 0.02859728]\n",
      " [-0.08068871]\n",
      " [ 0.12477832]]\n",
      "Iteration 4059 | Cost: 0.36428684887903473 | Gradient: [[ 0.02860023]\n",
      " [-0.0806749 ]\n",
      " [ 0.12476939]]\n",
      "Iteration 4060 | Cost: 0.3642639561375041 | Gradient: [[ 0.02860319]\n",
      " [-0.08066111]\n",
      " [ 0.12476045]]\n",
      "Iteration 4061 | Cost: 0.3642410676810971 | Gradient: [[ 0.02860614]\n",
      " [-0.08064732]\n",
      " [ 0.12475152]]\n",
      "Iteration 4062 | Cost: 0.36421818350835183 | Gradient: [[ 0.02860908]\n",
      " [-0.08063354]\n",
      " [ 0.12474259]]\n",
      "Iteration 4063 | Cost: 0.36419530361780794 | Gradient: [[ 0.02861203]\n",
      " [-0.08061977]\n",
      " [ 0.12473366]]\n",
      "Iteration 4064 | Cost: 0.3641724280080057 | Gradient: [[ 0.02861497]\n",
      " [-0.080606  ]\n",
      " [ 0.12472472]]\n",
      "Iteration 4065 | Cost: 0.36414955667748644 | Gradient: [[ 0.0286179 ]\n",
      " [-0.08059224]\n",
      " [ 0.12471579]]\n",
      "Iteration 4066 | Cost: 0.36412668962479294 | Gradient: [[ 0.02862084]\n",
      " [-0.08057849]\n",
      " [ 0.12470685]]\n",
      "Iteration 4067 | Cost: 0.36410382684846876 | Gradient: [[ 0.02862377]\n",
      " [-0.08056475]\n",
      " [ 0.12469792]]\n",
      "Iteration 4068 | Cost: 0.3640809683470584 | Gradient: [[ 0.0286267 ]\n",
      " [-0.08055101]\n",
      " [ 0.12468898]]\n",
      "Iteration 4069 | Cost: 0.3640581141191075 | Gradient: [[ 0.02862962]\n",
      " [-0.08053729]\n",
      " [ 0.12468005]]\n",
      "Iteration 4070 | Cost: 0.36403526416316295 | Gradient: [[ 0.02863254]\n",
      " [-0.08052357]\n",
      " [ 0.12467111]]\n",
      "Iteration 4071 | Cost: 0.36401241847777244 | Gradient: [[ 0.02863546]\n",
      " [-0.08050985]\n",
      " [ 0.12466217]]\n",
      "Iteration 4072 | Cost: 0.36398957706148455 | Gradient: [[ 0.02863838]\n",
      " [-0.08049615]\n",
      " [ 0.12465324]]\n",
      "Iteration 4073 | Cost: 0.36396673991284945 | Gradient: [[ 0.02864129]\n",
      " [-0.08048245]\n",
      " [ 0.1246443 ]]\n",
      "Iteration 4074 | Cost: 0.3639439070304178 | Gradient: [[ 0.0286442 ]\n",
      " [-0.08046876]\n",
      " [ 0.12463536]]\n",
      "Iteration 4075 | Cost: 0.3639210784127416 | Gradient: [[ 0.02864711]\n",
      " [-0.08045507]\n",
      " [ 0.12462642]]\n",
      "Iteration 4076 | Cost: 0.36389825405837384 | Gradient: [[ 0.02865001]\n",
      " [-0.0804414 ]\n",
      " [ 0.12461748]]\n",
      "Iteration 4077 | Cost: 0.36387543396586836 | Gradient: [[ 0.02865291]\n",
      " [-0.08042773]\n",
      " [ 0.12460854]]\n",
      "Iteration 4078 | Cost: 0.3638526181337803 | Gradient: [[ 0.02865581]\n",
      " [-0.08041407]\n",
      " [ 0.1245996 ]]\n",
      "Iteration 4079 | Cost: 0.36382980656066566 | Gradient: [[ 0.0286587 ]\n",
      " [-0.08040041]\n",
      " [ 0.12459066]]\n",
      "Iteration 4080 | Cost: 0.3638069992450814 | Gradient: [[ 0.02866159]\n",
      " [-0.08038677]\n",
      " [ 0.12458172]]\n",
      "Iteration 4081 | Cost: 0.36378419618558594 | Gradient: [[ 0.02866448]\n",
      " [-0.08037313]\n",
      " [ 0.12457278]]\n",
      "Iteration 4082 | Cost: 0.36376139738073815 | Gradient: [[ 0.02866736]\n",
      " [-0.0803595 ]\n",
      " [ 0.12456383]]\n",
      "Iteration 4083 | Cost: 0.36373860282909837 | Gradient: [[ 0.02867024]\n",
      " [-0.08034587]\n",
      " [ 0.12455489]]\n",
      "Iteration 4084 | Cost: 0.3637158125292276 | Gradient: [[ 0.02867312]\n",
      " [-0.08033225]\n",
      " [ 0.12454595]]\n",
      "Iteration 4085 | Cost: 0.36369302647968826 | Gradient: [[ 0.028676  ]\n",
      " [-0.08031864]\n",
      " [ 0.124537  ]]\n",
      "Iteration 4086 | Cost: 0.3636702446790434 | Gradient: [[ 0.02867887]\n",
      " [-0.08030504]\n",
      " [ 0.12452806]]\n",
      "Iteration 4087 | Cost: 0.3636474671258575 | Gradient: [[ 0.02868174]\n",
      " [-0.08029145]\n",
      " [ 0.12451911]]\n",
      "Iteration 4088 | Cost: 0.3636246938186957 | Gradient: [[ 0.02868461]\n",
      " [-0.08027786]\n",
      " [ 0.12451017]]\n",
      "Iteration 4089 | Cost: 0.3636019247561243 | Gradient: [[ 0.02868747]\n",
      " [-0.08026428]\n",
      " [ 0.12450122]]\n",
      "Iteration 4090 | Cost: 0.3635791599367106 | Gradient: [[ 0.02869033]\n",
      " [-0.08025071]\n",
      " [ 0.12449228]]\n",
      "Iteration 4091 | Cost: 0.36355639935902306 | Gradient: [[ 0.02869319]\n",
      " [-0.08023714]\n",
      " [ 0.12448333]]\n",
      "Iteration 4092 | Cost: 0.36353364302163105 | Gradient: [[ 0.02869604]\n",
      " [-0.08022358]\n",
      " [ 0.12447438]]\n",
      "Iteration 4093 | Cost: 0.36351089092310473 | Gradient: [[ 0.02869889]\n",
      " [-0.08021003]\n",
      " [ 0.12446544]]\n",
      "Iteration 4094 | Cost: 0.36348814306201577 | Gradient: [[ 0.02870174]\n",
      " [-0.08019649]\n",
      " [ 0.12445649]]\n",
      "Iteration 4095 | Cost: 0.3634653994369363 | Gradient: [[ 0.02870459]\n",
      " [-0.08018295]\n",
      " [ 0.12444754]]\n",
      "Iteration 4096 | Cost: 0.3634426600464399 | Gradient: [[ 0.02870743]\n",
      " [-0.08016942]\n",
      " [ 0.12443859]]\n",
      "Iteration 4097 | Cost: 0.3634199248891009 | Gradient: [[ 0.02871027]\n",
      " [-0.0801559 ]\n",
      " [ 0.12442964]]\n",
      "Iteration 4098 | Cost: 0.36339719396349474 | Gradient: [[ 0.0287131 ]\n",
      " [-0.08014238]\n",
      " [ 0.12442069]]\n",
      "Iteration 4099 | Cost: 0.36337446726819794 | Gradient: [[ 0.02871594]\n",
      " [-0.08012888]\n",
      " [ 0.12441174]]\n",
      "Iteration 4100 | Cost: 0.3633517448017878 | Gradient: [[ 0.02871877]\n",
      " [-0.08011538]\n",
      " [ 0.12440279]]\n",
      "Iteration 4101 | Cost: 0.36332902656284294 | Gradient: [[ 0.02872159]\n",
      " [-0.08010188]\n",
      " [ 0.12439384]]\n",
      "Iteration 4102 | Cost: 0.3633063125499427 | Gradient: [[ 0.02872442]\n",
      " [-0.0800884 ]\n",
      " [ 0.12438489]]\n",
      "Iteration 4103 | Cost: 0.3632836027616675 | Gradient: [[ 0.02872724]\n",
      " [-0.08007492]\n",
      " [ 0.12437594]]\n",
      "Iteration 4104 | Cost: 0.3632608971965989 | Gradient: [[ 0.02873006]\n",
      " [-0.08006145]\n",
      " [ 0.12436699]]\n",
      "Iteration 4105 | Cost: 0.36323819585331923 | Gradient: [[ 0.02873287]\n",
      " [-0.08004798]\n",
      " [ 0.12435803]]\n",
      "Iteration 4106 | Cost: 0.3632154987304119 | Gradient: [[ 0.02873568]\n",
      " [-0.08003453]\n",
      " [ 0.12434908]]\n",
      "Iteration 4107 | Cost: 0.36319280582646174 | Gradient: [[ 0.02873849]\n",
      " [-0.08002108]\n",
      " [ 0.12434013]]\n",
      "Iteration 4108 | Cost: 0.36317011714005365 | Gradient: [[ 0.0287413 ]\n",
      " [-0.08000763]\n",
      " [ 0.12433117]]\n",
      "Iteration 4109 | Cost: 0.3631474326697745 | Gradient: [[ 0.0287441 ]\n",
      " [-0.0799942 ]\n",
      " [ 0.12432222]]\n",
      "Iteration 4110 | Cost: 0.3631247524142115 | Gradient: [[ 0.0287469 ]\n",
      " [-0.07998077]\n",
      " [ 0.12431326]]\n",
      "Iteration 4111 | Cost: 0.36310207637195324 | Gradient: [[ 0.0287497 ]\n",
      " [-0.07996735]\n",
      " [ 0.12430431]]\n",
      "Iteration 4112 | Cost: 0.36307940454158893 | Gradient: [[ 0.02875249]\n",
      " [-0.07995394]\n",
      " [ 0.12429535]]\n",
      "Iteration 4113 | Cost: 0.36305673692170914 | Gradient: [[ 0.02875528]\n",
      " [-0.07994053]\n",
      " [ 0.1242864 ]]\n",
      "Iteration 4114 | Cost: 0.36303407351090516 | Gradient: [[ 0.02875807]\n",
      " [-0.07992713]\n",
      " [ 0.12427744]]\n",
      "Iteration 4115 | Cost: 0.3630114143077695 | Gradient: [[ 0.02876085]\n",
      " [-0.07991374]\n",
      " [ 0.12426848]]\n",
      "Iteration 4116 | Cost: 0.36298875931089547 | Gradient: [[ 0.02876363]\n",
      " [-0.07990036]\n",
      " [ 0.12425953]]\n",
      "Iteration 4117 | Cost: 0.3629661085188775 | Gradient: [[ 0.02876641]\n",
      " [-0.07988698]\n",
      " [ 0.12425057]]\n",
      "Iteration 4118 | Cost: 0.36294346193031074 | Gradient: [[ 0.02876919]\n",
      " [-0.07987361]\n",
      " [ 0.12424161]]\n",
      "Iteration 4119 | Cost: 0.36292081954379163 | Gradient: [[ 0.02877196]\n",
      " [-0.07986024]\n",
      " [ 0.12423265]]\n",
      "Iteration 4120 | Cost: 0.36289818135791757 | Gradient: [[ 0.02877473]\n",
      " [-0.07984689]\n",
      " [ 0.12422369]]\n",
      "Iteration 4121 | Cost: 0.36287554737128674 | Gradient: [[ 0.0287775 ]\n",
      " [-0.07983354]\n",
      " [ 0.12421473]]\n",
      "Iteration 4122 | Cost: 0.3628529175824984 | Gradient: [[ 0.02878026]\n",
      " [-0.0798202 ]\n",
      " [ 0.12420577]]\n",
      "Iteration 4123 | Cost: 0.3628302919901529 | Gradient: [[ 0.02878302]\n",
      " [-0.07980686]\n",
      " [ 0.12419681]]\n",
      "Iteration 4124 | Cost: 0.3628076705928513 | Gradient: [[ 0.02878578]\n",
      " [-0.07979354]\n",
      " [ 0.12418785]]\n",
      "Iteration 4125 | Cost: 0.3627850533891959 | Gradient: [[ 0.02878854]\n",
      " [-0.07978022]\n",
      " [ 0.12417889]]\n",
      "Iteration 4126 | Cost: 0.36276244037779004 | Gradient: [[ 0.02879129]\n",
      " [-0.0797669 ]\n",
      " [ 0.12416993]]\n",
      "Iteration 4127 | Cost: 0.3627398315572375 | Gradient: [[ 0.02879404]\n",
      " [-0.0797536 ]\n",
      " [ 0.12416097]]\n",
      "Iteration 4128 | Cost: 0.3627172269261437 | Gradient: [[ 0.02879678]\n",
      " [-0.0797403 ]\n",
      " [ 0.124152  ]]\n",
      "Iteration 4129 | Cost: 0.3626946264831146 | Gradient: [[ 0.02879953]\n",
      " [-0.07972701]\n",
      " [ 0.12414304]]\n",
      "Iteration 4130 | Cost: 0.3626720302267573 | Gradient: [[ 0.02880227]\n",
      " [-0.07971372]\n",
      " [ 0.12413408]]\n",
      "Iteration 4131 | Cost: 0.3626494381556799 | Gradient: [[ 0.028805  ]\n",
      " [-0.07970044]\n",
      " [ 0.12412512]]\n",
      "Iteration 4132 | Cost: 0.36262685026849123 | Gradient: [[ 0.02880774]\n",
      " [-0.07968717]\n",
      " [ 0.12411615]]\n",
      "Iteration 4133 | Cost: 0.3626042665638014 | Gradient: [[ 0.02881047]\n",
      " [-0.07967391]\n",
      " [ 0.12410719]]\n",
      "Iteration 4134 | Cost: 0.3625816870402213 | Gradient: [[ 0.0288132 ]\n",
      " [-0.07966065]\n",
      " [ 0.12409822]]\n",
      "Iteration 4135 | Cost: 0.3625591116963629 | Gradient: [[ 0.02881592]\n",
      " [-0.0796474 ]\n",
      " [ 0.12408926]]\n",
      "Iteration 4136 | Cost: 0.36253654053083895 | Gradient: [[ 0.02881865]\n",
      " [-0.07963416]\n",
      " [ 0.12408029]]\n",
      "Iteration 4137 | Cost: 0.3625139735422631 | Gradient: [[ 0.02882137]\n",
      " [-0.07962093]\n",
      " [ 0.12407133]]\n",
      "Iteration 4138 | Cost: 0.36249141072925056 | Gradient: [[ 0.02882408]\n",
      " [-0.0796077 ]\n",
      " [ 0.12406236]]\n",
      "Iteration 4139 | Cost: 0.3624688520904167 | Gradient: [[ 0.0288268 ]\n",
      " [-0.07959448]\n",
      " [ 0.12405339]]\n",
      "Iteration 4140 | Cost: 0.3624462976243783 | Gradient: [[ 0.02882951]\n",
      " [-0.07958126]\n",
      " [ 0.12404443]]\n",
      "Iteration 4141 | Cost: 0.36242374732975324 | Gradient: [[ 0.02883221]\n",
      " [-0.07956806]\n",
      " [ 0.12403546]]\n",
      "Iteration 4142 | Cost: 0.36240120120515995 | Gradient: [[ 0.02883492]\n",
      " [-0.07955486]\n",
      " [ 0.12402649]]\n",
      "Iteration 4143 | Cost: 0.362378659249218 | Gradient: [[ 0.02883762]\n",
      " [-0.07954166]\n",
      " [ 0.12401752]]\n",
      "Iteration 4144 | Cost: 0.3623561214605479 | Gradient: [[ 0.02884032]\n",
      " [-0.07952848]\n",
      " [ 0.12400855]]\n",
      "Iteration 4145 | Cost: 0.36233358783777125 | Gradient: [[ 0.02884302]\n",
      " [-0.0795153 ]\n",
      " [ 0.12399959]]\n",
      "Iteration 4146 | Cost: 0.3623110583795102 | Gradient: [[ 0.02884571]\n",
      " [-0.07950213]\n",
      " [ 0.12399062]]\n",
      "Iteration 4147 | Cost: 0.36228853308438835 | Gradient: [[ 0.0288484 ]\n",
      " [-0.07948896]\n",
      " [ 0.12398165]]\n",
      "Iteration 4148 | Cost: 0.3622660119510301 | Gradient: [[ 0.02885109]\n",
      " [-0.0794758 ]\n",
      " [ 0.12397268]]\n",
      "Iteration 4149 | Cost: 0.3622434949780605 | Gradient: [[ 0.02885377]\n",
      " [-0.07946265]\n",
      " [ 0.12396371]]\n",
      "Iteration 4150 | Cost: 0.36222098216410586 | Gradient: [[ 0.02885645]\n",
      " [-0.07944951]\n",
      " [ 0.12395473]]\n",
      "Iteration 4151 | Cost: 0.36219847350779344 | Gradient: [[ 0.02885913]\n",
      " [-0.07943637]\n",
      " [ 0.12394576]]\n",
      "Iteration 4152 | Cost: 0.36217596900775123 | Gradient: [[ 0.02886181]\n",
      " [-0.07942324]\n",
      " [ 0.12393679]]\n",
      "Iteration 4153 | Cost: 0.36215346866260834 | Gradient: [[ 0.02886448]\n",
      " [-0.07941012]\n",
      " [ 0.12392782]]\n",
      "Iteration 4154 | Cost: 0.36213097247099474 | Gradient: [[ 0.02886715]\n",
      " [-0.079397  ]\n",
      " [ 0.12391885]]\n",
      "Iteration 4155 | Cost: 0.3621084804315414 | Gradient: [[ 0.02886982]\n",
      " [-0.07938389]\n",
      " [ 0.12390988]]\n",
      "Iteration 4156 | Cost: 0.36208599254288026 | Gradient: [[ 0.02887248]\n",
      " [-0.07937079]\n",
      " [ 0.1239009 ]]\n",
      "Iteration 4157 | Cost: 0.3620635088036439 | Gradient: [[ 0.02887514]\n",
      " [-0.0793577 ]\n",
      " [ 0.12389193]]\n",
      "Iteration 4158 | Cost: 0.36204102921246634 | Gradient: [[ 0.0288778 ]\n",
      " [-0.07934461]\n",
      " [ 0.12388296]]\n",
      "Iteration 4159 | Cost: 0.3620185537679821 | Gradient: [[ 0.02888046]\n",
      " [-0.07933153]\n",
      " [ 0.12387398]]\n",
      "Iteration 4160 | Cost: 0.3619960824688269 | Gradient: [[ 0.02888311]\n",
      " [-0.07931845]\n",
      " [ 0.12386501]]\n",
      "Iteration 4161 | Cost: 0.3619736153136373 | Gradient: [[ 0.02888576]\n",
      " [-0.07930539]\n",
      " [ 0.12385603]]\n",
      "Iteration 4162 | Cost: 0.3619511523010508 | Gradient: [[ 0.0288884 ]\n",
      " [-0.07929233]\n",
      " [ 0.12384706]]\n",
      "Iteration 4163 | Cost: 0.36192869342970574 | Gradient: [[ 0.02889105]\n",
      " [-0.07927927]\n",
      " [ 0.12383808]]\n",
      "Iteration 4164 | Cost: 0.3619062386982415 | Gradient: [[ 0.02889369]\n",
      " [-0.07926623]\n",
      " [ 0.12382911]]\n",
      "Iteration 4165 | Cost: 0.3618837881052984 | Gradient: [[ 0.02889633]\n",
      " [-0.07925319]\n",
      " [ 0.12382013]]\n",
      "Iteration 4166 | Cost: 0.3618613416495178 | Gradient: [[ 0.02889896]\n",
      " [-0.07924015]\n",
      " [ 0.12381115]]\n",
      "Iteration 4167 | Cost: 0.3618388993295416 | Gradient: [[ 0.0289016 ]\n",
      " [-0.07922713]\n",
      " [ 0.12380218]]\n",
      "Iteration 4168 | Cost: 0.3618164611440131 | Gradient: [[ 0.02890422]\n",
      " [-0.07921411]\n",
      " [ 0.1237932 ]]\n",
      "Iteration 4169 | Cost: 0.36179402709157604 | Gradient: [[ 0.02890685]\n",
      " [-0.0792011 ]\n",
      " [ 0.12378422]]\n",
      "Iteration 4170 | Cost: 0.3617715971708757 | Gradient: [[ 0.02890948]\n",
      " [-0.07918809]\n",
      " [ 0.12377524]]\n",
      "Iteration 4171 | Cost: 0.3617491713805575 | Gradient: [[ 0.0289121 ]\n",
      " [-0.0791751 ]\n",
      " [ 0.12376626]]\n",
      "Iteration 4172 | Cost: 0.36172674971926855 | Gradient: [[ 0.02891471]\n",
      " [-0.0791621 ]\n",
      " [ 0.12375729]]\n",
      "Iteration 4173 | Cost: 0.36170433218565645 | Gradient: [[ 0.02891733]\n",
      " [-0.07914912]\n",
      " [ 0.12374831]]\n",
      "Iteration 4174 | Cost: 0.3616819187783695 | Gradient: [[ 0.02891994]\n",
      " [-0.07913614]\n",
      " [ 0.12373933]]\n",
      "Iteration 4175 | Cost: 0.3616595094960578 | Gradient: [[ 0.02892255]\n",
      " [-0.07912317]\n",
      " [ 0.12373035]]\n",
      "Iteration 4176 | Cost: 0.3616371043373714 | Gradient: [[ 0.02892516]\n",
      " [-0.07911021]\n",
      " [ 0.12372137]]\n",
      "Iteration 4177 | Cost: 0.36161470330096174 | Gradient: [[ 0.02892776]\n",
      " [-0.07909725]\n",
      " [ 0.12371239]]\n",
      "Iteration 4178 | Cost: 0.36159230638548123 | Gradient: [[ 0.02893036]\n",
      " [-0.0790843 ]\n",
      " [ 0.12370341]]\n",
      "Iteration 4179 | Cost: 0.3615699135895829 | Gradient: [[ 0.02893296]\n",
      " [-0.07907136]\n",
      " [ 0.12369443]]\n",
      "Iteration 4180 | Cost: 0.36154752491192094 | Gradient: [[ 0.02893556]\n",
      " [-0.07905842]\n",
      " [ 0.12368545]]\n",
      "Iteration 4181 | Cost: 0.3615251403511503 | Gradient: [[ 0.02893815]\n",
      " [-0.07904549]\n",
      " [ 0.12367646]]\n",
      "Iteration 4182 | Cost: 0.361502759905927 | Gradient: [[ 0.02894074]\n",
      " [-0.07903257]\n",
      " [ 0.12366748]]\n",
      "Iteration 4183 | Cost: 0.3614803835749078 | Gradient: [[ 0.02894332]\n",
      " [-0.07901965]\n",
      " [ 0.1236585 ]]\n",
      "Iteration 4184 | Cost: 0.3614580113567506 | Gradient: [[ 0.02894591]\n",
      " [-0.07900674]\n",
      " [ 0.12364952]]\n",
      "Iteration 4185 | Cost: 0.3614356432501139 | Gradient: [[ 0.02894849]\n",
      " [-0.07899384]\n",
      " [ 0.12364053]]\n",
      "Iteration 4186 | Cost: 0.36141327925365735 | Gradient: [[ 0.02895107]\n",
      " [-0.07898095]\n",
      " [ 0.12363155]]\n",
      "Iteration 4187 | Cost: 0.36139091936604134 | Gradient: [[ 0.02895364]\n",
      " [-0.07896806]\n",
      " [ 0.12362257]]\n",
      "Iteration 4188 | Cost: 0.36136856358592734 | Gradient: [[ 0.02895622]\n",
      " [-0.07895518]\n",
      " [ 0.12361358]]\n",
      "Iteration 4189 | Cost: 0.3613462119119776 | Gradient: [[ 0.02895879]\n",
      " [-0.0789423 ]\n",
      " [ 0.1236046 ]]\n",
      "Iteration 4190 | Cost: 0.3613238643428553 | Gradient: [[ 0.02896135]\n",
      " [-0.07892943]\n",
      " [ 0.12359561]]\n",
      "Iteration 4191 | Cost: 0.3613015208772245 | Gradient: [[ 0.02896392]\n",
      " [-0.07891657]\n",
      " [ 0.12358663]]\n",
      "Iteration 4192 | Cost: 0.3612791815137504 | Gradient: [[ 0.02896648]\n",
      " [-0.07890372]\n",
      " [ 0.12357764]]\n",
      "Iteration 4193 | Cost: 0.3612568462510984 | Gradient: [[ 0.02896904]\n",
      " [-0.07889087]\n",
      " [ 0.12356866]]\n",
      "Iteration 4194 | Cost: 0.3612345150879358 | Gradient: [[ 0.02897159]\n",
      " [-0.07887803]\n",
      " [ 0.12355967]]\n",
      "Iteration 4195 | Cost: 0.3612121880229299 | Gradient: [[ 0.02897414]\n",
      " [-0.07886519]\n",
      " [ 0.12355069]]\n",
      "Iteration 4196 | Cost: 0.36118986505474965 | Gradient: [[ 0.02897669]\n",
      " [-0.07885237]\n",
      " [ 0.1235417 ]]\n",
      "Iteration 4197 | Cost: 0.3611675461820642 | Gradient: [[ 0.02897924]\n",
      " [-0.07883955]\n",
      " [ 0.12353271]]\n",
      "Iteration 4198 | Cost: 0.36114523140354415 | Gradient: [[ 0.02898179]\n",
      " [-0.07882673]\n",
      " [ 0.12352373]]\n",
      "Iteration 4199 | Cost: 0.36112292071786056 | Gradient: [[ 0.02898433]\n",
      " [-0.07881392]\n",
      " [ 0.12351474]]\n",
      "Iteration 4200 | Cost: 0.36110061412368566 | Gradient: [[ 0.02898687]\n",
      " [-0.07880112]\n",
      " [ 0.12350575]]\n",
      "Iteration 4201 | Cost: 0.3610783116196926 | Gradient: [[ 0.0289894 ]\n",
      " [-0.07878833]\n",
      " [ 0.12349676]]\n",
      "Iteration 4202 | Cost: 0.36105601320455516 | Gradient: [[ 0.02899194]\n",
      " [-0.07877554]\n",
      " [ 0.12348778]]\n",
      "Iteration 4203 | Cost: 0.36103371887694824 | Gradient: [[ 0.02899447]\n",
      " [-0.07876276]\n",
      " [ 0.12347879]]\n",
      "Iteration 4204 | Cost: 0.3610114286355475 | Gradient: [[ 0.02899699]\n",
      " [-0.07874999]\n",
      " [ 0.1234698 ]]\n",
      "Iteration 4205 | Cost: 0.3609891424790297 | Gradient: [[ 0.02899952]\n",
      " [-0.07873722]\n",
      " [ 0.12346081]]\n",
      "Iteration 4206 | Cost: 0.3609668604060722 | Gradient: [[ 0.02900204]\n",
      " [-0.07872446]\n",
      " [ 0.12345182]]\n",
      "Iteration 4207 | Cost: 0.3609445824153534 | Gradient: [[ 0.02900456]\n",
      " [-0.07871171]\n",
      " [ 0.12344283]]\n",
      "Iteration 4208 | Cost: 0.3609223085055523 | Gradient: [[ 0.02900708]\n",
      " [-0.07869896]\n",
      " [ 0.12343384]]\n",
      "Iteration 4209 | Cost: 0.3609000386753494 | Gradient: [[ 0.02900959]\n",
      " [-0.07868622]\n",
      " [ 0.12342485]]\n",
      "Iteration 4210 | Cost: 0.36087777292342565 | Gradient: [[ 0.0290121 ]\n",
      " [-0.07867349]\n",
      " [ 0.12341586]]\n",
      "Iteration 4211 | Cost: 0.3608555112484628 | Gradient: [[ 0.02901461]\n",
      " [-0.07866076]\n",
      " [ 0.12340687]]\n",
      "Iteration 4212 | Cost: 0.36083325364914376 | Gradient: [[ 0.02901712]\n",
      " [-0.07864804]\n",
      " [ 0.12339788]]\n",
      "Iteration 4213 | Cost: 0.3608110001241522 | Gradient: [[ 0.02901962]\n",
      " [-0.07863533]\n",
      " [ 0.12338889]]\n",
      "Iteration 4214 | Cost: 0.36078875067217253 | Gradient: [[ 0.02902212]\n",
      " [-0.07862262]\n",
      " [ 0.12337989]]\n",
      "Iteration 4215 | Cost: 0.3607665052918902 | Gradient: [[ 0.02902461]\n",
      " [-0.07860992]\n",
      " [ 0.1233709 ]]\n",
      "Iteration 4216 | Cost: 0.3607442639819915 | Gradient: [[ 0.02902711]\n",
      " [-0.07859723]\n",
      " [ 0.12336191]]\n",
      "Iteration 4217 | Cost: 0.3607220267411636 | Gradient: [[ 0.0290296 ]\n",
      " [-0.07858454]\n",
      " [ 0.12335292]]\n",
      "Iteration 4218 | Cost: 0.3606997935680946 | Gradient: [[ 0.02903209]\n",
      " [-0.07857186]\n",
      " [ 0.12334392]]\n",
      "Iteration 4219 | Cost: 0.36067756446147337 | Gradient: [[ 0.02903458]\n",
      " [-0.07855919]\n",
      " [ 0.12333493]]\n",
      "Iteration 4220 | Cost: 0.3606553394199897 | Gradient: [[ 0.02903706]\n",
      " [-0.07854652]\n",
      " [ 0.12332594]]\n",
      "Iteration 4221 | Cost: 0.3606331184423341 | Gradient: [[ 0.02903954]\n",
      " [-0.07853386]\n",
      " [ 0.12331694]]\n",
      "Iteration 4222 | Cost: 0.36061090152719816 | Gradient: [[ 0.02904202]\n",
      " [-0.07852121]\n",
      " [ 0.12330795]]\n",
      "Iteration 4223 | Cost: 0.3605886886732744 | Gradient: [[ 0.02904449]\n",
      " [-0.07850856]\n",
      " [ 0.12329896]]\n",
      "Iteration 4224 | Cost: 0.360566479879256 | Gradient: [[ 0.02904696]\n",
      " [-0.07849592]\n",
      " [ 0.12328996]]\n",
      "Iteration 4225 | Cost: 0.36054427514383697 | Gradient: [[ 0.02904943]\n",
      " [-0.07848329]\n",
      " [ 0.12328097]]\n",
      "Iteration 4226 | Cost: 0.36052207446571244 | Gradient: [[ 0.0290519 ]\n",
      " [-0.07847066]\n",
      " [ 0.12327197]]\n",
      "Iteration 4227 | Cost: 0.360499877843578 | Gradient: [[ 0.02905436]\n",
      " [-0.07845804]\n",
      " [ 0.12326298]]\n",
      "Iteration 4228 | Cost: 0.3604776852761308 | Gradient: [[ 0.02905683]\n",
      " [-0.07844542]\n",
      " [ 0.12325398]]\n",
      "Iteration 4229 | Cost: 0.36045549676206806 | Gradient: [[ 0.02905928]\n",
      " [-0.07843282]\n",
      " [ 0.12324498]]\n",
      "Iteration 4230 | Cost: 0.36043331230008835 | Gradient: [[ 0.02906174]\n",
      " [-0.07842022]\n",
      " [ 0.12323599]]\n",
      "Iteration 4231 | Cost: 0.3604111318888909 | Gradient: [[ 0.02906419]\n",
      " [-0.07840762]\n",
      " [ 0.12322699]]\n",
      "Iteration 4232 | Cost: 0.36038895552717587 | Gradient: [[ 0.02906664]\n",
      " [-0.07839503]\n",
      " [ 0.12321799]]\n",
      "Iteration 4233 | Cost: 0.36036678321364446 | Gradient: [[ 0.02906909]\n",
      " [-0.07838245]\n",
      " [ 0.123209  ]]\n",
      "Iteration 4234 | Cost: 0.3603446149469983 | Gradient: [[ 0.02907154]\n",
      " [-0.07836988]\n",
      " [ 0.1232    ]]\n",
      "Iteration 4235 | Cost: 0.36032245072594016 | Gradient: [[ 0.02907398]\n",
      " [-0.07835731]\n",
      " [ 0.123191  ]]\n",
      "Iteration 4236 | Cost: 0.36030029054917373 | Gradient: [[ 0.02907642]\n",
      " [-0.07834475]\n",
      " [ 0.12318201]]\n",
      "Iteration 4237 | Cost: 0.36027813441540335 | Gradient: [[ 0.02907885]\n",
      " [-0.0783322 ]\n",
      " [ 0.12317301]]\n",
      "Iteration 4238 | Cost: 0.36025598232333444 | Gradient: [[ 0.02908129]\n",
      " [-0.07831965]\n",
      " [ 0.12316401]]\n",
      "Iteration 4239 | Cost: 0.3602338342716729 | Gradient: [[ 0.02908372]\n",
      " [-0.07830711]\n",
      " [ 0.12315501]]\n",
      "Iteration 4240 | Cost: 0.36021169025912597 | Gradient: [[ 0.02908615]\n",
      " [-0.07829457]\n",
      " [ 0.12314601]]\n",
      "Iteration 4241 | Cost: 0.36018955028440125 | Gradient: [[ 0.02908857]\n",
      " [-0.07828204]\n",
      " [ 0.12313701]]\n",
      "Iteration 4242 | Cost: 0.3601674143462077 | Gradient: [[ 0.029091  ]\n",
      " [-0.07826952]\n",
      " [ 0.12312801]]\n",
      "Iteration 4243 | Cost: 0.3601452824432547 | Gradient: [[ 0.02909342]\n",
      " [-0.078257  ]\n",
      " [ 0.12311901]]\n",
      "Iteration 4244 | Cost: 0.3601231545742527 | Gradient: [[ 0.02909584]\n",
      " [-0.0782445 ]\n",
      " [ 0.12311001]]\n",
      "Iteration 4245 | Cost: 0.3601010307379129 | Gradient: [[ 0.02909825]\n",
      " [-0.07823199]\n",
      " [ 0.12310101]]\n",
      "Iteration 4246 | Cost: 0.36007891093294736 | Gradient: [[ 0.02910066]\n",
      " [-0.0782195 ]\n",
      " [ 0.12309201]]\n",
      "Iteration 4247 | Cost: 0.3600567951580689 | Gradient: [[ 0.02910307]\n",
      " [-0.07820701]\n",
      " [ 0.12308301]]\n",
      "Iteration 4248 | Cost: 0.3600346834119915 | Gradient: [[ 0.02910548]\n",
      " [-0.07819452]\n",
      " [ 0.12307401]]\n",
      "Iteration 4249 | Cost: 0.36001257569342976 | Gradient: [[ 0.02910788]\n",
      " [-0.07818205]\n",
      " [ 0.12306501]]\n",
      "Iteration 4250 | Cost: 0.35999047200109896 | Gradient: [[ 0.02911028]\n",
      " [-0.07816958]\n",
      " [ 0.12305601]]\n",
      "Iteration 4251 | Cost: 0.3599683723337155 | Gradient: [[ 0.02911268]\n",
      " [-0.07815711]\n",
      " [ 0.12304701]]\n",
      "Iteration 4252 | Cost: 0.3599462766899965 | Gradient: [[ 0.02911508]\n",
      " [-0.07814466]\n",
      " [ 0.12303801]]\n",
      "Iteration 4253 | Cost: 0.3599241850686599 | Gradient: [[ 0.02911747]\n",
      " [-0.07813221]\n",
      " [ 0.12302901]]\n",
      "Iteration 4254 | Cost: 0.3599020974684246 | Gradient: [[ 0.02911986]\n",
      " [-0.07811976]\n",
      " [ 0.12302   ]]\n",
      "Iteration 4255 | Cost: 0.35988001388801 | Gradient: [[ 0.02912225]\n",
      " [-0.07810733]\n",
      " [ 0.123011  ]]\n",
      "Iteration 4256 | Cost: 0.3598579343261369 | Gradient: [[ 0.02912464]\n",
      " [-0.07809489]\n",
      " [ 0.123002  ]]\n",
      "Iteration 4257 | Cost: 0.35983585878152646 | Gradient: [[ 0.02912702]\n",
      " [-0.07808247]\n",
      " [ 0.122993  ]]\n",
      "Iteration 4258 | Cost: 0.3598137872529007 | Gradient: [[ 0.0291294 ]\n",
      " [-0.07807005]\n",
      " [ 0.12298399]]\n",
      "Iteration 4259 | Cost: 0.35979171973898283 | Gradient: [[ 0.02913178]\n",
      " [-0.07805764]\n",
      " [ 0.12297499]]\n",
      "Iteration 4260 | Cost: 0.3597696562384965 | Gradient: [[ 0.02913415]\n",
      " [-0.07804524]\n",
      " [ 0.12296599]]\n",
      "Iteration 4261 | Cost: 0.35974759675016627 | Gradient: [[ 0.02913652]\n",
      " [-0.07803284]\n",
      " [ 0.12295698]]\n",
      "Iteration 4262 | Cost: 0.35972554127271805 | Gradient: [[ 0.02913889]\n",
      " [-0.07802044]\n",
      " [ 0.12294798]]\n",
      "Iteration 4263 | Cost: 0.35970348980487754 | Gradient: [[ 0.02914126]\n",
      " [-0.07800806]\n",
      " [ 0.12293897]]\n",
      "Iteration 4264 | Cost: 0.35968144234537225 | Gradient: [[ 0.02914362]\n",
      " [-0.07799568]\n",
      " [ 0.12292997]]\n",
      "Iteration 4265 | Cost: 0.35965939889293 | Gradient: [[ 0.02914599]\n",
      " [-0.07798331]\n",
      " [ 0.12292096]]\n",
      "Iteration 4266 | Cost: 0.3596373594462798 | Gradient: [[ 0.02914834]\n",
      " [-0.07797094]\n",
      " [ 0.12291196]]\n",
      "Iteration 4267 | Cost: 0.3596153240041509 | Gradient: [[ 0.0291507 ]\n",
      " [-0.07795858]\n",
      " [ 0.12290295]]\n",
      "Iteration 4268 | Cost: 0.35959329256527395 | Gradient: [[ 0.02915305]\n",
      " [-0.07794622]\n",
      " [ 0.12289395]]\n",
      "Iteration 4269 | Cost: 0.3595712651283801 | Gradient: [[ 0.0291554 ]\n",
      " [-0.07793388]\n",
      " [ 0.12288494]]\n",
      "Iteration 4270 | Cost: 0.3595492416922015 | Gradient: [[ 0.02915775]\n",
      " [-0.07792154]\n",
      " [ 0.12287594]]\n",
      "Iteration 4271 | Cost: 0.35952722225547096 | Gradient: [[ 0.0291601 ]\n",
      " [-0.0779092 ]\n",
      " [ 0.12286693]]\n",
      "Iteration 4272 | Cost: 0.3595052068169224 | Gradient: [[ 0.02916244]\n",
      " [-0.07789687]\n",
      " [ 0.12285793]]\n",
      "Iteration 4273 | Cost: 0.35948319537529005 | Gradient: [[ 0.02916478]\n",
      " [-0.07788455]\n",
      " [ 0.12284892]]\n",
      "Iteration 4274 | Cost: 0.3594611879293095 | Gradient: [[ 0.02916712]\n",
      " [-0.07787224]\n",
      " [ 0.12283991]]\n",
      "Iteration 4275 | Cost: 0.35943918447771683 | Gradient: [[ 0.02916945]\n",
      " [-0.07785993]\n",
      " [ 0.12283091]]\n",
      "Iteration 4276 | Cost: 0.359417185019249 | Gradient: [[ 0.02917179]\n",
      " [-0.07784762]\n",
      " [ 0.1228219 ]]\n",
      "Iteration 4277 | Cost: 0.3593951895526438 | Gradient: [[ 0.02917412]\n",
      " [-0.07783533]\n",
      " [ 0.12281289]]\n",
      "Iteration 4278 | Cost: 0.3593731980766399 | Gradient: [[ 0.02917644]\n",
      " [-0.07782304]\n",
      " [ 0.12280388]]\n",
      "Iteration 4279 | Cost: 0.3593512105899768 | Gradient: [[ 0.02917877]\n",
      " [-0.07781075]\n",
      " [ 0.12279488]]\n",
      "Iteration 4280 | Cost: 0.3593292270913946 | Gradient: [[ 0.02918109]\n",
      " [-0.07779848]\n",
      " [ 0.12278587]]\n",
      "Iteration 4281 | Cost: 0.35930724757963456 | Gradient: [[ 0.02918341]\n",
      " [-0.07778621]\n",
      " [ 0.12277686]]\n",
      "Iteration 4282 | Cost: 0.3592852720534383 | Gradient: [[ 0.02918572]\n",
      " [-0.07777394]\n",
      " [ 0.12276785]]\n",
      "Iteration 4283 | Cost: 0.35926330051154853 | Gradient: [[ 0.02918804]\n",
      " [-0.07776168]\n",
      " [ 0.12275884]]\n",
      "Iteration 4284 | Cost: 0.3592413329527088 | Gradient: [[ 0.02919035]\n",
      " [-0.07774943]\n",
      " [ 0.12274983]]\n",
      "Iteration 4285 | Cost: 0.3592193693756635 | Gradient: [[ 0.02919266]\n",
      " [-0.07773718]\n",
      " [ 0.12274083]]\n",
      "Iteration 4286 | Cost: 0.35919740977915765 | Gradient: [[ 0.02919496]\n",
      " [-0.07772495]\n",
      " [ 0.12273182]]\n",
      "Iteration 4287 | Cost: 0.3591754541619371 | Gradient: [[ 0.02919727]\n",
      " [-0.07771271]\n",
      " [ 0.12272281]]\n",
      "Iteration 4288 | Cost: 0.3591535025227486 | Gradient: [[ 0.02919957]\n",
      " [-0.07770049]\n",
      " [ 0.1227138 ]]\n",
      "Iteration 4289 | Cost: 0.35913155486033965 | Gradient: [[ 0.02920186]\n",
      " [-0.07768827]\n",
      " [ 0.12270479]]\n",
      "Iteration 4290 | Cost: 0.3591096111734586 | Gradient: [[ 0.02920416]\n",
      " [-0.07767605]\n",
      " [ 0.12269578]]\n",
      "Iteration 4291 | Cost: 0.3590876714608545 | Gradient: [[ 0.02920645]\n",
      " [-0.07766384]\n",
      " [ 0.12268677]]\n",
      "Iteration 4292 | Cost: 0.35906573572127737 | Gradient: [[ 0.02920874]\n",
      " [-0.07765164]\n",
      " [ 0.12267776]]\n",
      "Iteration 4293 | Cost: 0.3590438039534778 | Gradient: [[ 0.02921103]\n",
      " [-0.07763945]\n",
      " [ 0.12266875]]\n",
      "Iteration 4294 | Cost: 0.35902187615620745 | Gradient: [[ 0.02921332]\n",
      " [-0.07762726]\n",
      " [ 0.12265974]]\n",
      "Iteration 4295 | Cost: 0.3589999523282187 | Gradient: [[ 0.0292156 ]\n",
      " [-0.07761508]\n",
      " [ 0.12265073]]\n",
      "Iteration 4296 | Cost: 0.3589780324682645 | Gradient: [[ 0.02921788]\n",
      " [-0.0776029 ]\n",
      " [ 0.12264172]]\n",
      "Iteration 4297 | Cost: 0.35895611657509874 | Gradient: [[ 0.02922016]\n",
      " [-0.07759073]\n",
      " [ 0.1226327 ]]\n",
      "Iteration 4298 | Cost: 0.3589342046474762 | Gradient: [[ 0.02922243]\n",
      " [-0.07757856]\n",
      " [ 0.12262369]]\n",
      "Iteration 4299 | Cost: 0.3589122966841525 | Gradient: [[ 0.0292247 ]\n",
      " [-0.07756641]\n",
      " [ 0.12261468]]\n",
      "Iteration 4300 | Cost: 0.3588903926838838 | Gradient: [[ 0.02922697]\n",
      " [-0.07755426]\n",
      " [ 0.12260567]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4301 | Cost: 0.3588684926454273 | Gradient: [[ 0.02922924]\n",
      " [-0.07754211]\n",
      " [ 0.12259666]]\n",
      "Iteration 4302 | Cost: 0.35884659656754075 | Gradient: [[ 0.0292315 ]\n",
      " [-0.07752997]\n",
      " [ 0.12258765]]\n",
      "Iteration 4303 | Cost: 0.3588247044489829 | Gradient: [[ 0.02923376]\n",
      " [-0.07751784]\n",
      " [ 0.12257863]]\n",
      "Iteration 4304 | Cost: 0.3588028162885133 | Gradient: [[ 0.02923602]\n",
      " [-0.07750571]\n",
      " [ 0.12256962]]\n",
      "Iteration 4305 | Cost: 0.35878093208489203 | Gradient: [[ 0.02923828]\n",
      " [-0.07749359]\n",
      " [ 0.12256061]]\n",
      "Iteration 4306 | Cost: 0.3587590518368803 | Gradient: [[ 0.02924053]\n",
      " [-0.07748148]\n",
      " [ 0.1225516 ]]\n",
      "Iteration 4307 | Cost: 0.3587371755432399 | Gradient: [[ 0.02924279]\n",
      " [-0.07746937]\n",
      " [ 0.12254258]]\n",
      "Iteration 4308 | Cost: 0.35871530320273337 | Gradient: [[ 0.02924503]\n",
      " [-0.07745727]\n",
      " [ 0.12253357]]\n",
      "Iteration 4309 | Cost: 0.3586934348141242 | Gradient: [[ 0.02924728]\n",
      " [-0.07744517]\n",
      " [ 0.12252456]]\n",
      "Iteration 4310 | Cost: 0.35867157037617664 | Gradient: [[ 0.02924952]\n",
      " [-0.07743309]\n",
      " [ 0.12251554]]\n",
      "Iteration 4311 | Cost: 0.3586497098876556 | Gradient: [[ 0.02925176]\n",
      " [-0.077421  ]\n",
      " [ 0.12250653]]\n",
      "Iteration 4312 | Cost: 0.3586278533473268 | Gradient: [[ 0.029254  ]\n",
      " [-0.07740893]\n",
      " [ 0.12249752]]\n",
      "Iteration 4313 | Cost: 0.35860600075395677 | Gradient: [[ 0.02925624]\n",
      " [-0.07739686]\n",
      " [ 0.1224885 ]]\n",
      "Iteration 4314 | Cost: 0.35858415210631295 | Gradient: [[ 0.02925847]\n",
      " [-0.07738479]\n",
      " [ 0.12247949]]\n",
      "Iteration 4315 | Cost: 0.35856230740316336 | Gradient: [[ 0.0292607 ]\n",
      " [-0.07737273]\n",
      " [ 0.12247047]]\n",
      "Iteration 4316 | Cost: 0.358540466643277 | Gradient: [[ 0.02926293]\n",
      " [-0.07736068]\n",
      " [ 0.12246146]]\n",
      "Iteration 4317 | Cost: 0.3585186298254233 | Gradient: [[ 0.02926516]\n",
      " [-0.07734864]\n",
      " [ 0.12245244]]\n",
      "Iteration 4318 | Cost: 0.3584967969483729 | Gradient: [[ 0.02926738]\n",
      " [-0.0773366 ]\n",
      " [ 0.12244343]]\n",
      "Iteration 4319 | Cost: 0.3584749680108971 | Gradient: [[ 0.0292696 ]\n",
      " [-0.07732456]\n",
      " [ 0.12243441]]\n",
      "Iteration 4320 | Cost: 0.35845314301176767 | Gradient: [[ 0.02927182]\n",
      " [-0.07731254]\n",
      " [ 0.1224254 ]]\n",
      "Iteration 4321 | Cost: 0.3584313219497574 | Gradient: [[ 0.02927403]\n",
      " [-0.07730052]\n",
      " [ 0.12241638]]\n",
      "Iteration 4322 | Cost: 0.35840950482364003 | Gradient: [[ 0.02927625]\n",
      " [-0.0772885 ]\n",
      " [ 0.12240737]]\n",
      "Iteration 4323 | Cost: 0.3583876916321897 | Gradient: [[ 0.02927846]\n",
      " [-0.07727649]\n",
      " [ 0.12239835]]\n",
      "Iteration 4324 | Cost: 0.35836588237418165 | Gradient: [[ 0.02928066]\n",
      " [-0.07726449]\n",
      " [ 0.12238934]]\n",
      "Iteration 4325 | Cost: 0.3583440770483916 | Gradient: [[ 0.02928287]\n",
      " [-0.07725249]\n",
      " [ 0.12238032]]\n",
      "Iteration 4326 | Cost: 0.3583222756535963 | Gradient: [[ 0.02928507]\n",
      " [-0.0772405 ]\n",
      " [ 0.12237131]]\n",
      "Iteration 4327 | Cost: 0.3583004781885731 | Gradient: [[ 0.02928727]\n",
      " [-0.07722852]\n",
      " [ 0.12236229]]\n",
      "Iteration 4328 | Cost: 0.3582786846521002 | Gradient: [[ 0.02928947]\n",
      " [-0.07721654]\n",
      " [ 0.12235327]]\n",
      "Iteration 4329 | Cost: 0.35825689504295644 | Gradient: [[ 0.02929167]\n",
      " [-0.07720457]\n",
      " [ 0.12234426]]\n",
      "Iteration 4330 | Cost: 0.35823510935992176 | Gradient: [[ 0.02929386]\n",
      " [-0.0771926 ]\n",
      " [ 0.12233524]]\n",
      "Iteration 4331 | Cost: 0.3582133276017765 | Gradient: [[ 0.02929605]\n",
      " [-0.07718064]\n",
      " [ 0.12232622]]\n",
      "Iteration 4332 | Cost: 0.3581915497673019 | Gradient: [[ 0.02929824]\n",
      " [-0.07716869]\n",
      " [ 0.12231721]]\n",
      "Iteration 4333 | Cost: 0.35816977585527987 | Gradient: [[ 0.02930042]\n",
      " [-0.07715674]\n",
      " [ 0.12230819]]\n",
      "Iteration 4334 | Cost: 0.35814800586449336 | Gradient: [[ 0.0293026 ]\n",
      " [-0.0771448 ]\n",
      " [ 0.12229917]]\n",
      "Iteration 4335 | Cost: 0.3581262397937259 | Gradient: [[ 0.02930478]\n",
      " [-0.07713287]\n",
      " [ 0.12229016]]\n",
      "Iteration 4336 | Cost: 0.3581044776417616 | Gradient: [[ 0.02930696]\n",
      " [-0.07712094]\n",
      " [ 0.12228114]]\n",
      "Iteration 4337 | Cost: 0.35808271940738573 | Gradient: [[ 0.02930914]\n",
      " [-0.07710901]\n",
      " [ 0.12227212]]\n",
      "Iteration 4338 | Cost: 0.3580609650893841 | Gradient: [[ 0.02931131]\n",
      " [-0.0770971 ]\n",
      " [ 0.1222631 ]]\n",
      "Iteration 4339 | Cost: 0.3580392146865432 | Gradient: [[ 0.02931348]\n",
      " [-0.07708519]\n",
      " [ 0.12225408]]\n",
      "Iteration 4340 | Cost: 0.35801746819765023 | Gradient: [[ 0.02931565]\n",
      " [-0.07707328]\n",
      " [ 0.12224507]]\n",
      "Iteration 4341 | Cost: 0.3579957256214936 | Gradient: [[ 0.02931781]\n",
      " [-0.07706138]\n",
      " [ 0.12223605]]\n",
      "Iteration 4342 | Cost: 0.3579739869568621 | Gradient: [[ 0.02931997]\n",
      " [-0.07704949]\n",
      " [ 0.12222703]]\n",
      "Iteration 4343 | Cost: 0.35795225220254506 | Gradient: [[ 0.02932213]\n",
      " [-0.0770376 ]\n",
      " [ 0.12221801]]\n",
      "Iteration 4344 | Cost: 0.3579305213573333 | Gradient: [[ 0.02932429]\n",
      " [-0.07702572]\n",
      " [ 0.12220899]]\n",
      "Iteration 4345 | Cost: 0.3579087944200175 | Gradient: [[ 0.02932644]\n",
      " [-0.07701385]\n",
      " [ 0.12219997]]\n",
      "Iteration 4346 | Cost: 0.3578870713893898 | Gradient: [[ 0.0293286 ]\n",
      " [-0.07700198]\n",
      " [ 0.12219096]]\n",
      "Iteration 4347 | Cost: 0.3578653522642427 | Gradient: [[ 0.02933075]\n",
      " [-0.07699012]\n",
      " [ 0.12218194]]\n",
      "Iteration 4348 | Cost: 0.3578436370433697 | Gradient: [[ 0.02933289]\n",
      " [-0.07697826]\n",
      " [ 0.12217292]]\n",
      "Iteration 4349 | Cost: 0.35782192572556487 | Gradient: [[ 0.02933504]\n",
      " [-0.07696641]\n",
      " [ 0.1221639 ]]\n",
      "Iteration 4350 | Cost: 0.3578002183096231 | Gradient: [[ 0.02933718]\n",
      " [-0.07695457]\n",
      " [ 0.12215488]]\n",
      "Iteration 4351 | Cost: 0.35777851479434003 | Gradient: [[ 0.02933932]\n",
      " [-0.07694273]\n",
      " [ 0.12214586]]\n",
      "Iteration 4352 | Cost: 0.35775681517851204 | Gradient: [[ 0.02934146]\n",
      " [-0.0769309 ]\n",
      " [ 0.12213684]]\n",
      "Iteration 4353 | Cost: 0.3577351194609362 | Gradient: [[ 0.02934359]\n",
      " [-0.07691907]\n",
      " [ 0.12212782]]\n",
      "Iteration 4354 | Cost: 0.35771342764041053 | Gradient: [[ 0.02934572]\n",
      " [-0.07690725]\n",
      " [ 0.1221188 ]]\n",
      "Iteration 4355 | Cost: 0.3576917397157335 | Gradient: [[ 0.02934785]\n",
      " [-0.07689544]\n",
      " [ 0.12210978]]\n",
      "Iteration 4356 | Cost: 0.35767005568570454 | Gradient: [[ 0.02934998]\n",
      " [-0.07688363]\n",
      " [ 0.12210076]]\n",
      "Iteration 4357 | Cost: 0.3576483755491239 | Gradient: [[ 0.02935211]\n",
      " [-0.07687183]\n",
      " [ 0.12209174]]\n",
      "Iteration 4358 | Cost: 0.3576266993047922 | Gradient: [[ 0.02935423]\n",
      " [-0.07686003]\n",
      " [ 0.12208272]]\n",
      "Iteration 4359 | Cost: 0.3576050269515111 | Gradient: [[ 0.02935635]\n",
      " [-0.07684824]\n",
      " [ 0.1220737 ]]\n",
      "Iteration 4360 | Cost: 0.35758335848808304 | Gradient: [[ 0.02935847]\n",
      " [-0.07683646]\n",
      " [ 0.12206468]]\n",
      "Iteration 4361 | Cost: 0.357561693913311 | Gradient: [[ 0.02936058]\n",
      " [-0.07682468]\n",
      " [ 0.12205566]]\n",
      "Iteration 4362 | Cost: 0.357540033225999 | Gradient: [[ 0.02936269]\n",
      " [-0.07681291]\n",
      " [ 0.12204664]]\n",
      "Iteration 4363 | Cost: 0.35751837642495127 | Gradient: [[ 0.0293648 ]\n",
      " [-0.07680114]\n",
      " [ 0.12203762]]\n",
      "Iteration 4364 | Cost: 0.3574967235089734 | Gradient: [[ 0.02936691]\n",
      " [-0.07678938]\n",
      " [ 0.1220286 ]]\n",
      "Iteration 4365 | Cost: 0.3574750744768713 | Gradient: [[ 0.02936902]\n",
      " [-0.07677763]\n",
      " [ 0.12201958]]\n",
      "Iteration 4366 | Cost: 0.3574534293274518 | Gradient: [[ 0.02937112]\n",
      " [-0.07676588]\n",
      " [ 0.12201056]]\n",
      "Iteration 4367 | Cost: 0.3574317880595224 | Gradient: [[ 0.02937322]\n",
      " [-0.07675414]\n",
      " [ 0.12200153]]\n",
      "Iteration 4368 | Cost: 0.35741015067189136 | Gradient: [[ 0.02937532]\n",
      " [-0.0767424 ]\n",
      " [ 0.12199251]]\n",
      "Iteration 4369 | Cost: 0.3573885171633677 | Gradient: [[ 0.02937741]\n",
      " [-0.07673067]\n",
      " [ 0.12198349]]\n",
      "Iteration 4370 | Cost: 0.35736688753276097 | Gradient: [[ 0.0293795 ]\n",
      " [-0.07671894]\n",
      " [ 0.12197447]]\n",
      "Iteration 4371 | Cost: 0.35734526177888176 | Gradient: [[ 0.0293816 ]\n",
      " [-0.07670723]\n",
      " [ 0.12196545]]\n",
      "Iteration 4372 | Cost: 0.3573236399005413 | Gradient: [[ 0.02938368]\n",
      " [-0.07669551]\n",
      " [ 0.12195643]]\n",
      "Iteration 4373 | Cost: 0.3573020218965514 | Gradient: [[ 0.02938577]\n",
      " [-0.07668381]\n",
      " [ 0.1219474 ]]\n",
      "Iteration 4374 | Cost: 0.35728040776572484 | Gradient: [[ 0.02938785]\n",
      " [-0.07667211]\n",
      " [ 0.12193838]]\n",
      "Iteration 4375 | Cost: 0.35725879750687467 | Gradient: [[ 0.02938993]\n",
      " [-0.07666041]\n",
      " [ 0.12192936]]\n",
      "Iteration 4376 | Cost: 0.35723719111881536 | Gradient: [[ 0.02939201]\n",
      " [-0.07664872]\n",
      " [ 0.12192034]]\n",
      "Iteration 4377 | Cost: 0.3572155886003617 | Gradient: [[ 0.02939409]\n",
      " [-0.07663704]\n",
      " [ 0.12191132]]\n",
      "Iteration 4378 | Cost: 0.357193989950329 | Gradient: [[ 0.02939616]\n",
      " [-0.07662536]\n",
      " [ 0.12190229]]\n",
      "Iteration 4379 | Cost: 0.3571723951675338 | Gradient: [[ 0.02939823]\n",
      " [-0.07661369]\n",
      " [ 0.12189327]]\n",
      "Iteration 4380 | Cost: 0.35715080425079293 | Gradient: [[ 0.0294003 ]\n",
      " [-0.07660202]\n",
      " [ 0.12188425]]\n",
      "Iteration 4381 | Cost: 0.35712921719892426 | Gradient: [[ 0.02940236]\n",
      " [-0.07659037]\n",
      " [ 0.12187523]]\n",
      "Iteration 4382 | Cost: 0.35710763401074613 | Gradient: [[ 0.02940443]\n",
      " [-0.07657871]\n",
      " [ 0.1218662 ]]\n",
      "Iteration 4383 | Cost: 0.3570860546850779 | Gradient: [[ 0.02940649]\n",
      " [-0.07656706]\n",
      " [ 0.12185718]]\n",
      "Iteration 4384 | Cost: 0.3570644792207393 | Gradient: [[ 0.02940855]\n",
      " [-0.07655542]\n",
      " [ 0.12184816]]\n",
      "Iteration 4385 | Cost: 0.3570429076165511 | Gradient: [[ 0.0294106 ]\n",
      " [-0.07654379]\n",
      " [ 0.12183914]]\n",
      "Iteration 4386 | Cost: 0.35702133987133455 | Gradient: [[ 0.02941266]\n",
      " [-0.07653216]\n",
      " [ 0.12183011]]\n",
      "Iteration 4387 | Cost: 0.3569997759839117 | Gradient: [[ 0.02941471]\n",
      " [-0.07652053]\n",
      " [ 0.12182109]]\n",
      "Iteration 4388 | Cost: 0.3569782159531055 | Gradient: [[ 0.02941676]\n",
      " [-0.07650891]\n",
      " [ 0.12181207]]\n",
      "Iteration 4389 | Cost: 0.3569566597777392 | Gradient: [[ 0.0294188 ]\n",
      " [-0.0764973 ]\n",
      " [ 0.12180304]]\n",
      "Iteration 4390 | Cost: 0.3569351074566373 | Gradient: [[ 0.02942085]\n",
      " [-0.0764857 ]\n",
      " [ 0.12179402]]\n",
      "Iteration 4391 | Cost: 0.3569135589886246 | Gradient: [[ 0.02942289]\n",
      " [-0.0764741 ]\n",
      " [ 0.121785  ]]\n",
      "Iteration 4392 | Cost: 0.35689201437252666 | Gradient: [[ 0.02942493]\n",
      " [-0.0764625 ]\n",
      " [ 0.12177597]]\n",
      "Iteration 4393 | Cost: 0.35687047360717006 | Gradient: [[ 0.02942696]\n",
      " [-0.07645091]\n",
      " [ 0.12176695]]\n",
      "Iteration 4394 | Cost: 0.3568489366913819 | Gradient: [[ 0.029429  ]\n",
      " [-0.07643933]\n",
      " [ 0.12175793]]\n",
      "Iteration 4395 | Cost: 0.3568274036239898 | Gradient: [[ 0.02943103]\n",
      " [-0.07642775]\n",
      " [ 0.1217489 ]]\n",
      "Iteration 4396 | Cost: 0.3568058744038223 | Gradient: [[ 0.02943306]\n",
      " [-0.07641618]\n",
      " [ 0.12173988]]\n",
      "Iteration 4397 | Cost: 0.3567843490297087 | Gradient: [[ 0.02943509]\n",
      " [-0.07640461]\n",
      " [ 0.12173085]]\n",
      "Iteration 4398 | Cost: 0.35676282750047894 | Gradient: [[ 0.02943711]\n",
      " [-0.07639305]\n",
      " [ 0.12172183]]\n",
      "Iteration 4399 | Cost: 0.35674130981496366 | Gradient: [[ 0.02943913]\n",
      " [-0.0763815 ]\n",
      " [ 0.12171281]]\n",
      "Iteration 4400 | Cost: 0.3567197959719942 | Gradient: [[ 0.02944115]\n",
      " [-0.07636995]\n",
      " [ 0.12170378]]\n",
      "Iteration 4401 | Cost: 0.35669828597040265 | Gradient: [[ 0.02944317]\n",
      " [-0.07635841]\n",
      " [ 0.12169476]]\n",
      "Iteration 4402 | Cost: 0.35667677980902174 | Gradient: [[ 0.02944519]\n",
      " [-0.07634687]\n",
      " [ 0.12168573]]\n",
      "Iteration 4403 | Cost: 0.3566552774866851 | Gradient: [[ 0.0294472 ]\n",
      " [-0.07633534]\n",
      " [ 0.12167671]]\n",
      "Iteration 4404 | Cost: 0.35663377900222665 | Gradient: [[ 0.02944921]\n",
      " [-0.07632382]\n",
      " [ 0.12166769]]\n",
      "Iteration 4405 | Cost: 0.35661228435448156 | Gradient: [[ 0.02945122]\n",
      " [-0.0763123 ]\n",
      " [ 0.12165866]]\n",
      "Iteration 4406 | Cost: 0.35659079354228534 | Gradient: [[ 0.02945322]\n",
      " [-0.07630079]\n",
      " [ 0.12164964]]\n",
      "Iteration 4407 | Cost: 0.3565693065644742 | Gradient: [[ 0.02945523]\n",
      " [-0.07628928]\n",
      " [ 0.12164061]]\n",
      "Iteration 4408 | Cost: 0.3565478234198853 | Gradient: [[ 0.02945723]\n",
      " [-0.07627778]\n",
      " [ 0.12163159]]\n",
      "Iteration 4409 | Cost: 0.35652634410735623 | Gradient: [[ 0.02945923]\n",
      " [-0.07626628]\n",
      " [ 0.12162256]]\n",
      "Iteration 4410 | Cost: 0.3565048686257255 | Gradient: [[ 0.02946122]\n",
      " [-0.07625479]\n",
      " [ 0.12161354]]\n",
      "Iteration 4411 | Cost: 0.3564833969738321 | Gradient: [[ 0.02946322]\n",
      " [-0.07624331]\n",
      " [ 0.12160451]]\n",
      "Iteration 4412 | Cost: 0.3564619291505161 | Gradient: [[ 0.02946521]\n",
      " [-0.07623183]\n",
      " [ 0.12159549]]\n",
      "Iteration 4413 | Cost: 0.35644046515461764 | Gradient: [[ 0.0294672 ]\n",
      " [-0.07622035]\n",
      " [ 0.12158646]]\n",
      "Iteration 4414 | Cost: 0.35641900498497825 | Gradient: [[ 0.02946918]\n",
      " [-0.07620889]\n",
      " [ 0.12157744]]\n",
      "Iteration 4415 | Cost: 0.3563975486404397 | Gradient: [[ 0.02947117]\n",
      " [-0.07619743]\n",
      " [ 0.12156841]]\n",
      "Iteration 4416 | Cost: 0.3563760961198447 | Gradient: [[ 0.02947315]\n",
      " [-0.07618597]\n",
      " [ 0.12155939]]\n",
      "Iteration 4417 | Cost: 0.3563546474220365 | Gradient: [[ 0.02947513]\n",
      " [-0.07617452]\n",
      " [ 0.12155036]]\n",
      "Iteration 4418 | Cost: 0.3563332025458591 | Gradient: [[ 0.0294771 ]\n",
      " [-0.07616308]\n",
      " [ 0.12154134]]\n",
      "Iteration 4419 | Cost: 0.35631176149015714 | Gradient: [[ 0.02947908]\n",
      " [-0.07615164]\n",
      " [ 0.12153231]]\n",
      "Iteration 4420 | Cost: 0.3562903242537761 | Gradient: [[ 0.02948105]\n",
      " [-0.0761402 ]\n",
      " [ 0.12152329]]\n",
      "Iteration 4421 | Cost: 0.35626889083556207 | Gradient: [[ 0.02948302]\n",
      " [-0.07612878]\n",
      " [ 0.12151426]]\n",
      "Iteration 4422 | Cost: 0.3562474612343617 | Gradient: [[ 0.02948499]\n",
      " [-0.07611736]\n",
      " [ 0.12150524]]\n",
      "Iteration 4423 | Cost: 0.35622603544902265 | Gradient: [[ 0.02948695]\n",
      " [-0.07610594]\n",
      " [ 0.12149621]]\n",
      "Iteration 4424 | Cost: 0.35620461347839294 | Gradient: [[ 0.02948892]\n",
      " [-0.07609453]\n",
      " [ 0.12148719]]\n",
      "Iteration 4425 | Cost: 0.35618319532132153 | Gradient: [[ 0.02949088]\n",
      " [-0.07608313]\n",
      " [ 0.12147816]]\n",
      "Iteration 4426 | Cost: 0.35616178097665796 | Gradient: [[ 0.02949283]\n",
      " [-0.07607173]\n",
      " [ 0.12146914]]\n",
      "Iteration 4427 | Cost: 0.3561403704432524 | Gradient: [[ 0.02949479]\n",
      " [-0.07606034]\n",
      " [ 0.12146011]]\n",
      "Iteration 4428 | Cost: 0.3561189637199557 | Gradient: [[ 0.02949674]\n",
      " [-0.07604895]\n",
      " [ 0.12145108]]\n",
      "Iteration 4429 | Cost: 0.35609756080561966 | Gradient: [[ 0.02949869]\n",
      " [-0.07603757]\n",
      " [ 0.12144206]]\n",
      "Iteration 4430 | Cost: 0.3560761616990965 | Gradient: [[ 0.02950064]\n",
      " [-0.07602619]\n",
      " [ 0.12143303]]\n",
      "Iteration 4431 | Cost: 0.35605476639923916 | Gradient: [[ 0.02950259]\n",
      " [-0.07601482]\n",
      " [ 0.12142401]]\n",
      "Iteration 4432 | Cost: 0.3560333749049013 | Gradient: [[ 0.02950453]\n",
      " [-0.07600346]\n",
      " [ 0.12141498]]\n",
      "Iteration 4433 | Cost: 0.3560119872149374 | Gradient: [[ 0.02950648]\n",
      " [-0.0759921 ]\n",
      " [ 0.12140596]]\n",
      "Iteration 4434 | Cost: 0.35599060332820226 | Gradient: [[ 0.02950841]\n",
      " [-0.07598075]\n",
      " [ 0.12139693]]\n",
      "Iteration 4435 | Cost: 0.35596922324355185 | Gradient: [[ 0.02951035]\n",
      " [-0.0759694 ]\n",
      " [ 0.1213879 ]]\n",
      "Iteration 4436 | Cost: 0.3559478469598424 | Gradient: [[ 0.02951229]\n",
      " [-0.07595806]\n",
      " [ 0.12137888]]\n",
      "Iteration 4437 | Cost: 0.35592647447593095 | Gradient: [[ 0.02951422]\n",
      " [-0.07594672]\n",
      " [ 0.12136985]]\n",
      "Iteration 4438 | Cost: 0.3559051057906755 | Gradient: [[ 0.02951615]\n",
      " [-0.07593539]\n",
      " [ 0.12136083]]\n",
      "Iteration 4439 | Cost: 0.3558837409029344 | Gradient: [[ 0.02951808]\n",
      " [-0.07592407]\n",
      " [ 0.1213518 ]]\n",
      "Iteration 4440 | Cost: 0.3558623798115666 | Gradient: [[ 0.02952   ]\n",
      " [-0.07591275]\n",
      " [ 0.12134278]]\n",
      "Iteration 4441 | Cost: 0.3558410225154322 | Gradient: [[ 0.02952192]\n",
      " [-0.07590143]\n",
      " [ 0.12133375]]\n",
      "Iteration 4442 | Cost: 0.35581966901339135 | Gradient: [[ 0.02952384]\n",
      " [-0.07589013]\n",
      " [ 0.12132472]]\n",
      "Iteration 4443 | Cost: 0.35579831930430544 | Gradient: [[ 0.02952576]\n",
      " [-0.07587882]\n",
      " [ 0.1213157 ]]\n",
      "Iteration 4444 | Cost: 0.3557769733870363 | Gradient: [[ 0.02952768]\n",
      " [-0.07586753]\n",
      " [ 0.12130667]]\n",
      "Iteration 4445 | Cost: 0.3557556312604463 | Gradient: [[ 0.02952959]\n",
      " [-0.07585624]\n",
      " [ 0.12129764]]\n",
      "Iteration 4446 | Cost: 0.3557342929233988 | Gradient: [[ 0.0295315 ]\n",
      " [-0.07584495]\n",
      " [ 0.12128862]]\n",
      "Iteration 4447 | Cost: 0.35571295837475747 | Gradient: [[ 0.02953341]\n",
      " [-0.07583367]\n",
      " [ 0.12127959]]\n",
      "Iteration 4448 | Cost: 0.355691627613387 | Gradient: [[ 0.02953532]\n",
      " [-0.0758224 ]\n",
      " [ 0.12127057]]\n",
      "Iteration 4449 | Cost: 0.3556703006381525 | Gradient: [[ 0.02953722]\n",
      " [-0.07581113]\n",
      " [ 0.12126154]]\n",
      "Iteration 4450 | Cost: 0.35564897744791996 | Gradient: [[ 0.02953913]\n",
      " [-0.07579987]\n",
      " [ 0.12125251]]\n",
      "Iteration 4451 | Cost: 0.35562765804155577 | Gradient: [[ 0.02954103]\n",
      " [-0.07578861]\n",
      " [ 0.12124349]]\n",
      "Iteration 4452 | Cost: 0.3556063424179272 | Gradient: [[ 0.02954292]\n",
      " [-0.07577736]\n",
      " [ 0.12123446]]\n",
      "Iteration 4453 | Cost: 0.3555850305759023 | Gradient: [[ 0.02954482]\n",
      " [-0.07576611]\n",
      " [ 0.12122544]]\n",
      "Iteration 4454 | Cost: 0.35556372251434937 | Gradient: [[ 0.02954671]\n",
      " [-0.07575487]\n",
      " [ 0.12121641]]\n",
      "Iteration 4455 | Cost: 0.35554241823213784 | Gradient: [[ 0.0295486 ]\n",
      " [-0.07574364]\n",
      " [ 0.12120738]]\n",
      "Iteration 4456 | Cost: 0.3555211177281376 | Gradient: [[ 0.02955049]\n",
      " [-0.07573241]\n",
      " [ 0.12119836]]\n",
      "Iteration 4457 | Cost: 0.3554998210012191 | Gradient: [[ 0.02955238]\n",
      " [-0.07572119]\n",
      " [ 0.12118933]]\n",
      "Iteration 4458 | Cost: 0.35547852805025343 | Gradient: [[ 0.02955426]\n",
      " [-0.07570997]\n",
      " [ 0.1211803 ]]\n",
      "Iteration 4459 | Cost: 0.3554572388741129 | Gradient: [[ 0.02955614]\n",
      " [-0.07569876]\n",
      " [ 0.12117128]]\n",
      "Iteration 4460 | Cost: 0.3554359534716697 | Gradient: [[ 0.02955802]\n",
      " [-0.07568755]\n",
      " [ 0.12116225]]\n",
      "Iteration 4461 | Cost: 0.35541467184179726 | Gradient: [[ 0.0295599 ]\n",
      " [-0.07567635]\n",
      " [ 0.12115322]]\n",
      "Iteration 4462 | Cost: 0.3553933939833694 | Gradient: [[ 0.02956177]\n",
      " [-0.07566515]\n",
      " [ 0.1211442 ]]\n",
      "Iteration 4463 | Cost: 0.35537211989526063 | Gradient: [[ 0.02956364]\n",
      " [-0.07565396]\n",
      " [ 0.12113517]]\n",
      "Iteration 4464 | Cost: 0.3553508495763463 | Gradient: [[ 0.02956551]\n",
      " [-0.07564278]\n",
      " [ 0.12112615]]\n",
      "Iteration 4465 | Cost: 0.355329583025502 | Gradient: [[ 0.02956738]\n",
      " [-0.0756316 ]\n",
      " [ 0.12111712]]\n",
      "Iteration 4466 | Cost: 0.3553083202416045 | Gradient: [[ 0.02956925]\n",
      " [-0.07562043]\n",
      " [ 0.12110809]]\n",
      "Iteration 4467 | Cost: 0.355287061223531 | Gradient: [[ 0.02957111]\n",
      " [-0.07560926]\n",
      " [ 0.12109907]]\n",
      "Iteration 4468 | Cost: 0.3552658059701593 | Gradient: [[ 0.02957297]\n",
      " [-0.0755981 ]\n",
      " [ 0.12109004]]\n",
      "Iteration 4469 | Cost: 0.3552445544803678 | Gradient: [[ 0.02957483]\n",
      " [-0.07558694]\n",
      " [ 0.12108101]]\n",
      "Iteration 4470 | Cost: 0.3552233067530358 | Gradient: [[ 0.02957668]\n",
      " [-0.07557579]\n",
      " [ 0.12107199]]\n",
      "Iteration 4471 | Cost: 0.35520206278704314 | Gradient: [[ 0.02957854]\n",
      " [-0.07556464]\n",
      " [ 0.12106296]]\n",
      "Iteration 4472 | Cost: 0.3551808225812702 | Gradient: [[ 0.02958039]\n",
      " [-0.0755535 ]\n",
      " [ 0.12105393]]\n",
      "Iteration 4473 | Cost: 0.35515958613459814 | Gradient: [[ 0.02958224]\n",
      " [-0.07554237]\n",
      " [ 0.12104491]]\n",
      "Iteration 4474 | Cost: 0.3551383534459088 | Gradient: [[ 0.02958409]\n",
      " [-0.07553124]\n",
      " [ 0.12103588]]\n",
      "Iteration 4475 | Cost: 0.35511712451408467 | Gradient: [[ 0.02958593]\n",
      " [-0.07552011]\n",
      " [ 0.12102686]]\n",
      "Iteration 4476 | Cost: 0.3550958993380087 | Gradient: [[ 0.02958777]\n",
      " [-0.075509  ]\n",
      " [ 0.12101783]]\n",
      "Iteration 4477 | Cost: 0.35507467791656483 | Gradient: [[ 0.02958961]\n",
      " [-0.07549788]\n",
      " [ 0.1210088 ]]\n",
      "Iteration 4478 | Cost: 0.3550534602486373 | Gradient: [[ 0.02959145]\n",
      " [-0.07548678]\n",
      " [ 0.12099978]]\n",
      "Iteration 4479 | Cost: 0.3550322463331113 | Gradient: [[ 0.02959329]\n",
      " [-0.07547567]\n",
      " [ 0.12099075]]\n",
      "Iteration 4480 | Cost: 0.3550110361688724 | Gradient: [[ 0.02959512]\n",
      " [-0.07546458]\n",
      " [ 0.12098172]]\n",
      "Iteration 4481 | Cost: 0.35498982975480703 | Gradient: [[ 0.02959695]\n",
      " [-0.07545349]\n",
      " [ 0.1209727 ]]\n",
      "Iteration 4482 | Cost: 0.35496862708980215 | Gradient: [[ 0.02959878]\n",
      " [-0.0754424 ]\n",
      " [ 0.12096367]]\n",
      "Iteration 4483 | Cost: 0.3549474281727455 | Gradient: [[ 0.02960061]\n",
      " [-0.07543132]\n",
      " [ 0.12095465]]\n",
      "Iteration 4484 | Cost: 0.35492623300252535 | Gradient: [[ 0.02960243]\n",
      " [-0.07542025]\n",
      " [ 0.12094562]]\n",
      "Iteration 4485 | Cost: 0.35490504157803066 | Gradient: [[ 0.02960426]\n",
      " [-0.07540918]\n",
      " [ 0.12093659]]\n",
      "Iteration 4486 | Cost: 0.35488385389815097 | Gradient: [[ 0.02960608]\n",
      " [-0.07539812]\n",
      " [ 0.12092757]]\n",
      "Iteration 4487 | Cost: 0.3548626699617765 | Gradient: [[ 0.02960789]\n",
      " [-0.07538706]\n",
      " [ 0.12091854]]\n",
      "Iteration 4488 | Cost: 0.3548414897677983 | Gradient: [[ 0.02960971]\n",
      " [-0.07537601]\n",
      " [ 0.12090951]]\n",
      "Iteration 4489 | Cost: 0.35482031331510766 | Gradient: [[ 0.02961152]\n",
      " [-0.07536496]\n",
      " [ 0.12090049]]\n",
      "Iteration 4490 | Cost: 0.35479914060259704 | Gradient: [[ 0.02961333]\n",
      " [-0.07535392]\n",
      " [ 0.12089146]]\n",
      "Iteration 4491 | Cost: 0.3547779716291591 | Gradient: [[ 0.02961514]\n",
      " [-0.07534288]\n",
      " [ 0.12088244]]\n",
      "Iteration 4492 | Cost: 0.35475680639368723 | Gradient: [[ 0.02961695]\n",
      " [-0.07533185]\n",
      " [ 0.12087341]]\n",
      "Iteration 4493 | Cost: 0.35473564489507553 | Gradient: [[ 0.02961875]\n",
      " [-0.07532083]\n",
      " [ 0.12086438]]\n",
      "Iteration 4494 | Cost: 0.354714487132219 | Gradient: [[ 0.02962055]\n",
      " [-0.07530981]\n",
      " [ 0.12085536]]\n",
      "Iteration 4495 | Cost: 0.3546933331040127 | Gradient: [[ 0.02962235]\n",
      " [-0.07529879]\n",
      " [ 0.12084633]]\n",
      "Iteration 4496 | Cost: 0.3546721828093529 | Gradient: [[ 0.02962415]\n",
      " [-0.07528778]\n",
      " [ 0.12083731]]\n",
      "Iteration 4497 | Cost: 0.35465103624713623 | Gradient: [[ 0.02962595]\n",
      " [-0.07527678]\n",
      " [ 0.12082828]]\n",
      "Iteration 4498 | Cost: 0.35462989341625983 | Gradient: [[ 0.02962774]\n",
      " [-0.07526578]\n",
      " [ 0.12081925]]\n",
      "Iteration 4499 | Cost: 0.35460875431562183 | Gradient: [[ 0.02962953]\n",
      " [-0.07525479]\n",
      " [ 0.12081023]]\n",
      "Iteration 4500 | Cost: 0.35458761894412055 | Gradient: [[ 0.02963132]\n",
      " [-0.0752438 ]\n",
      " [ 0.1208012 ]]\n",
      "Iteration 4501 | Cost: 0.35456648730065554 | Gradient: [[ 0.02963311]\n",
      " [-0.07523282]\n",
      " [ 0.12079218]]\n",
      "Iteration 4502 | Cost: 0.35454535938412635 | Gradient: [[ 0.02963489]\n",
      " [-0.07522184]\n",
      " [ 0.12078315]]\n",
      "Iteration 4503 | Cost: 0.3545242351934336 | Gradient: [[ 0.02963667]\n",
      " [-0.07521087]\n",
      " [ 0.12077413]]\n",
      "Iteration 4504 | Cost: 0.3545031147274785 | Gradient: [[ 0.02963845]\n",
      " [-0.07519991]\n",
      " [ 0.1207651 ]]\n",
      "Iteration 4505 | Cost: 0.3544819979851626 | Gradient: [[ 0.02964023]\n",
      " [-0.07518895]\n",
      " [ 0.12075607]]\n",
      "Iteration 4506 | Cost: 0.35446088496538847 | Gradient: [[ 0.029642  ]\n",
      " [-0.07517799]\n",
      " [ 0.12074705]]\n",
      "Iteration 4507 | Cost: 0.35443977566705887 | Gradient: [[ 0.02964378]\n",
      " [-0.07516704]\n",
      " [ 0.12073802]]\n",
      "Iteration 4508 | Cost: 0.3544186700890777 | Gradient: [[ 0.02964555]\n",
      " [-0.0751561 ]\n",
      " [ 0.120729  ]]\n",
      "Iteration 4509 | Cost: 0.3543975682303492 | Gradient: [[ 0.02964732]\n",
      " [-0.07514516]\n",
      " [ 0.12071997]]\n",
      "Iteration 4510 | Cost: 0.3543764700897781 | Gradient: [[ 0.02964908]\n",
      " [-0.07513423]\n",
      " [ 0.12071095]]\n",
      "Iteration 4511 | Cost: 0.3543553756662701 | Gradient: [[ 0.02965085]\n",
      " [-0.0751233 ]\n",
      " [ 0.12070192]]\n",
      "Iteration 4512 | Cost: 0.3543342849587315 | Gradient: [[ 0.02965261]\n",
      " [-0.07511238]\n",
      " [ 0.1206929 ]]\n",
      "Iteration 4513 | Cost: 0.35431319796606875 | Gradient: [[ 0.02965437]\n",
      " [-0.07510146]\n",
      " [ 0.12068387]]\n",
      "Iteration 4514 | Cost: 0.3542921146871895 | Gradient: [[ 0.02965613]\n",
      " [-0.07509055]\n",
      " [ 0.12067484]]\n",
      "Iteration 4515 | Cost: 0.3542710351210018 | Gradient: [[ 0.02965788]\n",
      " [-0.07507964]\n",
      " [ 0.12066582]]\n",
      "Iteration 4516 | Cost: 0.35424995926641417 | Gradient: [[ 0.02965964]\n",
      " [-0.07506874]\n",
      " [ 0.12065679]]\n",
      "Iteration 4517 | Cost: 0.354228887122336 | Gradient: [[ 0.02966139]\n",
      " [-0.07505784]\n",
      " [ 0.12064777]]\n",
      "Iteration 4518 | Cost: 0.3542078186876773 | Gradient: [[ 0.02966314]\n",
      " [-0.07504695]\n",
      " [ 0.12063874]]\n",
      "Iteration 4519 | Cost: 0.3541867539613486 | Gradient: [[ 0.02966488]\n",
      " [-0.07503607]\n",
      " [ 0.12062972]]\n",
      "Iteration 4520 | Cost: 0.3541656929422609 | Gradient: [[ 0.02966663]\n",
      " [-0.07502519]\n",
      " [ 0.12062069]]\n",
      "Iteration 4521 | Cost: 0.35414463562932624 | Gradient: [[ 0.02966837]\n",
      " [-0.07501431]\n",
      " [ 0.12061167]]\n",
      "Iteration 4522 | Cost: 0.35412358202145683 | Gradient: [[ 0.02967011]\n",
      " [-0.07500344]\n",
      " [ 0.12060264]]\n",
      "Iteration 4523 | Cost: 0.3541025321175659 | Gradient: [[ 0.02967185]\n",
      " [-0.07499258]\n",
      " [ 0.12059362]]\n",
      "Iteration 4524 | Cost: 0.35408148591656696 | Gradient: [[ 0.02967358]\n",
      " [-0.07498172]\n",
      " [ 0.12058459]]\n",
      "Iteration 4525 | Cost: 0.3540604434173743 | Gradient: [[ 0.02967532]\n",
      " [-0.07497087]\n",
      " [ 0.12057557]]\n",
      "Iteration 4526 | Cost: 0.35403940461890293 | Gradient: [[ 0.02967705]\n",
      " [-0.07496002]\n",
      " [ 0.12056654]]\n",
      "Iteration 4527 | Cost: 0.35401836952006827 | Gradient: [[ 0.02967878]\n",
      " [-0.07494918]\n",
      " [ 0.12055752]]\n",
      "Iteration 4528 | Cost: 0.35399733811978656 | Gradient: [[ 0.0296805 ]\n",
      " [-0.07493834]\n",
      " [ 0.1205485 ]]\n",
      "Iteration 4529 | Cost: 0.35397631041697447 | Gradient: [[ 0.02968223]\n",
      " [-0.07492751]\n",
      " [ 0.12053947]]\n",
      "Iteration 4530 | Cost: 0.3539552864105493 | Gradient: [[ 0.02968395]\n",
      " [-0.07491668]\n",
      " [ 0.12053045]]\n",
      "Iteration 4531 | Cost: 0.35393426609942924 | Gradient: [[ 0.02968567]\n",
      " [-0.07490586]\n",
      " [ 0.12052142]]\n",
      "Iteration 4532 | Cost: 0.35391324948253283 | Gradient: [[ 0.02968739]\n",
      " [-0.07489504]\n",
      " [ 0.1205124 ]]\n",
      "Iteration 4533 | Cost: 0.3538922365587792 | Gradient: [[ 0.02968911]\n",
      " [-0.07488423]\n",
      " [ 0.12050337]]\n",
      "Iteration 4534 | Cost: 0.35387122732708826 | Gradient: [[ 0.02969082]\n",
      " [-0.07487343]\n",
      " [ 0.12049435]]\n",
      "Iteration 4535 | Cost: 0.3538502217863803 | Gradient: [[ 0.02969253]\n",
      " [-0.07486263]\n",
      " [ 0.12048533]]\n",
      "Iteration 4536 | Cost: 0.35382921993557676 | Gradient: [[ 0.02969424]\n",
      " [-0.07485183]\n",
      " [ 0.1204763 ]]\n",
      "Iteration 4537 | Cost: 0.35380822177359905 | Gradient: [[ 0.02969595]\n",
      " [-0.07484104]\n",
      " [ 0.12046728]]\n",
      "Iteration 4538 | Cost: 0.3537872272993693 | Gradient: [[ 0.02969765]\n",
      " [-0.07483026]\n",
      " [ 0.12045825]]\n",
      "Iteration 4539 | Cost: 0.3537662365118107 | Gradient: [[ 0.02969936]\n",
      " [-0.07481948]\n",
      " [ 0.12044923]]\n",
      "Iteration 4540 | Cost: 0.3537452494098467 | Gradient: [[ 0.02970106]\n",
      " [-0.07480871]\n",
      " [ 0.12044021]]\n",
      "Iteration 4541 | Cost: 0.3537242659924013 | Gradient: [[ 0.02970276]\n",
      " [-0.07479794]\n",
      " [ 0.12043118]]\n",
      "Iteration 4542 | Cost: 0.3537032862583993 | Gradient: [[ 0.02970445]\n",
      " [-0.07478717]\n",
      " [ 0.12042216]]\n",
      "Iteration 4543 | Cost: 0.35368231020676605 | Gradient: [[ 0.02970615]\n",
      " [-0.07477642]\n",
      " [ 0.12041313]]\n",
      "Iteration 4544 | Cost: 0.35366133783642756 | Gradient: [[ 0.02970784]\n",
      " [-0.07476566]\n",
      " [ 0.12040411]]\n",
      "Iteration 4545 | Cost: 0.35364036914631014 | Gradient: [[ 0.02970953]\n",
      " [-0.07475492]\n",
      " [ 0.12039509]]\n",
      "Iteration 4546 | Cost: 0.3536194041353412 | Gradient: [[ 0.02971122]\n",
      " [-0.07474417]\n",
      " [ 0.12038606]]\n",
      "Iteration 4547 | Cost: 0.35359844280244845 | Gradient: [[ 0.0297129 ]\n",
      " [-0.07473344]\n",
      " [ 0.12037704]]\n",
      "Iteration 4548 | Cost: 0.3535774851465602 | Gradient: [[ 0.02971459]\n",
      " [-0.0747227 ]\n",
      " [ 0.12036802]]\n",
      "Iteration 4549 | Cost: 0.3535565311666055 | Gradient: [[ 0.02971627]\n",
      " [-0.07471198]\n",
      " [ 0.12035899]]\n",
      "Iteration 4550 | Cost: 0.35353558086151377 | Gradient: [[ 0.02971795]\n",
      " [-0.07470126]\n",
      " [ 0.12034997]]\n",
      "Iteration 4551 | Cost: 0.3535146342302154 | Gradient: [[ 0.02971962]\n",
      " [-0.07469054]\n",
      " [ 0.12034095]]\n",
      "Iteration 4552 | Cost: 0.35349369127164104 | Gradient: [[ 0.0297213 ]\n",
      " [-0.07467983]\n",
      " [ 0.12033193]]\n",
      "Iteration 4553 | Cost: 0.35347275198472217 | Gradient: [[ 0.02972297]\n",
      " [-0.07466912]\n",
      " [ 0.1203229 ]]\n",
      "Iteration 4554 | Cost: 0.3534518163683906 | Gradient: [[ 0.02972464]\n",
      " [-0.07465842]\n",
      " [ 0.12031388]]\n",
      "Iteration 4555 | Cost: 0.3534308844215792 | Gradient: [[ 0.02972631]\n",
      " [-0.07464773]\n",
      " [ 0.12030486]]\n",
      "Iteration 4556 | Cost: 0.353409956143221 | Gradient: [[ 0.02972798]\n",
      " [-0.07463704]\n",
      " [ 0.12029583]]\n",
      "Iteration 4557 | Cost: 0.3533890315322498 | Gradient: [[ 0.02972964]\n",
      " [-0.07462635]\n",
      " [ 0.12028681]]\n",
      "Iteration 4558 | Cost: 0.3533681105876 | Gradient: [[ 0.02973131]\n",
      " [-0.07461567]\n",
      " [ 0.12027779]]\n",
      "Iteration 4559 | Cost: 0.3533471933082066 | Gradient: [[ 0.02973297]\n",
      " [-0.074605  ]\n",
      " [ 0.12026877]]\n",
      "Iteration 4560 | Cost: 0.35332627969300506 | Gradient: [[ 0.02973462]\n",
      " [-0.07459433]\n",
      " [ 0.12025974]]\n",
      "Iteration 4561 | Cost: 0.35330536974093185 | Gradient: [[ 0.02973628]\n",
      " [-0.07458366]\n",
      " [ 0.12025072]]\n",
      "Iteration 4562 | Cost: 0.3532844634509235 | Gradient: [[ 0.02973793]\n",
      " [-0.074573  ]\n",
      " [ 0.1202417 ]]\n",
      "Iteration 4563 | Cost: 0.3532635608219174 | Gradient: [[ 0.02973959]\n",
      " [-0.07456235]\n",
      " [ 0.12023268]]\n",
      "Iteration 4564 | Cost: 0.35324266185285175 | Gradient: [[ 0.02974123]\n",
      " [-0.0745517 ]\n",
      " [ 0.12022366]]\n",
      "Iteration 4565 | Cost: 0.3532217665426649 | Gradient: [[ 0.02974288]\n",
      " [-0.07454106]\n",
      " [ 0.12021463]]\n",
      "Iteration 4566 | Cost: 0.35320087489029606 | Gradient: [[ 0.02974453]\n",
      " [-0.07453042]\n",
      " [ 0.12020561]]\n",
      "Iteration 4567 | Cost: 0.35317998689468505 | Gradient: [[ 0.02974617]\n",
      " [-0.07451979]\n",
      " [ 0.12019659]]\n",
      "Iteration 4568 | Cost: 0.3531591025547721 | Gradient: [[ 0.02974781]\n",
      " [-0.07450916]\n",
      " [ 0.12018757]]\n",
      "Iteration 4569 | Cost: 0.3531382218694982 | Gradient: [[ 0.02974945]\n",
      " [-0.07449854]\n",
      " [ 0.12017855]]\n",
      "Iteration 4570 | Cost: 0.3531173448378051 | Gradient: [[ 0.02975109]\n",
      " [-0.07448792]\n",
      " [ 0.12016953]]\n",
      "Iteration 4571 | Cost: 0.3530964714586346 | Gradient: [[ 0.02975272]\n",
      " [-0.0744773 ]\n",
      " [ 0.12016051]]\n",
      "Iteration 4572 | Cost: 0.3530756017309295 | Gradient: [[ 0.02975435]\n",
      " [-0.0744667 ]\n",
      " [ 0.12015148]]\n",
      "Iteration 4573 | Cost: 0.3530547356536332 | Gradient: [[ 0.02975598]\n",
      " [-0.07445609]\n",
      " [ 0.12014246]]\n",
      "Iteration 4574 | Cost: 0.3530338732256896 | Gradient: [[ 0.02975761]\n",
      " [-0.0744455 ]\n",
      " [ 0.12013344]]\n",
      "Iteration 4575 | Cost: 0.3530130144460431 | Gradient: [[ 0.02975924]\n",
      " [-0.07443491]\n",
      " [ 0.12012442]]\n",
      "Iteration 4576 | Cost: 0.3529921593136388 | Gradient: [[ 0.02976086]\n",
      " [-0.07442432]\n",
      " [ 0.1201154 ]]\n",
      "Iteration 4577 | Cost: 0.35297130782742236 | Gradient: [[ 0.02976249]\n",
      " [-0.07441374]\n",
      " [ 0.12010638]]\n",
      "Iteration 4578 | Cost: 0.35295045998634006 | Gradient: [[ 0.02976411]\n",
      " [-0.07440316]\n",
      " [ 0.12009736]]\n",
      "Iteration 4579 | Cost: 0.3529296157893386 | Gradient: [[ 0.02976572]\n",
      " [-0.07439259]\n",
      " [ 0.12008834]]\n",
      "Iteration 4580 | Cost: 0.35290877523536557 | Gradient: [[ 0.02976734]\n",
      " [-0.07438202]\n",
      " [ 0.12007932]]\n",
      "Iteration 4581 | Cost: 0.352887938323369 | Gradient: [[ 0.02976895]\n",
      " [-0.07437146]\n",
      " [ 0.1200703 ]]\n",
      "Iteration 4582 | Cost: 0.35286710505229724 | Gradient: [[ 0.02977056]\n",
      " [-0.0743609 ]\n",
      " [ 0.12006128]]\n",
      "Iteration 4583 | Cost: 0.3528462754210996 | Gradient: [[ 0.02977217]\n",
      " [-0.07435035]\n",
      " [ 0.12005226]]\n",
      "Iteration 4584 | Cost: 0.35282544942872585 | Gradient: [[ 0.02977378]\n",
      " [-0.07433981]\n",
      " [ 0.12004324]]\n",
      "Iteration 4585 | Cost: 0.35280462707412635 | Gradient: [[ 0.02977539]\n",
      " [-0.07432927]\n",
      " [ 0.12003422]]\n",
      "Iteration 4586 | Cost: 0.35278380835625195 | Gradient: [[ 0.02977699]\n",
      " [-0.07431873]\n",
      " [ 0.1200252 ]]\n",
      "Iteration 4587 | Cost: 0.35276299327405425 | Gradient: [[ 0.02977859]\n",
      " [-0.0743082 ]\n",
      " [ 0.12001618]]\n",
      "Iteration 4588 | Cost: 0.3527421818264852 | Gradient: [[ 0.02978019]\n",
      " [-0.07429767]\n",
      " [ 0.12000716]]\n",
      "Iteration 4589 | Cost: 0.3527213740124976 | Gradient: [[ 0.02978179]\n",
      " [-0.07428715]\n",
      " [ 0.11999814]]\n",
      "Iteration 4590 | Cost: 0.3527005698310446 | Gradient: [[ 0.02978338]\n",
      " [-0.07427664]\n",
      " [ 0.11998912]]\n",
      "Iteration 4591 | Cost: 0.35267976928107997 | Gradient: [[ 0.02978497]\n",
      " [-0.07426613]\n",
      " [ 0.1199801 ]]\n",
      "Iteration 4592 | Cost: 0.3526589723615582 | Gradient: [[ 0.02978657]\n",
      " [-0.07425562]\n",
      " [ 0.11997108]]\n",
      "Iteration 4593 | Cost: 0.35263817907143424 | Gradient: [[ 0.02978815]\n",
      " [-0.07424512]\n",
      " [ 0.11996206]]\n",
      "Iteration 4594 | Cost: 0.3526173894096637 | Gradient: [[ 0.02978974]\n",
      " [-0.07423462]\n",
      " [ 0.11995304]]\n",
      "Iteration 4595 | Cost: 0.3525966033752026 | Gradient: [[ 0.02979133]\n",
      " [-0.07422413]\n",
      " [ 0.11994403]]\n",
      "Iteration 4596 | Cost: 0.35257582096700774 | Gradient: [[ 0.02979291]\n",
      " [-0.07421365]\n",
      " [ 0.11993501]]\n",
      "Iteration 4597 | Cost: 0.35255504218403644 | Gradient: [[ 0.02979449]\n",
      " [-0.07420317]\n",
      " [ 0.11992599]]\n",
      "Iteration 4598 | Cost: 0.35253426702524643 | Gradient: [[ 0.02979607]\n",
      " [-0.07419269]\n",
      " [ 0.11991697]]\n",
      "Iteration 4599 | Cost: 0.35251349548959626 | Gradient: [[ 0.02979764]\n",
      " [-0.07418222]\n",
      " [ 0.11990795]]\n",
      "Iteration 4600 | Cost: 0.35249272757604483 | Gradient: [[ 0.02979922]\n",
      " [-0.07417176]\n",
      " [ 0.11989893]]\n",
      "Iteration 4601 | Cost: 0.35247196328355174 | Gradient: [[ 0.02980079]\n",
      " [-0.0741613 ]\n",
      " [ 0.11988992]]\n",
      "Iteration 4602 | Cost: 0.3524512026110772 | Gradient: [[ 0.02980236]\n",
      " [-0.07415084]\n",
      " [ 0.1198809 ]]\n",
      "Iteration 4603 | Cost: 0.35243044555758196 | Gradient: [[ 0.02980393]\n",
      " [-0.07414039]\n",
      " [ 0.11987188]]\n",
      "Iteration 4604 | Cost: 0.3524096921220273 | Gradient: [[ 0.02980549]\n",
      " [-0.07412995]\n",
      " [ 0.11986286]]\n",
      "Iteration 4605 | Cost: 0.352388942303375 | Gradient: [[ 0.02980706]\n",
      " [-0.07411951]\n",
      " [ 0.11985385]]\n",
      "Iteration 4606 | Cost: 0.3523681961005875 | Gradient: [[ 0.02980862]\n",
      " [-0.07410907]\n",
      " [ 0.11984483]]\n",
      "Iteration 4607 | Cost: 0.3523474535126279 | Gradient: [[ 0.02981018]\n",
      " [-0.07409864]\n",
      " [ 0.11983581]]\n",
      "Iteration 4608 | Cost: 0.3523267145384597 | Gradient: [[ 0.02981174]\n",
      " [-0.07408822]\n",
      " [ 0.11982679]]\n",
      "Iteration 4609 | Cost: 0.3523059791770471 | Gradient: [[ 0.02981329]\n",
      " [-0.0740778 ]\n",
      " [ 0.11981778]]\n",
      "Iteration 4610 | Cost: 0.3522852474273548 | Gradient: [[ 0.02981484]\n",
      " [-0.07406739]\n",
      " [ 0.11980876]]\n",
      "Iteration 4611 | Cost: 0.35226451928834807 | Gradient: [[ 0.0298164 ]\n",
      " [-0.07405698]\n",
      " [ 0.11979974]]\n",
      "Iteration 4612 | Cost: 0.3522437947589927 | Gradient: [[ 0.02981795]\n",
      " [-0.07404657]\n",
      " [ 0.11979073]]\n",
      "Iteration 4613 | Cost: 0.35222307383825513 | Gradient: [[ 0.02981949]\n",
      " [-0.07403617]\n",
      " [ 0.11978171]]\n",
      "Iteration 4614 | Cost: 0.35220235652510246 | Gradient: [[ 0.02982104]\n",
      " [-0.07402578]\n",
      " [ 0.11977269]]\n",
      "Iteration 4615 | Cost: 0.35218164281850206 | Gradient: [[ 0.02982258]\n",
      " [-0.07401539]\n",
      " [ 0.11976368]]\n",
      "Iteration 4616 | Cost: 0.35216093271742216 | Gradient: [[ 0.02982412]\n",
      " [-0.074005  ]\n",
      " [ 0.11975466]]\n",
      "Iteration 4617 | Cost: 0.3521402262208313 | Gradient: [[ 0.02982566]\n",
      " [-0.07399462]\n",
      " [ 0.11974565]]\n",
      "Iteration 4618 | Cost: 0.3521195233276988 | Gradient: [[ 0.0298272 ]\n",
      " [-0.07398425]\n",
      " [ 0.11973663]]\n",
      "Iteration 4619 | Cost: 0.35209882403699455 | Gradient: [[ 0.02982873]\n",
      " [-0.07397388]\n",
      " [ 0.11972761]]\n",
      "Iteration 4620 | Cost: 0.3520781283476888 | Gradient: [[ 0.02983027]\n",
      " [-0.07396351]\n",
      " [ 0.1197186 ]]\n",
      "Iteration 4621 | Cost: 0.35205743625875235 | Gradient: [[ 0.0298318 ]\n",
      " [-0.07395315]\n",
      " [ 0.11970958]]\n",
      "Iteration 4622 | Cost: 0.35203674776915694 | Gradient: [[ 0.02983333]\n",
      " [-0.0739428 ]\n",
      " [ 0.11970057]]\n",
      "Iteration 4623 | Cost: 0.35201606287787457 | Gradient: [[ 0.02983486]\n",
      " [-0.07393245]\n",
      " [ 0.11969155]]\n",
      "Iteration 4624 | Cost: 0.3519953815838776 | Gradient: [[ 0.02983638]\n",
      " [-0.0739221 ]\n",
      " [ 0.11968254]]\n",
      "Iteration 4625 | Cost: 0.35197470388613944 | Gradient: [[ 0.0298379 ]\n",
      " [-0.07391176]\n",
      " [ 0.11967352]]\n",
      "Iteration 4626 | Cost: 0.3519540297836337 | Gradient: [[ 0.02983942]\n",
      " [-0.07390143]\n",
      " [ 0.11966451]]\n",
      "Iteration 4627 | Cost: 0.3519333592753347 | Gradient: [[ 0.02984094]\n",
      " [-0.0738911 ]\n",
      " [ 0.11965549]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4628 | Cost: 0.35191269236021727 | Gradient: [[ 0.02984246]\n",
      " [-0.07388077]\n",
      " [ 0.11964648]]\n",
      "Iteration 4629 | Cost: 0.35189202903725675 | Gradient: [[ 0.02984398]\n",
      " [-0.07387045]\n",
      " [ 0.11963747]]\n",
      "Iteration 4630 | Cost: 0.3518713693054291 | Gradient: [[ 0.02984549]\n",
      " [-0.07386013]\n",
      " [ 0.11962845]]\n",
      "Iteration 4631 | Cost: 0.351850713163711 | Gradient: [[ 0.029847  ]\n",
      " [-0.07384982]\n",
      " [ 0.11961944]]\n",
      "Iteration 4632 | Cost: 0.35183006061107924 | Gradient: [[ 0.02984851]\n",
      " [-0.07383952]\n",
      " [ 0.11961042]]\n",
      "Iteration 4633 | Cost: 0.35180941164651164 | Gradient: [[ 0.02985001]\n",
      " [-0.07382922]\n",
      " [ 0.11960141]]\n",
      "Iteration 4634 | Cost: 0.35178876626898625 | Gradient: [[ 0.02985152]\n",
      " [-0.07381892]\n",
      " [ 0.1195924 ]]\n",
      "Iteration 4635 | Cost: 0.35176812447748185 | Gradient: [[ 0.02985302]\n",
      " [-0.07380863]\n",
      " [ 0.11958338]]\n",
      "Iteration 4636 | Cost: 0.3517474862709778 | Gradient: [[ 0.02985452]\n",
      " [-0.07379834]\n",
      " [ 0.11957437]]\n",
      "Iteration 4637 | Cost: 0.3517268516484537 | Gradient: [[ 0.02985602]\n",
      " [-0.07378806]\n",
      " [ 0.11956536]]\n",
      "Iteration 4638 | Cost: 0.3517062206088901 | Gradient: [[ 0.02985752]\n",
      " [-0.07377779]\n",
      " [ 0.11955634]]\n",
      "Iteration 4639 | Cost: 0.351685593151268 | Gradient: [[ 0.02985901]\n",
      " [-0.07376752]\n",
      " [ 0.11954733]]\n",
      "Iteration 4640 | Cost: 0.3516649692745687 | Gradient: [[ 0.02986051]\n",
      " [-0.07375725]\n",
      " [ 0.11953832]]\n",
      "Iteration 4641 | Cost: 0.35164434897777436 | Gradient: [[ 0.029862  ]\n",
      " [-0.07374699]\n",
      " [ 0.11952931]]\n",
      "Iteration 4642 | Cost: 0.3516237322598676 | Gradient: [[ 0.02986349]\n",
      " [-0.07373673]\n",
      " [ 0.1195203 ]]\n",
      "Iteration 4643 | Cost: 0.3516031191198314 | Gradient: [[ 0.02986497]\n",
      " [-0.07372648]\n",
      " [ 0.11951128]]\n",
      "Iteration 4644 | Cost: 0.3515825095566495 | Gradient: [[ 0.02986646]\n",
      " [-0.07371623]\n",
      " [ 0.11950227]]\n",
      "Iteration 4645 | Cost: 0.35156190356930617 | Gradient: [[ 0.02986794]\n",
      " [-0.07370599]\n",
      " [ 0.11949326]]\n",
      "Iteration 4646 | Cost: 0.35154130115678617 | Gradient: [[ 0.02986942]\n",
      " [-0.07369576]\n",
      " [ 0.11948425]]\n",
      "Iteration 4647 | Cost: 0.35152070231807486 | Gradient: [[ 0.0298709 ]\n",
      " [-0.07368552]\n",
      " [ 0.11947524]]\n",
      "Iteration 4648 | Cost: 0.35150010705215806 | Gradient: [[ 0.02987238]\n",
      " [-0.0736753 ]\n",
      " [ 0.11946622]]\n",
      "Iteration 4649 | Cost: 0.35147951535802213 | Gradient: [[ 0.02987385]\n",
      " [-0.07366507]\n",
      " [ 0.11945721]]\n",
      "Iteration 4650 | Cost: 0.3514589272346542 | Gradient: [[ 0.02987532]\n",
      " [-0.07365486]\n",
      " [ 0.1194482 ]]\n",
      "Iteration 4651 | Cost: 0.3514383426810416 | Gradient: [[ 0.02987679]\n",
      " [-0.07364464]\n",
      " [ 0.11943919]]\n",
      "Iteration 4652 | Cost: 0.3514177616961726 | Gradient: [[ 0.02987826]\n",
      " [-0.07363444]\n",
      " [ 0.11943018]]\n",
      "Iteration 4653 | Cost: 0.35139718427903555 | Gradient: [[ 0.02987973]\n",
      " [-0.07362423]\n",
      " [ 0.11942117]]\n",
      "Iteration 4654 | Cost: 0.35137661042861973 | Gradient: [[ 0.02988119]\n",
      " [-0.07361403]\n",
      " [ 0.11941216]]\n",
      "Iteration 4655 | Cost: 0.35135604014391486 | Gradient: [[ 0.02988266]\n",
      " [-0.07360384]\n",
      " [ 0.11940315]]\n",
      "Iteration 4656 | Cost: 0.351335473423911 | Gradient: [[ 0.02988412]\n",
      " [-0.07359365]\n",
      " [ 0.11939414]]\n",
      "Iteration 4657 | Cost: 0.3513149102675991 | Gradient: [[ 0.02988558]\n",
      " [-0.07358347]\n",
      " [ 0.11938513]]\n",
      "Iteration 4658 | Cost: 0.35129435067397025 | Gradient: [[ 0.02988703]\n",
      " [-0.07357329]\n",
      " [ 0.11937612]]\n",
      "Iteration 4659 | Cost: 0.35127379464201647 | Gradient: [[ 0.02988849]\n",
      " [-0.07356312]\n",
      " [ 0.11936711]]\n",
      "Iteration 4660 | Cost: 0.3512532421707302 | Gradient: [[ 0.02988994]\n",
      " [-0.07355295]\n",
      " [ 0.1193581 ]]\n",
      "Iteration 4661 | Cost: 0.3512326932591042 | Gradient: [[ 0.02989139]\n",
      " [-0.07354278]\n",
      " [ 0.11934909]]\n",
      "Iteration 4662 | Cost: 0.3512121479061319 | Gradient: [[ 0.02989284]\n",
      " [-0.07353262]\n",
      " [ 0.11934008]]\n",
      "Iteration 4663 | Cost: 0.35119160611080746 | Gradient: [[ 0.02989429]\n",
      " [-0.07352247]\n",
      " [ 0.11933108]]\n",
      "Iteration 4664 | Cost: 0.3511710678721255 | Gradient: [[ 0.02989573]\n",
      " [-0.07351232]\n",
      " [ 0.11932207]]\n",
      "Iteration 4665 | Cost: 0.35115053318908085 | Gradient: [[ 0.02989718]\n",
      " [-0.07350218]\n",
      " [ 0.11931306]]\n",
      "Iteration 4666 | Cost: 0.3511300020606692 | Gradient: [[ 0.02989862]\n",
      " [-0.07349204]\n",
      " [ 0.11930405]]\n",
      "Iteration 4667 | Cost: 0.3511094744858868 | Gradient: [[ 0.02990006]\n",
      " [-0.0734819 ]\n",
      " [ 0.11929504]]\n",
      "Iteration 4668 | Cost: 0.3510889504637303 | Gradient: [[ 0.02990149]\n",
      " [-0.07347177]\n",
      " [ 0.11928603]]\n",
      "Iteration 4669 | Cost: 0.35106842999319676 | Gradient: [[ 0.02990293]\n",
      " [-0.07346164]\n",
      " [ 0.11927703]]\n",
      "Iteration 4670 | Cost: 0.35104791307328426 | Gradient: [[ 0.02990436]\n",
      " [-0.07345152]\n",
      " [ 0.11926802]]\n",
      "Iteration 4671 | Cost: 0.3510273997029908 | Gradient: [[ 0.02990579]\n",
      " [-0.07344141]\n",
      " [ 0.11925901]]\n",
      "Iteration 4672 | Cost: 0.3510068898813153 | Gradient: [[ 0.02990722]\n",
      " [-0.0734313 ]\n",
      " [ 0.11925   ]]\n",
      "Iteration 4673 | Cost: 0.35098638360725704 | Gradient: [[ 0.02990865]\n",
      " [-0.07342119]\n",
      " [ 0.119241  ]]\n",
      "Iteration 4674 | Cost: 0.3509658808798161 | Gradient: [[ 0.02991008]\n",
      " [-0.07341109]\n",
      " [ 0.11923199]]\n",
      "Iteration 4675 | Cost: 0.3509453816979928 | Gradient: [[ 0.0299115 ]\n",
      " [-0.07340099]\n",
      " [ 0.11922298]]\n",
      "Iteration 4676 | Cost: 0.35092488606078803 | Gradient: [[ 0.02991292]\n",
      " [-0.0733909 ]\n",
      " [ 0.11921398]]\n",
      "Iteration 4677 | Cost: 0.35090439396720335 | Gradient: [[ 0.02991434]\n",
      " [-0.07338081]\n",
      " [ 0.11920497]]\n",
      "Iteration 4678 | Cost: 0.3508839054162407 | Gradient: [[ 0.02991576]\n",
      " [-0.07337073]\n",
      " [ 0.11919597]]\n",
      "Iteration 4679 | Cost: 0.3508634204069027 | Gradient: [[ 0.02991718]\n",
      " [-0.07336065]\n",
      " [ 0.11918696]]\n",
      "Iteration 4680 | Cost: 0.35084293893819246 | Gradient: [[ 0.02991859]\n",
      " [-0.07335058]\n",
      " [ 0.11917795]]\n",
      "Iteration 4681 | Cost: 0.3508224610091134 | Gradient: [[ 0.02992   ]\n",
      " [-0.07334051]\n",
      " [ 0.11916895]]\n",
      "Iteration 4682 | Cost: 0.35080198661866985 | Gradient: [[ 0.02992141]\n",
      " [-0.07333045]\n",
      " [ 0.11915994]]\n",
      "Iteration 4683 | Cost: 0.3507815157658664 | Gradient: [[ 0.02992282]\n",
      " [-0.07332039]\n",
      " [ 0.11915094]]\n",
      "Iteration 4684 | Cost: 0.3507610484497081 | Gradient: [[ 0.02992422]\n",
      " [-0.07331033]\n",
      " [ 0.11914193]]\n",
      "Iteration 4685 | Cost: 0.3507405846692009 | Gradient: [[ 0.02992563]\n",
      " [-0.07330028]\n",
      " [ 0.11913293]]\n",
      "Iteration 4686 | Cost: 0.3507201244233509 | Gradient: [[ 0.02992703]\n",
      " [-0.07329024]\n",
      " [ 0.11912392]]\n",
      "Iteration 4687 | Cost: 0.3506996677111647 | Gradient: [[ 0.02992843]\n",
      " [-0.0732802 ]\n",
      " [ 0.11911492]]\n",
      "Iteration 4688 | Cost: 0.3506792145316499 | Gradient: [[ 0.02992983]\n",
      " [-0.07327016]\n",
      " [ 0.11910592]]\n",
      "Iteration 4689 | Cost: 0.35065876488381426 | Gradient: [[ 0.02993123]\n",
      " [-0.07326013]\n",
      " [ 0.11909691]]\n",
      "Iteration 4690 | Cost: 0.35063831876666585 | Gradient: [[ 0.02993262]\n",
      " [-0.07325011]\n",
      " [ 0.11908791]]\n",
      "Iteration 4691 | Cost: 0.3506178761792138 | Gradient: [[ 0.02993401]\n",
      " [-0.07324009]\n",
      " [ 0.1190789 ]]\n",
      "Iteration 4692 | Cost: 0.3505974371204675 | Gradient: [[ 0.0299354 ]\n",
      " [-0.07323007]\n",
      " [ 0.1190699 ]]\n",
      "Iteration 4693 | Cost: 0.35057700158943655 | Gradient: [[ 0.02993679]\n",
      " [-0.07322006]\n",
      " [ 0.1190609 ]]\n",
      "Iteration 4694 | Cost: 0.35055656958513176 | Gradient: [[ 0.02993818]\n",
      " [-0.07321005]\n",
      " [ 0.11905189]]\n",
      "Iteration 4695 | Cost: 0.3505361411065638 | Gradient: [[ 0.02993956]\n",
      " [-0.07320005]\n",
      " [ 0.11904289]]\n",
      "Iteration 4696 | Cost: 0.3505157161527443 | Gradient: [[ 0.02994095]\n",
      " [-0.07319005]\n",
      " [ 0.11903389]]\n",
      "Iteration 4697 | Cost: 0.3504952947226851 | Gradient: [[ 0.02994233]\n",
      " [-0.07318006]\n",
      " [ 0.11902489]]\n",
      "Iteration 4698 | Cost: 0.35047487681539896 | Gradient: [[ 0.02994371]\n",
      " [-0.07317007]\n",
      " [ 0.11901588]]\n",
      "Iteration 4699 | Cost: 0.3504544624298986 | Gradient: [[ 0.02994508]\n",
      " [-0.07316009]\n",
      " [ 0.11900688]]\n",
      "Iteration 4700 | Cost: 0.35043405156519775 | Gradient: [[ 0.02994646]\n",
      " [-0.07315011]\n",
      " [ 0.11899788]]\n",
      "Iteration 4701 | Cost: 0.3504136442203105 | Gradient: [[ 0.02994783]\n",
      " [-0.07314014]\n",
      " [ 0.11898888]]\n",
      "Iteration 4702 | Cost: 0.35039324039425135 | Gradient: [[ 0.0299492 ]\n",
      " [-0.07313017]\n",
      " [ 0.11897988]]\n",
      "Iteration 4703 | Cost: 0.3503728400860354 | Gradient: [[ 0.02995057]\n",
      " [-0.0731202 ]\n",
      " [ 0.11897088]]\n",
      "Iteration 4704 | Cost: 0.35035244329467835 | Gradient: [[ 0.02995194]\n",
      " [-0.07311024]\n",
      " [ 0.11896188]]\n",
      "Iteration 4705 | Cost: 0.3503320500191962 | Gradient: [[ 0.0299533 ]\n",
      " [-0.07310029]\n",
      " [ 0.11895287]]\n",
      "Iteration 4706 | Cost: 0.3503116602586058 | Gradient: [[ 0.02995467]\n",
      " [-0.07309034]\n",
      " [ 0.11894387]]\n",
      "Iteration 4707 | Cost: 0.3502912740119242 | Gradient: [[ 0.02995603]\n",
      " [-0.07308039]\n",
      " [ 0.11893487]]\n",
      "Iteration 4708 | Cost: 0.35027089127816896 | Gradient: [[ 0.02995739]\n",
      " [-0.07307045]\n",
      " [ 0.11892587]]\n",
      "Iteration 4709 | Cost: 0.35025051205635843 | Gradient: [[ 0.02995875]\n",
      " [-0.07306052]\n",
      " [ 0.11891687]]\n",
      "Iteration 4710 | Cost: 0.35023013634551137 | Gradient: [[ 0.0299601 ]\n",
      " [-0.07305058]\n",
      " [ 0.11890787]]\n",
      "Iteration 4711 | Cost: 0.35020976414464683 | Gradient: [[ 0.02996146]\n",
      " [-0.07304066]\n",
      " [ 0.11889887]]\n",
      "Iteration 4712 | Cost: 0.35018939545278466 | Gradient: [[ 0.02996281]\n",
      " [-0.07303074]\n",
      " [ 0.11888988]]\n",
      "Iteration 4713 | Cost: 0.3501690302689451 | Gradient: [[ 0.02996416]\n",
      " [-0.07302082]\n",
      " [ 0.11888088]]\n",
      "Iteration 4714 | Cost: 0.3501486685921488 | Gradient: [[ 0.02996551]\n",
      " [-0.0730109 ]\n",
      " [ 0.11887188]]\n",
      "Iteration 4715 | Cost: 0.35012831042141723 | Gradient: [[ 0.02996686]\n",
      " [-0.073001  ]\n",
      " [ 0.11886288]]\n",
      "Iteration 4716 | Cost: 0.35010795575577197 | Gradient: [[ 0.0299682 ]\n",
      " [-0.07299109]\n",
      " [ 0.11885388]]\n",
      "Iteration 4717 | Cost: 0.3500876045942354 | Gradient: [[ 0.02996954]\n",
      " [-0.07298119]\n",
      " [ 0.11884488]]\n",
      "Iteration 4718 | Cost: 0.3500672569358303 | Gradient: [[ 0.02997088]\n",
      " [-0.0729713 ]\n",
      " [ 0.11883588]]\n",
      "Iteration 4719 | Cost: 0.35004691277958006 | Gradient: [[ 0.02997222]\n",
      " [-0.07296141]\n",
      " [ 0.11882689]]\n",
      "Iteration 4720 | Cost: 0.35002657212450844 | Gradient: [[ 0.02997356]\n",
      " [-0.07295152]\n",
      " [ 0.11881789]]\n",
      "Iteration 4721 | Cost: 0.3500062349696397 | Gradient: [[ 0.02997489]\n",
      " [-0.07294164]\n",
      " [ 0.11880889]]\n",
      "Iteration 4722 | Cost: 0.34998590131399876 | Gradient: [[ 0.02997623]\n",
      " [-0.07293177]\n",
      " [ 0.11879989]]\n",
      "Iteration 4723 | Cost: 0.34996557115661103 | Gradient: [[ 0.02997756]\n",
      " [-0.0729219 ]\n",
      " [ 0.1187909 ]]\n",
      "Iteration 4724 | Cost: 0.34994524449650216 | Gradient: [[ 0.02997889]\n",
      " [-0.07291203]\n",
      " [ 0.1187819 ]]\n",
      "Iteration 4725 | Cost: 0.3499249213326986 | Gradient: [[ 0.02998022]\n",
      " [-0.07290217]\n",
      " [ 0.1187729 ]]\n",
      "Iteration 4726 | Cost: 0.34990460166422727 | Gradient: [[ 0.02998154]\n",
      " [-0.07289231]\n",
      " [ 0.11876391]]\n",
      "Iteration 4727 | Cost: 0.34988428549011547 | Gradient: [[ 0.02998287]\n",
      " [-0.07288246]\n",
      " [ 0.11875491]]\n",
      "Iteration 4728 | Cost: 0.34986397280939113 | Gradient: [[ 0.02998419]\n",
      " [-0.07287261]\n",
      " [ 0.11874592]]\n",
      "Iteration 4729 | Cost: 0.34984366362108255 | Gradient: [[ 0.02998551]\n",
      " [-0.07286277]\n",
      " [ 0.11873692]]\n",
      "Iteration 4730 | Cost: 0.3498233579242187 | Gradient: [[ 0.02998683]\n",
      " [-0.07285293]\n",
      " [ 0.11872793]]\n",
      "Iteration 4731 | Cost: 0.3498030557178289 | Gradient: [[ 0.02998814]\n",
      " [-0.07284309]\n",
      " [ 0.11871893]]\n",
      "Iteration 4732 | Cost: 0.34978275700094297 | Gradient: [[ 0.02998946]\n",
      " [-0.07283326]\n",
      " [ 0.11870994]]\n",
      "Iteration 4733 | Cost: 0.34976246177259146 | Gradient: [[ 0.02999077]\n",
      " [-0.07282344]\n",
      " [ 0.11870094]]\n",
      "Iteration 4734 | Cost: 0.34974217003180513 | Gradient: [[ 0.02999208]\n",
      " [-0.07281362]\n",
      " [ 0.11869195]]\n",
      "Iteration 4735 | Cost: 0.34972188177761543 | Gradient: [[ 0.02999339]\n",
      " [-0.0728038 ]\n",
      " [ 0.11868295]]\n",
      "Iteration 4736 | Cost: 0.3497015970090542 | Gradient: [[ 0.0299947 ]\n",
      " [-0.07279399]\n",
      " [ 0.11867396]]\n",
      "Iteration 4737 | Cost: 0.34968131572515393 | Gradient: [[ 0.029996  ]\n",
      " [-0.07278418]\n",
      " [ 0.11866496]]\n",
      "Iteration 4738 | Cost: 0.34966103792494746 | Gradient: [[ 0.02999731]\n",
      " [-0.07277438]\n",
      " [ 0.11865597]]\n",
      "Iteration 4739 | Cost: 0.34964076360746804 | Gradient: [[ 0.02999861]\n",
      " [-0.07276458]\n",
      " [ 0.11864698]]\n",
      "Iteration 4740 | Cost: 0.34962049277174984 | Gradient: [[ 0.02999991]\n",
      " [-0.07275479]\n",
      " [ 0.11863798]]\n",
      "Iteration 4741 | Cost: 0.3496002254168269 | Gradient: [[ 0.0300012 ]\n",
      " [-0.072745  ]\n",
      " [ 0.11862899]]\n",
      "Iteration 4742 | Cost: 0.34957996154173454 | Gradient: [[ 0.0300025 ]\n",
      " [-0.07273522]\n",
      " [ 0.11862   ]]\n",
      "Iteration 4743 | Cost: 0.3495597011455077 | Gradient: [[ 0.03000379]\n",
      " [-0.07272544]\n",
      " [ 0.11861101]]\n",
      "Iteration 4744 | Cost: 0.34953944422718264 | Gradient: [[ 0.03000509]\n",
      " [-0.07271566]\n",
      " [ 0.11860201]]\n",
      "Iteration 4745 | Cost: 0.3495191907857956 | Gradient: [[ 0.03000638]\n",
      " [-0.07270589]\n",
      " [ 0.11859302]]\n",
      "Iteration 4746 | Cost: 0.34949894082038324 | Gradient: [[ 0.03000766]\n",
      " [-0.07269613]\n",
      " [ 0.11858403]]\n",
      "Iteration 4747 | Cost: 0.3494786943299833 | Gradient: [[ 0.03000895]\n",
      " [-0.07268636]\n",
      " [ 0.11857504]]\n",
      "Iteration 4748 | Cost: 0.3494584513136333 | Gradient: [[ 0.03001024]\n",
      " [-0.07267661]\n",
      " [ 0.11856605]]\n",
      "Iteration 4749 | Cost: 0.3494382117703719 | Gradient: [[ 0.03001152]\n",
      " [-0.07266686]\n",
      " [ 0.11855706]]\n",
      "Iteration 4750 | Cost: 0.34941797569923777 | Gradient: [[ 0.0300128 ]\n",
      " [-0.07265711]\n",
      " [ 0.11854807]]\n",
      "Iteration 4751 | Cost: 0.3493977430992702 | Gradient: [[ 0.03001408]\n",
      " [-0.07264736]\n",
      " [ 0.11853908]]\n",
      "Iteration 4752 | Cost: 0.3493775139695093 | Gradient: [[ 0.03001536]\n",
      " [-0.07263763]\n",
      " [ 0.11853009]]\n",
      "Iteration 4753 | Cost: 0.34935728830899504 | Gradient: [[ 0.03001663]\n",
      " [-0.07262789]\n",
      " [ 0.1185211 ]]\n",
      "Iteration 4754 | Cost: 0.3493370661167686 | Gradient: [[ 0.03001791]\n",
      " [-0.07261816]\n",
      " [ 0.11851211]]\n",
      "Iteration 4755 | Cost: 0.349316847391871 | Gradient: [[ 0.03001918]\n",
      " [-0.07260844]\n",
      " [ 0.11850312]]\n",
      "Iteration 4756 | Cost: 0.3492966321333444 | Gradient: [[ 0.03002045]\n",
      " [-0.07259872]\n",
      " [ 0.11849413]]\n",
      "Iteration 4757 | Cost: 0.34927642034023076 | Gradient: [[ 0.03002172]\n",
      " [-0.072589  ]\n",
      " [ 0.11848514]]\n",
      "Iteration 4758 | Cost: 0.34925621201157286 | Gradient: [[ 0.03002298]\n",
      " [-0.07257929]\n",
      " [ 0.11847615]]\n",
      "Iteration 4759 | Cost: 0.34923600714641423 | Gradient: [[ 0.03002425]\n",
      " [-0.07256958]\n",
      " [ 0.11846716]]\n",
      "Iteration 4760 | Cost: 0.3492158057437985 | Gradient: [[ 0.03002551]\n",
      " [-0.07255988]\n",
      " [ 0.11845817]]\n",
      "Iteration 4761 | Cost: 0.34919560780277 | Gradient: [[ 0.03002677]\n",
      " [-0.07255018]\n",
      " [ 0.11844919]]\n",
      "Iteration 4762 | Cost: 0.3491754133223734 | Gradient: [[ 0.03002803]\n",
      " [-0.07254049]\n",
      " [ 0.1184402 ]]\n",
      "Iteration 4763 | Cost: 0.34915522230165397 | Gradient: [[ 0.03002929]\n",
      " [-0.0725308 ]\n",
      " [ 0.11843121]]\n",
      "Iteration 4764 | Cost: 0.34913503473965735 | Gradient: [[ 0.03003054]\n",
      " [-0.07252112]\n",
      " [ 0.11842222]]\n",
      "Iteration 4765 | Cost: 0.3491148506354299 | Gradient: [[ 0.03003179]\n",
      " [-0.07251144]\n",
      " [ 0.11841324]]\n",
      "Iteration 4766 | Cost: 0.34909466998801814 | Gradient: [[ 0.03003305]\n",
      " [-0.07250176]\n",
      " [ 0.11840425]]\n",
      "Iteration 4767 | Cost: 0.34907449279646935 | Gradient: [[ 0.0300343 ]\n",
      " [-0.07249209]\n",
      " [ 0.11839526]]\n",
      "Iteration 4768 | Cost: 0.34905431905983125 | Gradient: [[ 0.03003554]\n",
      " [-0.07248242]\n",
      " [ 0.11838628]]\n",
      "Iteration 4769 | Cost: 0.349034148777152 | Gradient: [[ 0.03003679]\n",
      " [-0.07247276]\n",
      " [ 0.11837729]]\n",
      "Iteration 4770 | Cost: 0.34901398194748 | Gradient: [[ 0.03003803]\n",
      " [-0.0724631 ]\n",
      " [ 0.1183683 ]]\n",
      "Iteration 4771 | Cost: 0.3489938185698646 | Gradient: [[ 0.03003928]\n",
      " [-0.07245345]\n",
      " [ 0.11835932]]\n",
      "Iteration 4772 | Cost: 0.3489736586433554 | Gradient: [[ 0.03004052]\n",
      " [-0.0724438 ]\n",
      " [ 0.11835033]]\n",
      "Iteration 4773 | Cost: 0.3489535021670023 | Gradient: [[ 0.03004176]\n",
      " [-0.07243416]\n",
      " [ 0.11834135]]\n",
      "Iteration 4774 | Cost: 0.3489333491398561 | Gradient: [[ 0.03004299]\n",
      " [-0.07242452]\n",
      " [ 0.11833236]]\n",
      "Iteration 4775 | Cost: 0.34891319956096783 | Gradient: [[ 0.03004423]\n",
      " [-0.07241488]\n",
      " [ 0.11832338]]\n",
      "Iteration 4776 | Cost: 0.3488930534293888 | Gradient: [[ 0.03004546]\n",
      " [-0.07240525]\n",
      " [ 0.1183144 ]]\n",
      "Iteration 4777 | Cost: 0.34887291074417126 | Gradient: [[ 0.03004669]\n",
      " [-0.07239563]\n",
      " [ 0.11830541]]\n",
      "Iteration 4778 | Cost: 0.3488527715043675 | Gradient: [[ 0.03004792]\n",
      " [-0.072386  ]\n",
      " [ 0.11829643]]\n",
      "Iteration 4779 | Cost: 0.3488326357090308 | Gradient: [[ 0.03004915]\n",
      " [-0.07237639]\n",
      " [ 0.11828745]]\n",
      "Iteration 4780 | Cost: 0.34881250335721437 | Gradient: [[ 0.03005038]\n",
      " [-0.07236677]\n",
      " [ 0.11827846]]\n",
      "Iteration 4781 | Cost: 0.3487923744479722 | Gradient: [[ 0.0300516 ]\n",
      " [-0.07235717]\n",
      " [ 0.11826948]]\n",
      "Iteration 4782 | Cost: 0.34877224898035875 | Gradient: [[ 0.03005283]\n",
      " [-0.07234756]\n",
      " [ 0.1182605 ]]\n",
      "Iteration 4783 | Cost: 0.34875212695342883 | Gradient: [[ 0.03005405]\n",
      " [-0.07233796]\n",
      " [ 0.11825151]]\n",
      "Iteration 4784 | Cost: 0.3487320083662379 | Gradient: [[ 0.03005527]\n",
      " [-0.07232837]\n",
      " [ 0.11824253]]\n",
      "Iteration 4785 | Cost: 0.3487118932178418 | Gradient: [[ 0.03005648]\n",
      " [-0.07231878]\n",
      " [ 0.11823355]]\n",
      "Iteration 4786 | Cost: 0.34869178150729674 | Gradient: [[ 0.0300577 ]\n",
      " [-0.07230919]\n",
      " [ 0.11822457]]\n",
      "Iteration 4787 | Cost: 0.3486716732336598 | Gradient: [[ 0.03005891]\n",
      " [-0.07229961]\n",
      " [ 0.11821559]]\n",
      "Iteration 4788 | Cost: 0.348651568395988 | Gradient: [[ 0.03006012]\n",
      " [-0.07229003]\n",
      " [ 0.11820661]]\n",
      "Iteration 4789 | Cost: 0.3486314669933392 | Gradient: [[ 0.03006133]\n",
      " [-0.07228046]\n",
      " [ 0.11819763]]\n",
      "Iteration 4790 | Cost: 0.3486113690247715 | Gradient: [[ 0.03006254]\n",
      " [-0.07227089]\n",
      " [ 0.11818865]]\n",
      "Iteration 4791 | Cost: 0.34859127448934396 | Gradient: [[ 0.03006375]\n",
      " [-0.07226132]\n",
      " [ 0.11817966]]\n",
      "Iteration 4792 | Cost: 0.3485711833861154 | Gradient: [[ 0.03006495]\n",
      " [-0.07225176]\n",
      " [ 0.11817069]]\n",
      "Iteration 4793 | Cost: 0.34855109571414566 | Gradient: [[ 0.03006616]\n",
      " [-0.07224221]\n",
      " [ 0.11816171]]\n",
      "Iteration 4794 | Cost: 0.34853101147249477 | Gradient: [[ 0.03006736]\n",
      " [-0.07223266]\n",
      " [ 0.11815273]]\n",
      "Iteration 4795 | Cost: 0.3485109306602234 | Gradient: [[ 0.03006856]\n",
      " [-0.07222311]\n",
      " [ 0.11814375]]\n",
      "Iteration 4796 | Cost: 0.3484908532763926 | Gradient: [[ 0.03006975]\n",
      " [-0.07221357]\n",
      " [ 0.11813477]]\n",
      "Iteration 4797 | Cost: 0.34847077932006404 | Gradient: [[ 0.03007095]\n",
      " [-0.07220403]\n",
      " [ 0.11812579]]\n",
      "Iteration 4798 | Cost: 0.34845070879029955 | Gradient: [[ 0.03007214]\n",
      " [-0.0721945 ]\n",
      " [ 0.11811681]]\n",
      "Iteration 4799 | Cost: 0.3484306416861617 | Gradient: [[ 0.03007334]\n",
      " [-0.07218497]\n",
      " [ 0.11810783]]\n",
      "Iteration 4800 | Cost: 0.34841057800671343 | Gradient: [[ 0.03007453]\n",
      " [-0.07217544]\n",
      " [ 0.11809886]]\n",
      "Iteration 4801 | Cost: 0.34839051775101826 | Gradient: [[ 0.03007571]\n",
      " [-0.07216592]\n",
      " [ 0.11808988]]\n",
      "Iteration 4802 | Cost: 0.34837046091814 | Gradient: [[ 0.0300769 ]\n",
      " [-0.07215641]\n",
      " [ 0.1180809 ]]\n",
      "Iteration 4803 | Cost: 0.34835040750714313 | Gradient: [[ 0.03007809]\n",
      " [-0.0721469 ]\n",
      " [ 0.11807192]]\n",
      "Iteration 4804 | Cost: 0.34833035751709235 | Gradient: [[ 0.03007927]\n",
      " [-0.07213739]\n",
      " [ 0.11806295]]\n",
      "Iteration 4805 | Cost: 0.3483103109470531 | Gradient: [[ 0.03008045]\n",
      " [-0.07212789]\n",
      " [ 0.11805397]]\n",
      "Iteration 4806 | Cost: 0.34829026779609107 | Gradient: [[ 0.03008163]\n",
      " [-0.07211839]\n",
      " [ 0.11804499]]\n",
      "Iteration 4807 | Cost: 0.3482702280632725 | Gradient: [[ 0.03008281]\n",
      " [-0.07210889]\n",
      " [ 0.11803602]]\n",
      "Iteration 4808 | Cost: 0.3482501917476643 | Gradient: [[ 0.03008399]\n",
      " [-0.0720994 ]\n",
      " [ 0.11802704]]\n",
      "Iteration 4809 | Cost: 0.3482301588483334 | Gradient: [[ 0.03008516]\n",
      " [-0.07208992]\n",
      " [ 0.11801807]]\n",
      "Iteration 4810 | Cost: 0.3482101293643476 | Gradient: [[ 0.03008633]\n",
      " [-0.07208044]\n",
      " [ 0.11800909]]\n",
      "Iteration 4811 | Cost: 0.348190103294775 | Gradient: [[ 0.0300875 ]\n",
      " [-0.07207096]\n",
      " [ 0.11800012]]\n",
      "Iteration 4812 | Cost: 0.3481700806386841 | Gradient: [[ 0.03008867]\n",
      " [-0.07206149]\n",
      " [ 0.11799114]]\n",
      "Iteration 4813 | Cost: 0.348150061395144 | Gradient: [[ 0.03008984]\n",
      " [-0.07205202]\n",
      " [ 0.11798217]]\n",
      "Iteration 4814 | Cost: 0.3481300455632242 | Gradient: [[ 0.03009101]\n",
      " [-0.07204256]\n",
      " [ 0.1179732 ]]\n",
      "Iteration 4815 | Cost: 0.3481100331419948 | Gradient: [[ 0.03009217]\n",
      " [-0.0720331 ]\n",
      " [ 0.11796422]]\n",
      "Iteration 4816 | Cost: 0.348090024130526 | Gradient: [[ 0.03009333]\n",
      " [-0.07202364]\n",
      " [ 0.11795525]]\n",
      "Iteration 4817 | Cost: 0.34807001852788894 | Gradient: [[ 0.03009449]\n",
      " [-0.07201419]\n",
      " [ 0.11794628]]\n",
      "Iteration 4818 | Cost: 0.34805001633315474 | Gradient: [[ 0.03009565]\n",
      " [-0.07200475]\n",
      " [ 0.1179373 ]]\n",
      "Iteration 4819 | Cost: 0.3480300175453954 | Gradient: [[ 0.03009681]\n",
      " [-0.0719953 ]\n",
      " [ 0.11792833]]\n",
      "Iteration 4820 | Cost: 0.3480100221636832 | Gradient: [[ 0.03009796]\n",
      " [-0.07198587]\n",
      " [ 0.11791936]]\n",
      "Iteration 4821 | Cost: 0.3479900301870909 | Gradient: [[ 0.03009911]\n",
      " [-0.07197643]\n",
      " [ 0.11791039]]\n",
      "Iteration 4822 | Cost: 0.3479700416146917 | Gradient: [[ 0.03010027]\n",
      " [-0.07196701]\n",
      " [ 0.11790142]]\n",
      "Iteration 4823 | Cost: 0.3479500564455592 | Gradient: [[ 0.03010142]\n",
      " [-0.07195758]\n",
      " [ 0.11789245]]\n",
      "Iteration 4824 | Cost: 0.3479300746787677 | Gradient: [[ 0.03010256]\n",
      " [-0.07194816]\n",
      " [ 0.11788347]]\n",
      "Iteration 4825 | Cost: 0.3479100963133916 | Gradient: [[ 0.03010371]\n",
      " [-0.07193874]\n",
      " [ 0.1178745 ]]\n",
      "Iteration 4826 | Cost: 0.34789012134850605 | Gradient: [[ 0.03010486]\n",
      " [-0.07192933]\n",
      " [ 0.11786553]]\n",
      "Iteration 4827 | Cost: 0.34787014978318653 | Gradient: [[ 0.030106  ]\n",
      " [-0.07191993]\n",
      " [ 0.11785656]]\n",
      "Iteration 4828 | Cost: 0.3478501816165091 | Gradient: [[ 0.03010714]\n",
      " [-0.07191052]\n",
      " [ 0.11784759]]\n",
      "Iteration 4829 | Cost: 0.3478302168475501 | Gradient: [[ 0.03010828]\n",
      " [-0.07190112]\n",
      " [ 0.11783862]]\n",
      "Iteration 4830 | Cost: 0.3478102554753865 | Gradient: [[ 0.03010942]\n",
      " [-0.07189173]\n",
      " [ 0.11782965]]\n",
      "Iteration 4831 | Cost: 0.34779029749909546 | Gradient: [[ 0.03011055]\n",
      " [-0.07188234]\n",
      " [ 0.11782069]]\n",
      "Iteration 4832 | Cost: 0.3477703429177551 | Gradient: [[ 0.03011169]\n",
      " [-0.07187295]\n",
      " [ 0.11781172]]\n",
      "Iteration 4833 | Cost: 0.34775039173044336 | Gradient: [[ 0.03011282]\n",
      " [-0.07186357]\n",
      " [ 0.11780275]]\n",
      "Iteration 4834 | Cost: 0.34773044393623925 | Gradient: [[ 0.03011395]\n",
      " [-0.07185419]\n",
      " [ 0.11779378]]\n",
      "Iteration 4835 | Cost: 0.3477104995342216 | Gradient: [[ 0.03011508]\n",
      " [-0.07184482]\n",
      " [ 0.11778481]]\n",
      "Iteration 4836 | Cost: 0.3476905585234704 | Gradient: [[ 0.0301162 ]\n",
      " [-0.07183545]\n",
      " [ 0.11777585]]\n",
      "Iteration 4837 | Cost: 0.34767062090306555 | Gradient: [[ 0.03011733]\n",
      " [-0.07182609]\n",
      " [ 0.11776688]]\n",
      "Iteration 4838 | Cost: 0.34765068667208754 | Gradient: [[ 0.03011845]\n",
      " [-0.07181673]\n",
      " [ 0.11775791]]\n",
      "Iteration 4839 | Cost: 0.34763075582961744 | Gradient: [[ 0.03011958]\n",
      " [-0.07180737]\n",
      " [ 0.11774895]]\n",
      "Iteration 4840 | Cost: 0.34761082837473656 | Gradient: [[ 0.0301207 ]\n",
      " [-0.07179802]\n",
      " [ 0.11773998]]\n",
      "Iteration 4841 | Cost: 0.347590904306527 | Gradient: [[ 0.03012181]\n",
      " [-0.07178867]\n",
      " [ 0.11773101]]\n",
      "Iteration 4842 | Cost: 0.34757098362407113 | Gradient: [[ 0.03012293]\n",
      " [-0.07177933]\n",
      " [ 0.11772205]]\n",
      "Iteration 4843 | Cost: 0.34755106632645155 | Gradient: [[ 0.03012405]\n",
      " [-0.07176999]\n",
      " [ 0.11771308]]\n",
      "Iteration 4844 | Cost: 0.34753115241275156 | Gradient: [[ 0.03012516]\n",
      " [-0.07176066]\n",
      " [ 0.11770412]]\n",
      "Iteration 4845 | Cost: 0.34751124188205496 | Gradient: [[ 0.03012627]\n",
      " [-0.07175132]\n",
      " [ 0.11769515]]\n",
      "Iteration 4846 | Cost: 0.3474913347334459 | Gradient: [[ 0.03012738]\n",
      " [-0.071742  ]\n",
      " [ 0.11768619]]\n",
      "Iteration 4847 | Cost: 0.34747143096600885 | Gradient: [[ 0.03012849]\n",
      " [-0.07173268]\n",
      " [ 0.11767723]]\n",
      "Iteration 4848 | Cost: 0.3474515305788291 | Gradient: [[ 0.0301296 ]\n",
      " [-0.07172336]\n",
      " [ 0.11766826]]\n",
      "Iteration 4849 | Cost: 0.3474316335709919 | Gradient: [[ 0.0301307 ]\n",
      " [-0.07171405]\n",
      " [ 0.1176593 ]]\n",
      "Iteration 4850 | Cost: 0.34741173994158336 | Gradient: [[ 0.0301318 ]\n",
      " [-0.07170474]\n",
      " [ 0.11765034]]\n",
      "Iteration 4851 | Cost: 0.34739184968968995 | Gradient: [[ 0.0301329 ]\n",
      " [-0.07169543]\n",
      " [ 0.11764137]]\n",
      "Iteration 4852 | Cost: 0.3473719628143983 | Gradient: [[ 0.030134  ]\n",
      " [-0.07168613]\n",
      " [ 0.11763241]]\n",
      "Iteration 4853 | Cost: 0.34735207931479595 | Gradient: [[ 0.0301351 ]\n",
      " [-0.07167683]\n",
      " [ 0.11762345]]\n",
      "Iteration 4854 | Cost: 0.3473321991899706 | Gradient: [[ 0.0301362 ]\n",
      " [-0.07166754]\n",
      " [ 0.11761449]]\n",
      "Iteration 4855 | Cost: 0.3473123224390102 | Gradient: [[ 0.03013729]\n",
      " [-0.07165825]\n",
      " [ 0.11760552]]\n",
      "Iteration 4856 | Cost: 0.3472924490610037 | Gradient: [[ 0.03013839]\n",
      " [-0.07164897]\n",
      " [ 0.11759656]]\n",
      "Iteration 4857 | Cost: 0.3472725790550401 | Gradient: [[ 0.03013948]\n",
      " [-0.07163969]\n",
      " [ 0.1175876 ]]\n",
      "Iteration 4858 | Cost: 0.34725271242020894 | Gradient: [[ 0.03014057]\n",
      " [-0.07163041]\n",
      " [ 0.11757864]]\n",
      "Iteration 4859 | Cost: 0.3472328491556001 | Gradient: [[ 0.03014165]\n",
      " [-0.07162114]\n",
      " [ 0.11756968]]\n",
      "Iteration 4860 | Cost: 0.3472129892603041 | Gradient: [[ 0.03014274]\n",
      " [-0.07161188]\n",
      " [ 0.11756072]]\n",
      "Iteration 4861 | Cost: 0.34719313273341185 | Gradient: [[ 0.03014382]\n",
      " [-0.07160261]\n",
      " [ 0.11755176]]\n",
      "Iteration 4862 | Cost: 0.34717327957401467 | Gradient: [[ 0.03014491]\n",
      " [-0.07159336]\n",
      " [ 0.1175428 ]]\n",
      "Iteration 4863 | Cost: 0.34715342978120417 | Gradient: [[ 0.03014599]\n",
      " [-0.0715841 ]\n",
      " [ 0.11753384]]\n",
      "Iteration 4864 | Cost: 0.3471335833540727 | Gradient: [[ 0.03014707]\n",
      " [-0.07157485]\n",
      " [ 0.11752489]]\n",
      "Iteration 4865 | Cost: 0.3471137402917128 | Gradient: [[ 0.03014814]\n",
      " [-0.0715656 ]\n",
      " [ 0.11751593]]\n",
      "Iteration 4866 | Cost: 0.3470939005932177 | Gradient: [[ 0.03014922]\n",
      " [-0.07155636]\n",
      " [ 0.11750697]]\n",
      "Iteration 4867 | Cost: 0.34707406425768084 | Gradient: [[ 0.03015029]\n",
      " [-0.07154713]\n",
      " [ 0.11749801]]\n",
      "Iteration 4868 | Cost: 0.34705423128419627 | Gradient: [[ 0.03015137]\n",
      " [-0.07153789]\n",
      " [ 0.11748905]]\n",
      "Iteration 4869 | Cost: 0.3470344016718583 | Gradient: [[ 0.03015244]\n",
      " [-0.07152866]\n",
      " [ 0.1174801 ]]\n",
      "Iteration 4870 | Cost: 0.34701457541976183 | Gradient: [[ 0.0301535 ]\n",
      " [-0.07151944]\n",
      " [ 0.11747114]]\n",
      "Iteration 4871 | Cost: 0.3469947525270022 | Gradient: [[ 0.03015457]\n",
      " [-0.07151022]\n",
      " [ 0.11746218]]\n",
      "Iteration 4872 | Cost: 0.3469749329926751 | Gradient: [[ 0.03015564]\n",
      " [-0.071501  ]\n",
      " [ 0.11745323]]\n",
      "Iteration 4873 | Cost: 0.34695511681587676 | Gradient: [[ 0.0301567 ]\n",
      " [-0.07149179]\n",
      " [ 0.11744427]]\n",
      "Iteration 4874 | Cost: 0.34693530399570377 | Gradient: [[ 0.03015776]\n",
      " [-0.07148258]\n",
      " [ 0.11743532]]\n",
      "Iteration 4875 | Cost: 0.3469154945312531 | Gradient: [[ 0.03015882]\n",
      " [-0.07147337]\n",
      " [ 0.11742636]]\n",
      "Iteration 4876 | Cost: 0.3468956884216224 | Gradient: [[ 0.03015988]\n",
      " [-0.07146417]\n",
      " [ 0.11741741]]\n",
      "Iteration 4877 | Cost: 0.3468758856659095 | Gradient: [[ 0.03016094]\n",
      " [-0.07145498]\n",
      " [ 0.11740845]]\n",
      "Iteration 4878 | Cost: 0.3468560862632129 | Gradient: [[ 0.030162  ]\n",
      " [-0.07144579]\n",
      " [ 0.1173995 ]]\n",
      "Iteration 4879 | Cost: 0.3468362902126312 | Gradient: [[ 0.03016305]\n",
      " [-0.0714366 ]\n",
      " [ 0.11739054]]\n",
      "Iteration 4880 | Cost: 0.3468164975132638 | Gradient: [[ 0.0301641 ]\n",
      " [-0.07142742]\n",
      " [ 0.11738159]]\n",
      "Iteration 4881 | Cost: 0.3467967081642104 | Gradient: [[ 0.03016515]\n",
      " [-0.07141824]\n",
      " [ 0.11737264]]\n",
      "Iteration 4882 | Cost: 0.346776922164571 | Gradient: [[ 0.0301662 ]\n",
      " [-0.07140906]\n",
      " [ 0.11736368]]\n",
      "Iteration 4883 | Cost: 0.3467571395134463 | Gradient: [[ 0.03016725]\n",
      " [-0.07139989]\n",
      " [ 0.11735473]]\n",
      "Iteration 4884 | Cost: 0.34673736020993723 | Gradient: [[ 0.03016829]\n",
      " [-0.07139072]\n",
      " [ 0.11734578]]\n",
      "Iteration 4885 | Cost: 0.3467175842531451 | Gradient: [[ 0.03016934]\n",
      " [-0.07138156]\n",
      " [ 0.11733683]]\n",
      "Iteration 4886 | Cost: 0.346697811642172 | Gradient: [[ 0.03017038]\n",
      " [-0.0713724 ]\n",
      " [ 0.11732788]]\n",
      "Iteration 4887 | Cost: 0.34667804237612004 | Gradient: [[ 0.03017142]\n",
      " [-0.07136325]\n",
      " [ 0.11731893]]\n",
      "Iteration 4888 | Cost: 0.346658276454092 | Gradient: [[ 0.03017246]\n",
      " [-0.0713541 ]\n",
      " [ 0.11730997]]\n",
      "Iteration 4889 | Cost: 0.34663851387519107 | Gradient: [[ 0.03017349]\n",
      " [-0.07134495]\n",
      " [ 0.11730102]]\n",
      "Iteration 4890 | Cost: 0.3466187546385208 | Gradient: [[ 0.03017453]\n",
      " [-0.07133581]\n",
      " [ 0.11729207]]\n",
      "Iteration 4891 | Cost: 0.34659899874318534 | Gradient: [[ 0.03017556]\n",
      " [-0.07132667]\n",
      " [ 0.11728312]]\n",
      "Iteration 4892 | Cost: 0.34657924618828906 | Gradient: [[ 0.0301766 ]\n",
      " [-0.07131754]\n",
      " [ 0.11727417]]\n",
      "Iteration 4893 | Cost: 0.3465594969729368 | Gradient: [[ 0.03017763]\n",
      " [-0.07130841]\n",
      " [ 0.11726523]]\n",
      "Iteration 4894 | Cost: 0.3465397510962339 | Gradient: [[ 0.03017866]\n",
      " [-0.07129928]\n",
      " [ 0.11725628]]\n",
      "Iteration 4895 | Cost: 0.3465200085572863 | Gradient: [[ 0.03017968]\n",
      " [-0.07129016]\n",
      " [ 0.11724733]]\n",
      "Iteration 4896 | Cost: 0.34650026935519995 | Gradient: [[ 0.03018071]\n",
      " [-0.07128104]\n",
      " [ 0.11723838]]\n",
      "Iteration 4897 | Cost: 0.3464805334890816 | Gradient: [[ 0.03018173]\n",
      " [-0.07127193]\n",
      " [ 0.11722943]]\n",
      "Iteration 4898 | Cost: 0.3464608009580383 | Gradient: [[ 0.03018275]\n",
      " [-0.07126282]\n",
      " [ 0.11722048]]\n",
      "Iteration 4899 | Cost: 0.34644107176117733 | Gradient: [[ 0.03018377]\n",
      " [-0.07125372]\n",
      " [ 0.11721154]]\n",
      "Iteration 4900 | Cost: 0.3464213458976068 | Gradient: [[ 0.03018479]\n",
      " [-0.07124461]\n",
      " [ 0.11720259]]\n",
      "Iteration 4901 | Cost: 0.3464016233664351 | Gradient: [[ 0.03018581]\n",
      " [-0.07123552]\n",
      " [ 0.11719364]]\n",
      "Iteration 4902 | Cost: 0.34638190416677084 | Gradient: [[ 0.03018683]\n",
      " [-0.07122642]\n",
      " [ 0.1171847 ]]\n",
      "Iteration 4903 | Cost: 0.3463621882977232 | Gradient: [[ 0.03018784]\n",
      " [-0.07121734]\n",
      " [ 0.11717575]]\n",
      "Iteration 4904 | Cost: 0.346342475758402 | Gradient: [[ 0.03018885]\n",
      " [-0.07120825]\n",
      " [ 0.11716681]]\n",
      "Iteration 4905 | Cost: 0.346322766547917 | Gradient: [[ 0.03018986]\n",
      " [-0.07119917]\n",
      " [ 0.11715786]]\n",
      "Iteration 4906 | Cost: 0.34630306066537886 | Gradient: [[ 0.03019087]\n",
      " [-0.07119009]\n",
      " [ 0.11714892]]\n",
      "Iteration 4907 | Cost: 0.34628335810989846 | Gradient: [[ 0.03019188]\n",
      " [-0.07118102]\n",
      " [ 0.11713997]]\n",
      "Iteration 4908 | Cost: 0.3462636588805871 | Gradient: [[ 0.03019288]\n",
      " [-0.07117195]\n",
      " [ 0.11713103]]\n",
      "Iteration 4909 | Cost: 0.3462439629765564 | Gradient: [[ 0.03019389]\n",
      " [-0.07116289]\n",
      " [ 0.11712209]]\n",
      "Iteration 4910 | Cost: 0.3462242703969189 | Gradient: [[ 0.03019489]\n",
      " [-0.07115383]\n",
      " [ 0.11711314]]\n",
      "Iteration 4911 | Cost: 0.34620458114078684 | Gradient: [[ 0.03019589]\n",
      " [-0.07114477]\n",
      " [ 0.1171042 ]]\n",
      "Iteration 4912 | Cost: 0.34618489520727336 | Gradient: [[ 0.03019689]\n",
      " [-0.07113572]\n",
      " [ 0.11709526]]\n",
      "Iteration 4913 | Cost: 0.346165212595492 | Gradient: [[ 0.03019789]\n",
      " [-0.07112667]\n",
      " [ 0.11708631]]\n",
      "Iteration 4914 | Cost: 0.34614553330455644 | Gradient: [[ 0.03019888]\n",
      " [-0.07111763]\n",
      " [ 0.11707737]]\n",
      "Iteration 4915 | Cost: 0.3461258573335812 | Gradient: [[ 0.03019988]\n",
      " [-0.07110859]\n",
      " [ 0.11706843]]\n",
      "Iteration 4916 | Cost: 0.3461061846816809 | Gradient: [[ 0.03020087]\n",
      " [-0.07109955]\n",
      " [ 0.11705949]]\n",
      "Iteration 4917 | Cost: 0.34608651534797064 | Gradient: [[ 0.03020186]\n",
      " [-0.07109052]\n",
      " [ 0.11705055]]\n",
      "Iteration 4918 | Cost: 0.34606684933156606 | Gradient: [[ 0.03020285]\n",
      " [-0.07108149]\n",
      " [ 0.11704161]]\n",
      "Iteration 4919 | Cost: 0.3460471866315831 | Gradient: [[ 0.03020384]\n",
      " [-0.07107247]\n",
      " [ 0.11703267]]\n",
      "Iteration 4920 | Cost: 0.3460275272471382 | Gradient: [[ 0.03020482]\n",
      " [-0.07106345]\n",
      " [ 0.11702373]]\n",
      "Iteration 4921 | Cost: 0.3460078711773481 | Gradient: [[ 0.03020581]\n",
      " [-0.07105443]\n",
      " [ 0.11701479]]\n",
      "Iteration 4922 | Cost: 0.3459882184213301 | Gradient: [[ 0.03020679]\n",
      " [-0.07104542]\n",
      " [ 0.11700585]]\n",
      "Iteration 4923 | Cost: 0.34596856897820194 | Gradient: [[ 0.03020777]\n",
      " [-0.07103642]\n",
      " [ 0.11699691]]\n",
      "Iteration 4924 | Cost: 0.3459489228470816 | Gradient: [[ 0.03020875]\n",
      " [-0.07102741]\n",
      " [ 0.11698797]]\n",
      "Iteration 4925 | Cost: 0.3459292800270877 | Gradient: [[ 0.03020973]\n",
      " [-0.07101841]\n",
      " [ 0.11697903]]\n",
      "Iteration 4926 | Cost: 0.34590964051733913 | Gradient: [[ 0.0302107 ]\n",
      " [-0.07100942]\n",
      " [ 0.1169701 ]]\n",
      "Iteration 4927 | Cost: 0.34589000431695527 | Gradient: [[ 0.03021168]\n",
      " [-0.07100043]\n",
      " [ 0.11696116]]\n",
      "Iteration 4928 | Cost: 0.3458703714250556 | Gradient: [[ 0.03021265]\n",
      " [-0.07099144]\n",
      " [ 0.11695222]]\n",
      "Iteration 4929 | Cost: 0.34585074184076076 | Gradient: [[ 0.03021362]\n",
      " [-0.07098245]\n",
      " [ 0.11694329]]\n",
      "Iteration 4930 | Cost: 0.34583111556319107 | Gradient: [[ 0.03021459]\n",
      " [-0.07097348]\n",
      " [ 0.11693435]]\n",
      "Iteration 4931 | Cost: 0.34581149259146754 | Gradient: [[ 0.03021556]\n",
      " [-0.0709645 ]\n",
      " [ 0.11692541]]\n",
      "Iteration 4932 | Cost: 0.3457918729247118 | Gradient: [[ 0.03021653]\n",
      " [-0.07095553]\n",
      " [ 0.11691648]]\n",
      "Iteration 4933 | Cost: 0.3457722565620455 | Gradient: [[ 0.03021749]\n",
      " [-0.07094656]\n",
      " [ 0.11690754]]\n",
      "Iteration 4934 | Cost: 0.34575264350259094 | Gradient: [[ 0.03021846]\n",
      " [-0.0709376 ]\n",
      " [ 0.11689861]]\n",
      "Iteration 4935 | Cost: 0.34573303374547104 | Gradient: [[ 0.03021942]\n",
      " [-0.07092864]\n",
      " [ 0.11688967]]\n",
      "Iteration 4936 | Cost: 0.3457134272898086 | Gradient: [[ 0.03022038]\n",
      " [-0.07091968]\n",
      " [ 0.11688074]]\n",
      "Iteration 4937 | Cost: 0.3456938241347272 | Gradient: [[ 0.03022134]\n",
      " [-0.07091073]\n",
      " [ 0.11687181]]\n",
      "Iteration 4938 | Cost: 0.3456742242793508 | Gradient: [[ 0.03022229]\n",
      " [-0.07090178]\n",
      " [ 0.11686287]]\n",
      "Iteration 4939 | Cost: 0.34565462772280375 | Gradient: [[ 0.03022325]\n",
      " [-0.07089284]\n",
      " [ 0.11685394]]\n",
      "Iteration 4940 | Cost: 0.34563503446421096 | Gradient: [[ 0.0302242 ]\n",
      " [-0.0708839 ]\n",
      " [ 0.11684501]]\n",
      "Iteration 4941 | Cost: 0.34561544450269743 | Gradient: [[ 0.03022515]\n",
      " [-0.07087497]\n",
      " [ 0.11683608]]\n",
      "Iteration 4942 | Cost: 0.34559585783738866 | Gradient: [[ 0.0302261 ]\n",
      " [-0.07086603]\n",
      " [ 0.11682714]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4943 | Cost: 0.34557627446741074 | Gradient: [[ 0.03022705]\n",
      " [-0.07085711]\n",
      " [ 0.11681821]]\n",
      "Iteration 4944 | Cost: 0.3455566943918902 | Gradient: [[ 0.030228  ]\n",
      " [-0.07084818]\n",
      " [ 0.11680928]]\n",
      "Iteration 4945 | Cost: 0.34553711760995376 | Gradient: [[ 0.03022895]\n",
      " [-0.07083926]\n",
      " [ 0.11680035]]\n",
      "Iteration 4946 | Cost: 0.34551754412072855 | Gradient: [[ 0.03022989]\n",
      " [-0.07083035]\n",
      " [ 0.11679142]]\n",
      "Iteration 4947 | Cost: 0.3454979739233424 | Gradient: [[ 0.03023083]\n",
      " [-0.07082144]\n",
      " [ 0.11678249]]\n",
      "Iteration 4948 | Cost: 0.3454784070169233 | Gradient: [[ 0.03023177]\n",
      " [-0.07081253]\n",
      " [ 0.11677356]]\n",
      "Iteration 4949 | Cost: 0.3454588434005997 | Gradient: [[ 0.03023271]\n",
      " [-0.07080362]\n",
      " [ 0.11676463]]\n",
      "Iteration 4950 | Cost: 0.3454392830735004 | Gradient: [[ 0.03023365]\n",
      " [-0.07079473]\n",
      " [ 0.1167557 ]]\n",
      "Iteration 4951 | Cost: 0.34541972603475485 | Gradient: [[ 0.03023459]\n",
      " [-0.07078583]\n",
      " [ 0.11674677]]\n",
      "Iteration 4952 | Cost: 0.34540017228349257 | Gradient: [[ 0.03023552]\n",
      " [-0.07077694]\n",
      " [ 0.11673785]]\n",
      "Iteration 4953 | Cost: 0.3453806218188438 | Gradient: [[ 0.03023645]\n",
      " [-0.07076805]\n",
      " [ 0.11672892]]\n",
      "Iteration 4954 | Cost: 0.34536107463993904 | Gradient: [[ 0.03023738]\n",
      " [-0.07075917]\n",
      " [ 0.11671999]]\n",
      "Iteration 4955 | Cost: 0.3453415307459091 | Gradient: [[ 0.03023831]\n",
      " [-0.07075029]\n",
      " [ 0.11671106]]\n",
      "Iteration 4956 | Cost: 0.3453219901358855 | Gradient: [[ 0.03023924]\n",
      " [-0.07074141]\n",
      " [ 0.11670214]]\n",
      "Iteration 4957 | Cost: 0.34530245280899974 | Gradient: [[ 0.03024017]\n",
      " [-0.07073254]\n",
      " [ 0.11669321]]\n",
      "Iteration 4958 | Cost: 0.34528291876438416 | Gradient: [[ 0.03024109]\n",
      " [-0.07072367]\n",
      " [ 0.11668428]]\n",
      "Iteration 4959 | Cost: 0.3452633880011713 | Gradient: [[ 0.03024202]\n",
      " [-0.0707148 ]\n",
      " [ 0.11667536]]\n",
      "Iteration 4960 | Cost: 0.345243860518494 | Gradient: [[ 0.03024294]\n",
      " [-0.07070594]\n",
      " [ 0.11666643]]\n",
      "Iteration 4961 | Cost: 0.3452243363154857 | Gradient: [[ 0.03024386]\n",
      " [-0.07069709]\n",
      " [ 0.11665751]]\n",
      "Iteration 4962 | Cost: 0.34520481539128006 | Gradient: [[ 0.03024478]\n",
      " [-0.07068824]\n",
      " [ 0.11664859]]\n",
      "Iteration 4963 | Cost: 0.3451852977450115 | Gradient: [[ 0.03024569]\n",
      " [-0.07067939]\n",
      " [ 0.11663966]]\n",
      "Iteration 4964 | Cost: 0.3451657833758144 | Gradient: [[ 0.03024661]\n",
      " [-0.07067054]\n",
      " [ 0.11663074]]\n",
      "Iteration 4965 | Cost: 0.3451462722828238 | Gradient: [[ 0.03024752]\n",
      " [-0.0706617 ]\n",
      " [ 0.11662181]]\n",
      "Iteration 4966 | Cost: 0.34512676446517515 | Gradient: [[ 0.03024844]\n",
      " [-0.07065287]\n",
      " [ 0.11661289]]\n",
      "Iteration 4967 | Cost: 0.34510725992200414 | Gradient: [[ 0.03024935]\n",
      " [-0.07064403]\n",
      " [ 0.11660397]]\n",
      "Iteration 4968 | Cost: 0.345087758652447 | Gradient: [[ 0.03025026]\n",
      " [-0.0706352 ]\n",
      " [ 0.11659505]]\n",
      "Iteration 4969 | Cost: 0.3450682606556404 | Gradient: [[ 0.03025116]\n",
      " [-0.07062638]\n",
      " [ 0.11658613]]\n",
      "Iteration 4970 | Cost: 0.3450487659307213 | Gradient: [[ 0.03025207]\n",
      " [-0.07061756]\n",
      " [ 0.1165772 ]]\n",
      "Iteration 4971 | Cost: 0.345029274476827 | Gradient: [[ 0.03025297]\n",
      " [-0.07060874]\n",
      " [ 0.11656828]]\n",
      "Iteration 4972 | Cost: 0.34500978629309553 | Gradient: [[ 0.03025388]\n",
      " [-0.07059993]\n",
      " [ 0.11655936]]\n",
      "Iteration 4973 | Cost: 0.344990301378665 | Gradient: [[ 0.03025478]\n",
      " [-0.07059112]\n",
      " [ 0.11655044]]\n",
      "Iteration 4974 | Cost: 0.34497081973267385 | Gradient: [[ 0.03025568]\n",
      " [-0.07058231]\n",
      " [ 0.11654152]]\n",
      "Iteration 4975 | Cost: 0.3449513413542614 | Gradient: [[ 0.03025658]\n",
      " [-0.07057351]\n",
      " [ 0.1165326 ]]\n",
      "Iteration 4976 | Cost: 0.34493186624256683 | Gradient: [[ 0.03025747]\n",
      " [-0.07056471]\n",
      " [ 0.11652368]]\n",
      "Iteration 4977 | Cost: 0.34491239439673016 | Gradient: [[ 0.03025837]\n",
      " [-0.07055592]\n",
      " [ 0.11651477]]\n",
      "Iteration 4978 | Cost: 0.3448929258158914 | Gradient: [[ 0.03025926]\n",
      " [-0.07054713]\n",
      " [ 0.11650585]]\n",
      "Iteration 4979 | Cost: 0.34487346049919126 | Gradient: [[ 0.03026015]\n",
      " [-0.07053834]\n",
      " [ 0.11649693]]\n",
      "Iteration 4980 | Cost: 0.3448539984457708 | Gradient: [[ 0.03026104]\n",
      " [-0.07052956]\n",
      " [ 0.11648801]]\n",
      "Iteration 4981 | Cost: 0.3448345396547713 | Gradient: [[ 0.03026193]\n",
      " [-0.07052078]\n",
      " [ 0.11647909]]\n",
      "Iteration 4982 | Cost: 0.34481508412533474 | Gradient: [[ 0.03026282]\n",
      " [-0.07051201]\n",
      " [ 0.11647018]]\n",
      "Iteration 4983 | Cost: 0.3447956318566032 | Gradient: [[ 0.0302637 ]\n",
      " [-0.07050324]\n",
      " [ 0.11646126]]\n",
      "Iteration 4984 | Cost: 0.3447761828477194 | Gradient: [[ 0.03026459]\n",
      " [-0.07049447]\n",
      " [ 0.11645235]]\n",
      "Iteration 4985 | Cost: 0.34475673709782634 | Gradient: [[ 0.03026547]\n",
      " [-0.07048571]\n",
      " [ 0.11644343]]\n",
      "Iteration 4986 | Cost: 0.3447372946060672 | Gradient: [[ 0.03026635]\n",
      " [-0.07047695]\n",
      " [ 0.11643452]]\n",
      "Iteration 4987 | Cost: 0.3447178553715861 | Gradient: [[ 0.03026723]\n",
      " [-0.07046819]\n",
      " [ 0.1164256 ]]\n",
      "Iteration 4988 | Cost: 0.344698419393527 | Gradient: [[ 0.03026811]\n",
      " [-0.07045944]\n",
      " [ 0.11641669]]\n",
      "Iteration 4989 | Cost: 0.3446789866710347 | Gradient: [[ 0.03026899]\n",
      " [-0.07045069]\n",
      " [ 0.11640777]]\n",
      "Iteration 4990 | Cost: 0.344659557203254 | Gradient: [[ 0.03026986]\n",
      " [-0.07044195]\n",
      " [ 0.11639886]]\n",
      "Iteration 4991 | Cost: 0.3446401309893304 | Gradient: [[ 0.03027073]\n",
      " [-0.07043321]\n",
      " [ 0.11638995]]\n",
      "Iteration 4992 | Cost: 0.3446207080284096 | Gradient: [[ 0.03027161]\n",
      " [-0.07042448]\n",
      " [ 0.11638103]]\n",
      "Iteration 4993 | Cost: 0.3446012883196378 | Gradient: [[ 0.03027248]\n",
      " [-0.07041574]\n",
      " [ 0.11637212]]\n",
      "Iteration 4994 | Cost: 0.3445818718621617 | Gradient: [[ 0.03027334]\n",
      " [-0.07040702]\n",
      " [ 0.11636321]]\n",
      "Iteration 4995 | Cost: 0.3445624586551281 | Gradient: [[ 0.03027421]\n",
      " [-0.07039829]\n",
      " [ 0.1163543 ]]\n",
      "Iteration 4996 | Cost: 0.34454304869768443 | Gradient: [[ 0.03027508]\n",
      " [-0.07038957]\n",
      " [ 0.11634539]]\n",
      "Iteration 4997 | Cost: 0.3445236419889784 | Gradient: [[ 0.03027594]\n",
      " [-0.07038085]\n",
      " [ 0.11633648]]\n",
      "Iteration 4998 | Cost: 0.3445042385281582 | Gradient: [[ 0.0302768 ]\n",
      " [-0.07037214]\n",
      " [ 0.11632757]]\n",
      "Iteration 4999 | Cost: 0.3444848383143724 | Gradient: [[ 0.03027766]\n",
      " [-0.07036343]\n",
      " [ 0.11631866]]\n",
      "Iteration 5000 | Cost: 0.3444654413467698 | Gradient: [[ 0.03027852]\n",
      " [-0.07035473]\n",
      " [ 0.11630975]]\n",
      "Iteration 5001 | Cost: 0.3444460476244999 | Gradient: [[ 0.03027938]\n",
      " [-0.07034603]\n",
      " [ 0.11630084]]\n",
      "Iteration 5002 | Cost: 0.3444266571467123 | Gradient: [[ 0.03028024]\n",
      " [-0.07033733]\n",
      " [ 0.11629193]]\n",
      "Iteration 5003 | Cost: 0.3444072699125571 | Gradient: [[ 0.03028109]\n",
      " [-0.07032863]\n",
      " [ 0.11628302]]\n",
      "Iteration 5004 | Cost: 0.3443878859211849 | Gradient: [[ 0.03028195]\n",
      " [-0.07031994]\n",
      " [ 0.11627411]]\n",
      "Iteration 5005 | Cost: 0.3443685051717465 | Gradient: [[ 0.0302828 ]\n",
      " [-0.07031126]\n",
      " [ 0.1162652 ]]\n",
      "Iteration 5006 | Cost: 0.3443491276633932 | Gradient: [[ 0.03028365]\n",
      " [-0.07030258]\n",
      " [ 0.1162563 ]]\n",
      "Iteration 5007 | Cost: 0.34432975339527666 | Gradient: [[ 0.0302845 ]\n",
      " [-0.0702939 ]\n",
      " [ 0.11624739]]\n",
      "Iteration 5008 | Cost: 0.344310382366549 | Gradient: [[ 0.03028534]\n",
      " [-0.07028522]\n",
      " [ 0.11623848]]\n",
      "Iteration 5009 | Cost: 0.3442910145763625 | Gradient: [[ 0.03028619]\n",
      " [-0.07027655]\n",
      " [ 0.11622958]]\n",
      "Iteration 5010 | Cost: 0.3442716500238701 | Gradient: [[ 0.03028703]\n",
      " [-0.07026788]\n",
      " [ 0.11622067]]\n",
      "Iteration 5011 | Cost: 0.34425228870822516 | Gradient: [[ 0.03028787]\n",
      " [-0.07025922]\n",
      " [ 0.11621177]]\n",
      "Iteration 5012 | Cost: 0.3442329306285811 | Gradient: [[ 0.03028872]\n",
      " [-0.07025056]\n",
      " [ 0.11620286]]\n",
      "Iteration 5013 | Cost: 0.34421357578409195 | Gradient: [[ 0.03028956]\n",
      " [-0.07024191]\n",
      " [ 0.11619396]]\n",
      "Iteration 5014 | Cost: 0.3441942241739122 | Gradient: [[ 0.03029039]\n",
      " [-0.07023325]\n",
      " [ 0.11618505]]\n",
      "Iteration 5015 | Cost: 0.3441748757971966 | Gradient: [[ 0.03029123]\n",
      " [-0.07022461]\n",
      " [ 0.11617615]]\n",
      "Iteration 5016 | Cost: 0.3441555306531003 | Gradient: [[ 0.03029206]\n",
      " [-0.07021596]\n",
      " [ 0.11616725]]\n",
      "Iteration 5017 | Cost: 0.3441361887407788 | Gradient: [[ 0.0302929 ]\n",
      " [-0.07020732]\n",
      " [ 0.11615835]]\n",
      "Iteration 5018 | Cost: 0.344116850059388 | Gradient: [[ 0.03029373]\n",
      " [-0.07019869]\n",
      " [ 0.11614944]]\n",
      "Iteration 5019 | Cost: 0.3440975146080844 | Gradient: [[ 0.03029456]\n",
      " [-0.07019005]\n",
      " [ 0.11614054]]\n",
      "Iteration 5020 | Cost: 0.3440781823860246 | Gradient: [[ 0.03029539]\n",
      " [-0.07018142]\n",
      " [ 0.11613164]]\n",
      "Iteration 5021 | Cost: 0.34405885339236575 | Gradient: [[ 0.03029622]\n",
      " [-0.0701728 ]\n",
      " [ 0.11612274]]\n",
      "Iteration 5022 | Cost: 0.34403952762626516 | Gradient: [[ 0.03029704]\n",
      " [-0.07016418]\n",
      " [ 0.11611384]]\n",
      "Iteration 5023 | Cost: 0.3440202050868809 | Gradient: [[ 0.03029787]\n",
      " [-0.07015556]\n",
      " [ 0.11610494]]\n",
      "Iteration 5024 | Cost: 0.3440008857733711 | Gradient: [[ 0.03029869]\n",
      " [-0.07014694]\n",
      " [ 0.11609604]]\n",
      "Iteration 5025 | Cost: 0.3439815696848945 | Gradient: [[ 0.03029951]\n",
      " [-0.07013833]\n",
      " [ 0.11608714]]\n",
      "Iteration 5026 | Cost: 0.34396225682061005 | Gradient: [[ 0.03030033]\n",
      " [-0.07012973]\n",
      " [ 0.11607824]]\n",
      "Iteration 5027 | Cost: 0.3439429471796771 | Gradient: [[ 0.03030115]\n",
      " [-0.07012112]\n",
      " [ 0.11606934]]\n",
      "Iteration 5028 | Cost: 0.34392364076125553 | Gradient: [[ 0.03030197]\n",
      " [-0.07011253]\n",
      " [ 0.11606044]]\n",
      "Iteration 5029 | Cost: 0.3439043375645054 | Gradient: [[ 0.03030278]\n",
      " [-0.07010393]\n",
      " [ 0.11605155]]\n",
      "Iteration 5030 | Cost: 0.3438850375885873 | Gradient: [[ 0.03030359]\n",
      " [-0.07009534]\n",
      " [ 0.11604265]]\n",
      "Iteration 5031 | Cost: 0.34386574083266225 | Gradient: [[ 0.03030441]\n",
      " [-0.07008675]\n",
      " [ 0.11603375]]\n",
      "Iteration 5032 | Cost: 0.34384644729589137 | Gradient: [[ 0.03030522]\n",
      " [-0.07007817]\n",
      " [ 0.11602486]]\n",
      "Iteration 5033 | Cost: 0.34382715697743665 | Gradient: [[ 0.03030603]\n",
      " [-0.07006959]\n",
      " [ 0.11601596]]\n",
      "Iteration 5034 | Cost: 0.34380786987645984 | Gradient: [[ 0.03030683]\n",
      " [-0.07006101]\n",
      " [ 0.11600706]]\n",
      "Iteration 5035 | Cost: 0.34378858599212364 | Gradient: [[ 0.03030764]\n",
      " [-0.07005244]\n",
      " [ 0.11599817]]\n",
      "Iteration 5036 | Cost: 0.34376930532359073 | Gradient: [[ 0.03030845]\n",
      " [-0.07004387]\n",
      " [ 0.11598927]]\n",
      "Iteration 5037 | Cost: 0.3437500278700244 | Gradient: [[ 0.03030925]\n",
      " [-0.0700353 ]\n",
      " [ 0.11598038]]\n",
      "Iteration 5038 | Cost: 0.3437307536305882 | Gradient: [[ 0.03031005]\n",
      " [-0.07002674]\n",
      " [ 0.11597149]]\n",
      "Iteration 5039 | Cost: 0.3437114826044461 | Gradient: [[ 0.03031085]\n",
      " [-0.07001818]\n",
      " [ 0.11596259]]\n",
      "Iteration 5040 | Cost: 0.3436922147907626 | Gradient: [[ 0.03031165]\n",
      " [-0.07000963]\n",
      " [ 0.1159537 ]]\n",
      "Iteration 5041 | Cost: 0.34367295018870225 | Gradient: [[ 0.03031245]\n",
      " [-0.07000108]\n",
      " [ 0.11594481]]\n",
      "Iteration 5042 | Cost: 0.3436536887974303 | Gradient: [[ 0.03031324]\n",
      " [-0.06999253]\n",
      " [ 0.11593592]]\n",
      "Iteration 5043 | Cost: 0.34363443061611215 | Gradient: [[ 0.03031404]\n",
      " [-0.06998399]\n",
      " [ 0.11592702]]\n",
      "Iteration 5044 | Cost: 0.34361517564391364 | Gradient: [[ 0.03031483]\n",
      " [-0.06997545]\n",
      " [ 0.11591813]]\n",
      "Iteration 5045 | Cost: 0.3435959238800011 | Gradient: [[ 0.03031562]\n",
      " [-0.06996691]\n",
      " [ 0.11590924]]\n",
      "Iteration 5046 | Cost: 0.3435766753235412 | Gradient: [[ 0.03031641]\n",
      " [-0.06995838]\n",
      " [ 0.11590035]]\n",
      "Iteration 5047 | Cost: 0.34355742997370065 | Gradient: [[ 0.0303172 ]\n",
      " [-0.06994985]\n",
      " [ 0.11589146]]\n",
      "Iteration 5048 | Cost: 0.3435381878296471 | Gradient: [[ 0.03031799]\n",
      " [-0.06994133]\n",
      " [ 0.11588257]]\n",
      "Iteration 5049 | Cost: 0.34351894889054835 | Gradient: [[ 0.03031877]\n",
      " [-0.06993281]\n",
      " [ 0.11587368]]\n",
      "Iteration 5050 | Cost: 0.3434997131555724 | Gradient: [[ 0.03031956]\n",
      " [-0.06992429]\n",
      " [ 0.11586479]]\n",
      "Iteration 5051 | Cost: 0.3434804806238877 | Gradient: [[ 0.03032034]\n",
      " [-0.06991578]\n",
      " [ 0.1158559 ]]\n",
      "Iteration 5052 | Cost: 0.3434612512946631 | Gradient: [[ 0.03032112]\n",
      " [-0.06990727]\n",
      " [ 0.11584702]]\n",
      "Iteration 5053 | Cost: 0.34344202516706807 | Gradient: [[ 0.0303219 ]\n",
      " [-0.06989876]\n",
      " [ 0.11583813]]\n",
      "Iteration 5054 | Cost: 0.343422802240272 | Gradient: [[ 0.03032268]\n",
      " [-0.06989026]\n",
      " [ 0.11582924]]\n",
      "Iteration 5055 | Cost: 0.34340358251344516 | Gradient: [[ 0.03032345]\n",
      " [-0.06988176]\n",
      " [ 0.11582036]]\n",
      "Iteration 5056 | Cost: 0.34338436598575767 | Gradient: [[ 0.03032423]\n",
      " [-0.06987327]\n",
      " [ 0.11581147]]\n",
      "Iteration 5057 | Cost: 0.34336515265638035 | Gradient: [[ 0.030325  ]\n",
      " [-0.06986478]\n",
      " [ 0.11580258]]\n",
      "Iteration 5058 | Cost: 0.34334594252448436 | Gradient: [[ 0.03032577]\n",
      " [-0.06985629]\n",
      " [ 0.1157937 ]]\n",
      "Iteration 5059 | Cost: 0.34332673558924126 | Gradient: [[ 0.03032655]\n",
      " [-0.06984781]\n",
      " [ 0.11578481]]\n",
      "Iteration 5060 | Cost: 0.3433075318498227 | Gradient: [[ 0.03032731]\n",
      " [-0.06983933]\n",
      " [ 0.11577593]]\n",
      "Iteration 5061 | Cost: 0.3432883313054012 | Gradient: [[ 0.03032808]\n",
      " [-0.06983085]\n",
      " [ 0.11576705]]\n",
      "Iteration 5062 | Cost: 0.3432691339551492 | Gradient: [[ 0.03032885]\n",
      " [-0.06982238]\n",
      " [ 0.11575816]]\n",
      "Iteration 5063 | Cost: 0.34324993979823964 | Gradient: [[ 0.03032961]\n",
      " [-0.06981391]\n",
      " [ 0.11574928]]\n",
      "Iteration 5064 | Cost: 0.3432307488338461 | Gradient: [[ 0.03033038]\n",
      " [-0.06980544]\n",
      " [ 0.1157404 ]]\n",
      "Iteration 5065 | Cost: 0.3432115610611421 | Gradient: [[ 0.03033114]\n",
      " [-0.06979698]\n",
      " [ 0.11573151]]\n",
      "Iteration 5066 | Cost: 0.34319237647930173 | Gradient: [[ 0.0303319 ]\n",
      " [-0.06978852]\n",
      " [ 0.11572263]]\n",
      "Iteration 5067 | Cost: 0.34317319508749966 | Gradient: [[ 0.03033266]\n",
      " [-0.06978007]\n",
      " [ 0.11571375]]\n",
      "Iteration 5068 | Cost: 0.34315401688491043 | Gradient: [[ 0.03033341]\n",
      " [-0.06977162]\n",
      " [ 0.11570487]]\n",
      "Iteration 5069 | Cost: 0.3431348418707096 | Gradient: [[ 0.03033417]\n",
      " [-0.06976317]\n",
      " [ 0.11569599]]\n",
      "Iteration 5070 | Cost: 0.34311567004407245 | Gradient: [[ 0.03033493]\n",
      " [-0.06975473]\n",
      " [ 0.11568711]]\n",
      "Iteration 5071 | Cost: 0.343096501404175 | Gradient: [[ 0.03033568]\n",
      " [-0.06974629]\n",
      " [ 0.11567823]]\n",
      "Iteration 5072 | Cost: 0.34307733595019363 | Gradient: [[ 0.03033643]\n",
      " [-0.06973785]\n",
      " [ 0.11566935]]\n",
      "Iteration 5073 | Cost: 0.34305817368130503 | Gradient: [[ 0.03033718]\n",
      " [-0.06972942]\n",
      " [ 0.11566047]]\n",
      "Iteration 5074 | Cost: 0.34303901459668623 | Gradient: [[ 0.03033793]\n",
      " [-0.06972099]\n",
      " [ 0.11565159]]\n",
      "Iteration 5075 | Cost: 0.3430198586955146 | Gradient: [[ 0.03033868]\n",
      " [-0.06971256]\n",
      " [ 0.11564271]]\n",
      "Iteration 5076 | Cost: 0.34300070597696797 | Gradient: [[ 0.03033942]\n",
      " [-0.06970414]\n",
      " [ 0.11563384]]\n",
      "Iteration 5077 | Cost: 0.3429815564402245 | Gradient: [[ 0.03034017]\n",
      " [-0.06969572]\n",
      " [ 0.11562496]]\n",
      "Iteration 5078 | Cost: 0.3429624100844627 | Gradient: [[ 0.03034091]\n",
      " [-0.06968731]\n",
      " [ 0.11561608]]\n",
      "Iteration 5079 | Cost: 0.34294326690886145 | Gradient: [[ 0.03034165]\n",
      " [-0.0696789 ]\n",
      " [ 0.11560721]]\n",
      "Iteration 5080 | Cost: 0.34292412691260005 | Gradient: [[ 0.03034239]\n",
      " [-0.06967049]\n",
      " [ 0.11559833]]\n",
      "Iteration 5081 | Cost: 0.34290499009485814 | Gradient: [[ 0.03034313]\n",
      " [-0.06966209]\n",
      " [ 0.11558946]]\n",
      "Iteration 5082 | Cost: 0.3428858564548155 | Gradient: [[ 0.03034387]\n",
      " [-0.06965369]\n",
      " [ 0.11558058]]\n",
      "Iteration 5083 | Cost: 0.3428667259916528 | Gradient: [[ 0.0303446 ]\n",
      " [-0.06964529]\n",
      " [ 0.11557171]]\n",
      "Iteration 5084 | Cost: 0.3428475987045505 | Gradient: [[ 0.03034534]\n",
      " [-0.0696369 ]\n",
      " [ 0.11556283]]\n",
      "Iteration 5085 | Cost: 0.3428284745926898 | Gradient: [[ 0.03034607]\n",
      " [-0.06962851]\n",
      " [ 0.11555396]]\n",
      "Iteration 5086 | Cost: 0.3428093536552521 | Gradient: [[ 0.0303468 ]\n",
      " [-0.06962012]\n",
      " [ 0.11554509]]\n",
      "Iteration 5087 | Cost: 0.3427902358914192 | Gradient: [[ 0.03034753]\n",
      " [-0.06961174]\n",
      " [ 0.11553621]]\n",
      "Iteration 5088 | Cost: 0.3427711213003734 | Gradient: [[ 0.03034826]\n",
      " [-0.06960336]\n",
      " [ 0.11552734]]\n",
      "Iteration 5089 | Cost: 0.3427520098812971 | Gradient: [[ 0.03034899]\n",
      " [-0.06959499]\n",
      " [ 0.11551847]]\n",
      "Iteration 5090 | Cost: 0.34273290163337333 | Gradient: [[ 0.03034971]\n",
      " [-0.06958662]\n",
      " [ 0.1155096 ]]\n",
      "Iteration 5091 | Cost: 0.34271379655578516 | Gradient: [[ 0.03035044]\n",
      " [-0.06957825]\n",
      " [ 0.11550073]]\n",
      "Iteration 5092 | Cost: 0.34269469464771635 | Gradient: [[ 0.03035116]\n",
      " [-0.06956989]\n",
      " [ 0.11549186]]\n",
      "Iteration 5093 | Cost: 0.3426755959083509 | Gradient: [[ 0.03035188]\n",
      " [-0.06956153]\n",
      " [ 0.11548299]]\n",
      "Iteration 5094 | Cost: 0.3426565003368731 | Gradient: [[ 0.0303526 ]\n",
      " [-0.06955317]\n",
      " [ 0.11547412]]\n",
      "Iteration 5095 | Cost: 0.3426374079324678 | Gradient: [[ 0.03035332]\n",
      " [-0.06954482]\n",
      " [ 0.11546525]]\n",
      "Iteration 5096 | Cost: 0.3426183186943199 | Gradient: [[ 0.03035403]\n",
      " [-0.06953647]\n",
      " [ 0.11545638]]\n",
      "Iteration 5097 | Cost: 0.34259923262161485 | Gradient: [[ 0.03035475]\n",
      " [-0.06952812]\n",
      " [ 0.11544751]]\n",
      "Iteration 5098 | Cost: 0.34258014971353856 | Gradient: [[ 0.03035546]\n",
      " [-0.06951978]\n",
      " [ 0.11543865]]\n",
      "Iteration 5099 | Cost: 0.34256106996927715 | Gradient: [[ 0.03035618]\n",
      " [-0.06951144]\n",
      " [ 0.11542978]]\n",
      "Iteration 5100 | Cost: 0.3425419933880171 | Gradient: [[ 0.03035689]\n",
      " [-0.06950311]\n",
      " [ 0.11542091]]\n",
      "Iteration 5101 | Cost: 0.3425229199689453 | Gradient: [[ 0.0303576 ]\n",
      " [-0.06949478]\n",
      " [ 0.11541205]]\n",
      "Iteration 5102 | Cost: 0.34250384971124903 | Gradient: [[ 0.03035831]\n",
      " [-0.06948645]\n",
      " [ 0.11540318]]\n",
      "Iteration 5103 | Cost: 0.34248478261411575 | Gradient: [[ 0.03035901]\n",
      " [-0.06947812]\n",
      " [ 0.11539431]]\n",
      "Iteration 5104 | Cost: 0.3424657186767336 | Gradient: [[ 0.03035972]\n",
      " [-0.0694698 ]\n",
      " [ 0.11538545]]\n",
      "Iteration 5105 | Cost: 0.3424466578982908 | Gradient: [[ 0.03036042]\n",
      " [-0.06946149]\n",
      " [ 0.11537659]]\n",
      "Iteration 5106 | Cost: 0.34242760027797614 | Gradient: [[ 0.03036112]\n",
      " [-0.06945317]\n",
      " [ 0.11536772]]\n",
      "Iteration 5107 | Cost: 0.3424085458149784 | Gradient: [[ 0.03036183]\n",
      " [-0.06944486]\n",
      " [ 0.11535886]]\n",
      "Iteration 5108 | Cost: 0.3423894945084872 | Gradient: [[ 0.03036253]\n",
      " [-0.06943656]\n",
      " [ 0.11535   ]]\n",
      "Iteration 5109 | Cost: 0.34237044635769215 | Gradient: [[ 0.03036322]\n",
      " [-0.06942825]\n",
      " [ 0.11534113]]\n",
      "Iteration 5110 | Cost: 0.3423514013617834 | Gradient: [[ 0.03036392]\n",
      " [-0.06941995]\n",
      " [ 0.11533227]]\n",
      "Iteration 5111 | Cost: 0.34233235951995145 | Gradient: [[ 0.03036462]\n",
      " [-0.06941166]\n",
      " [ 0.11532341]]\n",
      "Iteration 5112 | Cost: 0.34231332083138705 | Gradient: [[ 0.03036531]\n",
      " [-0.06940337]\n",
      " [ 0.11531455]]\n",
      "Iteration 5113 | Cost: 0.3422942852952815 | Gradient: [[ 0.030366  ]\n",
      " [-0.06939508]\n",
      " [ 0.11530569]]\n",
      "Iteration 5114 | Cost: 0.3422752529108261 | Gradient: [[ 0.03036669]\n",
      " [-0.06938679]\n",
      " [ 0.11529683]]\n",
      "Iteration 5115 | Cost: 0.342256223677213 | Gradient: [[ 0.03036738]\n",
      " [-0.06937851]\n",
      " [ 0.11528797]]\n",
      "Iteration 5116 | Cost: 0.3422371975936342 | Gradient: [[ 0.03036807]\n",
      " [-0.06937023]\n",
      " [ 0.11527911]]\n",
      "Iteration 5117 | Cost: 0.34221817465928245 | Gradient: [[ 0.03036876]\n",
      " [-0.06936196]\n",
      " [ 0.11527025]]\n",
      "Iteration 5118 | Cost: 0.34219915487335073 | Gradient: [[ 0.03036945]\n",
      " [-0.06935369]\n",
      " [ 0.11526139]]\n",
      "Iteration 5119 | Cost: 0.34218013823503224 | Gradient: [[ 0.03037013]\n",
      " [-0.06934542]\n",
      " [ 0.11525253]]\n",
      "Iteration 5120 | Cost: 0.34216112474352056 | Gradient: [[ 0.03037081]\n",
      " [-0.06933716]\n",
      " [ 0.11524367]]\n",
      "Iteration 5121 | Cost: 0.34214211439801 | Gradient: [[ 0.03037149]\n",
      " [-0.06932889]\n",
      " [ 0.11523482]]\n",
      "Iteration 5122 | Cost: 0.3421231071976947 | Gradient: [[ 0.03037217]\n",
      " [-0.06932064]\n",
      " [ 0.11522596]]\n",
      "Iteration 5123 | Cost: 0.3421041031417693 | Gradient: [[ 0.03037285]\n",
      " [-0.06931238]\n",
      " [ 0.1152171 ]]\n",
      "Iteration 5124 | Cost: 0.3420851022294291 | Gradient: [[ 0.03037353]\n",
      " [-0.06930413]\n",
      " [ 0.11520825]]\n",
      "Iteration 5125 | Cost: 0.34206610445986946 | Gradient: [[ 0.03037421]\n",
      " [-0.06929589]\n",
      " [ 0.11519939]]\n",
      "Iteration 5126 | Cost: 0.3420471098322861 | Gradient: [[ 0.03037488]\n",
      " [-0.06928765]\n",
      " [ 0.11519054]]\n",
      "Iteration 5127 | Cost: 0.34202811834587515 | Gradient: [[ 0.03037555]\n",
      " [-0.06927941]\n",
      " [ 0.11518169]]\n",
      "Iteration 5128 | Cost: 0.34200912999983313 | Gradient: [[ 0.03037623]\n",
      " [-0.06927117]\n",
      " [ 0.11517283]]\n",
      "Iteration 5129 | Cost: 0.3419901447933569 | Gradient: [[ 0.0303769 ]\n",
      " [-0.06926294]\n",
      " [ 0.11516398]]\n",
      "Iteration 5130 | Cost: 0.3419711627256436 | Gradient: [[ 0.03037756]\n",
      " [-0.06925471]\n",
      " [ 0.11515513]]\n",
      "Iteration 5131 | Cost: 0.34195218379589076 | Gradient: [[ 0.03037823]\n",
      " [-0.06924648]\n",
      " [ 0.11514627]]\n",
      "Iteration 5132 | Cost: 0.3419332080032963 | Gradient: [[ 0.0303789 ]\n",
      " [-0.06923826]\n",
      " [ 0.11513742]]\n",
      "Iteration 5133 | Cost: 0.3419142353470584 | Gradient: [[ 0.03037956]\n",
      " [-0.06923004]\n",
      " [ 0.11512857]]\n",
      "Iteration 5134 | Cost: 0.34189526582637575 | Gradient: [[ 0.03038023]\n",
      " [-0.06922183]\n",
      " [ 0.11511972]]\n",
      "Iteration 5135 | Cost: 0.34187629944044723 | Gradient: [[ 0.03038089]\n",
      " [-0.06921362]\n",
      " [ 0.11511087]]\n",
      "Iteration 5136 | Cost: 0.3418573361884722 | Gradient: [[ 0.03038155]\n",
      " [-0.06920541]\n",
      " [ 0.11510202]]\n",
      "Iteration 5137 | Cost: 0.3418383760696502 | Gradient: [[ 0.03038221]\n",
      " [-0.06919721]\n",
      " [ 0.11509317]]\n",
      "Iteration 5138 | Cost: 0.3418194190831812 | Gradient: [[ 0.03038286]\n",
      " [-0.06918901]\n",
      " [ 0.11508432]]\n",
      "Iteration 5139 | Cost: 0.3418004652282655 | Gradient: [[ 0.03038352]\n",
      " [-0.06918081]\n",
      " [ 0.11507547]]\n",
      "Iteration 5140 | Cost: 0.34178151450410404 | Gradient: [[ 0.03038418]\n",
      " [-0.06917262]\n",
      " [ 0.11506662]]\n",
      "Iteration 5141 | Cost: 0.34176256690989754 | Gradient: [[ 0.03038483]\n",
      " [-0.06916443]\n",
      " [ 0.11505778]]\n",
      "Iteration 5142 | Cost: 0.34174362244484763 | Gradient: [[ 0.03038548]\n",
      " [-0.06915624]\n",
      " [ 0.11504893]]\n",
      "Iteration 5143 | Cost: 0.3417246811081559 | Gradient: [[ 0.03038613]\n",
      " [-0.06914806]\n",
      " [ 0.11504008]]\n",
      "Iteration 5144 | Cost: 0.3417057428990243 | Gradient: [[ 0.03038678]\n",
      " [-0.06913988]\n",
      " [ 0.11503124]]\n",
      "Iteration 5145 | Cost: 0.34168680781665556 | Gradient: [[ 0.03038743]\n",
      " [-0.0691317 ]\n",
      " [ 0.11502239]]\n",
      "Iteration 5146 | Cost: 0.34166787586025227 | Gradient: [[ 0.03038808]\n",
      " [-0.06912353]\n",
      " [ 0.11501354]]\n",
      "Iteration 5147 | Cost: 0.3416489470290175 | Gradient: [[ 0.03038872]\n",
      " [-0.06911536]\n",
      " [ 0.1150047 ]]\n",
      "Iteration 5148 | Cost: 0.34163002132215486 | Gradient: [[ 0.03038937]\n",
      " [-0.06910719]\n",
      " [ 0.11499586]]\n",
      "Iteration 5149 | Cost: 0.3416110987388681 | Gradient: [[ 0.03039001]\n",
      " [-0.06909903]\n",
      " [ 0.11498701]]\n",
      "Iteration 5150 | Cost: 0.34159217927836116 | Gradient: [[ 0.03039065]\n",
      " [-0.06909087]\n",
      " [ 0.11497817]]\n",
      "Iteration 5151 | Cost: 0.3415732629398389 | Gradient: [[ 0.03039129]\n",
      " [-0.06908271]\n",
      " [ 0.11496933]]\n",
      "Iteration 5152 | Cost: 0.34155434972250587 | Gradient: [[ 0.03039193]\n",
      " [-0.06907456]\n",
      " [ 0.11496048]]\n",
      "Iteration 5153 | Cost: 0.34153543962556737 | Gradient: [[ 0.03039256]\n",
      " [-0.06906641]\n",
      " [ 0.11495164]]\n",
      "Iteration 5154 | Cost: 0.341516532648229 | Gradient: [[ 0.0303932 ]\n",
      " [-0.06905827]\n",
      " [ 0.1149428 ]]\n",
      "Iteration 5155 | Cost: 0.3414976287896967 | Gradient: [[ 0.03039383]\n",
      " [-0.06905013]\n",
      " [ 0.11493396]]\n",
      "Iteration 5156 | Cost: 0.34147872804917634 | Gradient: [[ 0.03039447]\n",
      " [-0.06904199]\n",
      " [ 0.11492512]]\n",
      "Iteration 5157 | Cost: 0.34145983042587474 | Gradient: [[ 0.0303951 ]\n",
      " [-0.06903385]\n",
      " [ 0.11491628]]\n",
      "Iteration 5158 | Cost: 0.3414409359189989 | Gradient: [[ 0.03039573]\n",
      " [-0.06902572]\n",
      " [ 0.11490744]]\n",
      "Iteration 5159 | Cost: 0.3414220445277558 | Gradient: [[ 0.03039636]\n",
      " [-0.06901759]\n",
      " [ 0.1148986 ]]\n",
      "Iteration 5160 | Cost: 0.34140315625135326 | Gradient: [[ 0.03039698]\n",
      " [-0.06900947]\n",
      " [ 0.11488976]]\n",
      "Iteration 5161 | Cost: 0.3413842710889991 | Gradient: [[ 0.03039761]\n",
      " [-0.06900135]\n",
      " [ 0.11488092]]\n",
      "Iteration 5162 | Cost: 0.34136538903990155 | Gradient: [[ 0.03039824]\n",
      " [-0.06899323]\n",
      " [ 0.11487209]]\n",
      "Iteration 5163 | Cost: 0.34134651010326944 | Gradient: [[ 0.03039886]\n",
      " [-0.06898512]\n",
      " [ 0.11486325]]\n",
      "Iteration 5164 | Cost: 0.34132763427831153 | Gradient: [[ 0.03039948]\n",
      " [-0.06897701]\n",
      " [ 0.11485441]]\n",
      "Iteration 5165 | Cost: 0.3413087615642372 | Gradient: [[ 0.0304001 ]\n",
      " [-0.0689689 ]\n",
      " [ 0.11484558]]\n",
      "Iteration 5166 | Cost: 0.341289891960256 | Gradient: [[ 0.03040072]\n",
      " [-0.0689608 ]\n",
      " [ 0.11483674]]\n",
      "Iteration 5167 | Cost: 0.3412710254655781 | Gradient: [[ 0.03040134]\n",
      " [-0.06895269]\n",
      " [ 0.1148279 ]]\n",
      "Iteration 5168 | Cost: 0.34125216207941367 | Gradient: [[ 0.03040195]\n",
      " [-0.0689446 ]\n",
      " [ 0.11481907]]\n",
      "Iteration 5169 | Cost: 0.34123330180097344 | Gradient: [[ 0.03040257]\n",
      " [-0.0689365 ]\n",
      " [ 0.11481024]]\n",
      "Iteration 5170 | Cost: 0.34121444462946837 | Gradient: [[ 0.03040318]\n",
      " [-0.06892841]\n",
      " [ 0.1148014 ]]\n",
      "Iteration 5171 | Cost: 0.34119559056410986 | Gradient: [[ 0.0304038 ]\n",
      " [-0.06892033]\n",
      " [ 0.11479257]]\n",
      "Iteration 5172 | Cost: 0.3411767396041095 | Gradient: [[ 0.03040441]\n",
      " [-0.06891224]\n",
      " [ 0.11478374]]\n",
      "Iteration 5173 | Cost: 0.34115789174867944 | Gradient: [[ 0.03040502]\n",
      " [-0.06890416]\n",
      " [ 0.1147749 ]]\n",
      "Iteration 5174 | Cost: 0.341139046997032 | Gradient: [[ 0.03040562]\n",
      " [-0.06889609]\n",
      " [ 0.11476607]]\n",
      "Iteration 5175 | Cost: 0.3411202053483799 | Gradient: [[ 0.03040623]\n",
      " [-0.06888801]\n",
      " [ 0.11475724]]\n",
      "Iteration 5176 | Cost: 0.34110136680193603 | Gradient: [[ 0.03040684]\n",
      " [-0.06887994]\n",
      " [ 0.11474841]]\n",
      "Iteration 5177 | Cost: 0.3410825313569139 | Gradient: [[ 0.03040744]\n",
      " [-0.06887188]\n",
      " [ 0.11473958]]\n",
      "Iteration 5178 | Cost: 0.3410636990125273 | Gradient: [[ 0.03040804]\n",
      " [-0.06886382]\n",
      " [ 0.11473075]]\n",
      "Iteration 5179 | Cost: 0.3410448697679902 | Gradient: [[ 0.03040865]\n",
      " [-0.06885576]\n",
      " [ 0.11472192]]\n",
      "Iteration 5180 | Cost: 0.34102604362251693 | Gradient: [[ 0.03040925]\n",
      " [-0.0688477 ]\n",
      " [ 0.11471309]]\n",
      "Iteration 5181 | Cost: 0.3410072205753222 | Gradient: [[ 0.03040985]\n",
      " [-0.06883965]\n",
      " [ 0.11470426]]\n",
      "Iteration 5182 | Cost: 0.34098840062562114 | Gradient: [[ 0.03041044]\n",
      " [-0.0688316 ]\n",
      " [ 0.11469544]]\n",
      "Iteration 5183 | Cost: 0.3409695837726292 | Gradient: [[ 0.03041104]\n",
      " [-0.06882355]\n",
      " [ 0.11468661]]\n",
      "Iteration 5184 | Cost: 0.34095077001556207 | Gradient: [[ 0.03041163]\n",
      " [-0.06881551]\n",
      " [ 0.11467778]]\n",
      "Iteration 5185 | Cost: 0.3409319593536357 | Gradient: [[ 0.03041223]\n",
      " [-0.06880747]\n",
      " [ 0.11466896]]\n",
      "Iteration 5186 | Cost: 0.3409131517860667 | Gradient: [[ 0.03041282]\n",
      " [-0.06879943]\n",
      " [ 0.11466013]]\n",
      "Iteration 5187 | Cost: 0.34089434731207163 | Gradient: [[ 0.03041341]\n",
      " [-0.0687914 ]\n",
      " [ 0.1146513 ]]\n",
      "Iteration 5188 | Cost: 0.34087554593086783 | Gradient: [[ 0.030414  ]\n",
      " [-0.06878337]\n",
      " [ 0.11464248]]\n",
      "Iteration 5189 | Cost: 0.3408567476416724 | Gradient: [[ 0.03041459]\n",
      " [-0.06877535]\n",
      " [ 0.11463366]]\n",
      "Iteration 5190 | Cost: 0.3408379524437033 | Gradient: [[ 0.03041517]\n",
      " [-0.06876733]\n",
      " [ 0.11462483]]\n",
      "Iteration 5191 | Cost: 0.3408191603361785 | Gradient: [[ 0.03041576]\n",
      " [-0.06875931]\n",
      " [ 0.11461601]]\n",
      "Iteration 5192 | Cost: 0.34080037131831636 | Gradient: [[ 0.03041634]\n",
      " [-0.06875129]\n",
      " [ 0.11460719]]\n",
      "Iteration 5193 | Cost: 0.34078158538933584 | Gradient: [[ 0.03041693]\n",
      " [-0.06874328]\n",
      " [ 0.11459836]]\n",
      "Iteration 5194 | Cost: 0.3407628025484559 | Gradient: [[ 0.03041751]\n",
      " [-0.06873527]\n",
      " [ 0.11458954]]\n",
      "Iteration 5195 | Cost: 0.3407440227948959 | Gradient: [[ 0.03041809]\n",
      " [-0.06872727]\n",
      " [ 0.11458072]]\n",
      "Iteration 5196 | Cost: 0.3407252461278757 | Gradient: [[ 0.03041867]\n",
      " [-0.06871926]\n",
      " [ 0.1145719 ]]\n",
      "Iteration 5197 | Cost: 0.34070647254661524 | Gradient: [[ 0.03041924]\n",
      " [-0.06871126]\n",
      " [ 0.11456308]]\n",
      "Iteration 5198 | Cost: 0.3406877020503351 | Gradient: [[ 0.03041982]\n",
      " [-0.06870327]\n",
      " [ 0.11455426]]\n",
      "Iteration 5199 | Cost: 0.34066893463825587 | Gradient: [[ 0.0304204 ]\n",
      " [-0.06869528]\n",
      " [ 0.11454544]]\n",
      "Iteration 5200 | Cost: 0.3406501703095987 | Gradient: [[ 0.03042097]\n",
      " [-0.06868729]\n",
      " [ 0.11453662]]\n",
      "Iteration 5201 | Cost: 0.340631409063585 | Gradient: [[ 0.03042154]\n",
      " [-0.0686793 ]\n",
      " [ 0.1145278 ]]\n",
      "Iteration 5202 | Cost: 0.3406126508994366 | Gradient: [[ 0.03042211]\n",
      " [-0.06867132]\n",
      " [ 0.11451899]]\n",
      "Iteration 5203 | Cost: 0.3405938958163754 | Gradient: [[ 0.03042268]\n",
      " [-0.06866334]\n",
      " [ 0.11451017]]\n",
      "Iteration 5204 | Cost: 0.34057514381362386 | Gradient: [[ 0.03042325]\n",
      " [-0.06865537]\n",
      " [ 0.11450135]]\n",
      "Iteration 5205 | Cost: 0.34055639489040473 | Gradient: [[ 0.03042382]\n",
      " [-0.0686474 ]\n",
      " [ 0.11449253]]\n",
      "Iteration 5206 | Cost: 0.34053764904594114 | Gradient: [[ 0.03042438]\n",
      " [-0.06863943]\n",
      " [ 0.11448372]]\n",
      "Iteration 5207 | Cost: 0.34051890627945636 | Gradient: [[ 0.03042495]\n",
      " [-0.06863146]\n",
      " [ 0.1144749 ]]\n",
      "Iteration 5208 | Cost: 0.3405001665901741 | Gradient: [[ 0.03042551]\n",
      " [-0.0686235 ]\n",
      " [ 0.11446609]]\n",
      "Iteration 5209 | Cost: 0.3404814299773186 | Gradient: [[ 0.03042607]\n",
      " [-0.06861554]\n",
      " [ 0.11445727]]\n",
      "Iteration 5210 | Cost: 0.340462696440114 | Gradient: [[ 0.03042663]\n",
      " [-0.06860759]\n",
      " [ 0.11444846]]\n",
      "Iteration 5211 | Cost: 0.34044396597778526 | Gradient: [[ 0.03042719]\n",
      " [-0.06859963]\n",
      " [ 0.11443965]]\n",
      "Iteration 5212 | Cost: 0.34042523858955714 | Gradient: [[ 0.03042775]\n",
      " [-0.06859169]\n",
      " [ 0.11443083]]\n",
      "Iteration 5213 | Cost: 0.34040651427465524 | Gradient: [[ 0.0304283 ]\n",
      " [-0.06858374]\n",
      " [ 0.11442202]]\n",
      "Iteration 5214 | Cost: 0.34038779303230515 | Gradient: [[ 0.03042886]\n",
      " [-0.0685758 ]\n",
      " [ 0.11441321]]\n",
      "Iteration 5215 | Cost: 0.34036907486173285 | Gradient: [[ 0.03042941]\n",
      " [-0.06856786]\n",
      " [ 0.1144044 ]]\n",
      "Iteration 5216 | Cost: 0.34035035976216477 | Gradient: [[ 0.03042997]\n",
      " [-0.06855992]\n",
      " [ 0.11439559]]\n",
      "Iteration 5217 | Cost: 0.34033164773282754 | Gradient: [[ 0.03043052]\n",
      " [-0.06855199]\n",
      " [ 0.11438678]]\n",
      "Iteration 5218 | Cost: 0.3403129387729482 | Gradient: [[ 0.03043107]\n",
      " [-0.06854406]\n",
      " [ 0.11437797]]\n",
      "Iteration 5219 | Cost: 0.34029423288175403 | Gradient: [[ 0.03043161]\n",
      " [-0.06853614]\n",
      " [ 0.11436916]]\n",
      "Iteration 5220 | Cost: 0.3402755300584728 | Gradient: [[ 0.03043216]\n",
      " [-0.06852822]\n",
      " [ 0.11436035]]\n",
      "Iteration 5221 | Cost: 0.34025683030233234 | Gradient: [[ 0.03043271]\n",
      " [-0.0685203 ]\n",
      " [ 0.11435154]]\n",
      "Iteration 5222 | Cost: 0.3402381336125611 | Gradient: [[ 0.03043325]\n",
      " [-0.06851238]\n",
      " [ 0.11434274]]\n",
      "Iteration 5223 | Cost: 0.3402194399883876 | Gradient: [[ 0.03043379]\n",
      " [-0.06850447]\n",
      " [ 0.11433393]]\n",
      "Iteration 5224 | Cost: 0.34020074942904077 | Gradient: [[ 0.03043434]\n",
      " [-0.06849656]\n",
      " [ 0.11432512]]\n",
      "Iteration 5225 | Cost: 0.3401820619337501 | Gradient: [[ 0.03043488]\n",
      " [-0.06848866]\n",
      " [ 0.11431632]]\n",
      "Iteration 5226 | Cost: 0.340163377501745 | Gradient: [[ 0.03043542]\n",
      " [-0.06848075]\n",
      " [ 0.11430751]]\n",
      "Iteration 5227 | Cost: 0.3401446961322556 | Gradient: [[ 0.03043595]\n",
      " [-0.06847286]\n",
      " [ 0.1142987 ]]\n",
      "Iteration 5228 | Cost: 0.3401260178245119 | Gradient: [[ 0.03043649]\n",
      " [-0.06846496]\n",
      " [ 0.1142899 ]]\n",
      "Iteration 5229 | Cost: 0.34010734257774466 | Gradient: [[ 0.03043703]\n",
      " [-0.06845707]\n",
      " [ 0.1142811 ]]\n",
      "Iteration 5230 | Cost: 0.3400886703911847 | Gradient: [[ 0.03043756]\n",
      " [-0.06844918]\n",
      " [ 0.11427229]]\n",
      "Iteration 5231 | Cost: 0.34007000126406345 | Gradient: [[ 0.03043809]\n",
      " [-0.06844129]\n",
      " [ 0.11426349]]\n",
      "Iteration 5232 | Cost: 0.3400513351956122 | Gradient: [[ 0.03043863]\n",
      " [-0.06843341]\n",
      " [ 0.11425469]]\n",
      "Iteration 5233 | Cost: 0.34003267218506295 | Gradient: [[ 0.03043916]\n",
      " [-0.06842553]\n",
      " [ 0.11424588]]\n",
      "Iteration 5234 | Cost: 0.34001401223164796 | Gradient: [[ 0.03043968]\n",
      " [-0.06841765]\n",
      " [ 0.11423708]]\n",
      "Iteration 5235 | Cost: 0.3399953553345996 | Gradient: [[ 0.03044021]\n",
      " [-0.06840978]\n",
      " [ 0.11422828]]\n",
      "Iteration 5236 | Cost: 0.3399767014931509 | Gradient: [[ 0.03044074]\n",
      " [-0.06840191]\n",
      " [ 0.11421948]]\n",
      "Iteration 5237 | Cost: 0.3399580507065349 | Gradient: [[ 0.03044126]\n",
      " [-0.06839405]\n",
      " [ 0.11421068]]\n",
      "Iteration 5238 | Cost: 0.3399394029739851 | Gradient: [[ 0.03044179]\n",
      " [-0.06838618]\n",
      " [ 0.11420188]]\n",
      "Iteration 5239 | Cost: 0.3399207582947354 | Gradient: [[ 0.03044231]\n",
      " [-0.06837832]\n",
      " [ 0.11419308]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5240 | Cost: 0.3399021166680197 | Gradient: [[ 0.03044283]\n",
      " [-0.06837047]\n",
      " [ 0.11418429]]\n",
      "Iteration 5241 | Cost: 0.3398834780930729 | Gradient: [[ 0.03044335]\n",
      " [-0.06836261]\n",
      " [ 0.11417549]]\n",
      "Iteration 5242 | Cost: 0.3398648425691293 | Gradient: [[ 0.03044387]\n",
      " [-0.06835477]\n",
      " [ 0.11416669]]\n",
      "Iteration 5243 | Cost: 0.33984621009542415 | Gradient: [[ 0.03044439]\n",
      " [-0.06834692]\n",
      " [ 0.11415789]]\n",
      "Iteration 5244 | Cost: 0.3398275806711931 | Gradient: [[ 0.0304449 ]\n",
      " [-0.06833908]\n",
      " [ 0.1141491 ]]\n",
      "Iteration 5245 | Cost: 0.3398089542956716 | Gradient: [[ 0.03044542]\n",
      " [-0.06833124]\n",
      " [ 0.1141403 ]]\n",
      "Iteration 5246 | Cost: 0.33979033096809586 | Gradient: [[ 0.03044593]\n",
      " [-0.0683234 ]\n",
      " [ 0.11413151]]\n",
      "Iteration 5247 | Cost: 0.33977171068770207 | Gradient: [[ 0.03044644]\n",
      " [-0.06831557]\n",
      " [ 0.11412271]]\n",
      "Iteration 5248 | Cost: 0.3397530934537272 | Gradient: [[ 0.03044695]\n",
      " [-0.06830773]\n",
      " [ 0.11411392]]\n",
      "Iteration 5249 | Cost: 0.339734479265408 | Gradient: [[ 0.03044746]\n",
      " [-0.06829991]\n",
      " [ 0.11410512]]\n",
      "Iteration 5250 | Cost: 0.339715868121982 | Gradient: [[ 0.03044797]\n",
      " [-0.06829208]\n",
      " [ 0.11409633]]\n",
      "Iteration 5251 | Cost: 0.3396972600226868 | Gradient: [[ 0.03044848]\n",
      " [-0.06828426]\n",
      " [ 0.11408754]]\n",
      "Iteration 5252 | Cost: 0.3396786549667603 | Gradient: [[ 0.03044898]\n",
      " [-0.06827645]\n",
      " [ 0.11407875]]\n",
      "Iteration 5253 | Cost: 0.33966005295344087 | Gradient: [[ 0.03044949]\n",
      " [-0.06826863]\n",
      " [ 0.11406995]]\n",
      "Iteration 5254 | Cost: 0.339641453981967 | Gradient: [[ 0.03044999]\n",
      " [-0.06826082]\n",
      " [ 0.11406116]]\n",
      "Iteration 5255 | Cost: 0.3396228580515777 | Gradient: [[ 0.03045049]\n",
      " [-0.06825301]\n",
      " [ 0.11405237]]\n",
      "Iteration 5256 | Cost: 0.3396042651615122 | Gradient: [[ 0.03045099]\n",
      " [-0.06824521]\n",
      " [ 0.11404358]]\n",
      "Iteration 5257 | Cost: 0.33958567531101014 | Gradient: [[ 0.03045149]\n",
      " [-0.06823741]\n",
      " [ 0.11403479]]\n",
      "Iteration 5258 | Cost: 0.3395670884993113 | Gradient: [[ 0.03045199]\n",
      " [-0.06822961]\n",
      " [ 0.114026  ]]\n",
      "Iteration 5259 | Cost: 0.3395485047256558 | Gradient: [[ 0.03045249]\n",
      " [-0.06822182]\n",
      " [ 0.11401722]]\n",
      "Iteration 5260 | Cost: 0.3395299239892844 | Gradient: [[ 0.03045298]\n",
      " [-0.06821402]\n",
      " [ 0.11400843]]\n",
      "Iteration 5261 | Cost: 0.3395113462894376 | Gradient: [[ 0.03045348]\n",
      " [-0.06820624]\n",
      " [ 0.11399964]]\n",
      "Iteration 5262 | Cost: 0.33949277162535674 | Gradient: [[ 0.03045397]\n",
      " [-0.06819845]\n",
      " [ 0.11399085]]\n",
      "Iteration 5263 | Cost: 0.33947419999628325 | Gradient: [[ 0.03045446]\n",
      " [-0.06819067]\n",
      " [ 0.11398207]]\n",
      "Iteration 5264 | Cost: 0.33945563140145885 | Gradient: [[ 0.03045495]\n",
      " [-0.06818289]\n",
      " [ 0.11397328]]\n",
      "Iteration 5265 | Cost: 0.3394370658401257 | Gradient: [[ 0.03045544]\n",
      " [-0.06817512]\n",
      " [ 0.1139645 ]]\n",
      "Iteration 5266 | Cost: 0.3394185033115262 | Gradient: [[ 0.03045593]\n",
      " [-0.06816734]\n",
      " [ 0.11395571]]\n",
      "Iteration 5267 | Cost: 0.33939994381490296 | Gradient: [[ 0.03045642]\n",
      " [-0.06815957]\n",
      " [ 0.11394693]]\n",
      "Iteration 5268 | Cost: 0.3393813873494991 | Gradient: [[ 0.0304569 ]\n",
      " [-0.06815181]\n",
      " [ 0.11393814]]\n",
      "Iteration 5269 | Cost: 0.33936283391455785 | Gradient: [[ 0.03045739]\n",
      " [-0.06814405]\n",
      " [ 0.11392936]]\n",
      "Iteration 5270 | Cost: 0.339344283509323 | Gradient: [[ 0.03045787]\n",
      " [-0.06813629]\n",
      " [ 0.11392058]]\n",
      "Iteration 5271 | Cost: 0.3393257361330385 | Gradient: [[ 0.03045835]\n",
      " [-0.06812853]\n",
      " [ 0.1139118 ]]\n",
      "Iteration 5272 | Cost: 0.3393071917849486 | Gradient: [[ 0.03045883]\n",
      " [-0.06812078]\n",
      " [ 0.11390301]]\n",
      "Iteration 5273 | Cost: 0.3392886504642979 | Gradient: [[ 0.03045931]\n",
      " [-0.06811303]\n",
      " [ 0.11389423]]\n",
      "Iteration 5274 | Cost: 0.33927011217033143 | Gradient: [[ 0.03045979]\n",
      " [-0.06810528]\n",
      " [ 0.11388545]]\n",
      "Iteration 5275 | Cost: 0.33925157690229424 | Gradient: [[ 0.03046026]\n",
      " [-0.06809754]\n",
      " [ 0.11387667]]\n",
      "Iteration 5276 | Cost: 0.3392330446594318 | Gradient: [[ 0.03046074]\n",
      " [-0.0680898 ]\n",
      " [ 0.11386789]]\n",
      "Iteration 5277 | Cost: 0.33921451544099024 | Gradient: [[ 0.03046121]\n",
      " [-0.06808206]\n",
      " [ 0.11385911]]\n",
      "Iteration 5278 | Cost: 0.3391959892462155 | Gradient: [[ 0.03046169]\n",
      " [-0.06807433]\n",
      " [ 0.11385034]]\n",
      "Iteration 5279 | Cost: 0.3391774660743541 | Gradient: [[ 0.03046216]\n",
      " [-0.0680666 ]\n",
      " [ 0.11384156]]\n",
      "Iteration 5280 | Cost: 0.33915894592465284 | Gradient: [[ 0.03046263]\n",
      " [-0.06805887]\n",
      " [ 0.11383278]]\n",
      "Iteration 5281 | Cost: 0.3391404287963589 | Gradient: [[ 0.0304631 ]\n",
      " [-0.06805115]\n",
      " [ 0.113824  ]]\n",
      "Iteration 5282 | Cost: 0.33912191468871955 | Gradient: [[ 0.03046357]\n",
      " [-0.06804343]\n",
      " [ 0.11381523]]\n",
      "Iteration 5283 | Cost: 0.33910340360098246 | Gradient: [[ 0.03046403]\n",
      " [-0.06803571]\n",
      " [ 0.11380645]]\n",
      "Iteration 5284 | Cost: 0.3390848955323959 | Gradient: [[ 0.0304645 ]\n",
      " [-0.06802799]\n",
      " [ 0.11379768]]\n",
      "Iteration 5285 | Cost: 0.33906639048220805 | Gradient: [[ 0.03046496]\n",
      " [-0.06802028]\n",
      " [ 0.1137889 ]]\n",
      "Iteration 5286 | Cost: 0.33904788844966743 | Gradient: [[ 0.03046542]\n",
      " [-0.06801257]\n",
      " [ 0.11378013]]\n",
      "Iteration 5287 | Cost: 0.3390293894340233 | Gradient: [[ 0.03046589]\n",
      " [-0.06800487]\n",
      " [ 0.11377136]]\n",
      "Iteration 5288 | Cost: 0.3390108934345246 | Gradient: [[ 0.03046635]\n",
      " [-0.06799717]\n",
      " [ 0.11376258]]\n",
      "Iteration 5289 | Cost: 0.3389924004504212 | Gradient: [[ 0.0304668 ]\n",
      " [-0.06798947]\n",
      " [ 0.11375381]]\n",
      "Iteration 5290 | Cost: 0.3389739104809627 | Gradient: [[ 0.03046726]\n",
      " [-0.06798177]\n",
      " [ 0.11374504]]\n",
      "Iteration 5291 | Cost: 0.3389554235253996 | Gradient: [[ 0.03046772]\n",
      " [-0.06797408]\n",
      " [ 0.11373627]]\n",
      "Iteration 5292 | Cost: 0.3389369395829821 | Gradient: [[ 0.03046817]\n",
      " [-0.06796639]\n",
      " [ 0.1137275 ]]\n",
      "Iteration 5293 | Cost: 0.3389184586529611 | Gradient: [[ 0.03046863]\n",
      " [-0.0679587 ]\n",
      " [ 0.11371873]]\n",
      "Iteration 5294 | Cost: 0.338899980734588 | Gradient: [[ 0.03046908]\n",
      " [-0.06795102]\n",
      " [ 0.11370996]]\n",
      "Iteration 5295 | Cost: 0.33888150582711385 | Gradient: [[ 0.03046953]\n",
      " [-0.06794334]\n",
      " [ 0.11370119]]\n",
      "Iteration 5296 | Cost: 0.33886303392979056 | Gradient: [[ 0.03046998]\n",
      " [-0.06793566]\n",
      " [ 0.11369242]]\n",
      "Iteration 5297 | Cost: 0.3388445650418701 | Gradient: [[ 0.03047043]\n",
      " [-0.06792799]\n",
      " [ 0.11368365]]\n",
      "Iteration 5298 | Cost: 0.33882609916260487 | Gradient: [[ 0.03047088]\n",
      " [-0.06792032]\n",
      " [ 0.11367488]]\n",
      "Iteration 5299 | Cost: 0.3388076362912475 | Gradient: [[ 0.03047133]\n",
      " [-0.06791265]\n",
      " [ 0.11366612]]\n",
      "Iteration 5300 | Cost: 0.338789176427051 | Gradient: [[ 0.03047177]\n",
      " [-0.06790499]\n",
      " [ 0.11365735]]\n",
      "Iteration 5301 | Cost: 0.3387707195692685 | Gradient: [[ 0.03047222]\n",
      " [-0.06789733]\n",
      " [ 0.11364858]]\n",
      "Iteration 5302 | Cost: 0.3387522657171538 | Gradient: [[ 0.03047266]\n",
      " [-0.06788967]\n",
      " [ 0.11363982]]\n",
      "Iteration 5303 | Cost: 0.3387338148699606 | Gradient: [[ 0.0304731 ]\n",
      " [-0.06788201]\n",
      " [ 0.11363105]]\n",
      "Iteration 5304 | Cost: 0.3387153670269431 | Gradient: [[ 0.03047354]\n",
      " [-0.06787436]\n",
      " [ 0.11362229]]\n",
      "Iteration 5305 | Cost: 0.33869692218735586 | Gradient: [[ 0.03047398]\n",
      " [-0.06786671]\n",
      " [ 0.11361352]]\n",
      "Iteration 5306 | Cost: 0.3386784803504536 | Gradient: [[ 0.03047442]\n",
      " [-0.06785907]\n",
      " [ 0.11360476]]\n",
      "Iteration 5307 | Cost: 0.33866004151549156 | Gradient: [[ 0.03047486]\n",
      " [-0.06785143]\n",
      " [ 0.113596  ]]\n",
      "Iteration 5308 | Cost: 0.33864160568172497 | Gradient: [[ 0.03047529]\n",
      " [-0.06784379]\n",
      " [ 0.11358724]]\n",
      "Iteration 5309 | Cost: 0.33862317284840965 | Gradient: [[ 0.03047573]\n",
      " [-0.06783615]\n",
      " [ 0.11357848]]\n",
      "Iteration 5310 | Cost: 0.33860474301480153 | Gradient: [[ 0.03047616]\n",
      " [-0.06782852]\n",
      " [ 0.11356971]]\n",
      "Iteration 5311 | Cost: 0.33858631618015705 | Gradient: [[ 0.03047659]\n",
      " [-0.06782089]\n",
      " [ 0.11356095]]\n",
      "Iteration 5312 | Cost: 0.33856789234373275 | Gradient: [[ 0.03047702]\n",
      " [-0.06781326]\n",
      " [ 0.11355219]]\n",
      "Iteration 5313 | Cost: 0.3385494715047856 | Gradient: [[ 0.03047745]\n",
      " [-0.06780564]\n",
      " [ 0.11354343]]\n",
      "Iteration 5314 | Cost: 0.33853105366257275 | Gradient: [[ 0.03047788]\n",
      " [-0.06779802]\n",
      " [ 0.11353468]]\n",
      "Iteration 5315 | Cost: 0.3385126388163518 | Gradient: [[ 0.03047831]\n",
      " [-0.0677904 ]\n",
      " [ 0.11352592]]\n",
      "Iteration 5316 | Cost: 0.33849422696538056 | Gradient: [[ 0.03047873]\n",
      " [-0.06778279]\n",
      " [ 0.11351716]]\n",
      "Iteration 5317 | Cost: 0.3384758181089172 | Gradient: [[ 0.03047916]\n",
      " [-0.06777518]\n",
      " [ 0.1135084 ]]\n",
      "Iteration 5318 | Cost: 0.3384574122462201 | Gradient: [[ 0.03047958]\n",
      " [-0.06776757]\n",
      " [ 0.11349965]]\n",
      "Iteration 5319 | Cost: 0.33843900937654803 | Gradient: [[ 0.03048   ]\n",
      " [-0.06775996]\n",
      " [ 0.11349089]]\n",
      "Iteration 5320 | Cost: 0.33842060949916014 | Gradient: [[ 0.03048042]\n",
      " [-0.06775236]\n",
      " [ 0.11348214]]\n",
      "Iteration 5321 | Cost: 0.3384022126133156 | Gradient: [[ 0.03048084]\n",
      " [-0.06774476]\n",
      " [ 0.11347338]]\n",
      "Iteration 5322 | Cost: 0.3383838187182743 | Gradient: [[ 0.03048126]\n",
      " [-0.06773717]\n",
      " [ 0.11346463]]\n",
      "Iteration 5323 | Cost: 0.3383654278132958 | Gradient: [[ 0.03048168]\n",
      " [-0.06772957]\n",
      " [ 0.11345587]]\n",
      "Iteration 5324 | Cost: 0.3383470398976407 | Gradient: [[ 0.03048209]\n",
      " [-0.06772199]\n",
      " [ 0.11344712]]\n",
      "Iteration 5325 | Cost: 0.3383286549705694 | Gradient: [[ 0.03048251]\n",
      " [-0.0677144 ]\n",
      " [ 0.11343837]]\n",
      "Iteration 5326 | Cost: 0.33831027303134276 | Gradient: [[ 0.03048292]\n",
      " [-0.06770682]\n",
      " [ 0.11342961]]\n",
      "Iteration 5327 | Cost: 0.33829189407922206 | Gradient: [[ 0.03048334]\n",
      " [-0.06769924]\n",
      " [ 0.11342086]]\n",
      "Iteration 5328 | Cost: 0.3382735181134686 | Gradient: [[ 0.03048375]\n",
      " [-0.06769166]\n",
      " [ 0.11341211]]\n",
      "Iteration 5329 | Cost: 0.3382551451333441 | Gradient: [[ 0.03048416]\n",
      " [-0.06768408]\n",
      " [ 0.11340336]]\n",
      "Iteration 5330 | Cost: 0.33823677513811085 | Gradient: [[ 0.03048457]\n",
      " [-0.06767651]\n",
      " [ 0.11339461]]\n",
      "Iteration 5331 | Cost: 0.3382184081270309 | Gradient: [[ 0.03048497]\n",
      " [-0.06766895]\n",
      " [ 0.11338586]]\n",
      "Iteration 5332 | Cost: 0.3382000440993671 | Gradient: [[ 0.03048538]\n",
      " [-0.06766138]\n",
      " [ 0.11337711]]\n",
      "Iteration 5333 | Cost: 0.33818168305438234 | Gradient: [[ 0.03048578]\n",
      " [-0.06765382]\n",
      " [ 0.11336836]]\n",
      "Iteration 5334 | Cost: 0.3381633249913399 | Gradient: [[ 0.03048619]\n",
      " [-0.06764626]\n",
      " [ 0.11335962]]\n",
      "Iteration 5335 | Cost: 0.33814496990950327 | Gradient: [[ 0.03048659]\n",
      " [-0.06763871]\n",
      " [ 0.11335087]]\n",
      "Iteration 5336 | Cost: 0.3381266178081363 | Gradient: [[ 0.03048699]\n",
      " [-0.06763115]\n",
      " [ 0.11334212]]\n",
      "Iteration 5337 | Cost: 0.33810826868650323 | Gradient: [[ 0.03048739]\n",
      " [-0.0676236 ]\n",
      " [ 0.11333338]]\n",
      "Iteration 5338 | Cost: 0.3380899225438683 | Gradient: [[ 0.03048779]\n",
      " [-0.06761606]\n",
      " [ 0.11332463]]\n",
      "Iteration 5339 | Cost: 0.3380715793794966 | Gradient: [[ 0.03048819]\n",
      " [-0.06760851]\n",
      " [ 0.11331589]]\n",
      "Iteration 5340 | Cost: 0.3380532391926528 | Gradient: [[ 0.03048859]\n",
      " [-0.06760097]\n",
      " [ 0.11330714]]\n",
      "Iteration 5341 | Cost: 0.33803490198260233 | Gradient: [[ 0.03048898]\n",
      " [-0.06759344]\n",
      " [ 0.1132984 ]]\n",
      "Iteration 5342 | Cost: 0.3380165677486109 | Gradient: [[ 0.03048938]\n",
      " [-0.0675859 ]\n",
      " [ 0.11328966]]\n",
      "Iteration 5343 | Cost: 0.3379982364899445 | Gradient: [[ 0.03048977]\n",
      " [-0.06757837]\n",
      " [ 0.11328091]]\n",
      "Iteration 5344 | Cost: 0.33797990820586915 | Gradient: [[ 0.03049016]\n",
      " [-0.06757084]\n",
      " [ 0.11327217]]\n",
      "Iteration 5345 | Cost: 0.33796158289565154 | Gradient: [[ 0.03049055]\n",
      " [-0.06756332]\n",
      " [ 0.11326343]]\n",
      "Iteration 5346 | Cost: 0.3379432605585584 | Gradient: [[ 0.03049094]\n",
      " [-0.0675558 ]\n",
      " [ 0.11325469]]\n",
      "Iteration 5347 | Cost: 0.3379249411938568 | Gradient: [[ 0.03049133]\n",
      " [-0.06754828]\n",
      " [ 0.11324595]]\n",
      "Iteration 5348 | Cost: 0.3379066248008143 | Gradient: [[ 0.03049172]\n",
      " [-0.06754076]\n",
      " [ 0.11323721]]\n",
      "Iteration 5349 | Cost: 0.3378883113786985 | Gradient: [[ 0.0304921 ]\n",
      " [-0.06753325]\n",
      " [ 0.11322847]]\n",
      "Iteration 5350 | Cost: 0.33787000092677744 | Gradient: [[ 0.03049249]\n",
      " [-0.06752574]\n",
      " [ 0.11321973]]\n",
      "Iteration 5351 | Cost: 0.3378516934443193 | Gradient: [[ 0.03049287]\n",
      " [-0.06751823]\n",
      " [ 0.11321099]]\n",
      "Iteration 5352 | Cost: 0.33783338893059284 | Gradient: [[ 0.03049325]\n",
      " [-0.06751073]\n",
      " [ 0.11320225]]\n",
      "Iteration 5353 | Cost: 0.33781508738486676 | Gradient: [[ 0.03049364]\n",
      " [-0.06750323]\n",
      " [ 0.11319352]]\n",
      "Iteration 5354 | Cost: 0.3377967888064104 | Gradient: [[ 0.03049402]\n",
      " [-0.06749573]\n",
      " [ 0.11318478]]\n",
      "Iteration 5355 | Cost: 0.3377784931944932 | Gradient: [[ 0.03049439]\n",
      " [-0.06748824]\n",
      " [ 0.11317604]]\n",
      "Iteration 5356 | Cost: 0.3377602005483848 | Gradient: [[ 0.03049477]\n",
      " [-0.06748075]\n",
      " [ 0.11316731]]\n",
      "Iteration 5357 | Cost: 0.3377419108673554 | Gradient: [[ 0.03049515]\n",
      " [-0.06747326]\n",
      " [ 0.11315857]]\n",
      "Iteration 5358 | Cost: 0.33772362415067525 | Gradient: [[ 0.03049552]\n",
      " [-0.06746577]\n",
      " [ 0.11314984]]\n",
      "Iteration 5359 | Cost: 0.337705340397615 | Gradient: [[ 0.0304959 ]\n",
      " [-0.06745829]\n",
      " [ 0.11314111]]\n",
      "Iteration 5360 | Cost: 0.33768705960744577 | Gradient: [[ 0.03049627]\n",
      " [-0.06745081]\n",
      " [ 0.11313237]]\n",
      "Iteration 5361 | Cost: 0.33766878177943854 | Gradient: [[ 0.03049664]\n",
      " [-0.06744333]\n",
      " [ 0.11312364]]\n",
      "Iteration 5362 | Cost: 0.3376505069128649 | Gradient: [[ 0.03049701]\n",
      " [-0.06743586]\n",
      " [ 0.11311491]]\n",
      "Iteration 5363 | Cost: 0.3376322350069968 | Gradient: [[ 0.03049738]\n",
      " [-0.06742839]\n",
      " [ 0.11310618]]\n",
      "Iteration 5364 | Cost: 0.33761396606110616 | Gradient: [[ 0.03049775]\n",
      " [-0.06742092]\n",
      " [ 0.11309745]]\n",
      "Iteration 5365 | Cost: 0.33759570007446554 | Gradient: [[ 0.03049812]\n",
      " [-0.06741346]\n",
      " [ 0.11308872]]\n",
      "Iteration 5366 | Cost: 0.3375774370463475 | Gradient: [[ 0.03049848]\n",
      " [-0.067406  ]\n",
      " [ 0.11307999]]\n",
      "Iteration 5367 | Cost: 0.3375591769760251 | Gradient: [[ 0.03049885]\n",
      " [-0.06739854]\n",
      " [ 0.11307126]]\n",
      "Iteration 5368 | Cost: 0.3375409198627716 | Gradient: [[ 0.03049921]\n",
      " [-0.06739109]\n",
      " [ 0.11306253]]\n",
      "Iteration 5369 | Cost: 0.3375226657058606 | Gradient: [[ 0.03049957]\n",
      " [-0.06738363]\n",
      " [ 0.1130538 ]]\n",
      "Iteration 5370 | Cost: 0.3375044145045658 | Gradient: [[ 0.03049994]\n",
      " [-0.06737618]\n",
      " [ 0.11304507]]\n",
      "Iteration 5371 | Cost: 0.3374861662581616 | Gradient: [[ 0.0305003 ]\n",
      " [-0.06736874]\n",
      " [ 0.11303635]]\n",
      "Iteration 5372 | Cost: 0.3374679209659222 | Gradient: [[ 0.03050065]\n",
      " [-0.06736129]\n",
      " [ 0.11302762]]\n",
      "Iteration 5373 | Cost: 0.33744967862712244 | Gradient: [[ 0.03050101]\n",
      " [-0.06735385]\n",
      " [ 0.1130189 ]]\n",
      "Iteration 5374 | Cost: 0.3374314392410373 | Gradient: [[ 0.03050137]\n",
      " [-0.06734642]\n",
      " [ 0.11301017]]\n",
      "Iteration 5375 | Cost: 0.3374132028069421 | Gradient: [[ 0.03050172]\n",
      " [-0.06733898]\n",
      " [ 0.11300145]]\n",
      "Iteration 5376 | Cost: 0.3373949693241125 | Gradient: [[ 0.03050208]\n",
      " [-0.06733155]\n",
      " [ 0.11299272]]\n",
      "Iteration 5377 | Cost: 0.3373767387918242 | Gradient: [[ 0.03050243]\n",
      " [-0.06732412]\n",
      " [ 0.112984  ]]\n",
      "Iteration 5378 | Cost: 0.33735851120935356 | Gradient: [[ 0.03050278]\n",
      " [-0.0673167 ]\n",
      " [ 0.11297528]]\n",
      "Iteration 5379 | Cost: 0.3373402865759769 | Gradient: [[ 0.03050313]\n",
      " [-0.06730928]\n",
      " [ 0.11296655]]\n",
      "Iteration 5380 | Cost: 0.3373220648909711 | Gradient: [[ 0.03050348]\n",
      " [-0.06730186]\n",
      " [ 0.11295783]]\n",
      "Iteration 5381 | Cost: 0.3373038461536131 | Gradient: [[ 0.03050383]\n",
      " [-0.06729444]\n",
      " [ 0.11294911]]\n",
      "Iteration 5382 | Cost: 0.3372856303631803 | Gradient: [[ 0.03050418]\n",
      " [-0.06728703]\n",
      " [ 0.11294039]]\n",
      "Iteration 5383 | Cost: 0.33726741751895023 | Gradient: [[ 0.03050452]\n",
      " [-0.06727962]\n",
      " [ 0.11293167]]\n",
      "Iteration 5384 | Cost: 0.3372492076202009 | Gradient: [[ 0.03050487]\n",
      " [-0.06727221]\n",
      " [ 0.11292295]]\n",
      "Iteration 5385 | Cost: 0.3372310006662104 | Gradient: [[ 0.03050521]\n",
      " [-0.0672648 ]\n",
      " [ 0.11291423]]\n",
      "Iteration 5386 | Cost: 0.3372127966562573 | Gradient: [[ 0.03050556]\n",
      " [-0.0672574 ]\n",
      " [ 0.11290551]]\n",
      "Iteration 5387 | Cost: 0.3371945955896202 | Gradient: [[ 0.0305059]\n",
      " [-0.06725  ]\n",
      " [ 0.1128968]]\n",
      "Iteration 5388 | Cost: 0.3371763974655784 | Gradient: [[ 0.03050624]\n",
      " [-0.06724261]\n",
      " [ 0.11288808]]\n",
      "Iteration 5389 | Cost: 0.3371582022834111 | Gradient: [[ 0.03050658]\n",
      " [-0.06723522]\n",
      " [ 0.11287936]]\n",
      "Iteration 5390 | Cost: 0.33714001004239785 | Gradient: [[ 0.03050691]\n",
      " [-0.06722783]\n",
      " [ 0.11287065]]\n",
      "Iteration 5391 | Cost: 0.3371218207418186 | Gradient: [[ 0.03050725]\n",
      " [-0.06722044]\n",
      " [ 0.11286193]]\n",
      "Iteration 5392 | Cost: 0.33710363438095375 | Gradient: [[ 0.03050759]\n",
      " [-0.06721306]\n",
      " [ 0.11285322]]\n",
      "Iteration 5393 | Cost: 0.33708545095908343 | Gradient: [[ 0.03050792]\n",
      " [-0.06720568]\n",
      " [ 0.1128445 ]]\n",
      "Iteration 5394 | Cost: 0.33706727047548873 | Gradient: [[ 0.03050825]\n",
      " [-0.0671983 ]\n",
      " [ 0.11283579]]\n",
      "Iteration 5395 | Cost: 0.3370490929294504 | Gradient: [[ 0.03050859]\n",
      " [-0.06719092]\n",
      " [ 0.11282708]]\n",
      "Iteration 5396 | Cost: 0.33703091832025006 | Gradient: [[ 0.03050892]\n",
      " [-0.06718355]\n",
      " [ 0.11281836]]\n",
      "Iteration 5397 | Cost: 0.33701274664716924 | Gradient: [[ 0.03050925]\n",
      " [-0.06717618]\n",
      " [ 0.11280965]]\n",
      "Iteration 5398 | Cost: 0.3369945779094899 | Gradient: [[ 0.03050957]\n",
      " [-0.06716882]\n",
      " [ 0.11280094]]\n",
      "Iteration 5399 | Cost: 0.336976412106494 | Gradient: [[ 0.0305099 ]\n",
      " [-0.06716145]\n",
      " [ 0.11279223]]\n",
      "Iteration 5400 | Cost: 0.3369582492374642 | Gradient: [[ 0.03051023]\n",
      " [-0.06715409]\n",
      " [ 0.11278352]]\n",
      "Iteration 5401 | Cost: 0.3369400893016833 | Gradient: [[ 0.03051055]\n",
      " [-0.06714674]\n",
      " [ 0.11277481]]\n",
      "Iteration 5402 | Cost: 0.3369219322984342 | Gradient: [[ 0.03051088]\n",
      " [-0.06713938]\n",
      " [ 0.1127661 ]]\n",
      "Iteration 5403 | Cost: 0.3369037782270003 | Gradient: [[ 0.0305112 ]\n",
      " [-0.06713203]\n",
      " [ 0.11275739]]\n",
      "Iteration 5404 | Cost: 0.33688562708666536 | Gradient: [[ 0.03051152]\n",
      " [-0.06712468]\n",
      " [ 0.11274869]]\n",
      "Iteration 5405 | Cost: 0.33686747887671303 | Gradient: [[ 0.03051184]\n",
      " [-0.06711734]\n",
      " [ 0.11273998]]\n",
      "Iteration 5406 | Cost: 0.33684933359642766 | Gradient: [[ 0.03051216]\n",
      " [-0.06711   ]\n",
      " [ 0.11273127]]\n",
      "Iteration 5407 | Cost: 0.3368311912450936 | Gradient: [[ 0.03051248]\n",
      " [-0.06710266]\n",
      " [ 0.11272257]]\n",
      "Iteration 5408 | Cost: 0.33681305182199567 | Gradient: [[ 0.0305128 ]\n",
      " [-0.06709532]\n",
      " [ 0.11271386]]\n",
      "Iteration 5409 | Cost: 0.33679491532641886 | Gradient: [[ 0.03051311]\n",
      " [-0.06708799]\n",
      " [ 0.11270516]]\n",
      "Iteration 5410 | Cost: 0.33677678175764847 | Gradient: [[ 0.03051343]\n",
      " [-0.06708066]\n",
      " [ 0.11269645]]\n",
      "Iteration 5411 | Cost: 0.3367586511149701 | Gradient: [[ 0.03051374]\n",
      " [-0.06707333]\n",
      " [ 0.11268775]]\n",
      "Iteration 5412 | Cost: 0.3367405233976697 | Gradient: [[ 0.03051406]\n",
      " [-0.067066  ]\n",
      " [ 0.11267905]]\n",
      "Iteration 5413 | Cost: 0.3367223986050333 | Gradient: [[ 0.03051437]\n",
      " [-0.06705868]\n",
      " [ 0.11267034]]\n",
      "Iteration 5414 | Cost: 0.33670427673634734 | Gradient: [[ 0.03051468]\n",
      " [-0.06705136]\n",
      " [ 0.11266164]]\n",
      "Iteration 5415 | Cost: 0.3366861577908987 | Gradient: [[ 0.03051499]\n",
      " [-0.06704405]\n",
      " [ 0.11265294]]\n",
      "Iteration 5416 | Cost: 0.3366680417679742 | Gradient: [[ 0.03051529]\n",
      " [-0.06703673]\n",
      " [ 0.11264424]]\n",
      "Iteration 5417 | Cost: 0.3366499286668612 | Gradient: [[ 0.0305156 ]\n",
      " [-0.06702942]\n",
      " [ 0.11263554]]\n",
      "Iteration 5418 | Cost: 0.33663181848684737 | Gradient: [[ 0.03051591]\n",
      " [-0.06702212]\n",
      " [ 0.11262684]]\n",
      "Iteration 5419 | Cost: 0.3366137112272203 | Gradient: [[ 0.03051621]\n",
      " [-0.06701481]\n",
      " [ 0.11261814]]\n",
      "Iteration 5420 | Cost: 0.33659560688726814 | Gradient: [[ 0.03051652]\n",
      " [-0.06700751]\n",
      " [ 0.11260944]]\n",
      "Iteration 5421 | Cost: 0.3365775054662795 | Gradient: [[ 0.03051682]\n",
      " [-0.06700021]\n",
      " [ 0.11260075]]\n",
      "Iteration 5422 | Cost: 0.336559406963543 | Gradient: [[ 0.03051712]\n",
      " [-0.06699291]\n",
      " [ 0.11259205]]\n",
      "Iteration 5423 | Cost: 0.3365413113783474 | Gradient: [[ 0.03051742]\n",
      " [-0.06698562]\n",
      " [ 0.11258335]]\n",
      "Iteration 5424 | Cost: 0.3365232187099822 | Gradient: [[ 0.03051772]\n",
      " [-0.06697833]\n",
      " [ 0.11257466]]\n",
      "Iteration 5425 | Cost: 0.3365051289577367 | Gradient: [[ 0.03051802]\n",
      " [-0.06697105]\n",
      " [ 0.11256596]]\n",
      "Iteration 5426 | Cost: 0.33648704212090086 | Gradient: [[ 0.03051831]\n",
      " [-0.06696376]\n",
      " [ 0.11255727]]\n",
      "Iteration 5427 | Cost: 0.33646895819876466 | Gradient: [[ 0.03051861]\n",
      " [-0.06695648]\n",
      " [ 0.11254857]]\n",
      "Iteration 5428 | Cost: 0.33645087719061856 | Gradient: [[ 0.0305189 ]\n",
      " [-0.0669492 ]\n",
      " [ 0.11253988]]\n",
      "Iteration 5429 | Cost: 0.336432799095753 | Gradient: [[ 0.0305192 ]\n",
      " [-0.06694193]\n",
      " [ 0.11253118]]\n",
      "Iteration 5430 | Cost: 0.33641472391345906 | Gradient: [[ 0.03051949]\n",
      " [-0.06693465]\n",
      " [ 0.11252249]]\n",
      "Iteration 5431 | Cost: 0.33639665164302784 | Gradient: [[ 0.03051978]\n",
      " [-0.06692738]\n",
      " [ 0.1125138 ]]\n",
      "Iteration 5432 | Cost: 0.3363785822837509 | Gradient: [[ 0.03052007]\n",
      " [-0.06692012]\n",
      " [ 0.11250511]]\n",
      "Iteration 5433 | Cost: 0.33636051583492 | Gradient: [[ 0.03052036]\n",
      " [-0.06691285]\n",
      " [ 0.11249642]]\n",
      "Iteration 5434 | Cost: 0.3363424522958269 | Gradient: [[ 0.03052065]\n",
      " [-0.06690559]\n",
      " [ 0.11248773]]\n",
      "Iteration 5435 | Cost: 0.3363243916657642 | Gradient: [[ 0.03052093]\n",
      " [-0.06689833]\n",
      " [ 0.11247904]]\n",
      "Iteration 5436 | Cost: 0.33630633394402437 | Gradient: [[ 0.03052122]\n",
      " [-0.06689108]\n",
      " [ 0.11247035]]\n",
      "Iteration 5437 | Cost: 0.33628827912990017 | Gradient: [[ 0.0305215 ]\n",
      " [-0.06688383]\n",
      " [ 0.11246166]]\n",
      "Iteration 5438 | Cost: 0.33627022722268485 | Gradient: [[ 0.03052179]\n",
      " [-0.06687658]\n",
      " [ 0.11245297]]\n",
      "Iteration 5439 | Cost: 0.3362521782216718 | Gradient: [[ 0.03052207]\n",
      " [-0.06686933]\n",
      " [ 0.11244429]]\n",
      "Iteration 5440 | Cost: 0.33623413212615466 | Gradient: [[ 0.03052235]\n",
      " [-0.06686209]\n",
      " [ 0.1124356 ]]\n",
      "Iteration 5441 | Cost: 0.33621608893542737 | Gradient: [[ 0.03052263]\n",
      " [-0.06685485]\n",
      " [ 0.11242692]]\n",
      "Iteration 5442 | Cost: 0.3361980486487843 | Gradient: [[ 0.03052291]\n",
      " [-0.06684761]\n",
      " [ 0.11241823]]\n",
      "Iteration 5443 | Cost: 0.3361800112655196 | Gradient: [[ 0.03052319]\n",
      " [-0.06684037]\n",
      " [ 0.11240955]]\n",
      "Iteration 5444 | Cost: 0.3361619767849285 | Gradient: [[ 0.03052346]\n",
      " [-0.06683314]\n",
      " [ 0.11240086]]\n",
      "Iteration 5445 | Cost: 0.3361439452063058 | Gradient: [[ 0.03052374]\n",
      " [-0.06682591]\n",
      " [ 0.11239218]]\n",
      "Iteration 5446 | Cost: 0.33612591652894697 | Gradient: [[ 0.03052401]\n",
      " [-0.06681868]\n",
      " [ 0.11238349]]\n",
      "Iteration 5447 | Cost: 0.3361078907521475 | Gradient: [[ 0.03052429]\n",
      " [-0.06681146]\n",
      " [ 0.11237481]]\n",
      "Iteration 5448 | Cost: 0.33608986787520323 | Gradient: [[ 0.03052456]\n",
      " [-0.06680424]\n",
      " [ 0.11236613]]\n",
      "Iteration 5449 | Cost: 0.3360718478974105 | Gradient: [[ 0.03052483]\n",
      " [-0.06679702]\n",
      " [ 0.11235745]]\n",
      "Iteration 5450 | Cost: 0.3360538308180656 | Gradient: [[ 0.0305251 ]\n",
      " [-0.06678981]\n",
      " [ 0.11234877]]\n",
      "Iteration 5451 | Cost: 0.33603581663646526 | Gradient: [[ 0.03052537]\n",
      " [-0.06678259]\n",
      " [ 0.11234009]]\n",
      "Iteration 5452 | Cost: 0.33601780535190645 | Gradient: [[ 0.03052564]\n",
      " [-0.06677539]\n",
      " [ 0.11233141]]\n",
      "Iteration 5453 | Cost: 0.33599979696368654 | Gradient: [[ 0.0305259 ]\n",
      " [-0.06676818]\n",
      " [ 0.11232273]]\n",
      "Iteration 5454 | Cost: 0.33598179147110296 | Gradient: [[ 0.03052617]\n",
      " [-0.06676098]\n",
      " [ 0.11231405]]\n",
      "Iteration 5455 | Cost: 0.3359637888734534 | Gradient: [[ 0.03052643]\n",
      " [-0.06675377]\n",
      " [ 0.11230538]]\n",
      "Iteration 5456 | Cost: 0.33594578917003615 | Gradient: [[ 0.0305267 ]\n",
      " [-0.06674658]\n",
      " [ 0.1122967 ]]\n",
      "Iteration 5457 | Cost: 0.3359277923601494 | Gradient: [[ 0.03052696]\n",
      " [-0.06673938]\n",
      " [ 0.11228802]]\n",
      "Iteration 5458 | Cost: 0.33590979844309177 | Gradient: [[ 0.03052722]\n",
      " [-0.06673219]\n",
      " [ 0.11227935]]\n",
      "Iteration 5459 | Cost: 0.3358918074181622 | Gradient: [[ 0.03052748]\n",
      " [-0.066725  ]\n",
      " [ 0.11227067]]\n",
      "Iteration 5460 | Cost: 0.33587381928465987 | Gradient: [[ 0.03052774]\n",
      " [-0.06671781]\n",
      " [ 0.112262  ]]\n",
      "Iteration 5461 | Cost: 0.33585583404188424 | Gradient: [[ 0.030528  ]\n",
      " [-0.06671063]\n",
      " [ 0.11225332]]\n",
      "Iteration 5462 | Cost: 0.3358378516891349 | Gradient: [[ 0.03052825]\n",
      " [-0.06670345]\n",
      " [ 0.11224465]]\n",
      "Iteration 5463 | Cost: 0.33581987222571186 | Gradient: [[ 0.03052851]\n",
      " [-0.06669627]\n",
      " [ 0.11223598]]\n",
      "Iteration 5464 | Cost: 0.3358018956509154 | Gradient: [[ 0.03052876]\n",
      " [-0.06668909]\n",
      " [ 0.11222731]]\n",
      "Iteration 5465 | Cost: 0.33578392196404605 | Gradient: [[ 0.03052902]\n",
      " [-0.06668192]\n",
      " [ 0.11221863]]\n",
      "Iteration 5466 | Cost: 0.33576595116440455 | Gradient: [[ 0.03052927]\n",
      " [-0.06667475]\n",
      " [ 0.11220996]]\n",
      "Iteration 5467 | Cost: 0.335747983251292 | Gradient: [[ 0.03052952]\n",
      " [-0.06666759]\n",
      " [ 0.11220129]]\n",
      "Iteration 5468 | Cost: 0.3357300182240097 | Gradient: [[ 0.03052977]\n",
      " [-0.06666042]\n",
      " [ 0.11219262]]\n",
      "Iteration 5469 | Cost: 0.33571205608185933 | Gradient: [[ 0.03053002]\n",
      " [-0.06665326]\n",
      " [ 0.11218395]]\n",
      "Iteration 5470 | Cost: 0.3356940968241427 | Gradient: [[ 0.03053027]\n",
      " [-0.0666461 ]\n",
      " [ 0.11217529]]\n",
      "Iteration 5471 | Cost: 0.3356761404501619 | Gradient: [[ 0.03053051]\n",
      " [-0.06663895]\n",
      " [ 0.11216662]]\n",
      "Iteration 5472 | Cost: 0.3356581869592195 | Gradient: [[ 0.03053076]\n",
      " [-0.06663179]\n",
      " [ 0.11215795]]\n",
      "Iteration 5473 | Cost: 0.335640236350618 | Gradient: [[ 0.030531  ]\n",
      " [-0.06662464]\n",
      " [ 0.11214928]]\n",
      "Iteration 5474 | Cost: 0.33562228862366045 | Gradient: [[ 0.03053125]\n",
      " [-0.0666175 ]\n",
      " [ 0.11214062]]\n",
      "Iteration 5475 | Cost: 0.33560434377765 | Gradient: [[ 0.03053149]\n",
      " [-0.06661035]\n",
      " [ 0.11213195]]\n",
      "Iteration 5476 | Cost: 0.33558640181189026 | Gradient: [[ 0.03053173]\n",
      " [-0.06660321]\n",
      " [ 0.11212329]]\n",
      "Iteration 5477 | Cost: 0.33556846272568486 | Gradient: [[ 0.03053197]\n",
      " [-0.06659607]\n",
      " [ 0.11211462]]\n",
      "Iteration 5478 | Cost: 0.33555052651833794 | Gradient: [[ 0.03053221]\n",
      " [-0.06658894]\n",
      " [ 0.11210596]]\n",
      "Iteration 5479 | Cost: 0.33553259318915374 | Gradient: [[ 0.03053245]\n",
      " [-0.0665818 ]\n",
      " [ 0.1120973 ]]\n",
      "Iteration 5480 | Cost: 0.33551466273743674 | Gradient: [[ 0.03053269]\n",
      " [-0.06657467]\n",
      " [ 0.11208864]]\n",
      "Iteration 5481 | Cost: 0.33549673516249184 | Gradient: [[ 0.03053292]\n",
      " [-0.06656754]\n",
      " [ 0.11207997]]\n",
      "Iteration 5482 | Cost: 0.33547881046362427 | Gradient: [[ 0.03053316]\n",
      " [-0.06656042]\n",
      " [ 0.11207131]]\n",
      "Iteration 5483 | Cost: 0.3354608886401392 | Gradient: [[ 0.03053339]\n",
      " [-0.0665533 ]\n",
      " [ 0.11206265]]\n",
      "Iteration 5484 | Cost: 0.33544296969134235 | Gradient: [[ 0.03053362]\n",
      " [-0.06654618]\n",
      " [ 0.11205399]]\n",
      "Iteration 5485 | Cost: 0.33542505361653957 | Gradient: [[ 0.03053386]\n",
      " [-0.06653906]\n",
      " [ 0.11204533]]\n",
      "Iteration 5486 | Cost: 0.3354071404150371 | Gradient: [[ 0.03053409]\n",
      " [-0.06653195]\n",
      " [ 0.11203667]]\n",
      "Iteration 5487 | Cost: 0.33538923008614135 | Gradient: [[ 0.03053432]\n",
      " [-0.06652484]\n",
      " [ 0.11202802]]\n",
      "Iteration 5488 | Cost: 0.3353713226291591 | Gradient: [[ 0.03053454]\n",
      " [-0.06651773]\n",
      " [ 0.11201936]]\n",
      "Iteration 5489 | Cost: 0.33535341804339713 | Gradient: [[ 0.03053477]\n",
      " [-0.06651062]\n",
      " [ 0.1120107 ]]\n",
      "Iteration 5490 | Cost: 0.3353355163281627 | Gradient: [[ 0.030535  ]\n",
      " [-0.06650352]\n",
      " [ 0.11200205]]\n",
      "Iteration 5491 | Cost: 0.33531761748276356 | Gradient: [[ 0.03053522]\n",
      " [-0.06649642]\n",
      " [ 0.11199339]]\n",
      "Iteration 5492 | Cost: 0.3352997215065073 | Gradient: [[ 0.03053545]\n",
      " [-0.06648933]\n",
      " [ 0.11198474]]\n",
      "Iteration 5493 | Cost: 0.33528182839870185 | Gradient: [[ 0.03053567]\n",
      " [-0.06648223]\n",
      " [ 0.11197608]]\n",
      "Iteration 5494 | Cost: 0.33526393815865574 | Gradient: [[ 0.03053589]\n",
      " [-0.06647514]\n",
      " [ 0.11196743]]\n",
      "Iteration 5495 | Cost: 0.3352460507856773 | Gradient: [[ 0.03053611]\n",
      " [-0.06646805]\n",
      " [ 0.11195877]]\n",
      "Iteration 5496 | Cost: 0.3352281662790756 | Gradient: [[ 0.03053633]\n",
      " [-0.06646097]\n",
      " [ 0.11195012]]\n",
      "Iteration 5497 | Cost: 0.3352102846381595 | Gradient: [[ 0.03053655]\n",
      " [-0.06645388]\n",
      " [ 0.11194147]]\n",
      "Iteration 5498 | Cost: 0.3351924058622386 | Gradient: [[ 0.03053677]\n",
      " [-0.0664468 ]\n",
      " [ 0.11193282]]\n",
      "Iteration 5499 | Cost: 0.33517452995062225 | Gradient: [[ 0.03053699]\n",
      " [-0.06643972]\n",
      " [ 0.11192417]]\n",
      "Iteration 5500 | Cost: 0.33515665690262053 | Gradient: [[ 0.0305372 ]\n",
      " [-0.06643265]\n",
      " [ 0.11191552]]\n",
      "Iteration 5501 | Cost: 0.33513878671754355 | Gradient: [[ 0.03053742]\n",
      " [-0.06642558]\n",
      " [ 0.11190687]]\n",
      "Iteration 5502 | Cost: 0.33512091939470173 | Gradient: [[ 0.03053763]\n",
      " [-0.06641851]\n",
      " [ 0.11189822]]\n",
      "Iteration 5503 | Cost: 0.33510305493340575 | Gradient: [[ 0.03053784]\n",
      " [-0.06641144]\n",
      " [ 0.11188957]]\n",
      "Iteration 5504 | Cost: 0.3350851933329665 | Gradient: [[ 0.03053805]\n",
      " [-0.06640438]\n",
      " [ 0.11188092]]\n",
      "Iteration 5505 | Cost: 0.33506733459269533 | Gradient: [[ 0.03053826]\n",
      " [-0.06639732]\n",
      " [ 0.11187228]]\n",
      "Iteration 5506 | Cost: 0.3350494787119035 | Gradient: [[ 0.03053847]\n",
      " [-0.06639026]\n",
      " [ 0.11186363]]\n",
      "Iteration 5507 | Cost: 0.3350316256899029 | Gradient: [[ 0.03053868]\n",
      " [-0.0663832 ]\n",
      " [ 0.11185498]]\n",
      "Iteration 5508 | Cost: 0.3350137755260055 | Gradient: [[ 0.03053889]\n",
      " [-0.06637615]\n",
      " [ 0.11184634]]\n",
      "Iteration 5509 | Cost: 0.3349959282195235 | Gradient: [[ 0.03053909]\n",
      " [-0.0663691 ]\n",
      " [ 0.11183769]]\n",
      "Iteration 5510 | Cost: 0.3349780837697695 | Gradient: [[ 0.0305393 ]\n",
      " [-0.06636205]\n",
      " [ 0.11182905]]\n",
      "Iteration 5511 | Cost: 0.3349602421760563 | Gradient: [[ 0.0305395 ]\n",
      " [-0.06635501]\n",
      " [ 0.11182041]]\n",
      "Iteration 5512 | Cost: 0.3349424034376968 | Gradient: [[ 0.03053971]\n",
      " [-0.06634797]\n",
      " [ 0.11181177]]\n",
      "Iteration 5513 | Cost: 0.3349245675540045 | Gradient: [[ 0.03053991]\n",
      " [-0.06634093]\n",
      " [ 0.11180312]]\n",
      "Iteration 5514 | Cost: 0.3349067345242929 | Gradient: [[ 0.03054011]\n",
      " [-0.06633389]\n",
      " [ 0.11179448]]\n",
      "Iteration 5515 | Cost: 0.3348889043478757 | Gradient: [[ 0.03054031]\n",
      " [-0.06632686]\n",
      " [ 0.11178584]]\n",
      "Iteration 5516 | Cost: 0.33487107702406715 | Gradient: [[ 0.03054051]\n",
      " [-0.06631983]\n",
      " [ 0.1117772 ]]\n",
      "Iteration 5517 | Cost: 0.3348532525521817 | Gradient: [[ 0.0305407 ]\n",
      " [-0.0663128 ]\n",
      " [ 0.11176856]]\n",
      "Iteration 5518 | Cost: 0.3348354309315337 | Gradient: [[ 0.0305409 ]\n",
      " [-0.06630578]\n",
      " [ 0.11175992]]\n",
      "Iteration 5519 | Cost: 0.3348176121614381 | Gradient: [[ 0.0305411 ]\n",
      " [-0.06629875]\n",
      " [ 0.11175128]]\n",
      "Iteration 5520 | Cost: 0.3347997962412103 | Gradient: [[ 0.03054129]\n",
      " [-0.06629173]\n",
      " [ 0.11174265]]\n",
      "Iteration 5521 | Cost: 0.33478198317016533 | Gradient: [[ 0.03054148]\n",
      " [-0.06628472]\n",
      " [ 0.11173401]]\n",
      "Iteration 5522 | Cost: 0.3347641729476191 | Gradient: [[ 0.03054168]\n",
      " [-0.0662777 ]\n",
      " [ 0.11172537]]\n",
      "Iteration 5523 | Cost: 0.33474636557288745 | Gradient: [[ 0.03054187]\n",
      " [-0.06627069]\n",
      " [ 0.11171674]]\n",
      "Iteration 5524 | Cost: 0.3347285610452865 | Gradient: [[ 0.03054206]\n",
      " [-0.06626368]\n",
      " [ 0.1117081 ]]\n",
      "Iteration 5525 | Cost: 0.33471075936413275 | Gradient: [[ 0.03054225]\n",
      " [-0.06625667]\n",
      " [ 0.11169947]]\n",
      "Iteration 5526 | Cost: 0.334692960528743 | Gradient: [[ 0.03054243]\n",
      " [-0.06624967]\n",
      " [ 0.11169083]]\n",
      "Iteration 5527 | Cost: 0.334675164538434 | Gradient: [[ 0.03054262]\n",
      " [-0.06624267]\n",
      " [ 0.1116822 ]]\n",
      "Iteration 5528 | Cost: 0.33465737139252316 | Gradient: [[ 0.03054281]\n",
      " [-0.06623567]\n",
      " [ 0.11167357]]\n",
      "Iteration 5529 | Cost: 0.33463958109032776 | Gradient: [[ 0.03054299]\n",
      " [-0.06622868]\n",
      " [ 0.11166494]]\n",
      "Iteration 5530 | Cost: 0.3346217936311657 | Gradient: [[ 0.03054318]\n",
      " [-0.06622168]\n",
      " [ 0.1116563 ]]\n",
      "Iteration 5531 | Cost: 0.334604009014355 | Gradient: [[ 0.03054336]\n",
      " [-0.06621469]\n",
      " [ 0.11164767]]\n",
      "Iteration 5532 | Cost: 0.3345862272392137 | Gradient: [[ 0.03054354]\n",
      " [-0.06620771]\n",
      " [ 0.11163904]]\n",
      "Iteration 5533 | Cost: 0.33456844830506055 | Gradient: [[ 0.03054372]\n",
      " [-0.06620072]\n",
      " [ 0.11163041]]\n",
      "Iteration 5534 | Cost: 0.3345506722112142 | Gradient: [[ 0.0305439 ]\n",
      " [-0.06619374]\n",
      " [ 0.11162178]]\n",
      "Iteration 5535 | Cost: 0.3345328989569938 | Gradient: [[ 0.03054408]\n",
      " [-0.06618676]\n",
      " [ 0.11161316]]\n",
      "Iteration 5536 | Cost: 0.33451512854171833 | Gradient: [[ 0.03054426]\n",
      " [-0.06617979]\n",
      " [ 0.11160453]]\n",
      "Iteration 5537 | Cost: 0.3344973609647076 | Gradient: [[ 0.03054443]\n",
      " [-0.06617281]\n",
      " [ 0.1115959 ]]\n",
      "Iteration 5538 | Cost: 0.3344795962252815 | Gradient: [[ 0.03054461]\n",
      " [-0.06616584]\n",
      " [ 0.11158728]]\n",
      "Iteration 5539 | Cost: 0.3344618343227598 | Gradient: [[ 0.03054478]\n",
      " [-0.06615887]\n",
      " [ 0.11157865]]\n",
      "Iteration 5540 | Cost: 0.33444407525646297 | Gradient: [[ 0.03054496]\n",
      " [-0.06615191]\n",
      " [ 0.11157002]]\n",
      "Iteration 5541 | Cost: 0.3344263190257116 | Gradient: [[ 0.03054513]\n",
      " [-0.06614494]\n",
      " [ 0.1115614 ]]\n",
      "Iteration 5542 | Cost: 0.3344085656298264 | Gradient: [[ 0.0305453 ]\n",
      " [-0.06613798]\n",
      " [ 0.11155278]]\n",
      "Iteration 5543 | Cost: 0.3343908150681286 | Gradient: [[ 0.03054547]\n",
      " [-0.06613103]\n",
      " [ 0.11154415]]\n",
      "Iteration 5544 | Cost: 0.33437306733993954 | Gradient: [[ 0.03054564]\n",
      " [-0.06612407]\n",
      " [ 0.11153553]]\n",
      "Iteration 5545 | Cost: 0.3343553224445807 | Gradient: [[ 0.03054581]\n",
      " [-0.06611712]\n",
      " [ 0.11152691]]\n",
      "Iteration 5546 | Cost: 0.3343375803813741 | Gradient: [[ 0.03054598]\n",
      " [-0.06611017]\n",
      " [ 0.11151829]]\n",
      "Iteration 5547 | Cost: 0.33431984114964164 | Gradient: [[ 0.03054614]\n",
      " [-0.06610322]\n",
      " [ 0.11150967]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5548 | Cost: 0.33430210474870586 | Gradient: [[ 0.03054631]\n",
      " [-0.06609628]\n",
      " [ 0.11150105]]\n",
      "Iteration 5549 | Cost: 0.3342843711778893 | Gradient: [[ 0.03054647]\n",
      " [-0.06608934]\n",
      " [ 0.11149243]]\n",
      "Iteration 5550 | Cost: 0.3342666404365149 | Gradient: [[ 0.03054664]\n",
      " [-0.0660824 ]\n",
      " [ 0.11148381]]\n",
      "Iteration 5551 | Cost: 0.33424891252390565 | Gradient: [[ 0.0305468 ]\n",
      " [-0.06607546]\n",
      " [ 0.11147519]]\n",
      "Iteration 5552 | Cost: 0.3342311874393851 | Gradient: [[ 0.03054696]\n",
      " [-0.06606853]\n",
      " [ 0.11146657]]\n",
      "Iteration 5553 | Cost: 0.3342134651822769 | Gradient: [[ 0.03054712]\n",
      " [-0.0660616 ]\n",
      " [ 0.11145795]]\n",
      "Iteration 5554 | Cost: 0.33419574575190475 | Gradient: [[ 0.03054728]\n",
      " [-0.06605467]\n",
      " [ 0.11144934]]\n",
      "Iteration 5555 | Cost: 0.3341780291475929 | Gradient: [[ 0.03054744]\n",
      " [-0.06604775]\n",
      " [ 0.11144072]]\n",
      "Iteration 5556 | Cost: 0.3341603153686659 | Gradient: [[ 0.03054759]\n",
      " [-0.06604082]\n",
      " [ 0.11143211]]\n",
      "Iteration 5557 | Cost: 0.3341426044144483 | Gradient: [[ 0.03054775]\n",
      " [-0.0660339 ]\n",
      " [ 0.11142349]]\n",
      "Iteration 5558 | Cost: 0.334124896284265 | Gradient: [[ 0.0305479 ]\n",
      " [-0.06602699]\n",
      " [ 0.11141488]]\n",
      "Iteration 5559 | Cost: 0.33410719097744124 | Gradient: [[ 0.03054806]\n",
      " [-0.06602007]\n",
      " [ 0.11140627]]\n",
      "Iteration 5560 | Cost: 0.3340894884933023 | Gradient: [[ 0.03054821]\n",
      " [-0.06601316]\n",
      " [ 0.11139765]]\n",
      "Iteration 5561 | Cost: 0.3340717888311739 | Gradient: [[ 0.03054836]\n",
      " [-0.06600625]\n",
      " [ 0.11138904]]\n",
      "Iteration 5562 | Cost: 0.33405409199038205 | Gradient: [[ 0.03054851]\n",
      " [-0.06599934]\n",
      " [ 0.11138043]]\n",
      "Iteration 5563 | Cost: 0.3340363979702529 | Gradient: [[ 0.03054866]\n",
      " [-0.06599244]\n",
      " [ 0.11137182]]\n",
      "Iteration 5564 | Cost: 0.33401870677011275 | Gradient: [[ 0.03054881]\n",
      " [-0.06598554]\n",
      " [ 0.11136321]]\n",
      "Iteration 5565 | Cost: 0.33400101838928853 | Gradient: [[ 0.03054896]\n",
      " [-0.06597864]\n",
      " [ 0.1113546 ]]\n",
      "Iteration 5566 | Cost: 0.333983332827107 | Gradient: [[ 0.03054911]\n",
      " [-0.06597174]\n",
      " [ 0.11134599]]\n",
      "Iteration 5567 | Cost: 0.3339656500828954 | Gradient: [[ 0.03054925]\n",
      " [-0.06596485]\n",
      " [ 0.11133738]]\n",
      "Iteration 5568 | Cost: 0.3339479701559812 | Gradient: [[ 0.0305494 ]\n",
      " [-0.06595796]\n",
      " [ 0.11132878]]\n",
      "Iteration 5569 | Cost: 0.3339302930456921 | Gradient: [[ 0.03054954]\n",
      " [-0.06595107]\n",
      " [ 0.11132017]]\n",
      "Iteration 5570 | Cost: 0.333912618751356 | Gradient: [[ 0.03054968]\n",
      " [-0.06594418]\n",
      " [ 0.11131156]]\n",
      "Iteration 5571 | Cost: 0.3338949472723011 | Gradient: [[ 0.03054982]\n",
      " [-0.0659373 ]\n",
      " [ 0.11130296]]\n",
      "Iteration 5572 | Cost: 0.33387727860785593 | Gradient: [[ 0.03054996]\n",
      " [-0.06593042]\n",
      " [ 0.11129435]]\n",
      "Iteration 5573 | Cost: 0.33385961275734916 | Gradient: [[ 0.0305501 ]\n",
      " [-0.06592354]\n",
      " [ 0.11128575]]\n",
      "Iteration 5574 | Cost: 0.33384194972010967 | Gradient: [[ 0.03055024]\n",
      " [-0.06591667]\n",
      " [ 0.11127715]]\n",
      "Iteration 5575 | Cost: 0.3338242894954668 | Gradient: [[ 0.03055038]\n",
      " [-0.0659098 ]\n",
      " [ 0.11126854]]\n",
      "Iteration 5576 | Cost: 0.3338066320827498 | Gradient: [[ 0.03055052]\n",
      " [-0.06590293]\n",
      " [ 0.11125994]]\n",
      "Iteration 5577 | Cost: 0.3337889774812885 | Gradient: [[ 0.03055065]\n",
      " [-0.06589606]\n",
      " [ 0.11125134]]\n",
      "Iteration 5578 | Cost: 0.33377132569041296 | Gradient: [[ 0.03055079]\n",
      " [-0.0658892 ]\n",
      " [ 0.11124274]]\n",
      "Iteration 5579 | Cost: 0.33375367670945316 | Gradient: [[ 0.03055092]\n",
      " [-0.06588233]\n",
      " [ 0.11123414]]\n",
      "Iteration 5580 | Cost: 0.33373603053773976 | Gradient: [[ 0.03055105]\n",
      " [-0.06587548]\n",
      " [ 0.11122554]]\n",
      "Iteration 5581 | Cost: 0.33371838717460334 | Gradient: [[ 0.03055119]\n",
      " [-0.06586862]\n",
      " [ 0.11121694]]\n",
      "Iteration 5582 | Cost: 0.33370074661937493 | Gradient: [[ 0.03055132]\n",
      " [-0.06586176]\n",
      " [ 0.11120834]]\n",
      "Iteration 5583 | Cost: 0.3336831088713857 | Gradient: [[ 0.03055145]\n",
      " [-0.06585491]\n",
      " [ 0.11119974]]\n",
      "Iteration 5584 | Cost: 0.33366547392996704 | Gradient: [[ 0.03055157]\n",
      " [-0.06584806]\n",
      " [ 0.11119114]]\n",
      "Iteration 5585 | Cost: 0.3336478417944509 | Gradient: [[ 0.0305517 ]\n",
      " [-0.06584122]\n",
      " [ 0.11118255]]\n",
      "Iteration 5586 | Cost: 0.3336302124641689 | Gradient: [[ 0.03055183]\n",
      " [-0.06583438]\n",
      " [ 0.11117395]]\n",
      "Iteration 5587 | Cost: 0.33361258593845344 | Gradient: [[ 0.03055195]\n",
      " [-0.06582753]\n",
      " [ 0.11116536]]\n",
      "Iteration 5588 | Cost: 0.333594962216637 | Gradient: [[ 0.03055208]\n",
      " [-0.0658207 ]\n",
      " [ 0.11115676]]\n",
      "Iteration 5589 | Cost: 0.3335773412980522 | Gradient: [[ 0.0305522 ]\n",
      " [-0.06581386]\n",
      " [ 0.11114817]]\n",
      "Iteration 5590 | Cost: 0.333559723182032 | Gradient: [[ 0.03055232]\n",
      " [-0.06580703]\n",
      " [ 0.11113957]]\n",
      "Iteration 5591 | Cost: 0.33354210786790955 | Gradient: [[ 0.03055245]\n",
      " [-0.0658002 ]\n",
      " [ 0.11113098]]\n",
      "Iteration 5592 | Cost: 0.33352449535501844 | Gradient: [[ 0.03055257]\n",
      " [-0.06579337]\n",
      " [ 0.11112239]]\n",
      "Iteration 5593 | Cost: 0.33350688564269226 | Gradient: [[ 0.03055269]\n",
      " [-0.06578654]\n",
      " [ 0.1111138 ]]\n",
      "Iteration 5594 | Cost: 0.3334892787302649 | Gradient: [[ 0.0305528 ]\n",
      " [-0.06577972]\n",
      " [ 0.11110521]]\n",
      "Iteration 5595 | Cost: 0.33347167461707067 | Gradient: [[ 0.03055292]\n",
      " [-0.0657729 ]\n",
      " [ 0.11109662]]\n",
      "Iteration 5596 | Cost: 0.333454073302444 | Gradient: [[ 0.03055304]\n",
      " [-0.06576608]\n",
      " [ 0.11108803]]\n",
      "Iteration 5597 | Cost: 0.33343647478571936 | Gradient: [[ 0.03055315]\n",
      " [-0.06575927]\n",
      " [ 0.11107944]]\n",
      "Iteration 5598 | Cost: 0.33341887906623197 | Gradient: [[ 0.03055327]\n",
      " [-0.06575246]\n",
      " [ 0.11107085]]\n",
      "Iteration 5599 | Cost: 0.3334012861433169 | Gradient: [[ 0.03055338]\n",
      " [-0.06574565]\n",
      " [ 0.11106226]]\n",
      "Iteration 5600 | Cost: 0.3333836960163095 | Gradient: [[ 0.03055349]\n",
      " [-0.06573884]\n",
      " [ 0.11105368]]\n",
      "Iteration 5601 | Cost: 0.3333661086845455 | Gradient: [[ 0.03055361]\n",
      " [-0.06573204]\n",
      " [ 0.11104509]]\n",
      "Iteration 5602 | Cost: 0.3333485241473609 | Gradient: [[ 0.03055372]\n",
      " [-0.06572524]\n",
      " [ 0.11103651]]\n",
      "Iteration 5603 | Cost: 0.3333309424040916 | Gradient: [[ 0.03055383]\n",
      " [-0.06571844]\n",
      " [ 0.11102792]]\n",
      "Iteration 5604 | Cost: 0.3333133634540743 | Gradient: [[ 0.03055393]\n",
      " [-0.06571164]\n",
      " [ 0.11101934]]\n",
      "Iteration 5605 | Cost: 0.33329578729664555 | Gradient: [[ 0.03055404]\n",
      " [-0.06570485]\n",
      " [ 0.11101075]]\n",
      "Iteration 5606 | Cost: 0.3332782139311422 | Gradient: [[ 0.03055415]\n",
      " [-0.06569805]\n",
      " [ 0.11100217]]\n",
      "Iteration 5607 | Cost: 0.3332606433569015 | Gradient: [[ 0.03055425]\n",
      " [-0.06569127]\n",
      " [ 0.11099359]]\n",
      "Iteration 5608 | Cost: 0.33324307557326066 | Gradient: [[ 0.03055436]\n",
      " [-0.06568448]\n",
      " [ 0.11098501]]\n",
      "Iteration 5609 | Cost: 0.3332255105795575 | Gradient: [[ 0.03055446]\n",
      " [-0.0656777 ]\n",
      " [ 0.11097642]]\n",
      "Iteration 5610 | Cost: 0.33320794837512985 | Gradient: [[ 0.03055457]\n",
      " [-0.06567092]\n",
      " [ 0.11096784]]\n",
      "Iteration 5611 | Cost: 0.3331903889593159 | Gradient: [[ 0.03055467]\n",
      " [-0.06566414]\n",
      " [ 0.11095926]]\n",
      "Iteration 5612 | Cost: 0.33317283233145384 | Gradient: [[ 0.03055477]\n",
      " [-0.06565736]\n",
      " [ 0.11095068]]\n",
      "Iteration 5613 | Cost: 0.33315527849088244 | Gradient: [[ 0.03055487]\n",
      " [-0.06565059]\n",
      " [ 0.11094211]]\n",
      "Iteration 5614 | Cost: 0.33313772743694053 | Gradient: [[ 0.03055497]\n",
      " [-0.06564382]\n",
      " [ 0.11093353]]\n",
      "Iteration 5615 | Cost: 0.33312017916896713 | Gradient: [[ 0.03055506]\n",
      " [-0.06563705]\n",
      " [ 0.11092495]]\n",
      "Iteration 5616 | Cost: 0.3331026336863017 | Gradient: [[ 0.03055516]\n",
      " [-0.06563028]\n",
      " [ 0.11091637]]\n",
      "Iteration 5617 | Cost: 0.3330850909882839 | Gradient: [[ 0.03055526]\n",
      " [-0.06562352]\n",
      " [ 0.1109078 ]]\n",
      "Iteration 5618 | Cost: 0.33306755107425334 | Gradient: [[ 0.03055535]\n",
      " [-0.06561676]\n",
      " [ 0.11089922]]\n",
      "Iteration 5619 | Cost: 0.3330500139435503 | Gradient: [[ 0.03055545]\n",
      " [-0.06561   ]\n",
      " [ 0.11089065]]\n",
      "Iteration 5620 | Cost: 0.33303247959551496 | Gradient: [[ 0.03055554]\n",
      " [-0.06560325]\n",
      " [ 0.11088208]]\n",
      "Iteration 5621 | Cost: 0.33301494802948806 | Gradient: [[ 0.03055563]\n",
      " [-0.06559649]\n",
      " [ 0.1108735 ]]\n",
      "Iteration 5622 | Cost: 0.3329974192448102 | Gradient: [[ 0.03055572]\n",
      " [-0.06558974]\n",
      " [ 0.11086493]]\n",
      "Iteration 5623 | Cost: 0.3329798932408226 | Gradient: [[ 0.03055581]\n",
      " [-0.065583  ]\n",
      " [ 0.11085636]]\n",
      "Iteration 5624 | Cost: 0.3329623700168664 | Gradient: [[ 0.0305559 ]\n",
      " [-0.06557625]\n",
      " [ 0.11084779]]\n",
      "Iteration 5625 | Cost: 0.3329448495722834 | Gradient: [[ 0.03055599]\n",
      " [-0.06556951]\n",
      " [ 0.11083922]]\n",
      "Iteration 5626 | Cost: 0.3329273319064151 | Gradient: [[ 0.03055607]\n",
      " [-0.06556277]\n",
      " [ 0.11083065]]\n",
      "Iteration 5627 | Cost: 0.3329098170186036 | Gradient: [[ 0.03055616]\n",
      " [-0.06555603]\n",
      " [ 0.11082208]]\n",
      "Iteration 5628 | Cost: 0.3328923049081913 | Gradient: [[ 0.03055625]\n",
      " [-0.0655493 ]\n",
      " [ 0.11081351]]\n",
      "Iteration 5629 | Cost: 0.3328747955745206 | Gradient: [[ 0.03055633]\n",
      " [-0.06554256]\n",
      " [ 0.11080494]]\n",
      "Iteration 5630 | Cost: 0.33285728901693423 | Gradient: [[ 0.03055641]\n",
      " [-0.06553583]\n",
      " [ 0.11079637]]\n",
      "Iteration 5631 | Cost: 0.33283978523477525 | Gradient: [[ 0.03055649]\n",
      " [-0.06552911]\n",
      " [ 0.11078781]]\n",
      "Iteration 5632 | Cost: 0.33282228422738686 | Gradient: [[ 0.03055658]\n",
      " [-0.06552238]\n",
      " [ 0.11077924]]\n",
      "Iteration 5633 | Cost: 0.3328047859941124 | Gradient: [[ 0.03055666]\n",
      " [-0.06551566]\n",
      " [ 0.11077067]]\n",
      "Iteration 5634 | Cost: 0.33278729053429584 | Gradient: [[ 0.03055674]\n",
      " [-0.06550894]\n",
      " [ 0.11076211]]\n",
      "Iteration 5635 | Cost: 0.33276979784728106 | Gradient: [[ 0.03055681]\n",
      " [-0.06550222]\n",
      " [ 0.11075355]]\n",
      "Iteration 5636 | Cost: 0.3327523079324121 | Gradient: [[ 0.03055689]\n",
      " [-0.06549551]\n",
      " [ 0.11074498]]\n",
      "Iteration 5637 | Cost: 0.33273482078903355 | Gradient: [[ 0.03055697]\n",
      " [-0.0654888 ]\n",
      " [ 0.11073642]]\n",
      "Iteration 5638 | Cost: 0.33271733641649004 | Gradient: [[ 0.03055704]\n",
      " [-0.06548209]\n",
      " [ 0.11072786]]\n",
      "Iteration 5639 | Cost: 0.3326998548141265 | Gradient: [[ 0.03055712]\n",
      " [-0.06547538]\n",
      " [ 0.1107193 ]]\n",
      "Iteration 5640 | Cost: 0.332682375981288 | Gradient: [[ 0.03055719]\n",
      " [-0.06546868]\n",
      " [ 0.11071073]]\n",
      "Iteration 5641 | Cost: 0.3326648999173202 | Gradient: [[ 0.03055726]\n",
      " [-0.06546197]\n",
      " [ 0.11070217]]\n",
      "Iteration 5642 | Cost: 0.3326474266215684 | Gradient: [[ 0.03055733]\n",
      " [-0.06545527]\n",
      " [ 0.11069362]]\n",
      "Iteration 5643 | Cost: 0.3326299560933787 | Gradient: [[ 0.0305574 ]\n",
      " [-0.06544858]\n",
      " [ 0.11068506]]\n",
      "Iteration 5644 | Cost: 0.3326124883320972 | Gradient: [[ 0.03055747]\n",
      " [-0.06544188]\n",
      " [ 0.1106765 ]]\n",
      "Iteration 5645 | Cost: 0.3325950233370701 | Gradient: [[ 0.03055754]\n",
      " [-0.06543519]\n",
      " [ 0.11066794]]\n",
      "Iteration 5646 | Cost: 0.33257756110764414 | Gradient: [[ 0.03055761]\n",
      " [-0.0654285 ]\n",
      " [ 0.11065938]]\n",
      "Iteration 5647 | Cost: 0.33256010164316613 | Gradient: [[ 0.03055768]\n",
      " [-0.06542182]\n",
      " [ 0.11065083]]\n",
      "Iteration 5648 | Cost: 0.33254264494298325 | Gradient: [[ 0.03055774]\n",
      " [-0.06541513]\n",
      " [ 0.11064227]]\n",
      "Iteration 5649 | Cost: 0.33252519100644257 | Gradient: [[ 0.03055781]\n",
      " [-0.06540845]\n",
      " [ 0.11063372]]\n",
      "Iteration 5650 | Cost: 0.33250773983289184 | Gradient: [[ 0.03055787]\n",
      " [-0.06540177]\n",
      " [ 0.11062516]]\n",
      "Iteration 5651 | Cost: 0.33249029142167874 | Gradient: [[ 0.03055793]\n",
      " [-0.06539509]\n",
      " [ 0.11061661]]\n",
      "Iteration 5652 | Cost: 0.3324728457721514 | Gradient: [[ 0.030558  ]\n",
      " [-0.06538842]\n",
      " [ 0.11060806]]\n",
      "Iteration 5653 | Cost: 0.332455402883658 | Gradient: [[ 0.03055806]\n",
      " [-0.06538175]\n",
      " [ 0.1105995 ]]\n",
      "Iteration 5654 | Cost: 0.3324379627555471 | Gradient: [[ 0.03055812]\n",
      " [-0.06537508]\n",
      " [ 0.11059095]]\n",
      "Iteration 5655 | Cost: 0.3324205253871674 | Gradient: [[ 0.03055818]\n",
      " [-0.06536841]\n",
      " [ 0.1105824 ]]\n",
      "Iteration 5656 | Cost: 0.3324030907778679 | Gradient: [[ 0.03055823]\n",
      " [-0.06536175]\n",
      " [ 0.11057385]]\n",
      "Iteration 5657 | Cost: 0.3323856589269978 | Gradient: [[ 0.03055829]\n",
      " [-0.06535509]\n",
      " [ 0.1105653 ]]\n",
      "Iteration 5658 | Cost: 0.33236822983390657 | Gradient: [[ 0.03055835]\n",
      " [-0.06534843]\n",
      " [ 0.11055675]]\n",
      "Iteration 5659 | Cost: 0.3323508034979439 | Gradient: [[ 0.0305584 ]\n",
      " [-0.06534177]\n",
      " [ 0.1105482 ]]\n",
      "Iteration 5660 | Cost: 0.33233337991845974 | Gradient: [[ 0.03055846]\n",
      " [-0.06533512]\n",
      " [ 0.11053966]]\n",
      "Iteration 5661 | Cost: 0.33231595909480427 | Gradient: [[ 0.03055851]\n",
      " [-0.06532847]\n",
      " [ 0.11053111]]\n",
      "Iteration 5662 | Cost: 0.3322985410263278 | Gradient: [[ 0.03055856]\n",
      " [-0.06532182]\n",
      " [ 0.11052256]]\n",
      "Iteration 5663 | Cost: 0.33228112571238105 | Gradient: [[ 0.03055861]\n",
      " [-0.06531517]\n",
      " [ 0.11051402]]\n",
      "Iteration 5664 | Cost: 0.33226371315231484 | Gradient: [[ 0.03055866]\n",
      " [-0.06530853]\n",
      " [ 0.11050547]]\n",
      "Iteration 5665 | Cost: 0.33224630334548033 | Gradient: [[ 0.03055871]\n",
      " [-0.06530188]\n",
      " [ 0.11049693]]\n",
      "Iteration 5666 | Cost: 0.33222889629122887 | Gradient: [[ 0.03055876]\n",
      " [-0.06529524]\n",
      " [ 0.11048839]]\n",
      "Iteration 5667 | Cost: 0.33221149198891203 | Gradient: [[ 0.03055881]\n",
      " [-0.06528861]\n",
      " [ 0.11047984]]\n",
      "Iteration 5668 | Cost: 0.3321940904378816 | Gradient: [[ 0.03055886]\n",
      " [-0.06528197]\n",
      " [ 0.1104713 ]]\n",
      "Iteration 5669 | Cost: 0.3321766916374898 | Gradient: [[ 0.0305589 ]\n",
      " [-0.06527534]\n",
      " [ 0.11046276]]\n",
      "Iteration 5670 | Cost: 0.3321592955870887 | Gradient: [[ 0.03055895]\n",
      " [-0.06526871]\n",
      " [ 0.11045422]]\n",
      "Iteration 5671 | Cost: 0.3321419022860308 | Gradient: [[ 0.03055899]\n",
      " [-0.06526209]\n",
      " [ 0.11044568]]\n",
      "Iteration 5672 | Cost: 0.33212451173366914 | Gradient: [[ 0.03055903]\n",
      " [-0.06525546]\n",
      " [ 0.11043714]]\n",
      "Iteration 5673 | Cost: 0.33210712392935643 | Gradient: [[ 0.03055908]\n",
      " [-0.06524884]\n",
      " [ 0.1104286 ]]\n",
      "Iteration 5674 | Cost: 0.3320897388724461 | Gradient: [[ 0.03055912]\n",
      " [-0.06524222]\n",
      " [ 0.11042006]]\n",
      "Iteration 5675 | Cost: 0.33207235656229145 | Gradient: [[ 0.03055916]\n",
      " [-0.0652356 ]\n",
      " [ 0.11041152]]\n",
      "Iteration 5676 | Cost: 0.3320549769982464 | Gradient: [[ 0.0305592 ]\n",
      " [-0.06522899]\n",
      " [ 0.11040299]]\n",
      "Iteration 5677 | Cost: 0.3320376001796647 | Gradient: [[ 0.03055923]\n",
      " [-0.06522238]\n",
      " [ 0.11039445]]\n",
      "Iteration 5678 | Cost: 0.33202022610590054 | Gradient: [[ 0.03055927]\n",
      " [-0.06521577]\n",
      " [ 0.11038591]]\n",
      "Iteration 5679 | Cost: 0.3320028547763083 | Gradient: [[ 0.03055931]\n",
      " [-0.06520916]\n",
      " [ 0.11037738]]\n",
      "Iteration 5680 | Cost: 0.3319854861902428 | Gradient: [[ 0.03055934]\n",
      " [-0.06520256]\n",
      " [ 0.11036884]]\n",
      "Iteration 5681 | Cost: 0.33196812034705864 | Gradient: [[ 0.03055938]\n",
      " [-0.06519596]\n",
      " [ 0.11036031]]\n",
      "Iteration 5682 | Cost: 0.33195075724611117 | Gradient: [[ 0.03055941]\n",
      " [-0.06518936]\n",
      " [ 0.11035178]]\n",
      "Iteration 5683 | Cost: 0.33193339688675555 | Gradient: [[ 0.03055944]\n",
      " [-0.06518276]\n",
      " [ 0.11034325]]\n",
      "Iteration 5684 | Cost: 0.33191603926834745 | Gradient: [[ 0.03055947]\n",
      " [-0.06517617]\n",
      " [ 0.11033471]]\n",
      "Iteration 5685 | Cost: 0.33189868439024267 | Gradient: [[ 0.0305595 ]\n",
      " [-0.06516957]\n",
      " [ 0.11032618]]\n",
      "Iteration 5686 | Cost: 0.3318813322517972 | Gradient: [[ 0.03055953]\n",
      " [-0.06516298]\n",
      " [ 0.11031765]]\n",
      "Iteration 5687 | Cost: 0.33186398285236735 | Gradient: [[ 0.03055956]\n",
      " [-0.0651564 ]\n",
      " [ 0.11030912]]\n",
      "Iteration 5688 | Cost: 0.3318466361913096 | Gradient: [[ 0.03055959]\n",
      " [-0.06514981]\n",
      " [ 0.11030059]]\n",
      "Iteration 5689 | Cost: 0.3318292922679807 | Gradient: [[ 0.03055962]\n",
      " [-0.06514323]\n",
      " [ 0.11029207]]\n",
      "Iteration 5690 | Cost: 0.3318119510817376 | Gradient: [[ 0.03055964]\n",
      " [-0.06513665]\n",
      " [ 0.11028354]]\n",
      "Iteration 5691 | Cost: 0.33179461263193755 | Gradient: [[ 0.03055967]\n",
      " [-0.06513007]\n",
      " [ 0.11027501]]\n",
      "Iteration 5692 | Cost: 0.3317772769179379 | Gradient: [[ 0.03055969]\n",
      " [-0.0651235 ]\n",
      " [ 0.11026649]]\n",
      "Iteration 5693 | Cost: 0.3317599439390964 | Gradient: [[ 0.03055972]\n",
      " [-0.06511693]\n",
      " [ 0.11025796]]\n",
      "Iteration 5694 | Cost: 0.33174261369477087 | Gradient: [[ 0.03055974]\n",
      " [-0.06511036]\n",
      " [ 0.11024943]]\n",
      "Iteration 5695 | Cost: 0.33172528618431946 | Gradient: [[ 0.03055976]\n",
      " [-0.06510379]\n",
      " [ 0.11024091]]\n",
      "Iteration 5696 | Cost: 0.3317079614071005 | Gradient: [[ 0.03055978]\n",
      " [-0.06509722]\n",
      " [ 0.11023239]]\n",
      "Iteration 5697 | Cost: 0.3316906393624727 | Gradient: [[ 0.0305598 ]\n",
      " [-0.06509066]\n",
      " [ 0.11022386]]\n",
      "Iteration 5698 | Cost: 0.3316733200497947 | Gradient: [[ 0.03055982]\n",
      " [-0.0650841 ]\n",
      " [ 0.11021534]]\n",
      "Iteration 5699 | Cost: 0.33165600346842583 | Gradient: [[ 0.03055984]\n",
      " [-0.06507754]\n",
      " [ 0.11020682]]\n",
      "Iteration 5700 | Cost: 0.33163868961772497 | Gradient: [[ 0.03055985]\n",
      " [-0.06507099]\n",
      " [ 0.1101983 ]]\n",
      "Iteration 5701 | Cost: 0.33162137849705203 | Gradient: [[ 0.03055987]\n",
      " [-0.06506443]\n",
      " [ 0.11018978]]\n",
      "Iteration 5702 | Cost: 0.33160407010576654 | Gradient: [[ 0.03055988]\n",
      " [-0.06505788]\n",
      " [ 0.11018126]]\n",
      "Iteration 5703 | Cost: 0.3315867644432285 | Gradient: [[ 0.0305599 ]\n",
      " [-0.06505134]\n",
      " [ 0.11017274]]\n",
      "Iteration 5704 | Cost: 0.3315694615087982 | Gradient: [[ 0.03055991]\n",
      " [-0.06504479]\n",
      " [ 0.11016422]]\n",
      "Iteration 5705 | Cost: 0.33155216130183596 | Gradient: [[ 0.03055992]\n",
      " [-0.06503825]\n",
      " [ 0.1101557 ]]\n",
      "Iteration 5706 | Cost: 0.3315348638217025 | Gradient: [[ 0.03055993]\n",
      " [-0.06503171]\n",
      " [ 0.11014719]]\n",
      "Iteration 5707 | Cost: 0.3315175690677587 | Gradient: [[ 0.03055994]\n",
      " [-0.06502517]\n",
      " [ 0.11013867]]\n",
      "Iteration 5708 | Cost: 0.33150027703936563 | Gradient: [[ 0.03055995]\n",
      " [-0.06501863]\n",
      " [ 0.11013016]]\n",
      "Iteration 5709 | Cost: 0.33148298773588486 | Gradient: [[ 0.03055996]\n",
      " [-0.0650121 ]\n",
      " [ 0.11012164]]\n",
      "Iteration 5710 | Cost: 0.33146570115667773 | Gradient: [[ 0.03055997]\n",
      " [-0.06500557]\n",
      " [ 0.11011313]]\n",
      "Iteration 5711 | Cost: 0.3314484173011062 | Gradient: [[ 0.03055998]\n",
      " [-0.06499904]\n",
      " [ 0.11010461]]\n",
      "Iteration 5712 | Cost: 0.3314311361685322 | Gradient: [[ 0.03055998]\n",
      " [-0.06499251]\n",
      " [ 0.1100961 ]]\n",
      "Iteration 5713 | Cost: 0.33141385775831805 | Gradient: [[ 0.03055999]\n",
      " [-0.06498599]\n",
      " [ 0.11008759]]\n",
      "Iteration 5714 | Cost: 0.3313965820698263 | Gradient: [[ 0.03055999]\n",
      " [-0.06497947]\n",
      " [ 0.11007908]]\n",
      "Iteration 5715 | Cost: 0.33137930910241964 | Gradient: [[ 0.03055999]\n",
      " [-0.06497295]\n",
      " [ 0.11007057]]\n",
      "Iteration 5716 | Cost: 0.331362038855461 | Gradient: [[ 0.03056   ]\n",
      " [-0.06496643]\n",
      " [ 0.11006206]]\n",
      "Iteration 5717 | Cost: 0.33134477132831364 | Gradient: [[ 0.03056   ]\n",
      " [-0.06495992]\n",
      " [ 0.11005355]]\n",
      "Iteration 5718 | Cost: 0.33132750652034093 | Gradient: [[ 0.03056   ]\n",
      " [-0.06495341]\n",
      " [ 0.11004504]]\n",
      "Iteration 5719 | Cost: 0.33131024443090645 | Gradient: [[ 0.03056   ]\n",
      " [-0.0649469 ]\n",
      " [ 0.11003653]]\n",
      "Iteration 5720 | Cost: 0.33129298505937416 | Gradient: [[ 0.03056   ]\n",
      " [-0.06494039]\n",
      " [ 0.11002802]]\n",
      "Iteration 5721 | Cost: 0.33127572840510816 | Gradient: [[ 0.03055999]\n",
      " [-0.06493389]\n",
      " [ 0.11001952]]\n",
      "Iteration 5722 | Cost: 0.33125847446747264 | Gradient: [[ 0.03055999]\n",
      " [-0.06492738]\n",
      " [ 0.11001101]]\n",
      "Iteration 5723 | Cost: 0.3312412232458324 | Gradient: [[ 0.03055998]\n",
      " [-0.06492088]\n",
      " [ 0.11000251]]\n",
      "Iteration 5724 | Cost: 0.3312239747395519 | Gradient: [[ 0.03055998]\n",
      " [-0.06491439]\n",
      " [ 0.109994  ]]\n",
      "Iteration 5725 | Cost: 0.33120672894799646 | Gradient: [[ 0.03055997]\n",
      " [-0.06490789]\n",
      " [ 0.1099855 ]]\n",
      "Iteration 5726 | Cost: 0.3311894858705311 | Gradient: [[ 0.03055997]\n",
      " [-0.0649014 ]\n",
      " [ 0.10997699]]\n",
      "Iteration 5727 | Cost: 0.33117224550652136 | Gradient: [[ 0.03055996]\n",
      " [-0.06489491]\n",
      " [ 0.10996849]]\n",
      "Iteration 5728 | Cost: 0.3311550078553329 | Gradient: [[ 0.03055995]\n",
      " [-0.06488842]\n",
      " [ 0.10995999]]\n",
      "Iteration 5729 | Cost: 0.33113777291633173 | Gradient: [[ 0.03055994]\n",
      " [-0.06488194]\n",
      " [ 0.10995149]]\n",
      "Iteration 5730 | Cost: 0.33112054068888386 | Gradient: [[ 0.03055993]\n",
      " [-0.06487545]\n",
      " [ 0.10994299]]\n",
      "Iteration 5731 | Cost: 0.3311033111723557 | Gradient: [[ 0.03055992]\n",
      " [-0.06486897]\n",
      " [ 0.10993449]]\n",
      "Iteration 5732 | Cost: 0.3310860843661139 | Gradient: [[ 0.0305599 ]\n",
      " [-0.0648625 ]\n",
      " [ 0.10992599]]\n",
      "Iteration 5733 | Cost: 0.3310688602695252 | Gradient: [[ 0.03055989]\n",
      " [-0.06485602]\n",
      " [ 0.10991749]]\n",
      "Iteration 5734 | Cost: 0.3310516388819567 | Gradient: [[ 0.03055988]\n",
      " [-0.06484955]\n",
      " [ 0.10990899]]\n",
      "Iteration 5735 | Cost: 0.3310344202027757 | Gradient: [[ 0.03055986]\n",
      " [-0.06484308]\n",
      " [ 0.10990049]]\n",
      "Iteration 5736 | Cost: 0.33101720423134956 | Gradient: [[ 0.03055985]\n",
      " [-0.06483661]\n",
      " [ 0.109892  ]]\n",
      "Iteration 5737 | Cost: 0.3309999909670462 | Gradient: [[ 0.03055983]\n",
      " [-0.06483014]\n",
      " [ 0.1098835 ]]\n",
      "Iteration 5738 | Cost: 0.33098278040923335 | Gradient: [[ 0.03055981]\n",
      " [-0.06482368]\n",
      " [ 0.10987501]]\n",
      "Iteration 5739 | Cost: 0.3309655725572793 | Gradient: [[ 0.03055979]\n",
      " [-0.06481722]\n",
      " [ 0.10986651]]\n",
      "Iteration 5740 | Cost: 0.33094836741055245 | Gradient: [[ 0.03055977]\n",
      " [-0.06481076]\n",
      " [ 0.10985802]]\n",
      "Iteration 5741 | Cost: 0.33093116496842145 | Gradient: [[ 0.03055975]\n",
      " [-0.0648043 ]\n",
      " [ 0.10984953]]\n",
      "Iteration 5742 | Cost: 0.33091396523025507 | Gradient: [[ 0.03055973]\n",
      " [-0.06479785]\n",
      " [ 0.10984103]]\n",
      "Iteration 5743 | Cost: 0.3308967681954224 | Gradient: [[ 0.03055971]\n",
      " [-0.0647914 ]\n",
      " [ 0.10983254]]\n",
      "Iteration 5744 | Cost: 0.33087957386329275 | Gradient: [[ 0.03055968]\n",
      " [-0.06478495]\n",
      " [ 0.10982405]]\n",
      "Iteration 5745 | Cost: 0.3308623822332356 | Gradient: [[ 0.03055966]\n",
      " [-0.0647785 ]\n",
      " [ 0.10981556]]\n",
      "Iteration 5746 | Cost: 0.33084519330462087 | Gradient: [[ 0.03055964]\n",
      " [-0.06477205]\n",
      " [ 0.10980707]]\n",
      "Iteration 5747 | Cost: 0.33082800707681825 | Gradient: [[ 0.03055961]\n",
      " [-0.06476561]\n",
      " [ 0.10979858]]\n",
      "Iteration 5748 | Cost: 0.33081082354919816 | Gradient: [[ 0.03055958]\n",
      " [-0.06475917]\n",
      " [ 0.10979009]]\n",
      "Iteration 5749 | Cost: 0.33079364272113093 | Gradient: [[ 0.03055956]\n",
      " [-0.06475273]\n",
      " [ 0.10978161]]\n",
      "Iteration 5750 | Cost: 0.3307764645919872 | Gradient: [[ 0.03055953]\n",
      " [-0.0647463 ]\n",
      " [ 0.10977312]]\n",
      "Iteration 5751 | Cost: 0.33075928916113784 | Gradient: [[ 0.0305595 ]\n",
      " [-0.06473987]\n",
      " [ 0.10976463]]\n",
      "Iteration 5752 | Cost: 0.33074211642795387 | Gradient: [[ 0.03055947]\n",
      " [-0.06473344]\n",
      " [ 0.10975615]]\n",
      "Iteration 5753 | Cost: 0.33072494639180666 | Gradient: [[ 0.03055944]\n",
      " [-0.06472701]\n",
      " [ 0.10974766]]\n",
      "Iteration 5754 | Cost: 0.3307077790520677 | Gradient: [[ 0.0305594 ]\n",
      " [-0.06472058]\n",
      " [ 0.10973918]]\n",
      "Iteration 5755 | Cost: 0.3306906144081089 | Gradient: [[ 0.03055937]\n",
      " [-0.06471416]\n",
      " [ 0.10973069]]\n",
      "Iteration 5756 | Cost: 0.3306734524593021 | Gradient: [[ 0.03055934]\n",
      " [-0.06470774]\n",
      " [ 0.10972221]]\n",
      "Iteration 5757 | Cost: 0.3306562932050195 | Gradient: [[ 0.0305593 ]\n",
      " [-0.06470132]\n",
      " [ 0.10971373]]\n",
      "Iteration 5758 | Cost: 0.33063913664463346 | Gradient: [[ 0.03055927]\n",
      " [-0.0646949 ]\n",
      " [ 0.10970525]]\n",
      "Iteration 5759 | Cost: 0.33062198277751687 | Gradient: [[ 0.03055923]\n",
      " [-0.06468849]\n",
      " [ 0.10969677]]\n",
      "Iteration 5760 | Cost: 0.3306048316030423 | Gradient: [[ 0.03055919]\n",
      " [-0.06468208]\n",
      " [ 0.10968829]]\n",
      "Iteration 5761 | Cost: 0.33058768312058306 | Gradient: [[ 0.03055915]\n",
      " [-0.06467567]\n",
      " [ 0.10967981]]\n",
      "Iteration 5762 | Cost: 0.3305705373295123 | Gradient: [[ 0.03055911]\n",
      " [-0.06466926]\n",
      " [ 0.10967133]]\n",
      "Iteration 5763 | Cost: 0.3305533942292037 | Gradient: [[ 0.03055907]\n",
      " [-0.06466286]\n",
      " [ 0.10966285]]\n",
      "Iteration 5764 | Cost: 0.33053625381903096 | Gradient: [[ 0.03055903]\n",
      " [-0.06465645]\n",
      " [ 0.10965437]]\n",
      "Iteration 5765 | Cost: 0.330519116098368 | Gradient: [[ 0.03055899]\n",
      " [-0.06465005]\n",
      " [ 0.1096459 ]]\n",
      "Iteration 5766 | Cost: 0.330501981066589 | Gradient: [[ 0.03055895]\n",
      " [-0.06464366]\n",
      " [ 0.10963742]]\n",
      "Iteration 5767 | Cost: 0.33048484872306855 | Gradient: [[ 0.0305589 ]\n",
      " [-0.06463726]\n",
      " [ 0.10962895]]\n",
      "Iteration 5768 | Cost: 0.33046771906718114 | Gradient: [[ 0.03055886]\n",
      " [-0.06463087]\n",
      " [ 0.10962047]]\n",
      "Iteration 5769 | Cost: 0.33045059209830163 | Gradient: [[ 0.03055881]\n",
      " [-0.06462448]\n",
      " [ 0.109612  ]]\n",
      "Iteration 5770 | Cost: 0.3304334678158051 | Gradient: [[ 0.03055877]\n",
      " [-0.06461809]\n",
      " [ 0.10960352]]\n",
      "Iteration 5771 | Cost: 0.33041634621906696 | Gradient: [[ 0.03055872]\n",
      " [-0.0646117 ]\n",
      " [ 0.10959505]]\n",
      "Iteration 5772 | Cost: 0.33039922730746263 | Gradient: [[ 0.03055867]\n",
      " [-0.06460532]\n",
      " [ 0.10958658]]\n",
      "Iteration 5773 | Cost: 0.33038211108036786 | Gradient: [[ 0.03055862]\n",
      " [-0.06459894]\n",
      " [ 0.10957811]]\n",
      "Iteration 5774 | Cost: 0.33036499753715864 | Gradient: [[ 0.03055857]\n",
      " [-0.06459256]\n",
      " [ 0.10956964]]\n",
      "Iteration 5775 | Cost: 0.3303478866772112 | Gradient: [[ 0.03055852]\n",
      " [-0.06458618]\n",
      " [ 0.10956117]]\n",
      "Iteration 5776 | Cost: 0.33033077849990183 | Gradient: [[ 0.03055847]\n",
      " [-0.06457981]\n",
      " [ 0.1095527 ]]\n",
      "Iteration 5777 | Cost: 0.3303136730046073 | Gradient: [[ 0.03055842]\n",
      " [-0.06457344]\n",
      " [ 0.10954423]]\n",
      "Iteration 5778 | Cost: 0.3302965701907043 | Gradient: [[ 0.03055837]\n",
      " [-0.06456707]\n",
      " [ 0.10953576]]\n",
      "Iteration 5779 | Cost: 0.3302794700575699 | Gradient: [[ 0.03055831]\n",
      " [-0.0645607 ]\n",
      " [ 0.1095273 ]]\n",
      "Iteration 5780 | Cost: 0.3302623726045815 | Gradient: [[ 0.03055826]\n",
      " [-0.06455433]\n",
      " [ 0.10951883]]\n",
      "Iteration 5781 | Cost: 0.3302452778311165 | Gradient: [[ 0.0305582 ]\n",
      " [-0.06454797]\n",
      " [ 0.10951036]]\n",
      "Iteration 5782 | Cost: 0.33022818573655277 | Gradient: [[ 0.03055814]\n",
      " [-0.06454161]\n",
      " [ 0.1095019 ]]\n",
      "Iteration 5783 | Cost: 0.33021109632026796 | Gradient: [[ 0.03055809]\n",
      " [-0.06453525]\n",
      " [ 0.10949344]]\n",
      "Iteration 5784 | Cost: 0.33019400958164047 | Gradient: [[ 0.03055803]\n",
      " [-0.0645289 ]\n",
      " [ 0.10948497]]\n",
      "Iteration 5785 | Cost: 0.3301769255200487 | Gradient: [[ 0.03055797]\n",
      " [-0.06452255]\n",
      " [ 0.10947651]]\n",
      "Iteration 5786 | Cost: 0.330159844134871 | Gradient: [[ 0.03055791]\n",
      " [-0.06451619]\n",
      " [ 0.10946805]]\n",
      "Iteration 5787 | Cost: 0.3301427654254864 | Gradient: [[ 0.03055785]\n",
      " [-0.06450985]\n",
      " [ 0.10945959]]\n",
      "Iteration 5788 | Cost: 0.3301256893912738 | Gradient: [[ 0.03055778]\n",
      " [-0.0645035 ]\n",
      " [ 0.10945112]]\n",
      "Iteration 5789 | Cost: 0.33010861603161257 | Gradient: [[ 0.03055772]\n",
      " [-0.06449715]\n",
      " [ 0.10944266]]\n",
      "Iteration 5790 | Cost: 0.3300915453458821 | Gradient: [[ 0.03055766]\n",
      " [-0.06449081]\n",
      " [ 0.10943421]]\n",
      "Iteration 5791 | Cost: 0.330074477333462 | Gradient: [[ 0.03055759]\n",
      " [-0.06448447]\n",
      " [ 0.10942575]]\n",
      "Iteration 5792 | Cost: 0.33005741199373245 | Gradient: [[ 0.03055753]\n",
      " [-0.06447814]\n",
      " [ 0.10941729]]\n",
      "Iteration 5793 | Cost: 0.3300403493260733 | Gradient: [[ 0.03055746]\n",
      " [-0.0644718 ]\n",
      " [ 0.10940883]]\n",
      "Iteration 5794 | Cost: 0.33002328932986497 | Gradient: [[ 0.03055739]\n",
      " [-0.06446547]\n",
      " [ 0.10940037]]\n",
      "Iteration 5795 | Cost: 0.330006232004488 | Gradient: [[ 0.03055733]\n",
      " [-0.06445914]\n",
      " [ 0.10939192]]\n",
      "Iteration 5796 | Cost: 0.32998917734932315 | Gradient: [[ 0.03055726]\n",
      " [-0.06445281]\n",
      " [ 0.10938346]]\n",
      "Iteration 5797 | Cost: 0.3299721253637515 | Gradient: [[ 0.03055719]\n",
      " [-0.06444649]\n",
      " [ 0.10937501]]\n",
      "Iteration 5798 | Cost: 0.32995507604715407 | Gradient: [[ 0.03055712]\n",
      " [-0.06444016]\n",
      " [ 0.10936656]]\n",
      "Iteration 5799 | Cost: 0.3299380293989126 | Gradient: [[ 0.03055705]\n",
      " [-0.06443384]\n",
      " [ 0.1093581 ]]\n",
      "Iteration 5800 | Cost: 0.32992098541840836 | Gradient: [[ 0.03055697]\n",
      " [-0.06442752]\n",
      " [ 0.10934965]]\n",
      "Iteration 5801 | Cost: 0.3299039441050235 | Gradient: [[ 0.0305569 ]\n",
      " [-0.06442121]\n",
      " [ 0.1093412 ]]\n",
      "Iteration 5802 | Cost: 0.32988690545813987 | Gradient: [[ 0.03055683]\n",
      " [-0.06441489]\n",
      " [ 0.10933275]]\n",
      "Iteration 5803 | Cost: 0.32986986947714 | Gradient: [[ 0.03055675]\n",
      " [-0.06440858]\n",
      " [ 0.1093243 ]]\n",
      "Iteration 5804 | Cost: 0.32985283616140604 | Gradient: [[ 0.03055667]\n",
      " [-0.06440227]\n",
      " [ 0.10931585]]\n",
      "Iteration 5805 | Cost: 0.3298358055103211 | Gradient: [[ 0.0305566 ]\n",
      " [-0.06439596]\n",
      " [ 0.1093074 ]]\n",
      "Iteration 5806 | Cost: 0.3298187775232678 | Gradient: [[ 0.03055652]\n",
      " [-0.06438966]\n",
      " [ 0.10929895]]\n",
      "Iteration 5807 | Cost: 0.3298017521996296 | Gradient: [[ 0.03055644]\n",
      " [-0.06438335]\n",
      " [ 0.1092905 ]]\n",
      "Iteration 5808 | Cost: 0.3297847295387896 | Gradient: [[ 0.03055636]\n",
      " [-0.06437705]\n",
      " [ 0.10928206]]\n",
      "Iteration 5809 | Cost: 0.32976770954013146 | Gradient: [[ 0.03055628]\n",
      " [-0.06437076]\n",
      " [ 0.10927361]]\n",
      "Iteration 5810 | Cost: 0.3297506922030391 | Gradient: [[ 0.0305562 ]\n",
      " [-0.06436446]\n",
      " [ 0.10926516]]\n",
      "Iteration 5811 | Cost: 0.32973367752689636 | Gradient: [[ 0.03055612]\n",
      " [-0.06435817]\n",
      " [ 0.10925672]]\n",
      "Iteration 5812 | Cost: 0.3297166655110875 | Gradient: [[ 0.03055604]\n",
      " [-0.06435188]\n",
      " [ 0.10924828]]\n",
      "Iteration 5813 | Cost: 0.32969965615499713 | Gradient: [[ 0.03055595]\n",
      " [-0.06434559]\n",
      " [ 0.10923983]]\n",
      "Iteration 5814 | Cost: 0.3296826494580097 | Gradient: [[ 0.03055587]\n",
      " [-0.0643393 ]\n",
      " [ 0.10923139]]\n",
      "Iteration 5815 | Cost: 0.32966564541951016 | Gradient: [[ 0.03055578]\n",
      " [-0.06433301]\n",
      " [ 0.10922295]]\n",
      "Iteration 5816 | Cost: 0.3296486440388836 | Gradient: [[ 0.0305557 ]\n",
      " [-0.06432673]\n",
      " [ 0.10921451]]\n",
      "Iteration 5817 | Cost: 0.32963164531551536 | Gradient: [[ 0.03055561]\n",
      " [-0.06432045]\n",
      " [ 0.10920607]]\n",
      "Iteration 5818 | Cost: 0.3296146492487909 | Gradient: [[ 0.03055552]\n",
      " [-0.06431417]\n",
      " [ 0.10919763]]\n",
      "Iteration 5819 | Cost: 0.3295976558380959 | Gradient: [[ 0.03055544]\n",
      " [-0.0643079 ]\n",
      " [ 0.10918919]]\n",
      "Iteration 5820 | Cost: 0.32958066508281647 | Gradient: [[ 0.03055535]\n",
      " [-0.06430163]\n",
      " [ 0.10918075]]\n",
      "Iteration 5821 | Cost: 0.3295636769823386 | Gradient: [[ 0.03055526]\n",
      " [-0.06429536]\n",
      " [ 0.10917231]]\n",
      "Iteration 5822 | Cost: 0.3295466915360488 | Gradient: [[ 0.03055516]\n",
      " [-0.06428909]\n",
      " [ 0.10916387]]\n",
      "Iteration 5823 | Cost: 0.3295297087433336 | Gradient: [[ 0.03055507]\n",
      " [-0.06428282]\n",
      " [ 0.10915544]]\n",
      "Iteration 5824 | Cost: 0.3295127286035797 | Gradient: [[ 0.03055498]\n",
      " [-0.06427656]\n",
      " [ 0.109147  ]]\n",
      "Iteration 5825 | Cost: 0.32949575111617424 | Gradient: [[ 0.03055489]\n",
      " [-0.06427029]\n",
      " [ 0.10913857]]\n",
      "Iteration 5826 | Cost: 0.3294787762805044 | Gradient: [[ 0.03055479]\n",
      " [-0.06426403]\n",
      " [ 0.10913013]]\n",
      "Iteration 5827 | Cost: 0.32946180409595766 | Gradient: [[ 0.0305547 ]\n",
      " [-0.06425778]\n",
      " [ 0.1091217 ]]\n",
      "Iteration 5828 | Cost: 0.32944483456192153 | Gradient: [[ 0.0305546 ]\n",
      " [-0.06425152]\n",
      " [ 0.10911327]]\n",
      "Iteration 5829 | Cost: 0.329427867677784 | Gradient: [[ 0.0305545 ]\n",
      " [-0.06424527]\n",
      " [ 0.10910483]]\n",
      "Iteration 5830 | Cost: 0.32941090344293317 | Gradient: [[ 0.0305544 ]\n",
      " [-0.06423902]\n",
      " [ 0.1090964 ]]\n",
      "Iteration 5831 | Cost: 0.32939394185675724 | Gradient: [[ 0.03055431]\n",
      " [-0.06423277]\n",
      " [ 0.10908797]]\n",
      "Iteration 5832 | Cost: 0.3293769829186447 | Gradient: [[ 0.03055421]\n",
      " [-0.06422652]\n",
      " [ 0.10907954]]\n",
      "Iteration 5833 | Cost: 0.32936002662798436 | Gradient: [[ 0.03055411]\n",
      " [-0.06422028]\n",
      " [ 0.10907111]]\n",
      "Iteration 5834 | Cost: 0.32934307298416515 | Gradient: [[ 0.030554  ]\n",
      " [-0.06421404]\n",
      " [ 0.10906268]]\n",
      "Iteration 5835 | Cost: 0.329326121986576 | Gradient: [[ 0.0305539 ]\n",
      " [-0.0642078 ]\n",
      " [ 0.10905426]]\n",
      "Iteration 5836 | Cost: 0.3293091736346065 | Gradient: [[ 0.0305538 ]\n",
      " [-0.06420156]\n",
      " [ 0.10904583]]\n",
      "Iteration 5837 | Cost: 0.3292922279276461 | Gradient: [[ 0.0305537 ]\n",
      " [-0.06419533]\n",
      " [ 0.1090374 ]]\n",
      "Iteration 5838 | Cost: 0.3292752848650846 | Gradient: [[ 0.03055359]\n",
      " [-0.06418909]\n",
      " [ 0.10902898]]\n",
      "Iteration 5839 | Cost: 0.329258344446312 | Gradient: [[ 0.03055349]\n",
      " [-0.06418286]\n",
      " [ 0.10902055]]\n",
      "Iteration 5840 | Cost: 0.3292414066707185 | Gradient: [[ 0.03055338]\n",
      " [-0.06417664]\n",
      " [ 0.10901213]]\n",
      "Iteration 5841 | Cost: 0.32922447153769446 | Gradient: [[ 0.03055327]\n",
      " [-0.06417041]\n",
      " [ 0.1090037 ]]\n",
      "Iteration 5842 | Cost: 0.32920753904663047 | Gradient: [[ 0.03055316]\n",
      " [-0.06416419]\n",
      " [ 0.10899528]]\n",
      "Iteration 5843 | Cost: 0.3291906091969174 | Gradient: [[ 0.03055306]\n",
      " [-0.06415797]\n",
      " [ 0.10898686]]\n",
      "Iteration 5844 | Cost: 0.32917368198794633 | Gradient: [[ 0.03055295]\n",
      " [-0.06415175]\n",
      " [ 0.10897844]]\n",
      "Iteration 5845 | Cost: 0.3291567574191085 | Gradient: [[ 0.03055284]\n",
      " [-0.06414553]\n",
      " [ 0.10897002]]\n",
      "Iteration 5846 | Cost: 0.32913983548979525 | Gradient: [[ 0.03055272]\n",
      " [-0.06413931]\n",
      " [ 0.1089616 ]]\n",
      "Iteration 5847 | Cost: 0.32912291619939843 | Gradient: [[ 0.03055261]\n",
      " [-0.0641331 ]\n",
      " [ 0.10895318]]\n",
      "Iteration 5848 | Cost: 0.3291059995473098 | Gradient: [[ 0.0305525 ]\n",
      " [-0.06412689]\n",
      " [ 0.10894476]]\n",
      "Iteration 5849 | Cost: 0.3290890855329215 | Gradient: [[ 0.03055239]\n",
      " [-0.06412068]\n",
      " [ 0.10893634]]\n",
      "Iteration 5850 | Cost: 0.32907217415562573 | Gradient: [[ 0.03055227]\n",
      " [-0.06411448]\n",
      " [ 0.10892792]]\n",
      "Iteration 5851 | Cost: 0.3290552654148153 | Gradient: [[ 0.03055216]\n",
      " [-0.06410827]\n",
      " [ 0.10891951]]\n",
      "Iteration 5852 | Cost: 0.32903835930988246 | Gradient: [[ 0.03055204]\n",
      " [-0.06410207]\n",
      " [ 0.10891109]]\n",
      "Iteration 5853 | Cost: 0.3290214558402206 | Gradient: [[ 0.03055192]\n",
      " [-0.06409587]\n",
      " [ 0.10890267]]\n",
      "Iteration 5854 | Cost: 0.3290045550052226 | Gradient: [[ 0.0305518 ]\n",
      " [-0.06408968]\n",
      " [ 0.10889426]]\n",
      "Iteration 5855 | Cost: 0.3289876568042818 | Gradient: [[ 0.03055169]\n",
      " [-0.06408348]\n",
      " [ 0.10888585]]\n",
      "Iteration 5856 | Cost: 0.3289707612367919 | Gradient: [[ 0.03055157]\n",
      " [-0.06407729]\n",
      " [ 0.10887743]]\n",
      "Iteration 5857 | Cost: 0.32895386830214657 | Gradient: [[ 0.03055145]\n",
      " [-0.0640711 ]\n",
      " [ 0.10886902]]\n",
      "Iteration 5858 | Cost: 0.3289369779997399 | Gradient: [[ 0.03055133]\n",
      " [-0.06406491]\n",
      " [ 0.10886061]]\n",
      "Iteration 5859 | Cost: 0.3289200903289659 | Gradient: [[ 0.0305512 ]\n",
      " [-0.06405873]\n",
      " [ 0.1088522 ]]\n",
      "Iteration 5860 | Cost: 0.32890320528921907 | Gradient: [[ 0.03055108]\n",
      " [-0.06405254]\n",
      " [ 0.10884379]]\n",
      "Iteration 5861 | Cost: 0.328886322879894 | Gradient: [[ 0.03055096]\n",
      " [-0.06404636]\n",
      " [ 0.10883538]]\n",
      "Iteration 5862 | Cost: 0.3288694431003855 | Gradient: [[ 0.03055083]\n",
      " [-0.06404018]\n",
      " [ 0.10882697]]\n",
      "Iteration 5863 | Cost: 0.3288525659500886 | Gradient: [[ 0.03055071]\n",
      " [-0.064034  ]\n",
      " [ 0.10881856]]\n",
      "Iteration 5864 | Cost: 0.32883569142839847 | Gradient: [[ 0.03055058]\n",
      " [-0.06402783]\n",
      " [ 0.10881015]]\n",
      "Iteration 5865 | Cost: 0.3288188195347107 | Gradient: [[ 0.03055045]\n",
      " [-0.06402166]\n",
      " [ 0.10880175]]\n",
      "Iteration 5866 | Cost: 0.3288019502684208 | Gradient: [[ 0.03055033]\n",
      " [-0.06401549]\n",
      " [ 0.10879334]]\n",
      "Iteration 5867 | Cost: 0.3287850836289246 | Gradient: [[ 0.0305502 ]\n",
      " [-0.06400932]\n",
      " [ 0.10878494]]\n",
      "Iteration 5868 | Cost: 0.3287682196156182 | Gradient: [[ 0.03055007]\n",
      " [-0.06400315]\n",
      " [ 0.10877653]]\n",
      "Iteration 5869 | Cost: 0.32875135822789797 | Gradient: [[ 0.03054994]\n",
      " [-0.06399699]\n",
      " [ 0.10876813]]\n",
      "Iteration 5870 | Cost: 0.32873449946516026 | Gradient: [[ 0.03054981]\n",
      " [-0.06399083]\n",
      " [ 0.10875972]]\n",
      "Iteration 5871 | Cost: 0.32871764332680176 | Gradient: [[ 0.03054967]\n",
      " [-0.06398467]\n",
      " [ 0.10875132]]\n",
      "Iteration 5872 | Cost: 0.3287007898122194 | Gradient: [[ 0.03054954]\n",
      " [-0.06397851]\n",
      " [ 0.10874292]]\n",
      "Iteration 5873 | Cost: 0.3286839389208103 | Gradient: [[ 0.03054941]\n",
      " [-0.06397236]\n",
      " [ 0.10873452]]\n",
      "Iteration 5874 | Cost: 0.32866709065197175 | Gradient: [[ 0.03054927]\n",
      " [-0.0639662 ]\n",
      " [ 0.10872612]]\n",
      "Iteration 5875 | Cost: 0.32865024500510115 | Gradient: [[ 0.03054914]\n",
      " [-0.06396005]\n",
      " [ 0.10871772]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5876 | Cost: 0.3286334019795964 | Gradient: [[ 0.030549  ]\n",
      " [-0.0639539 ]\n",
      " [ 0.10870932]]\n",
      "Iteration 5877 | Cost: 0.32861656157485525 | Gradient: [[ 0.03054887]\n",
      " [-0.06394776]\n",
      " [ 0.10870092]]\n",
      "Iteration 5878 | Cost: 0.328599723790276 | Gradient: [[ 0.03054873]\n",
      " [-0.06394161]\n",
      " [ 0.10869253]]\n",
      "Iteration 5879 | Cost: 0.3285828886252568 | Gradient: [[ 0.03054859]\n",
      " [-0.06393547]\n",
      " [ 0.10868413]]\n",
      "Iteration 5880 | Cost: 0.3285660560791964 | Gradient: [[ 0.03054845]\n",
      " [-0.06392933]\n",
      " [ 0.10867573]]\n",
      "Iteration 5881 | Cost: 0.3285492261514935 | Gradient: [[ 0.03054831]\n",
      " [-0.06392319]\n",
      " [ 0.10866734]]\n",
      "Iteration 5882 | Cost: 0.3285323988415469 | Gradient: [[ 0.03054817]\n",
      " [-0.06391706]\n",
      " [ 0.10865894]]\n",
      "Iteration 5883 | Cost: 0.32851557414875593 | Gradient: [[ 0.03054803]\n",
      " [-0.06391093]\n",
      " [ 0.10865055]]\n",
      "Iteration 5884 | Cost: 0.3284987520725198 | Gradient: [[ 0.03054789]\n",
      " [-0.06390479]\n",
      " [ 0.10864216]]\n",
      "Iteration 5885 | Cost: 0.32848193261223824 | Gradient: [[ 0.03054774]\n",
      " [-0.06389867]\n",
      " [ 0.10863376]]\n",
      "Iteration 5886 | Cost: 0.3284651157673109 | Gradient: [[ 0.0305476 ]\n",
      " [-0.06389254]\n",
      " [ 0.10862537]]\n",
      "Iteration 5887 | Cost: 0.32844830153713794 | Gradient: [[ 0.03054745]\n",
      " [-0.06388641]\n",
      " [ 0.10861698]]\n",
      "Iteration 5888 | Cost: 0.32843148992111937 | Gradient: [[ 0.03054731]\n",
      " [-0.06388029]\n",
      " [ 0.10860859]]\n",
      "Iteration 5889 | Cost: 0.32841468091865555 | Gradient: [[ 0.03054716]\n",
      " [-0.06387417]\n",
      " [ 0.1086002 ]]\n",
      "Iteration 5890 | Cost: 0.3283978745291473 | Gradient: [[ 0.03054702]\n",
      " [-0.06386805]\n",
      " [ 0.10859181]]\n",
      "Iteration 5891 | Cost: 0.3283810707519953 | Gradient: [[ 0.03054687]\n",
      " [-0.06386194]\n",
      " [ 0.10858342]]\n",
      "Iteration 5892 | Cost: 0.3283642695866006 | Gradient: [[ 0.03054672]\n",
      " [-0.06385583]\n",
      " [ 0.10857504]]\n",
      "Iteration 5893 | Cost: 0.3283474710323643 | Gradient: [[ 0.03054657]\n",
      " [-0.06384971]\n",
      " [ 0.10856665]]\n",
      "Iteration 5894 | Cost: 0.32833067508868796 | Gradient: [[ 0.03054642]\n",
      " [-0.0638436 ]\n",
      " [ 0.10855826]]\n",
      "Iteration 5895 | Cost: 0.32831388175497306 | Gradient: [[ 0.03054627]\n",
      " [-0.0638375 ]\n",
      " [ 0.10854988]]\n",
      "Iteration 5896 | Cost: 0.32829709103062166 | Gradient: [[ 0.03054612]\n",
      " [-0.06383139]\n",
      " [ 0.10854149]]\n",
      "Iteration 5897 | Cost: 0.32828030291503546 | Gradient: [[ 0.03054596]\n",
      " [-0.06382529]\n",
      " [ 0.10853311]]\n",
      "Iteration 5898 | Cost: 0.3282635174076169 | Gradient: [[ 0.03054581]\n",
      " [-0.06381919]\n",
      " [ 0.10852473]]\n",
      "Iteration 5899 | Cost: 0.32824673450776853 | Gradient: [[ 0.03054565]\n",
      " [-0.06381309]\n",
      " [ 0.10851634]]\n",
      "Iteration 5900 | Cost: 0.3282299542148927 | Gradient: [[ 0.0305455 ]\n",
      " [-0.06380699]\n",
      " [ 0.10850796]]\n",
      "Iteration 5901 | Cost: 0.32821317652839255 | Gradient: [[ 0.03054534]\n",
      " [-0.0638009 ]\n",
      " [ 0.10849958]]\n",
      "Iteration 5902 | Cost: 0.3281964014476708 | Gradient: [[ 0.03054519]\n",
      " [-0.06379481]\n",
      " [ 0.1084912 ]]\n",
      "Iteration 5903 | Cost: 0.328179628972131 | Gradient: [[ 0.03054503]\n",
      " [-0.06378872]\n",
      " [ 0.10848282]]\n",
      "Iteration 5904 | Cost: 0.32816285910117654 | Gradient: [[ 0.03054487]\n",
      " [-0.06378263]\n",
      " [ 0.10847444]]\n",
      "Iteration 5905 | Cost: 0.328146091834211 | Gradient: [[ 0.03054471]\n",
      " [-0.06377655]\n",
      " [ 0.10846606]]\n",
      "Iteration 5906 | Cost: 0.32812932717063825 | Gradient: [[ 0.03054455]\n",
      " [-0.06377046]\n",
      " [ 0.10845769]]\n",
      "Iteration 5907 | Cost: 0.3281125651098624 | Gradient: [[ 0.03054439]\n",
      " [-0.06376438]\n",
      " [ 0.10844931]]\n",
      "Iteration 5908 | Cost: 0.3280958056512877 | Gradient: [[ 0.03054423]\n",
      " [-0.0637583 ]\n",
      " [ 0.10844093]]\n",
      "Iteration 5909 | Cost: 0.32807904879431876 | Gradient: [[ 0.03054407]\n",
      " [-0.06375223]\n",
      " [ 0.10843256]]\n",
      "Iteration 5910 | Cost: 0.32806229453836 | Gradient: [[ 0.0305439 ]\n",
      " [-0.06374615]\n",
      " [ 0.10842418]]\n",
      "Iteration 5911 | Cost: 0.32804554288281645 | Gradient: [[ 0.03054374]\n",
      " [-0.06374008]\n",
      " [ 0.10841581]]\n",
      "Iteration 5912 | Cost: 0.32802879382709305 | Gradient: [[ 0.03054357]\n",
      " [-0.06373401]\n",
      " [ 0.10840744]]\n",
      "Iteration 5913 | Cost: 0.3280120473705953 | Gradient: [[ 0.03054341]\n",
      " [-0.06372794]\n",
      " [ 0.10839907]]\n",
      "Iteration 5914 | Cost: 0.3279953035127286 | Gradient: [[ 0.03054324]\n",
      " [-0.06372187]\n",
      " [ 0.10839069]]\n",
      "Iteration 5915 | Cost: 0.3279785622528986 | Gradient: [[ 0.03054307]\n",
      " [-0.06371581]\n",
      " [ 0.10838232]]\n",
      "Iteration 5916 | Cost: 0.3279618235905111 | Gradient: [[ 0.03054291]\n",
      " [-0.06370975]\n",
      " [ 0.10837395]]\n",
      "Iteration 5917 | Cost: 0.32794508752497237 | Gradient: [[ 0.03054274]\n",
      " [-0.06370369]\n",
      " [ 0.10836558]]\n",
      "Iteration 5918 | Cost: 0.3279283540556886 | Gradient: [[ 0.03054257]\n",
      " [-0.06369763]\n",
      " [ 0.10835721]]\n",
      "Iteration 5919 | Cost: 0.32791162318206624 | Gradient: [[ 0.0305424 ]\n",
      " [-0.06369157]\n",
      " [ 0.10834885]]\n",
      "Iteration 5920 | Cost: 0.32789489490351215 | Gradient: [[ 0.03054223]\n",
      " [-0.06368552]\n",
      " [ 0.10834048]]\n",
      "Iteration 5921 | Cost: 0.3278781692194331 | Gradient: [[ 0.03054205]\n",
      " [-0.06367947]\n",
      " [ 0.10833211]]\n",
      "Iteration 5922 | Cost: 0.3278614461292361 | Gradient: [[ 0.03054188]\n",
      " [-0.06367342]\n",
      " [ 0.10832375]]\n",
      "Iteration 5923 | Cost: 0.32784472563232864 | Gradient: [[ 0.03054171]\n",
      " [-0.06366737]\n",
      " [ 0.10831538]]\n",
      "Iteration 5924 | Cost: 0.327828007728118 | Gradient: [[ 0.03054153]\n",
      " [-0.06366133]\n",
      " [ 0.10830702]]\n",
      "Iteration 5925 | Cost: 0.3278112924160121 | Gradient: [[ 0.03054136]\n",
      " [-0.06365529]\n",
      " [ 0.10829865]]\n",
      "Iteration 5926 | Cost: 0.3277945796954187 | Gradient: [[ 0.03054118]\n",
      " [-0.06364925]\n",
      " [ 0.10829029]]\n",
      "Iteration 5927 | Cost: 0.32777786956574595 | Gradient: [[ 0.03054101]\n",
      " [-0.06364321]\n",
      " [ 0.10828193]]\n",
      "Iteration 5928 | Cost: 0.3277611620264022 | Gradient: [[ 0.03054083]\n",
      " [-0.06363717]\n",
      " [ 0.10827357]]\n",
      "Iteration 5929 | Cost: 0.32774445707679584 | Gradient: [[ 0.03054065]\n",
      " [-0.06363114]\n",
      " [ 0.10826521]]\n",
      "Iteration 5930 | Cost: 0.3277277547163356 | Gradient: [[ 0.03054047]\n",
      " [-0.06362511]\n",
      " [ 0.10825685]]\n",
      "Iteration 5931 | Cost: 0.32771105494443037 | Gradient: [[ 0.03054029]\n",
      " [-0.06361908]\n",
      " [ 0.10824849]]\n",
      "Iteration 5932 | Cost: 0.32769435776048933 | Gradient: [[ 0.03054011]\n",
      " [-0.06361305]\n",
      " [ 0.10824013]]\n",
      "Iteration 5933 | Cost: 0.3276776631639217 | Gradient: [[ 0.03053993]\n",
      " [-0.06360702]\n",
      " [ 0.10823177]]\n",
      "Iteration 5934 | Cost: 0.32766097115413706 | Gradient: [[ 0.03053975]\n",
      " [-0.063601  ]\n",
      " [ 0.10822341]]\n",
      "Iteration 5935 | Cost: 0.32764428173054505 | Gradient: [[ 0.03053957]\n",
      " [-0.06359498]\n",
      " [ 0.10821506]]\n",
      "Iteration 5936 | Cost: 0.3276275948925555 | Gradient: [[ 0.03053938]\n",
      " [-0.06358896]\n",
      " [ 0.1082067 ]]\n",
      "Iteration 5937 | Cost: 0.3276109106395787 | Gradient: [[ 0.0305392 ]\n",
      " [-0.06358294]\n",
      " [ 0.10819834]]\n",
      "Iteration 5938 | Cost: 0.32759422897102486 | Gradient: [[ 0.03053901]\n",
      " [-0.06357692]\n",
      " [ 0.10818999]]\n",
      "Iteration 5939 | Cost: 0.32757754988630433 | Gradient: [[ 0.03053883]\n",
      " [-0.06357091]\n",
      " [ 0.10818164]]\n",
      "Iteration 5940 | Cost: 0.327560873384828 | Gradient: [[ 0.03053864]\n",
      " [-0.0635649 ]\n",
      " [ 0.10817328]]\n",
      "Iteration 5941 | Cost: 0.32754419946600666 | Gradient: [[ 0.03053845]\n",
      " [-0.06355889]\n",
      " [ 0.10816493]]\n",
      "Iteration 5942 | Cost: 0.3275275281292515 | Gradient: [[ 0.03053826]\n",
      " [-0.06355289]\n",
      " [ 0.10815658]]\n",
      "Iteration 5943 | Cost: 0.3275108593739736 | Gradient: [[ 0.03053807]\n",
      " [-0.06354688]\n",
      " [ 0.10814823]]\n",
      "Iteration 5944 | Cost: 0.3274941931995847 | Gradient: [[ 0.03053788]\n",
      " [-0.06354088]\n",
      " [ 0.10813988]]\n",
      "Iteration 5945 | Cost: 0.3274775296054964 | Gradient: [[ 0.03053769]\n",
      " [-0.06353488]\n",
      " [ 0.10813153]]\n",
      "Iteration 5946 | Cost: 0.3274608685911206 | Gradient: [[ 0.0305375 ]\n",
      " [-0.06352888]\n",
      " [ 0.10812318]]\n",
      "Iteration 5947 | Cost: 0.32744421015586933 | Gradient: [[ 0.03053731]\n",
      " [-0.06352288]\n",
      " [ 0.10811483]]\n",
      "Iteration 5948 | Cost: 0.327427554299155 | Gradient: [[ 0.03053712]\n",
      " [-0.06351689]\n",
      " [ 0.10810649]]\n",
      "Iteration 5949 | Cost: 0.32741090102038983 | Gradient: [[ 0.03053692]\n",
      " [-0.0635109 ]\n",
      " [ 0.10809814]]\n",
      "Iteration 5950 | Cost: 0.3273942503189867 | Gradient: [[ 0.03053673]\n",
      " [-0.06350491]\n",
      " [ 0.10808979]]\n",
      "Iteration 5951 | Cost: 0.32737760219435846 | Gradient: [[ 0.03053653]\n",
      " [-0.06349892]\n",
      " [ 0.10808145]]\n",
      "Iteration 5952 | Cost: 0.32736095664591824 | Gradient: [[ 0.03053634]\n",
      " [-0.06349293]\n",
      " [ 0.10807311]]\n",
      "Iteration 5953 | Cost: 0.3273443136730792 | Gradient: [[ 0.03053614]\n",
      " [-0.06348695]\n",
      " [ 0.10806476]]\n",
      "Iteration 5954 | Cost: 0.32732767327525486 | Gradient: [[ 0.03053594]\n",
      " [-0.06348097]\n",
      " [ 0.10805642]]\n",
      "Iteration 5955 | Cost: 0.32731103545185897 | Gradient: [[ 0.03053575]\n",
      " [-0.06347499]\n",
      " [ 0.10804808]]\n",
      "Iteration 5956 | Cost: 0.3272944002023052 | Gradient: [[ 0.03053555]\n",
      " [-0.06346901]\n",
      " [ 0.10803974]]\n",
      "Iteration 5957 | Cost: 0.3272777675260078 | Gradient: [[ 0.03053535]\n",
      " [-0.06346304]\n",
      " [ 0.1080314 ]]\n",
      "Iteration 5958 | Cost: 0.3272611374223809 | Gradient: [[ 0.03053515]\n",
      " [-0.06345706]\n",
      " [ 0.10802306]]\n",
      "Iteration 5959 | Cost: 0.32724450989083903 | Gradient: [[ 0.03053494]\n",
      " [-0.06345109]\n",
      " [ 0.10801472]]\n",
      "Iteration 5960 | Cost: 0.3272278849307968 | Gradient: [[ 0.03053474]\n",
      " [-0.06344512]\n",
      " [ 0.10800638]]\n",
      "Iteration 5961 | Cost: 0.32721126254166905 | Gradient: [[ 0.03053454]\n",
      " [-0.06343916]\n",
      " [ 0.10799804]]\n",
      "Iteration 5962 | Cost: 0.3271946427228709 | Gradient: [[ 0.03053434]\n",
      " [-0.06343319]\n",
      " [ 0.1079897 ]]\n",
      "Iteration 5963 | Cost: 0.3271780254738175 | Gradient: [[ 0.03053413]\n",
      " [-0.06342723]\n",
      " [ 0.10798137]]\n",
      "Iteration 5964 | Cost: 0.3271614107939244 | Gradient: [[ 0.03053393]\n",
      " [-0.06342127]\n",
      " [ 0.10797303]]\n",
      "Iteration 5965 | Cost: 0.3271447986826071 | Gradient: [[ 0.03053372]\n",
      " [-0.06341531]\n",
      " [ 0.1079647 ]]\n",
      "Iteration 5966 | Cost: 0.32712818913928154 | Gradient: [[ 0.03053351]\n",
      " [-0.06340935]\n",
      " [ 0.10795636]]\n",
      "Iteration 5967 | Cost: 0.3271115821633636 | Gradient: [[ 0.03053331]\n",
      " [-0.0634034 ]\n",
      " [ 0.10794803]]\n",
      "Iteration 5968 | Cost: 0.3270949777542696 | Gradient: [[ 0.0305331 ]\n",
      " [-0.06339745]\n",
      " [ 0.1079397 ]]\n",
      "Iteration 5969 | Cost: 0.3270783759114161 | Gradient: [[ 0.03053289]\n",
      " [-0.06339149]\n",
      " [ 0.10793137]]\n",
      "Iteration 5970 | Cost: 0.3270617766342194 | Gradient: [[ 0.03053268]\n",
      " [-0.06338555]\n",
      " [ 0.10792303]]\n",
      "Iteration 5971 | Cost: 0.32704517992209664 | Gradient: [[ 0.03053247]\n",
      " [-0.0633796 ]\n",
      " [ 0.1079147 ]]\n",
      "Iteration 5972 | Cost: 0.3270285857744645 | Gradient: [[ 0.03053226]\n",
      " [-0.06337366]\n",
      " [ 0.10790637]]\n",
      "Iteration 5973 | Cost: 0.3270119941907404 | Gradient: [[ 0.03053204]\n",
      " [-0.06336771]\n",
      " [ 0.10789805]]\n",
      "Iteration 5974 | Cost: 0.32699540517034165 | Gradient: [[ 0.03053183]\n",
      " [-0.06336177]\n",
      " [ 0.10788972]]\n",
      "Iteration 5975 | Cost: 0.3269788187126859 | Gradient: [[ 0.03053162]\n",
      " [-0.06335584]\n",
      " [ 0.10788139]]\n",
      "Iteration 5976 | Cost: 0.32696223481719083 | Gradient: [[ 0.0305314 ]\n",
      " [-0.0633499 ]\n",
      " [ 0.10787306]]\n",
      "Iteration 5977 | Cost: 0.3269456534832745 | Gradient: [[ 0.03053119]\n",
      " [-0.06334397]\n",
      " [ 0.10786474]]\n",
      "Iteration 5978 | Cost: 0.32692907471035504 | Gradient: [[ 0.03053097]\n",
      " [-0.06333803]\n",
      " [ 0.10785641]]\n",
      "Iteration 5979 | Cost: 0.3269124984978508 | Gradient: [[ 0.03053076]\n",
      " [-0.06333211]\n",
      " [ 0.10784809]]\n",
      "Iteration 5980 | Cost: 0.3268959248451805 | Gradient: [[ 0.03053054]\n",
      " [-0.06332618]\n",
      " [ 0.10783976]]\n",
      "Iteration 5981 | Cost: 0.32687935375176275 | Gradient: [[ 0.03053032]\n",
      " [-0.06332025]\n",
      " [ 0.10783144]]\n",
      "Iteration 5982 | Cost: 0.3268627852170164 | Gradient: [[ 0.0305301 ]\n",
      " [-0.06331433]\n",
      " [ 0.10782312]]\n",
      "Iteration 5983 | Cost: 0.32684621924036084 | Gradient: [[ 0.03052988]\n",
      " [-0.06330841]\n",
      " [ 0.1078148 ]]\n",
      "Iteration 5984 | Cost: 0.32682965582121515 | Gradient: [[ 0.03052966]\n",
      " [-0.06330249]\n",
      " [ 0.10780648]]\n",
      "Iteration 5985 | Cost: 0.3268130949589992 | Gradient: [[ 0.03052944]\n",
      " [-0.06329657]\n",
      " [ 0.10779816]]\n",
      "Iteration 5986 | Cost: 0.3267965366531323 | Gradient: [[ 0.03052922]\n",
      " [-0.06329065]\n",
      " [ 0.10778984]]\n",
      "Iteration 5987 | Cost: 0.3267799809030347 | Gradient: [[ 0.030529  ]\n",
      " [-0.06328474]\n",
      " [ 0.10778152]]\n",
      "Iteration 5988 | Cost: 0.32676342770812633 | Gradient: [[ 0.03052877]\n",
      " [-0.06327883]\n",
      " [ 0.1077732 ]]\n",
      "Iteration 5989 | Cost: 0.3267468770678277 | Gradient: [[ 0.03052855]\n",
      " [-0.06327292]\n",
      " [ 0.10776488]]\n",
      "Iteration 5990 | Cost: 0.32673032898155896 | Gradient: [[ 0.03052832]\n",
      " [-0.06326701]\n",
      " [ 0.10775657]]\n",
      "Iteration 5991 | Cost: 0.3267137834487412 | Gradient: [[ 0.0305281 ]\n",
      " [-0.06326111]\n",
      " [ 0.10774825]]\n",
      "Iteration 5992 | Cost: 0.326697240468795 | Gradient: [[ 0.03052787]\n",
      " [-0.06325521]\n",
      " [ 0.10773994]]\n",
      "Iteration 5993 | Cost: 0.3266807000411417 | Gradient: [[ 0.03052764]\n",
      " [-0.0632493 ]\n",
      " [ 0.10773162]]\n",
      "Iteration 5994 | Cost: 0.3266641621652022 | Gradient: [[ 0.03052742]\n",
      " [-0.06324341]\n",
      " [ 0.10772331]]\n",
      "Iteration 5995 | Cost: 0.32664762684039833 | Gradient: [[ 0.03052719]\n",
      " [-0.06323751]\n",
      " [ 0.10771499]]\n",
      "Iteration 5996 | Cost: 0.3266310940661516 | Gradient: [[ 0.03052696]\n",
      " [-0.06323161]\n",
      " [ 0.10770668]]\n",
      "Iteration 5997 | Cost: 0.32661456384188386 | Gradient: [[ 0.03052673]\n",
      " [-0.06322572]\n",
      " [ 0.10769837]]\n",
      "Iteration 5998 | Cost: 0.3265980361670172 | Gradient: [[ 0.0305265 ]\n",
      " [-0.06321983]\n",
      " [ 0.10769006]]\n",
      "Iteration 5999 | Cost: 0.3265815110409737 | Gradient: [[ 0.03052627]\n",
      " [-0.06321394]\n",
      " [ 0.10768175]]\n",
      "Iteration 6000 | Cost: 0.32656498846317605 | Gradient: [[ 0.03052603]\n",
      " [-0.06320805]\n",
      " [ 0.10767344]]\n",
      "Iteration 6001 | Cost: 0.32654846843304663 | Gradient: [[ 0.0305258 ]\n",
      " [-0.06320217]\n",
      " [ 0.10766513]]\n",
      "Iteration 6002 | Cost: 0.32653195095000837 | Gradient: [[ 0.03052557]\n",
      " [-0.06319629]\n",
      " [ 0.10765683]]\n",
      "Iteration 6003 | Cost: 0.32651543601348426 | Gradient: [[ 0.03052533]\n",
      " [-0.06319041]\n",
      " [ 0.10764852]]\n",
      "Iteration 6004 | Cost: 0.32649892362289745 | Gradient: [[ 0.0305251 ]\n",
      " [-0.06318453]\n",
      " [ 0.10764021]]\n",
      "Iteration 6005 | Cost: 0.32648241377767134 | Gradient: [[ 0.03052486]\n",
      " [-0.06317865]\n",
      " [ 0.10763191]]\n",
      "Iteration 6006 | Cost: 0.3264659064772295 | Gradient: [[ 0.03052462]\n",
      " [-0.06317278]\n",
      " [ 0.1076236 ]]\n",
      "Iteration 6007 | Cost: 0.32644940172099574 | Gradient: [[ 0.03052439]\n",
      " [-0.0631669 ]\n",
      " [ 0.1076153 ]]\n",
      "Iteration 6008 | Cost: 0.32643289950839405 | Gradient: [[ 0.03052415]\n",
      " [-0.06316103]\n",
      " [ 0.107607  ]]\n",
      "Iteration 6009 | Cost: 0.3264163998388484 | Gradient: [[ 0.03052391]\n",
      " [-0.06315517]\n",
      " [ 0.10759869]]\n",
      "Iteration 6010 | Cost: 0.3263999027117833 | Gradient: [[ 0.03052367]\n",
      " [-0.0631493 ]\n",
      " [ 0.10759039]]\n",
      "Iteration 6011 | Cost: 0.32638340812662336 | Gradient: [[ 0.03052343]\n",
      " [-0.06314343]\n",
      " [ 0.10758209]]\n",
      "Iteration 6012 | Cost: 0.32636691608279306 | Gradient: [[ 0.03052319]\n",
      " [-0.06313757]\n",
      " [ 0.10757379]]\n",
      "Iteration 6013 | Cost: 0.3263504265797175 | Gradient: [[ 0.03052295]\n",
      " [-0.06313171]\n",
      " [ 0.10756549]]\n",
      "Iteration 6014 | Cost: 0.3263339396168218 | Gradient: [[ 0.0305227 ]\n",
      " [-0.06312585]\n",
      " [ 0.10755719]]\n",
      "Iteration 6015 | Cost: 0.32631745519353106 | Gradient: [[ 0.03052246]\n",
      " [-0.06312   ]\n",
      " [ 0.10754889]]\n",
      "Iteration 6016 | Cost: 0.3263009733092709 | Gradient: [[ 0.03052222]\n",
      " [-0.06311414]\n",
      " [ 0.1075406 ]]\n",
      "Iteration 6017 | Cost: 0.3262844939634671 | Gradient: [[ 0.03052197]\n",
      " [-0.06310829]\n",
      " [ 0.1075323 ]]\n",
      "Iteration 6018 | Cost: 0.32626801715554526 | Gradient: [[ 0.03052173]\n",
      " [-0.06310244]\n",
      " [ 0.107524  ]]\n",
      "Iteration 6019 | Cost: 0.32625154288493163 | Gradient: [[ 0.03052148]\n",
      " [-0.06309659]\n",
      " [ 0.10751571]]\n",
      "Iteration 6020 | Cost: 0.3262350711510525 | Gradient: [[ 0.03052123]\n",
      " [-0.06309074]\n",
      " [ 0.10750741]]\n",
      "Iteration 6021 | Cost: 0.3262186019533341 | Gradient: [[ 0.03052098]\n",
      " [-0.0630849 ]\n",
      " [ 0.10749912]]\n",
      "Iteration 6022 | Cost: 0.3262021352912033 | Gradient: [[ 0.03052074]\n",
      " [-0.06307906]\n",
      " [ 0.10749083]]\n",
      "Iteration 6023 | Cost: 0.32618567116408664 | Gradient: [[ 0.03052049]\n",
      " [-0.06307322]\n",
      " [ 0.10748253]]\n",
      "Iteration 6024 | Cost: 0.32616920957141143 | Gradient: [[ 0.03052024]\n",
      " [-0.06306738]\n",
      " [ 0.10747424]]\n",
      "Iteration 6025 | Cost: 0.32615275051260467 | Gradient: [[ 0.03051999]\n",
      " [-0.06306154]\n",
      " [ 0.10746595]]\n",
      "Iteration 6026 | Cost: 0.3261362939870937 | Gradient: [[ 0.03051973]\n",
      " [-0.06305571]\n",
      " [ 0.10745766]]\n",
      "Iteration 6027 | Cost: 0.3261198399943063 | Gradient: [[ 0.03051948]\n",
      " [-0.06304988]\n",
      " [ 0.10744937]]\n",
      "Iteration 6028 | Cost: 0.3261033885336701 | Gradient: [[ 0.03051923]\n",
      " [-0.06304405]\n",
      " [ 0.10744108]]\n",
      "Iteration 6029 | Cost: 0.3260869396046131 | Gradient: [[ 0.03051898]\n",
      " [-0.06303822]\n",
      " [ 0.1074328 ]]\n",
      "Iteration 6030 | Cost: 0.3260704932065634 | Gradient: [[ 0.03051872]\n",
      " [-0.06303239]\n",
      " [ 0.10742451]]\n",
      "Iteration 6031 | Cost: 0.3260540493389493 | Gradient: [[ 0.03051847]\n",
      " [-0.06302657]\n",
      " [ 0.10741622]]\n",
      "Iteration 6032 | Cost: 0.32603760800119935 | Gradient: [[ 0.03051821]\n",
      " [-0.06302075]\n",
      " [ 0.10740794]]\n",
      "Iteration 6033 | Cost: 0.3260211691927424 | Gradient: [[ 0.03051795]\n",
      " [-0.06301492]\n",
      " [ 0.10739965]]\n",
      "Iteration 6034 | Cost: 0.326004732913007 | Gradient: [[ 0.0305177 ]\n",
      " [-0.06300911]\n",
      " [ 0.10739137]]\n",
      "Iteration 6035 | Cost: 0.32598829916142263 | Gradient: [[ 0.03051744]\n",
      " [-0.06300329]\n",
      " [ 0.10738309]]\n",
      "Iteration 6036 | Cost: 0.32597186793741834 | Gradient: [[ 0.03051718]\n",
      " [-0.06299748]\n",
      " [ 0.1073748 ]]\n",
      "Iteration 6037 | Cost: 0.3259554392404236 | Gradient: [[ 0.03051692]\n",
      " [-0.06299166]\n",
      " [ 0.10736652]]\n",
      "Iteration 6038 | Cost: 0.3259390130698681 | Gradient: [[ 0.03051666]\n",
      " [-0.06298585]\n",
      " [ 0.10735824]]\n",
      "Iteration 6039 | Cost: 0.3259225894251817 | Gradient: [[ 0.0305164 ]\n",
      " [-0.06298004]\n",
      " [ 0.10734996]]\n",
      "Iteration 6040 | Cost: 0.3259061683057944 | Gradient: [[ 0.03051614]\n",
      " [-0.06297424]\n",
      " [ 0.10734168]]\n",
      "Iteration 6041 | Cost: 0.32588974971113627 | Gradient: [[ 0.03051588]\n",
      " [-0.06296843]\n",
      " [ 0.1073334 ]]\n",
      "Iteration 6042 | Cost: 0.325873333640638 | Gradient: [[ 0.03051561]\n",
      " [-0.06296263]\n",
      " [ 0.10732512]]\n",
      "Iteration 6043 | Cost: 0.32585692009372996 | Gradient: [[ 0.03051535]\n",
      " [-0.06295683]\n",
      " [ 0.10731685]]\n",
      "Iteration 6044 | Cost: 0.325840509069843 | Gradient: [[ 0.03051508]\n",
      " [-0.06295103]\n",
      " [ 0.10730857]]\n",
      "Iteration 6045 | Cost: 0.32582410056840805 | Gradient: [[ 0.03051482]\n",
      " [-0.06294524]\n",
      " [ 0.10730029]]\n",
      "Iteration 6046 | Cost: 0.3258076945888563 | Gradient: [[ 0.03051455]\n",
      " [-0.06293944]\n",
      " [ 0.10729202]]\n",
      "Iteration 6047 | Cost: 0.325791291130619 | Gradient: [[ 0.03051429]\n",
      " [-0.06293365]\n",
      " [ 0.10728374]]\n",
      "Iteration 6048 | Cost: 0.32577489019312783 | Gradient: [[ 0.03051402]\n",
      " [-0.06292786]\n",
      " [ 0.10727547]]\n",
      "Iteration 6049 | Cost: 0.3257584917758144 | Gradient: [[ 0.03051375]\n",
      " [-0.06292207]\n",
      " [ 0.1072672 ]]\n",
      "Iteration 6050 | Cost: 0.3257420958781105 | Gradient: [[ 0.03051348]\n",
      " [-0.06291628]\n",
      " [ 0.10725893]]\n",
      "Iteration 6051 | Cost: 0.3257257024994484 | Gradient: [[ 0.03051321]\n",
      " [-0.0629105 ]\n",
      " [ 0.10725065]]\n",
      "Iteration 6052 | Cost: 0.3257093116392603 | Gradient: [[ 0.03051294]\n",
      " [-0.06290472]\n",
      " [ 0.10724238]]\n",
      "Iteration 6053 | Cost: 0.3256929232969787 | Gradient: [[ 0.03051267]\n",
      " [-0.06289894]\n",
      " [ 0.10723411]]\n",
      "Iteration 6054 | Cost: 0.3256765374720362 | Gradient: [[ 0.0305124 ]\n",
      " [-0.06289316]\n",
      " [ 0.10722584]]\n",
      "Iteration 6055 | Cost: 0.3256601541638655 | Gradient: [[ 0.03051213]\n",
      " [-0.06288738]\n",
      " [ 0.10721758]]\n",
      "Iteration 6056 | Cost: 0.3256437733718998 | Gradient: [[ 0.03051185]\n",
      " [-0.06288161]\n",
      " [ 0.10720931]]\n",
      "Iteration 6057 | Cost: 0.32562739509557237 | Gradient: [[ 0.03051158]\n",
      " [-0.06287583]\n",
      " [ 0.10720104]]\n",
      "Iteration 6058 | Cost: 0.3256110193343163 | Gradient: [[ 0.03051131]\n",
      " [-0.06287006]\n",
      " [ 0.10719277]]\n",
      "Iteration 6059 | Cost: 0.3255946460875655 | Gradient: [[ 0.03051103]\n",
      " [-0.06286429]\n",
      " [ 0.10718451]]\n",
      "Iteration 6060 | Cost: 0.3255782753547535 | Gradient: [[ 0.03051075]\n",
      " [-0.06285853]\n",
      " [ 0.10717624]]\n",
      "Iteration 6061 | Cost: 0.3255619071353143 | Gradient: [[ 0.03051048]\n",
      " [-0.06285276]\n",
      " [ 0.10716798]]\n",
      "Iteration 6062 | Cost: 0.32554554142868203 | Gradient: [[ 0.0305102 ]\n",
      " [-0.062847  ]\n",
      " [ 0.10715972]]\n",
      "Iteration 6063 | Cost: 0.32552917823429106 | Gradient: [[ 0.03050992]\n",
      " [-0.06284124]\n",
      " [ 0.10715145]]\n",
      "Iteration 6064 | Cost: 0.32551281755157585 | Gradient: [[ 0.03050964]\n",
      " [-0.06283548]\n",
      " [ 0.10714319]]\n",
      "Iteration 6065 | Cost: 0.32549645937997107 | Gradient: [[ 0.03050936]\n",
      " [-0.06282972]\n",
      " [ 0.10713493]]\n",
      "Iteration 6066 | Cost: 0.3254801037189116 | Gradient: [[ 0.03050908]\n",
      " [-0.06282397]\n",
      " [ 0.10712667]]\n",
      "Iteration 6067 | Cost: 0.3254637505678325 | Gradient: [[ 0.0305088 ]\n",
      " [-0.06281821]\n",
      " [ 0.10711841]]\n",
      "Iteration 6068 | Cost: 0.32544739992616906 | Gradient: [[ 0.03050852]\n",
      " [-0.06281246]\n",
      " [ 0.10711015]]\n",
      "Iteration 6069 | Cost: 0.32543105179335663 | Gradient: [[ 0.03050824]\n",
      " [-0.06280671]\n",
      " [ 0.10710189]]\n",
      "Iteration 6070 | Cost: 0.3254147061688309 | Gradient: [[ 0.03050796]\n",
      " [-0.06280096]\n",
      " [ 0.10709364]]\n",
      "Iteration 6071 | Cost: 0.3253983630520276 | Gradient: [[ 0.03050767]\n",
      " [-0.06279522]\n",
      " [ 0.10708538]]\n",
      "Iteration 6072 | Cost: 0.3253820224423827 | Gradient: [[ 0.03050739]\n",
      " [-0.06278948]\n",
      " [ 0.10707713]]\n",
      "Iteration 6073 | Cost: 0.32536568433933244 | Gradient: [[ 0.0305071 ]\n",
      " [-0.06278373]\n",
      " [ 0.10706887]]\n",
      "Iteration 6074 | Cost: 0.325349348742313 | Gradient: [[ 0.03050682]\n",
      " [-0.06277799]\n",
      " [ 0.10706062]]\n",
      "Iteration 6075 | Cost: 0.3253330156507612 | Gradient: [[ 0.03050653]\n",
      " [-0.06277226]\n",
      " [ 0.10705236]]\n",
      "Iteration 6076 | Cost: 0.3253166850641136 | Gradient: [[ 0.03050624]\n",
      " [-0.06276652]\n",
      " [ 0.10704411]]\n",
      "Iteration 6077 | Cost: 0.325300356981807 | Gradient: [[ 0.03050595]\n",
      " [-0.06276079]\n",
      " [ 0.10703586]]\n",
      "Iteration 6078 | Cost: 0.3252840314032786 | Gradient: [[ 0.03050567]\n",
      " [-0.06275506]\n",
      " [ 0.10702761]]\n",
      "Iteration 6079 | Cost: 0.32526770832796575 | Gradient: [[ 0.03050538]\n",
      " [-0.06274933]\n",
      " [ 0.10701936]]\n",
      "Iteration 6080 | Cost: 0.3252513877553057 | Gradient: [[ 0.03050509]\n",
      " [-0.0627436 ]\n",
      " [ 0.10701111]]\n",
      "Iteration 6081 | Cost: 0.32523506968473626 | Gradient: [[ 0.0305048 ]\n",
      " [-0.06273787]\n",
      " [ 0.10700286]]\n",
      "Iteration 6082 | Cost: 0.3252187541156951 | Gradient: [[ 0.0305045 ]\n",
      " [-0.06273215]\n",
      " [ 0.10699461]]\n",
      "Iteration 6083 | Cost: 0.3252024410476204 | Gradient: [[ 0.03050421]\n",
      " [-0.06272643]\n",
      " [ 0.10698636]]\n",
      "Iteration 6084 | Cost: 0.32518613047995026 | Gradient: [[ 0.03050392]\n",
      " [-0.06272071]\n",
      " [ 0.10697811]]\n",
      "Iteration 6085 | Cost: 0.325169822412123 | Gradient: [[ 0.03050363]\n",
      " [-0.06271499]\n",
      " [ 0.10696987]]\n",
      "Iteration 6086 | Cost: 0.32515351684357724 | Gradient: [[ 0.03050333]\n",
      " [-0.06270927]\n",
      " [ 0.10696162]]\n",
      "Iteration 6087 | Cost: 0.3251372137737516 | Gradient: [[ 0.03050304]\n",
      " [-0.06270356]\n",
      " [ 0.10695338]]\n",
      "Iteration 6088 | Cost: 0.32512091320208514 | Gradient: [[ 0.03050274]\n",
      " [-0.06269784]\n",
      " [ 0.10694513]]\n",
      "Iteration 6089 | Cost: 0.32510461512801697 | Gradient: [[ 0.03050244]\n",
      " [-0.06269213]\n",
      " [ 0.10693689]]\n",
      "Iteration 6090 | Cost: 0.32508831955098627 | Gradient: [[ 0.03050215]\n",
      " [-0.06268642]\n",
      " [ 0.10692865]]\n",
      "Iteration 6091 | Cost: 0.32507202647043254 | Gradient: [[ 0.03050185]\n",
      " [-0.06268072]\n",
      " [ 0.10692041]]\n",
      "Iteration 6092 | Cost: 0.32505573588579545 | Gradient: [[ 0.03050155]\n",
      " [-0.06267501]\n",
      " [ 0.10691217]]\n",
      "Iteration 6093 | Cost: 0.3250394477965149 | Gradient: [[ 0.03050125]\n",
      " [-0.06266931]\n",
      " [ 0.10690393]]\n",
      "Iteration 6094 | Cost: 0.32502316220203076 | Gradient: [[ 0.03050095]\n",
      " [-0.06266361]\n",
      " [ 0.10689569]]\n",
      "Iteration 6095 | Cost: 0.3250068791017832 | Gradient: [[ 0.03050065]\n",
      " [-0.06265791]\n",
      " [ 0.10688745]]\n",
      "Iteration 6096 | Cost: 0.32499059849521283 | Gradient: [[ 0.03050035]\n",
      " [-0.06265221]\n",
      " [ 0.10687921]]\n",
      "Iteration 6097 | Cost: 0.32497432038176 | Gradient: [[ 0.03050005]\n",
      " [-0.06264652]\n",
      " [ 0.10687097]]\n",
      "Iteration 6098 | Cost: 0.32495804476086554 | Gradient: [[ 0.03049975]\n",
      " [-0.06264082]\n",
      " [ 0.10686274]]\n",
      "Iteration 6099 | Cost: 0.32494177163197036 | Gradient: [[ 0.03049944]\n",
      " [-0.06263513]\n",
      " [ 0.1068545 ]]\n",
      "Iteration 6100 | Cost: 0.32492550099451556 | Gradient: [[ 0.03049914]\n",
      " [-0.06262944]\n",
      " [ 0.10684627]]\n",
      "Iteration 6101 | Cost: 0.3249092328479425 | Gradient: [[ 0.03049883]\n",
      " [-0.06262376]\n",
      " [ 0.10683803]]\n",
      "Iteration 6102 | Cost: 0.32489296719169247 | Gradient: [[ 0.03049853]\n",
      " [-0.06261807]\n",
      " [ 0.1068298 ]]\n",
      "Iteration 6103 | Cost: 0.3248767040252073 | Gradient: [[ 0.03049822]\n",
      " [-0.06261239]\n",
      " [ 0.10682157]]\n",
      "Iteration 6104 | Cost: 0.3248604433479287 | Gradient: [[ 0.03049792]\n",
      " [-0.06260671]\n",
      " [ 0.10681333]]\n",
      "Iteration 6105 | Cost: 0.32484418515929875 | Gradient: [[ 0.03049761]\n",
      " [-0.06260103]\n",
      " [ 0.1068051 ]]\n",
      "Iteration 6106 | Cost: 0.3248279294587596 | Gradient: [[ 0.0304973 ]\n",
      " [-0.06259535]\n",
      " [ 0.10679687]]\n",
      "Iteration 6107 | Cost: 0.3248116762457538 | Gradient: [[ 0.03049699]\n",
      " [-0.06258967]\n",
      " [ 0.10678864]]\n",
      "Iteration 6108 | Cost: 0.3247954255197236 | Gradient: [[ 0.03049668]\n",
      " [-0.062584  ]\n",
      " [ 0.10678041]]\n",
      "Iteration 6109 | Cost: 0.32477917728011185 | Gradient: [[ 0.03049637]\n",
      " [-0.06257833]\n",
      " [ 0.10677219]]\n",
      "Iteration 6110 | Cost: 0.32476293152636165 | Gradient: [[ 0.03049606]\n",
      " [-0.06257266]\n",
      " [ 0.10676396]]\n",
      "Iteration 6111 | Cost: 0.3247466882579158 | Gradient: [[ 0.03049575]\n",
      " [-0.06256699]\n",
      " [ 0.10675573]]\n",
      "Iteration 6112 | Cost: 0.32473044747421786 | Gradient: [[ 0.03049544]\n",
      " [-0.06256132]\n",
      " [ 0.10674751]]\n",
      "Iteration 6113 | Cost: 0.32471420917471105 | Gradient: [[ 0.03049512]\n",
      " [-0.06255566]\n",
      " [ 0.10673928]]\n",
      "Iteration 6114 | Cost: 0.32469797335883926 | Gradient: [[ 0.03049481]\n",
      " [-0.06254999]\n",
      " [ 0.10673106]]\n",
      "Iteration 6115 | Cost: 0.324681740026046 | Gradient: [[ 0.0304945 ]\n",
      " [-0.06254433]\n",
      " [ 0.10672283]]\n",
      "Iteration 6116 | Cost: 0.3246655091757756 | Gradient: [[ 0.03049418]\n",
      " [-0.06253867]\n",
      " [ 0.10671461]]\n",
      "Iteration 6117 | Cost: 0.32464928080747196 | Gradient: [[ 0.03049387]\n",
      " [-0.06253302]\n",
      " [ 0.10670639]]\n",
      "Iteration 6118 | Cost: 0.32463305492057953 | Gradient: [[ 0.03049355]\n",
      " [-0.06252736]\n",
      " [ 0.10669817]]\n",
      "Iteration 6119 | Cost: 0.3246168315145429 | Gradient: [[ 0.03049323]\n",
      " [-0.06252171]\n",
      " [ 0.10668995]]\n",
      "Iteration 6120 | Cost: 0.32460061058880685 | Gradient: [[ 0.03049292]\n",
      " [-0.06251606]\n",
      " [ 0.10668173]]\n",
      "Iteration 6121 | Cost: 0.32458439214281604 | Gradient: [[ 0.0304926 ]\n",
      " [-0.06251041]\n",
      " [ 0.10667351]]\n",
      "Iteration 6122 | Cost: 0.32456817617601574 | Gradient: [[ 0.03049228]\n",
      " [-0.06250476]\n",
      " [ 0.10666529]]\n",
      "Iteration 6123 | Cost: 0.3245519626878512 | Gradient: [[ 0.03049196]\n",
      " [-0.06249911]\n",
      " [ 0.10665707]]\n",
      "Iteration 6124 | Cost: 0.32453575167776777 | Gradient: [[ 0.03049164]\n",
      " [-0.06249347]\n",
      " [ 0.10664885]]\n",
      "Iteration 6125 | Cost: 0.3245195431452112 | Gradient: [[ 0.03049132]\n",
      " [-0.06248783]\n",
      " [ 0.10664064]]\n",
      "Iteration 6126 | Cost: 0.3245033370896271 | Gradient: [[ 0.03049099]\n",
      " [-0.06248219]\n",
      " [ 0.10663242]]\n",
      "Iteration 6127 | Cost: 0.32448713351046155 | Gradient: [[ 0.03049067]\n",
      " [-0.06247655]\n",
      " [ 0.10662421]]\n",
      "Iteration 6128 | Cost: 0.3244709324071607 | Gradient: [[ 0.03049035]\n",
      " [-0.06247091]\n",
      " [ 0.10661599]]\n",
      "Iteration 6129 | Cost: 0.32445473377917083 | Gradient: [[ 0.03049003]\n",
      " [-0.06246528]\n",
      " [ 0.10660778]]\n",
      "Iteration 6130 | Cost: 0.32443853762593855 | Gradient: [[ 0.0304897 ]\n",
      " [-0.06245965]\n",
      " [ 0.10659957]]\n",
      "Iteration 6131 | Cost: 0.32442234394691044 | Gradient: [[ 0.03048938]\n",
      " [-0.06245402]\n",
      " [ 0.10659136]]\n",
      "Iteration 6132 | Cost: 0.32440615274153345 | Gradient: [[ 0.03048905]\n",
      " [-0.06244839]\n",
      " [ 0.10658315]]\n",
      "Iteration 6133 | Cost: 0.32438996400925446 | Gradient: [[ 0.03048872]\n",
      " [-0.06244276]\n",
      " [ 0.10657494]]\n",
      "Iteration 6134 | Cost: 0.3243737777495209 | Gradient: [[ 0.0304884 ]\n",
      " [-0.06243714]\n",
      " [ 0.10656673]]\n",
      "Iteration 6135 | Cost: 0.32435759396178016 | Gradient: [[ 0.03048807]\n",
      " [-0.06243151]\n",
      " [ 0.10655852]]\n",
      "Iteration 6136 | Cost: 0.3243414126454796 | Gradient: [[ 0.03048774]\n",
      " [-0.06242589]\n",
      " [ 0.10655031]]\n",
      "Iteration 6137 | Cost: 0.3243252338000673 | Gradient: [[ 0.03048741]\n",
      " [-0.06242027]\n",
      " [ 0.1065421 ]]\n",
      "Iteration 6138 | Cost: 0.3243090574249909 | Gradient: [[ 0.03048708]\n",
      " [-0.06241466]\n",
      " [ 0.1065339 ]]\n",
      "Iteration 6139 | Cost: 0.32429288351969876 | Gradient: [[ 0.03048675]\n",
      " [-0.06240904]\n",
      " [ 0.10652569]]\n",
      "Iteration 6140 | Cost: 0.32427671208363895 | Gradient: [[ 0.03048642]\n",
      " [-0.06240343]\n",
      " [ 0.10651749]]\n",
      "Iteration 6141 | Cost: 0.32426054311626 | Gradient: [[ 0.03048609]\n",
      " [-0.06239782]\n",
      " [ 0.10650928]]\n",
      "Iteration 6142 | Cost: 0.3242443766170106 | Gradient: [[ 0.03048575]\n",
      " [-0.06239221]\n",
      " [ 0.10650108]]\n",
      "Iteration 6143 | Cost: 0.3242282125853397 | Gradient: [[ 0.03048542]\n",
      " [-0.0623866 ]\n",
      " [ 0.10649288]]\n",
      "Iteration 6144 | Cost: 0.324212051020696 | Gradient: [[ 0.03048509]\n",
      " [-0.06238099]\n",
      " [ 0.10648468]]\n",
      "Iteration 6145 | Cost: 0.3241958919225289 | Gradient: [[ 0.03048475]\n",
      " [-0.06237539]\n",
      " [ 0.10647647]]\n",
      "Iteration 6146 | Cost: 0.3241797352902878 | Gradient: [[ 0.03048442]\n",
      " [-0.06236978]\n",
      " [ 0.10646827]]\n",
      "Iteration 6147 | Cost: 0.324163581123422 | Gradient: [[ 0.03048408]\n",
      " [-0.06236418]\n",
      " [ 0.10646007]]\n",
      "Iteration 6148 | Cost: 0.3241474294213814 | Gradient: [[ 0.03048375]\n",
      " [-0.06235859]\n",
      " [ 0.10645188]]\n",
      "Iteration 6149 | Cost: 0.3241312801836158 | Gradient: [[ 0.03048341]\n",
      " [-0.06235299]\n",
      " [ 0.10644368]]\n",
      "Iteration 6150 | Cost: 0.32411513340957526 | Gradient: [[ 0.03048307]\n",
      " [-0.06234739]\n",
      " [ 0.10643548]]\n",
      "Iteration 6151 | Cost: 0.3240989890987101 | Gradient: [[ 0.03048273]\n",
      " [-0.0623418 ]\n",
      " [ 0.10642728]]\n",
      "Iteration 6152 | Cost: 0.32408284725047065 | Gradient: [[ 0.03048239]\n",
      " [-0.06233621]\n",
      " [ 0.10641909]]\n",
      "Iteration 6153 | Cost: 0.3240667078643076 | Gradient: [[ 0.03048205]\n",
      " [-0.06233062]\n",
      " [ 0.10641089]]\n",
      "Iteration 6154 | Cost: 0.3240505709396716 | Gradient: [[ 0.03048171]\n",
      " [-0.06232503]\n",
      " [ 0.1064027 ]]\n",
      "Iteration 6155 | Cost: 0.3240344364760137 | Gradient: [[ 0.03048137]\n",
      " [-0.06231945]\n",
      " [ 0.10639451]]\n",
      "Iteration 6156 | Cost: 0.3240183044727849 | Gradient: [[ 0.03048103]\n",
      " [-0.06231386]\n",
      " [ 0.10638631]]\n",
      "Iteration 6157 | Cost: 0.3240021749294367 | Gradient: [[ 0.03048069]\n",
      " [-0.06230828]\n",
      " [ 0.10637812]]\n",
      "Iteration 6158 | Cost: 0.32398604784542034 | Gradient: [[ 0.03048034]\n",
      " [-0.0623027 ]\n",
      " [ 0.10636993]]\n",
      "Iteration 6159 | Cost: 0.3239699232201876 | Gradient: [[ 0.03048   ]\n",
      " [-0.06229712]\n",
      " [ 0.10636174]]\n",
      "Iteration 6160 | Cost: 0.3239538010531903 | Gradient: [[ 0.03047965]\n",
      " [-0.06229155]\n",
      " [ 0.10635355]]\n",
      "Iteration 6161 | Cost: 0.3239376813438804 | Gradient: [[ 0.03047931]\n",
      " [-0.06228597]\n",
      " [ 0.10634536]]\n",
      "Iteration 6162 | Cost: 0.32392156409171013 | Gradient: [[ 0.03047896]\n",
      " [-0.0622804 ]\n",
      " [ 0.10633717]]\n",
      "Iteration 6163 | Cost: 0.3239054492961318 | Gradient: [[ 0.03047862]\n",
      " [-0.06227483]\n",
      " [ 0.10632899]]\n",
      "Iteration 6164 | Cost: 0.32388933695659794 | Gradient: [[ 0.03047827]\n",
      " [-0.06226926]\n",
      " [ 0.1063208 ]]\n",
      "Iteration 6165 | Cost: 0.3238732270725612 | Gradient: [[ 0.03047792]\n",
      " [-0.06226369]\n",
      " [ 0.10631261]]\n",
      "Iteration 6166 | Cost: 0.32385711964347463 | Gradient: [[ 0.03047757]\n",
      " [-0.06225813]\n",
      " [ 0.10630443]]\n",
      "Iteration 6167 | Cost: 0.32384101466879117 | Gradient: [[ 0.03047722]\n",
      " [-0.06225256]\n",
      " [ 0.10629624]]\n",
      "Iteration 6168 | Cost: 0.32382491214796405 | Gradient: [[ 0.03047687]\n",
      " [-0.062247  ]\n",
      " [ 0.10628806]]\n",
      "Iteration 6169 | Cost: 0.3238088120804466 | Gradient: [[ 0.03047652]\n",
      " [-0.06224144]\n",
      " [ 0.10627988]]\n",
      "Iteration 6170 | Cost: 0.3237927144656925 | Gradient: [[ 0.03047617]\n",
      " [-0.06223588]\n",
      " [ 0.1062717 ]]\n",
      "Iteration 6171 | Cost: 0.3237766193031556 | Gradient: [[ 0.03047582]\n",
      " [-0.06223033]\n",
      " [ 0.10626351]]\n",
      "Iteration 6172 | Cost: 0.3237605265922896 | Gradient: [[ 0.03047547]\n",
      " [-0.06222477]\n",
      " [ 0.10625533]]\n",
      "Iteration 6173 | Cost: 0.3237444363325487 | Gradient: [[ 0.03047512]\n",
      " [-0.06221922]\n",
      " [ 0.10624715]]\n",
      "Iteration 6174 | Cost: 0.3237283485233871 | Gradient: [[ 0.03047476]\n",
      " [-0.06221367]\n",
      " [ 0.10623897]]\n",
      "Iteration 6175 | Cost: 0.3237122631642596 | Gradient: [[ 0.03047441]\n",
      " [-0.06220812]\n",
      " [ 0.1062308 ]]\n",
      "Iteration 6176 | Cost: 0.3236961802546203 | Gradient: [[ 0.03047405]\n",
      " [-0.06220257]\n",
      " [ 0.10622262]]\n",
      "Iteration 6177 | Cost: 0.3236800997939245 | Gradient: [[ 0.0304737 ]\n",
      " [-0.06219703]\n",
      " [ 0.10621444]]\n",
      "Iteration 6178 | Cost: 0.3236640217816268 | Gradient: [[ 0.03047334]\n",
      " [-0.06219149]\n",
      " [ 0.10620627]]\n",
      "Iteration 6179 | Cost: 0.3236479462171825 | Gradient: [[ 0.03047298]\n",
      " [-0.06218594]\n",
      " [ 0.10619809]]\n",
      "Iteration 6180 | Cost: 0.32363187310004693 | Gradient: [[ 0.03047263]\n",
      " [-0.0621804 ]\n",
      " [ 0.10618992]]\n",
      "Iteration 6181 | Cost: 0.3236158024296756 | Gradient: [[ 0.03047227]\n",
      " [-0.06217487]\n",
      " [ 0.10618174]]\n",
      "Iteration 6182 | Cost: 0.32359973420552407 | Gradient: [[ 0.03047191]\n",
      " [-0.06216933]\n",
      " [ 0.10617357]]\n",
      "Iteration 6183 | Cost: 0.3235836684270482 | Gradient: [[ 0.03047155]\n",
      " [-0.0621638 ]\n",
      " [ 0.1061654 ]]\n",
      "Iteration 6184 | Cost: 0.32356760509370425 | Gradient: [[ 0.03047119]\n",
      " [-0.06215826]\n",
      " [ 0.10615723]]\n",
      "Iteration 6185 | Cost: 0.32355154420494814 | Gradient: [[ 0.03047083]\n",
      " [-0.06215273]\n",
      " [ 0.10614906]]\n",
      "Iteration 6186 | Cost: 0.3235354857602363 | Gradient: [[ 0.03047047]\n",
      " [-0.0621472 ]\n",
      " [ 0.10614089]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6187 | Cost: 0.3235194297590253 | Gradient: [[ 0.0304701 ]\n",
      " [-0.06214168]\n",
      " [ 0.10613272]]\n",
      "Iteration 6188 | Cost: 0.32350337620077185 | Gradient: [[ 0.03046974]\n",
      " [-0.06213615]\n",
      " [ 0.10612455]]\n",
      "Iteration 6189 | Cost: 0.32348732508493283 | Gradient: [[ 0.03046938]\n",
      " [-0.06213063]\n",
      " [ 0.10611638]]\n",
      "Iteration 6190 | Cost: 0.32347127641096524 | Gradient: [[ 0.03046901]\n",
      " [-0.06212511]\n",
      " [ 0.10610821]]\n",
      "Iteration 6191 | Cost: 0.32345523017832634 | Gradient: [[ 0.03046865]\n",
      " [-0.06211959]\n",
      " [ 0.10610005]]\n",
      "Iteration 6192 | Cost: 0.3234391863864737 | Gradient: [[ 0.03046828]\n",
      " [-0.06211407]\n",
      " [ 0.10609188]]\n",
      "Iteration 6193 | Cost: 0.3234231450348646 | Gradient: [[ 0.03046792]\n",
      " [-0.06210855]\n",
      " [ 0.10608372]]\n",
      "Iteration 6194 | Cost: 0.323407106122957 | Gradient: [[ 0.03046755]\n",
      " [-0.06210304]\n",
      " [ 0.10607555]]\n",
      "Iteration 6195 | Cost: 0.32339106965020875 | Gradient: [[ 0.03046718]\n",
      " [-0.06209753]\n",
      " [ 0.10606739]]\n",
      "Iteration 6196 | Cost: 0.32337503561607794 | Gradient: [[ 0.03046682]\n",
      " [-0.06209202]\n",
      " [ 0.10605923]]\n",
      "Iteration 6197 | Cost: 0.32335900402002277 | Gradient: [[ 0.03046645]\n",
      " [-0.06208651]\n",
      " [ 0.10605107]]\n",
      "Iteration 6198 | Cost: 0.3233429748615018 | Gradient: [[ 0.03046608]\n",
      " [-0.062081  ]\n",
      " [ 0.10604291]]\n",
      "Iteration 6199 | Cost: 0.32332694813997365 | Gradient: [[ 0.03046571]\n",
      " [-0.0620755 ]\n",
      " [ 0.10603475]]\n",
      "Iteration 6200 | Cost: 0.32331092385489696 | Gradient: [[ 0.03046534]\n",
      " [-0.06206999]\n",
      " [ 0.10602659]]\n",
      "Iteration 6201 | Cost: 0.3232949020057308 | Gradient: [[ 0.03046497]\n",
      " [-0.06206449]\n",
      " [ 0.10601843]]\n",
      "Iteration 6202 | Cost: 0.3232788825919342 | Gradient: [[ 0.03046459]\n",
      " [-0.06205899]\n",
      " [ 0.10601027]]\n",
      "Iteration 6203 | Cost: 0.32326286561296663 | Gradient: [[ 0.03046422]\n",
      " [-0.06205349]\n",
      " [ 0.10600211]]\n",
      "Iteration 6204 | Cost: 0.32324685106828743 | Gradient: [[ 0.03046385]\n",
      " [-0.062048  ]\n",
      " [ 0.10599396]]\n",
      "Iteration 6205 | Cost: 0.3232308389573561 | Gradient: [[ 0.03046347]\n",
      " [-0.0620425 ]\n",
      " [ 0.1059858 ]]\n",
      "Iteration 6206 | Cost: 0.3232148292796328 | Gradient: [[ 0.0304631 ]\n",
      " [-0.06203701]\n",
      " [ 0.10597765]]\n",
      "Iteration 6207 | Cost: 0.3231988220345772 | Gradient: [[ 0.03046273]\n",
      " [-0.06203152]\n",
      " [ 0.10596949]]\n",
      "Iteration 6208 | Cost: 0.32318281722164965 | Gradient: [[ 0.03046235]\n",
      " [-0.06202603]\n",
      " [ 0.10596134]]\n",
      "Iteration 6209 | Cost: 0.32316681484031035 | Gradient: [[ 0.03046197]\n",
      " [-0.06202054]\n",
      " [ 0.10595319]]\n",
      "Iteration 6210 | Cost: 0.3231508148900199 | Gradient: [[ 0.0304616 ]\n",
      " [-0.06201506]\n",
      " [ 0.10594504]]\n",
      "Iteration 6211 | Cost: 0.3231348173702389 | Gradient: [[ 0.03046122]\n",
      " [-0.06200958]\n",
      " [ 0.10593689]]\n",
      "Iteration 6212 | Cost: 0.3231188222804282 | Gradient: [[ 0.03046084]\n",
      " [-0.06200409]\n",
      " [ 0.10592874]]\n",
      "Iteration 6213 | Cost: 0.3231028296200488 | Gradient: [[ 0.03046046]\n",
      " [-0.06199861]\n",
      " [ 0.10592059]]\n",
      "Iteration 6214 | Cost: 0.323086839388562 | Gradient: [[ 0.03046008]\n",
      " [-0.06199314]\n",
      " [ 0.10591244]]\n",
      "Iteration 6215 | Cost: 0.323070851585429 | Gradient: [[ 0.0304597 ]\n",
      " [-0.06198766]\n",
      " [ 0.10590429]]\n",
      "Iteration 6216 | Cost: 0.3230548662101113 | Gradient: [[ 0.03045932]\n",
      " [-0.06198218]\n",
      " [ 0.10589614]]\n",
      "Iteration 6217 | Cost: 0.3230388832620708 | Gradient: [[ 0.03045894]\n",
      " [-0.06197671]\n",
      " [ 0.105888  ]]\n",
      "Iteration 6218 | Cost: 0.32302290274076917 | Gradient: [[ 0.03045856]\n",
      " [-0.06197124]\n",
      " [ 0.10587985]]\n",
      "Iteration 6219 | Cost: 0.3230069246456685 | Gradient: [[ 0.03045817]\n",
      " [-0.06196577]\n",
      " [ 0.10587171]]\n",
      "Iteration 6220 | Cost: 0.32299094897623104 | Gradient: [[ 0.03045779]\n",
      " [-0.0619603 ]\n",
      " [ 0.10586356]]\n",
      "Iteration 6221 | Cost: 0.3229749757319191 | Gradient: [[ 0.03045741]\n",
      " [-0.06195484]\n",
      " [ 0.10585542]]\n",
      "Iteration 6222 | Cost: 0.32295900491219526 | Gradient: [[ 0.03045702]\n",
      " [-0.06194937]\n",
      " [ 0.10584728]]\n",
      "Iteration 6223 | Cost: 0.3229430365165223 | Gradient: [[ 0.03045664]\n",
      " [-0.06194391]\n",
      " [ 0.10583914]]\n",
      "Iteration 6224 | Cost: 0.32292707054436287 | Gradient: [[ 0.03045625]\n",
      " [-0.06193845]\n",
      " [ 0.105831  ]]\n",
      "Iteration 6225 | Cost: 0.3229111069951804 | Gradient: [[ 0.03045587]\n",
      " [-0.06193299]\n",
      " [ 0.10582286]]\n",
      "Iteration 6226 | Cost: 0.32289514586843776 | Gradient: [[ 0.03045548]\n",
      " [-0.06192754]\n",
      " [ 0.10581472]]\n",
      "Iteration 6227 | Cost: 0.32287918716359854 | Gradient: [[ 0.03045509]\n",
      " [-0.06192208]\n",
      " [ 0.10580658]]\n",
      "Iteration 6228 | Cost: 0.32286323088012625 | Gradient: [[ 0.0304547 ]\n",
      " [-0.06191663]\n",
      " [ 0.10579844]]\n",
      "Iteration 6229 | Cost: 0.32284727701748456 | Gradient: [[ 0.03045431]\n",
      " [-0.06191118]\n",
      " [ 0.1057903 ]]\n",
      "Iteration 6230 | Cost: 0.3228313255751375 | Gradient: [[ 0.03045392]\n",
      " [-0.06190573]\n",
      " [ 0.10578217]]\n",
      "Iteration 6231 | Cost: 0.3228153765525491 | Gradient: [[ 0.03045353]\n",
      " [-0.06190028]\n",
      " [ 0.10577403]]\n",
      "Iteration 6232 | Cost: 0.3227994299491835 | Gradient: [[ 0.03045314]\n",
      " [-0.06189483]\n",
      " [ 0.1057659 ]]\n",
      "Iteration 6233 | Cost: 0.3227834857645053 | Gradient: [[ 0.03045275]\n",
      " [-0.06188939]\n",
      " [ 0.10575776]]\n",
      "Iteration 6234 | Cost: 0.3227675439979789 | Gradient: [[ 0.03045236]\n",
      " [-0.06188395]\n",
      " [ 0.10574963]]\n",
      "Iteration 6235 | Cost: 0.3227516046490691 | Gradient: [[ 0.03045197]\n",
      " [-0.06187851]\n",
      " [ 0.1057415 ]]\n",
      "Iteration 6236 | Cost: 0.32273566771724094 | Gradient: [[ 0.03045157]\n",
      " [-0.06187307]\n",
      " [ 0.10573337]]\n",
      "Iteration 6237 | Cost: 0.3227197332019593 | Gradient: [[ 0.03045118]\n",
      " [-0.06186763]\n",
      " [ 0.10572523]]\n",
      "Iteration 6238 | Cost: 0.3227038011026896 | Gradient: [[ 0.03045078]\n",
      " [-0.0618622 ]\n",
      " [ 0.1057171 ]]\n",
      "Iteration 6239 | Cost: 0.32268787141889715 | Gradient: [[ 0.03045039]\n",
      " [-0.06185676]\n",
      " [ 0.10570897]]\n",
      "Iteration 6240 | Cost: 0.32267194415004763 | Gradient: [[ 0.03044999]\n",
      " [-0.06185133]\n",
      " [ 0.10570085]]\n",
      "Iteration 6241 | Cost: 0.3226560192956068 | Gradient: [[ 0.0304496 ]\n",
      " [-0.0618459 ]\n",
      " [ 0.10569272]]\n",
      "Iteration 6242 | Cost: 0.3226400968550404 | Gradient: [[ 0.0304492 ]\n",
      " [-0.06184047]\n",
      " [ 0.10568459]]\n",
      "Iteration 6243 | Cost: 0.32262417682781486 | Gradient: [[ 0.0304488 ]\n",
      " [-0.06183504]\n",
      " [ 0.10567647]]\n",
      "Iteration 6244 | Cost: 0.32260825921339614 | Gradient: [[ 0.0304484 ]\n",
      " [-0.06182962]\n",
      " [ 0.10566834]]\n",
      "Iteration 6245 | Cost: 0.32259234401125086 | Gradient: [[ 0.030448  ]\n",
      " [-0.0618242 ]\n",
      " [ 0.10566021]]\n",
      "Iteration 6246 | Cost: 0.3225764312208455 | Gradient: [[ 0.0304476 ]\n",
      " [-0.06181878]\n",
      " [ 0.10565209]]\n",
      "Iteration 6247 | Cost: 0.32256052084164694 | Gradient: [[ 0.0304472 ]\n",
      " [-0.06181336]\n",
      " [ 0.10564397]]\n",
      "Iteration 6248 | Cost: 0.3225446128731221 | Gradient: [[ 0.0304468 ]\n",
      " [-0.06180794]\n",
      " [ 0.10563585]]\n",
      "Iteration 6249 | Cost: 0.322528707314738 | Gradient: [[ 0.0304464 ]\n",
      " [-0.06180252]\n",
      " [ 0.10562772]]\n",
      "Iteration 6250 | Cost: 0.32251280416596195 | Gradient: [[ 0.030446  ]\n",
      " [-0.06179711]\n",
      " [ 0.1056196 ]]\n",
      "Iteration 6251 | Cost: 0.32249690342626136 | Gradient: [[ 0.0304456 ]\n",
      " [-0.0617917 ]\n",
      " [ 0.10561148]]\n",
      "Iteration 6252 | Cost: 0.32248100509510397 | Gradient: [[ 0.03044519]\n",
      " [-0.06178628]\n",
      " [ 0.10560336]]\n",
      "Iteration 6253 | Cost: 0.3224651091719574 | Gradient: [[ 0.03044479]\n",
      " [-0.06178088]\n",
      " [ 0.10559524]]\n",
      "Iteration 6254 | Cost: 0.3224492156562897 | Gradient: [[ 0.03044439]\n",
      " [-0.06177547]\n",
      " [ 0.10558713]]\n",
      "Iteration 6255 | Cost: 0.3224333245475689 | Gradient: [[ 0.03044398]\n",
      " [-0.06177006]\n",
      " [ 0.10557901]]\n",
      "Iteration 6256 | Cost: 0.3224174358452633 | Gradient: [[ 0.03044357]\n",
      " [-0.06176466]\n",
      " [ 0.10557089]]\n",
      "Iteration 6257 | Cost: 0.3224015495488414 | Gradient: [[ 0.03044317]\n",
      " [-0.06175926]\n",
      " [ 0.10556278]]\n",
      "Iteration 6258 | Cost: 0.3223856656577717 | Gradient: [[ 0.03044276]\n",
      " [-0.06175386]\n",
      " [ 0.10555466]]\n",
      "Iteration 6259 | Cost: 0.32236978417152307 | Gradient: [[ 0.03044235]\n",
      " [-0.06174846]\n",
      " [ 0.10554655]]\n",
      "Iteration 6260 | Cost: 0.3223539050895644 | Gradient: [[ 0.03044194]\n",
      " [-0.06174306]\n",
      " [ 0.10553844]]\n",
      "Iteration 6261 | Cost: 0.32233802841136494 | Gradient: [[ 0.03044154]\n",
      " [-0.06173767]\n",
      " [ 0.10553032]]\n",
      "Iteration 6262 | Cost: 0.3223221541363937 | Gradient: [[ 0.03044113]\n",
      " [-0.06173227]\n",
      " [ 0.10552221]]\n",
      "Iteration 6263 | Cost: 0.3223062822641203 | Gradient: [[ 0.03044072]\n",
      " [-0.06172688]\n",
      " [ 0.1055141 ]]\n",
      "Iteration 6264 | Cost: 0.3222904127940144 | Gradient: [[ 0.03044031]\n",
      " [-0.06172149]\n",
      " [ 0.10550599]]\n",
      "Iteration 6265 | Cost: 0.32227454572554565 | Gradient: [[ 0.03043989]\n",
      " [-0.0617161 ]\n",
      " [ 0.10549788]]\n",
      "Iteration 6266 | Cost: 0.32225868105818406 | Gradient: [[ 0.03043948]\n",
      " [-0.06171072]\n",
      " [ 0.10548977]]\n",
      "Iteration 6267 | Cost: 0.3222428187913997 | Gradient: [[ 0.03043907]\n",
      " [-0.06170533]\n",
      " [ 0.10548166]]\n",
      "Iteration 6268 | Cost: 0.3222269589246628 | Gradient: [[ 0.03043866]\n",
      " [-0.06169995]\n",
      " [ 0.10547356]]\n",
      "Iteration 6269 | Cost: 0.32221110145744397 | Gradient: [[ 0.03043824]\n",
      " [-0.06169457]\n",
      " [ 0.10546545]]\n",
      "Iteration 6270 | Cost: 0.3221952463892137 | Gradient: [[ 0.03043783]\n",
      " [-0.06168919]\n",
      " [ 0.10545735]]\n",
      "Iteration 6271 | Cost: 0.32217939371944276 | Gradient: [[ 0.03043741]\n",
      " [-0.06168381]\n",
      " [ 0.10544924]]\n",
      "Iteration 6272 | Cost: 0.3221635434476021 | Gradient: [[ 0.030437  ]\n",
      " [-0.06167844]\n",
      " [ 0.10544114]]\n",
      "Iteration 6273 | Cost: 0.32214769557316286 | Gradient: [[ 0.03043658]\n",
      " [-0.06167306]\n",
      " [ 0.10543303]]\n",
      "Iteration 6274 | Cost: 0.3221318500955963 | Gradient: [[ 0.03043617]\n",
      " [-0.06166769]\n",
      " [ 0.10542493]]\n",
      "Iteration 6275 | Cost: 0.32211600701437376 | Gradient: [[ 0.03043575]\n",
      " [-0.06166232]\n",
      " [ 0.10541683]]\n",
      "Iteration 6276 | Cost: 0.32210016632896693 | Gradient: [[ 0.03043533]\n",
      " [-0.06165695]\n",
      " [ 0.10540873]]\n",
      "Iteration 6277 | Cost: 0.3220843280388476 | Gradient: [[ 0.03043491]\n",
      " [-0.06165158]\n",
      " [ 0.10540063]]\n",
      "Iteration 6278 | Cost: 0.32206849214348765 | Gradient: [[ 0.03043449]\n",
      " [-0.06164622]\n",
      " [ 0.10539253]]\n",
      "Iteration 6279 | Cost: 0.3220526586423591 | Gradient: [[ 0.03043407]\n",
      " [-0.06164085]\n",
      " [ 0.10538443]]\n",
      "Iteration 6280 | Cost: 0.32203682753493446 | Gradient: [[ 0.03043365]\n",
      " [-0.06163549]\n",
      " [ 0.10537633]]\n",
      "Iteration 6281 | Cost: 0.3220209988206859 | Gradient: [[ 0.03043323]\n",
      " [-0.06163013]\n",
      " [ 0.10536824]]\n",
      "Iteration 6282 | Cost: 0.32200517249908617 | Gradient: [[ 0.03043281]\n",
      " [-0.06162477]\n",
      " [ 0.10536014]]\n",
      "Iteration 6283 | Cost: 0.3219893485696078 | Gradient: [[ 0.03043239]\n",
      " [-0.06161941]\n",
      " [ 0.10535204]]\n",
      "Iteration 6284 | Cost: 0.321973527031724 | Gradient: [[ 0.03043196]\n",
      " [-0.06161406]\n",
      " [ 0.10534395]]\n",
      "Iteration 6285 | Cost: 0.32195770788490774 | Gradient: [[ 0.03043154]\n",
      " [-0.06160871]\n",
      " [ 0.10533586]]\n",
      "Iteration 6286 | Cost: 0.3219418911286322 | Gradient: [[ 0.03043112]\n",
      " [-0.06160335]\n",
      " [ 0.10532776]]\n",
      "Iteration 6287 | Cost: 0.3219260767623709 | Gradient: [[ 0.03043069]\n",
      " [-0.061598  ]\n",
      " [ 0.10531967]]\n",
      "Iteration 6288 | Cost: 0.3219102647855973 | Gradient: [[ 0.03043027]\n",
      " [-0.06159266]\n",
      " [ 0.10531158]]\n",
      "Iteration 6289 | Cost: 0.3218944551977853 | Gradient: [[ 0.03042984]\n",
      " [-0.06158731]\n",
      " [ 0.10530349]]\n",
      "Iteration 6290 | Cost: 0.32187864799840865 | Gradient: [[ 0.03042941]\n",
      " [-0.06158196]\n",
      " [ 0.1052954 ]]\n",
      "Iteration 6291 | Cost: 0.3218628431869415 | Gradient: [[ 0.03042899]\n",
      " [-0.06157662]\n",
      " [ 0.10528731]]\n",
      "Iteration 6292 | Cost: 0.32184704076285814 | Gradient: [[ 0.03042856]\n",
      " [-0.06157128]\n",
      " [ 0.10527922]]\n",
      "Iteration 6293 | Cost: 0.3218312407256329 | Gradient: [[ 0.03042813]\n",
      " [-0.06156594]\n",
      " [ 0.10527113]]\n",
      "Iteration 6294 | Cost: 0.3218154430747403 | Gradient: [[ 0.0304277 ]\n",
      " [-0.0615606 ]\n",
      " [ 0.10526305]]\n",
      "Iteration 6295 | Cost: 0.3217996478096551 | Gradient: [[ 0.03042727]\n",
      " [-0.06155527]\n",
      " [ 0.10525496]]\n",
      "Iteration 6296 | Cost: 0.3217838549298523 | Gradient: [[ 0.03042684]\n",
      " [-0.06154993]\n",
      " [ 0.10524687]]\n",
      "Iteration 6297 | Cost: 0.32176806443480677 | Gradient: [[ 0.03042641]\n",
      " [-0.0615446 ]\n",
      " [ 0.10523879]]\n",
      "Iteration 6298 | Cost: 0.3217522763239938 | Gradient: [[ 0.03042598]\n",
      " [-0.06153927]\n",
      " [ 0.10523071]]\n",
      "Iteration 6299 | Cost: 0.32173649059688886 | Gradient: [[ 0.03042555]\n",
      " [-0.06153394]\n",
      " [ 0.10522262]]\n",
      "Iteration 6300 | Cost: 0.32172070725296736 | Gradient: [[ 0.03042512]\n",
      " [-0.06152861]\n",
      " [ 0.10521454]]\n",
      "Iteration 6301 | Cost: 0.32170492629170505 | Gradient: [[ 0.03042468]\n",
      " [-0.06152328]\n",
      " [ 0.10520646]]\n",
      "Iteration 6302 | Cost: 0.32168914771257795 | Gradient: [[ 0.03042425]\n",
      " [-0.06151796]\n",
      " [ 0.10519838]]\n",
      "Iteration 6303 | Cost: 0.3216733715150619 | Gradient: [[ 0.03042382]\n",
      " [-0.06151264]\n",
      " [ 0.1051903 ]]\n",
      "Iteration 6304 | Cost: 0.3216575976986331 | Gradient: [[ 0.03042338]\n",
      " [-0.06150732]\n",
      " [ 0.10518222]]\n",
      "Iteration 6305 | Cost: 0.32164182626276805 | Gradient: [[ 0.03042294]\n",
      " [-0.061502  ]\n",
      " [ 0.10517414]]\n",
      "Iteration 6306 | Cost: 0.32162605720694326 | Gradient: [[ 0.03042251]\n",
      " [-0.06149668]\n",
      " [ 0.10516606]]\n",
      "Iteration 6307 | Cost: 0.3216102905306353 | Gradient: [[ 0.03042207]\n",
      " [-0.06149136]\n",
      " [ 0.10515799]]\n",
      "Iteration 6308 | Cost: 0.3215945262333211 | Gradient: [[ 0.03042163]\n",
      " [-0.06148605]\n",
      " [ 0.10514991]]\n",
      "Iteration 6309 | Cost: 0.32157876431447757 | Gradient: [[ 0.0304212 ]\n",
      " [-0.06148074]\n",
      " [ 0.10514183]]\n",
      "Iteration 6310 | Cost: 0.32156300477358196 | Gradient: [[ 0.03042076]\n",
      " [-0.06147542]\n",
      " [ 0.10513376]]\n",
      "Iteration 6311 | Cost: 0.3215472476101116 | Gradient: [[ 0.03042032]\n",
      " [-0.06147012]\n",
      " [ 0.10512569]]\n",
      "Iteration 6312 | Cost: 0.32153149282354404 | Gradient: [[ 0.03041988]\n",
      " [-0.06146481]\n",
      " [ 0.10511761]]\n",
      "Iteration 6313 | Cost: 0.32151574041335684 | Gradient: [[ 0.03041944]\n",
      " [-0.0614595 ]\n",
      " [ 0.10510954]]\n",
      "Iteration 6314 | Cost: 0.321499990379028 | Gradient: [[ 0.030419  ]\n",
      " [-0.0614542 ]\n",
      " [ 0.10510147]]\n",
      "Iteration 6315 | Cost: 0.32148424272003523 | Gradient: [[ 0.03041856]\n",
      " [-0.0614489 ]\n",
      " [ 0.1050934 ]]\n",
      "Iteration 6316 | Cost: 0.32146849743585687 | Gradient: [[ 0.03041812]\n",
      " [-0.0614436 ]\n",
      " [ 0.10508533]]\n",
      "Iteration 6317 | Cost: 0.3214527545259712 | Gradient: [[ 0.03041767]\n",
      " [-0.0614383 ]\n",
      " [ 0.10507726]]\n",
      "Iteration 6318 | Cost: 0.32143701398985675 | Gradient: [[ 0.03041723]\n",
      " [-0.061433  ]\n",
      " [ 0.10506919]]\n",
      "Iteration 6319 | Cost: 0.32142127582699204 | Gradient: [[ 0.03041679]\n",
      " [-0.0614277 ]\n",
      " [ 0.10506112]]\n",
      "Iteration 6320 | Cost: 0.3214055400368559 | Gradient: [[ 0.03041634]\n",
      " [-0.06142241]\n",
      " [ 0.10505306]]\n",
      "Iteration 6321 | Cost: 0.32138980661892724 | Gradient: [[ 0.0304159 ]\n",
      " [-0.06141712]\n",
      " [ 0.10504499]]\n",
      "Iteration 6322 | Cost: 0.32137407557268527 | Gradient: [[ 0.03041545]\n",
      " [-0.06141183]\n",
      " [ 0.10503692]]\n",
      "Iteration 6323 | Cost: 0.3213583468976093 | Gradient: [[ 0.03041501]\n",
      " [-0.06140654]\n",
      " [ 0.10502886]]\n",
      "Iteration 6324 | Cost: 0.3213426205931786 | Gradient: [[ 0.03041456]\n",
      " [-0.06140125]\n",
      " [ 0.1050208 ]]\n",
      "Iteration 6325 | Cost: 0.32132689665887293 | Gradient: [[ 0.03041411]\n",
      " [-0.06139597]\n",
      " [ 0.10501273]]\n",
      "Iteration 6326 | Cost: 0.321311175094172 | Gradient: [[ 0.03041366]\n",
      " [-0.06139068]\n",
      " [ 0.10500467]]\n",
      "Iteration 6327 | Cost: 0.3212954558985557 | Gradient: [[ 0.03041322]\n",
      " [-0.0613854 ]\n",
      " [ 0.10499661]]\n",
      "Iteration 6328 | Cost: 0.3212797390715042 | Gradient: [[ 0.03041277]\n",
      " [-0.06138012]\n",
      " [ 0.10498855]]\n",
      "Iteration 6329 | Cost: 0.3212640246124977 | Gradient: [[ 0.03041232]\n",
      " [-0.06137484]\n",
      " [ 0.10498049]]\n",
      "Iteration 6330 | Cost: 0.3212483125210165 | Gradient: [[ 0.03041187]\n",
      " [-0.06136956]\n",
      " [ 0.10497243]]\n",
      "Iteration 6331 | Cost: 0.32123260279654137 | Gradient: [[ 0.03041142]\n",
      " [-0.06136429]\n",
      " [ 0.10496437]]\n",
      "Iteration 6332 | Cost: 0.3212168954385529 | Gradient: [[ 0.03041097]\n",
      " [-0.06135901]\n",
      " [ 0.10495631]]\n",
      "Iteration 6333 | Cost: 0.321201190446532 | Gradient: [[ 0.03041051]\n",
      " [-0.06135374]\n",
      " [ 0.10494826]]\n",
      "Iteration 6334 | Cost: 0.3211854878199598 | Gradient: [[ 0.03041006]\n",
      " [-0.06134847]\n",
      " [ 0.1049402 ]]\n",
      "Iteration 6335 | Cost: 0.32116978755831743 | Gradient: [[ 0.03040961]\n",
      " [-0.0613432 ]\n",
      " [ 0.10493215]]\n",
      "Iteration 6336 | Cost: 0.3211540896610862 | Gradient: [[ 0.03040915]\n",
      " [-0.06133794]\n",
      " [ 0.10492409]]\n",
      "Iteration 6337 | Cost: 0.3211383941277478 | Gradient: [[ 0.0304087 ]\n",
      " [-0.06133267]\n",
      " [ 0.10491604]]\n",
      "Iteration 6338 | Cost: 0.3211227009577839 | Gradient: [[ 0.03040824]\n",
      " [-0.06132741]\n",
      " [ 0.10490799]]\n",
      "Iteration 6339 | Cost: 0.32110701015067616 | Gradient: [[ 0.03040779]\n",
      " [-0.06132215]\n",
      " [ 0.10489993]]\n",
      "Iteration 6340 | Cost: 0.3210913217059068 | Gradient: [[ 0.03040733]\n",
      " [-0.06131688]\n",
      " [ 0.10489188]]\n",
      "Iteration 6341 | Cost: 0.3210756356229579 | Gradient: [[ 0.03040688]\n",
      " [-0.06131163]\n",
      " [ 0.10488383]]\n",
      "Iteration 6342 | Cost: 0.3210599519013118 | Gradient: [[ 0.03040642]\n",
      " [-0.06130637]\n",
      " [ 0.10487578]]\n",
      "Iteration 6343 | Cost: 0.3210442705404511 | Gradient: [[ 0.03040596]\n",
      " [-0.06130111]\n",
      " [ 0.10486773]]\n",
      "Iteration 6344 | Cost: 0.3210285915398582 | Gradient: [[ 0.0304055 ]\n",
      " [-0.06129586]\n",
      " [ 0.10485969]]\n",
      "Iteration 6345 | Cost: 0.32101291489901623 | Gradient: [[ 0.03040505]\n",
      " [-0.06129061]\n",
      " [ 0.10485164]]\n",
      "Iteration 6346 | Cost: 0.3209972406174079 | Gradient: [[ 0.03040459]\n",
      " [-0.06128536]\n",
      " [ 0.10484359]]\n",
      "Iteration 6347 | Cost: 0.32098156869451644 | Gradient: [[ 0.03040413]\n",
      " [-0.06128011]\n",
      " [ 0.10483555]]\n",
      "Iteration 6348 | Cost: 0.32096589912982515 | Gradient: [[ 0.03040367]\n",
      " [-0.06127486]\n",
      " [ 0.1048275 ]]\n",
      "Iteration 6349 | Cost: 0.32095023192281746 | Gradient: [[ 0.0304032 ]\n",
      " [-0.06126962]\n",
      " [ 0.10481946]]\n",
      "Iteration 6350 | Cost: 0.3209345670729771 | Gradient: [[ 0.03040274]\n",
      " [-0.06126437]\n",
      " [ 0.10481141]]\n",
      "Iteration 6351 | Cost: 0.32091890457978756 | Gradient: [[ 0.03040228]\n",
      " [-0.06125913]\n",
      " [ 0.10480337]]\n",
      "Iteration 6352 | Cost: 0.320903244442733 | Gradient: [[ 0.03040182]\n",
      " [-0.06125389]\n",
      " [ 0.10479533]]\n",
      "Iteration 6353 | Cost: 0.3208875866612974 | Gradient: [[ 0.03040135]\n",
      " [-0.06124865]\n",
      " [ 0.10478729]]\n",
      "Iteration 6354 | Cost: 0.32087193123496516 | Gradient: [[ 0.03040089]\n",
      " [-0.06124341]\n",
      " [ 0.10477925]]\n",
      "Iteration 6355 | Cost: 0.3208562781632204 | Gradient: [[ 0.03040042]\n",
      " [-0.06123818]\n",
      " [ 0.10477121]]\n",
      "Iteration 6356 | Cost: 0.320840627445548 | Gradient: [[ 0.03039996]\n",
      " [-0.06123294]\n",
      " [ 0.10476317]]\n",
      "Iteration 6357 | Cost: 0.32082497908143237 | Gradient: [[ 0.03039949]\n",
      " [-0.06122771]\n",
      " [ 0.10475513]]\n",
      "Iteration 6358 | Cost: 0.32080933307035864 | Gradient: [[ 0.03039903]\n",
      " [-0.06122248]\n",
      " [ 0.10474709]]\n",
      "Iteration 6359 | Cost: 0.3207936894118118 | Gradient: [[ 0.03039856]\n",
      " [-0.06121725]\n",
      " [ 0.10473906]]\n",
      "Iteration 6360 | Cost: 0.320778048105277 | Gradient: [[ 0.03039809]\n",
      " [-0.06121203]\n",
      " [ 0.10473102]]\n",
      "Iteration 6361 | Cost: 0.3207624091502395 | Gradient: [[ 0.03039763]\n",
      " [-0.0612068 ]\n",
      " [ 0.10472299]]\n",
      "Iteration 6362 | Cost: 0.320746772546185 | Gradient: [[ 0.03039716]\n",
      " [-0.06120158]\n",
      " [ 0.10471495]]\n",
      "Iteration 6363 | Cost: 0.3207311382925991 | Gradient: [[ 0.03039669]\n",
      " [-0.06119635]\n",
      " [ 0.10470692]]\n",
      "Iteration 6364 | Cost: 0.3207155063889675 | Gradient: [[ 0.03039622]\n",
      " [-0.06119113]\n",
      " [ 0.10469889]]\n",
      "Iteration 6365 | Cost: 0.3206998768347764 | Gradient: [[ 0.03039575]\n",
      " [-0.06118591]\n",
      " [ 0.10469085]]\n",
      "Iteration 6366 | Cost: 0.3206842496295119 | Gradient: [[ 0.03039528]\n",
      " [-0.0611807 ]\n",
      " [ 0.10468282]]\n",
      "Iteration 6367 | Cost: 0.32066862477266017 | Gradient: [[ 0.03039481]\n",
      " [-0.06117548]\n",
      " [ 0.10467479]]\n",
      "Iteration 6368 | Cost: 0.3206530022637078 | Gradient: [[ 0.03039433]\n",
      " [-0.06117027]\n",
      " [ 0.10466676]]\n",
      "Iteration 6369 | Cost: 0.3206373821021414 | Gradient: [[ 0.03039386]\n",
      " [-0.06116505]\n",
      " [ 0.10465873]]\n",
      "Iteration 6370 | Cost: 0.3206217642874476 | Gradient: [[ 0.03039339]\n",
      " [-0.06115984]\n",
      " [ 0.10465071]]\n",
      "Iteration 6371 | Cost: 0.32060614881911353 | Gradient: [[ 0.03039291]\n",
      " [-0.06115463]\n",
      " [ 0.10464268]]\n",
      "Iteration 6372 | Cost: 0.32059053569662627 | Gradient: [[ 0.03039244]\n",
      " [-0.06114943]\n",
      " [ 0.10463465]]\n",
      "Iteration 6373 | Cost: 0.32057492491947287 | Gradient: [[ 0.03039196]\n",
      " [-0.06114422]\n",
      " [ 0.10462663]]\n",
      "Iteration 6374 | Cost: 0.32055931648714103 | Gradient: [[ 0.03039149]\n",
      " [-0.06113902]\n",
      " [ 0.1046186 ]]\n",
      "Iteration 6375 | Cost: 0.32054371039911805 | Gradient: [[ 0.03039101]\n",
      " [-0.06113381]\n",
      " [ 0.10461058]]\n",
      "Iteration 6376 | Cost: 0.32052810665489173 | Gradient: [[ 0.03039054]\n",
      " [-0.06112861]\n",
      " [ 0.10460256]]\n",
      "Iteration 6377 | Cost: 0.3205125052539501 | Gradient: [[ 0.03039006]\n",
      " [-0.06112341]\n",
      " [ 0.10459453]]\n",
      "Iteration 6378 | Cost: 0.32049690619578103 | Gradient: [[ 0.03038958]\n",
      " [-0.06111822]\n",
      " [ 0.10458651]]\n",
      "Iteration 6379 | Cost: 0.32048130947987274 | Gradient: [[ 0.0303891 ]\n",
      " [-0.06111302]\n",
      " [ 0.10457849]]\n",
      "Iteration 6380 | Cost: 0.32046571510571364 | Gradient: [[ 0.03038862]\n",
      " [-0.06110783]\n",
      " [ 0.10457047]]\n",
      "Iteration 6381 | Cost: 0.3204501230727922 | Gradient: [[ 0.03038815]\n",
      " [-0.06110263]\n",
      " [ 0.10456245]]\n",
      "Iteration 6382 | Cost: 0.320434533380597 | Gradient: [[ 0.03038767]\n",
      " [-0.06109744]\n",
      " [ 0.10455443]]\n",
      "Iteration 6383 | Cost: 0.32041894602861704 | Gradient: [[ 0.03038719]\n",
      " [-0.06109225]\n",
      " [ 0.10454641]]\n",
      "Iteration 6384 | Cost: 0.32040336101634115 | Gradient: [[ 0.0303867 ]\n",
      " [-0.06108706]\n",
      " [ 0.1045384 ]]\n",
      "Iteration 6385 | Cost: 0.32038777834325854 | Gradient: [[ 0.03038622]\n",
      " [-0.06108188]\n",
      " [ 0.10453038]]\n",
      "Iteration 6386 | Cost: 0.32037219800885847 | Gradient: [[ 0.03038574]\n",
      " [-0.06107669]\n",
      " [ 0.10452237]]\n",
      "Iteration 6387 | Cost: 0.3203566200126304 | Gradient: [[ 0.03038526]\n",
      " [-0.06107151]\n",
      " [ 0.10451435]]\n",
      "Iteration 6388 | Cost: 0.32034104435406396 | Gradient: [[ 0.03038477]\n",
      " [-0.06106633]\n",
      " [ 0.10450634]]\n",
      "Iteration 6389 | Cost: 0.3203254710326488 | Gradient: [[ 0.03038429]\n",
      " [-0.06106115]\n",
      " [ 0.10449832]]\n",
      "Iteration 6390 | Cost: 0.32030990004787496 | Gradient: [[ 0.03038381]\n",
      " [-0.06105597]\n",
      " [ 0.10449031]]\n",
      "Iteration 6391 | Cost: 0.3202943313992325 | Gradient: [[ 0.03038332]\n",
      " [-0.06105079]\n",
      " [ 0.1044823 ]]\n",
      "Iteration 6392 | Cost: 0.3202787650862116 | Gradient: [[ 0.03038284]\n",
      " [-0.06104562]\n",
      " [ 0.10447429]]\n",
      "Iteration 6393 | Cost: 0.3202632011083026 | Gradient: [[ 0.03038235]\n",
      " [-0.06104045]\n",
      " [ 0.10446628]]\n",
      "Iteration 6394 | Cost: 0.3202476394649962 | Gradient: [[ 0.03038186]\n",
      " [-0.06103527]\n",
      " [ 0.10445827]]\n",
      "Iteration 6395 | Cost: 0.3202320801557829 | Gradient: [[ 0.03038138]\n",
      " [-0.0610301 ]\n",
      " [ 0.10445026]]\n",
      "Iteration 6396 | Cost: 0.32021652318015364 | Gradient: [[ 0.03038089]\n",
      " [-0.06102493]\n",
      " [ 0.10444226]]\n",
      "Iteration 6397 | Cost: 0.32020096853759944 | Gradient: [[ 0.0303804 ]\n",
      " [-0.06101977]\n",
      " [ 0.10443425]]\n",
      "Iteration 6398 | Cost: 0.3201854162276115 | Gradient: [[ 0.03037991]\n",
      " [-0.0610146 ]\n",
      " [ 0.10442624]]\n",
      "Iteration 6399 | Cost: 0.320169866249681 | Gradient: [[ 0.03037942]\n",
      " [-0.06100944]\n",
      " [ 0.10441824]]\n",
      "Iteration 6400 | Cost: 0.3201543186032996 | Gradient: [[ 0.03037893]\n",
      " [-0.06100428]\n",
      " [ 0.10441023]]\n",
      "Iteration 6401 | Cost: 0.32013877328795876 | Gradient: [[ 0.03037844]\n",
      " [-0.06099912]\n",
      " [ 0.10440223]]\n",
      "Iteration 6402 | Cost: 0.32012323030315043 | Gradient: [[ 0.03037795]\n",
      " [-0.06099396]\n",
      " [ 0.10439423]]\n",
      "Iteration 6403 | Cost: 0.3201076896483664 | Gradient: [[ 0.03037746]\n",
      " [-0.0609888 ]\n",
      " [ 0.10438622]]\n",
      "Iteration 6404 | Cost: 0.3200921513230987 | Gradient: [[ 0.03037697]\n",
      " [-0.06098364]\n",
      " [ 0.10437822]]\n",
      "Iteration 6405 | Cost: 0.3200766153268399 | Gradient: [[ 0.03037647]\n",
      " [-0.06097849]\n",
      " [ 0.10437022]]\n",
      "Iteration 6406 | Cost: 0.3200610816590821 | Gradient: [[ 0.03037598]\n",
      " [-0.06097334]\n",
      " [ 0.10436222]]\n",
      "Iteration 6407 | Cost: 0.320045550319318 | Gradient: [[ 0.03037549]\n",
      " [-0.06096819]\n",
      " [ 0.10435422]]\n",
      "Iteration 6408 | Cost: 0.3200300213070402 | Gradient: [[ 0.03037499]\n",
      " [-0.06096304]\n",
      " [ 0.10434623]]\n",
      "Iteration 6409 | Cost: 0.32001449462174164 | Gradient: [[ 0.0303745 ]\n",
      " [-0.06095789]\n",
      " [ 0.10433823]]\n",
      "Iteration 6410 | Cost: 0.31999897026291535 | Gradient: [[ 0.030374  ]\n",
      " [-0.06095274]\n",
      " [ 0.10433023]]\n",
      "Iteration 6411 | Cost: 0.31998344823005453 | Gradient: [[ 0.03037351]\n",
      " [-0.0609476 ]\n",
      " [ 0.10432224]]\n",
      "Iteration 6412 | Cost: 0.31996792852265243 | Gradient: [[ 0.03037301]\n",
      " [-0.06094246]\n",
      " [ 0.10431424]]\n",
      "Iteration 6413 | Cost: 0.3199524111402027 | Gradient: [[ 0.03037251]\n",
      " [-0.06093732]\n",
      " [ 0.10430625]]\n",
      "Iteration 6414 | Cost: 0.31993689608219883 | Gradient: [[ 0.03037201]\n",
      " [-0.06093218]\n",
      " [ 0.10429825]]\n",
      "Iteration 6415 | Cost: 0.3199213833481346 | Gradient: [[ 0.03037152]\n",
      " [-0.06092704]\n",
      " [ 0.10429026]]\n",
      "Iteration 6416 | Cost: 0.319905872937504 | Gradient: [[ 0.03037102]\n",
      " [-0.0609219 ]\n",
      " [ 0.10428227]]\n",
      "Iteration 6417 | Cost: 0.3198903648498012 | Gradient: [[ 0.03037052]\n",
      " [-0.06091677]\n",
      " [ 0.10427428]]\n",
      "Iteration 6418 | Cost: 0.3198748590845204 | Gradient: [[ 0.03037002]\n",
      " [-0.06091163]\n",
      " [ 0.10426629]]\n",
      "Iteration 6419 | Cost: 0.319859355641156 | Gradient: [[ 0.03036952]\n",
      " [-0.0609065 ]\n",
      " [ 0.1042583 ]]\n",
      "Iteration 6420 | Cost: 0.3198438545192025 | Gradient: [[ 0.03036902]\n",
      " [-0.06090137]\n",
      " [ 0.10425031]]\n",
      "Iteration 6421 | Cost: 0.3198283557181548 | Gradient: [[ 0.03036852]\n",
      " [-0.06089624]\n",
      " [ 0.10424232]]\n",
      "Iteration 6422 | Cost: 0.3198128592375077 | Gradient: [[ 0.03036801]\n",
      " [-0.06089112]\n",
      " [ 0.10423433]]\n",
      "Iteration 6423 | Cost: 0.31979736507675616 | Gradient: [[ 0.03036751]\n",
      " [-0.06088599]\n",
      " [ 0.10422635]]\n",
      "Iteration 6424 | Cost: 0.3197818732353953 | Gradient: [[ 0.03036701]\n",
      " [-0.06088087]\n",
      " [ 0.10421836]]\n",
      "Iteration 6425 | Cost: 0.31976638371292065 | Gradient: [[ 0.0303665 ]\n",
      " [-0.06087574]\n",
      " [ 0.10421038]]\n",
      "Iteration 6426 | Cost: 0.3197508965088275 | Gradient: [[ 0.030366  ]\n",
      " [-0.06087062]\n",
      " [ 0.10420239]]\n",
      "Iteration 6427 | Cost: 0.31973541162261165 | Gradient: [[ 0.0303655 ]\n",
      " [-0.06086551]\n",
      " [ 0.10419441]]\n",
      "Iteration 6428 | Cost: 0.3197199290537688 | Gradient: [[ 0.03036499]\n",
      " [-0.06086039]\n",
      " [ 0.10418643]]\n",
      "Iteration 6429 | Cost: 0.319704448801795 | Gradient: [[ 0.03036448]\n",
      " [-0.06085527]\n",
      " [ 0.10417845]]\n",
      "Iteration 6430 | Cost: 0.3196889708661862 | Gradient: [[ 0.03036398]\n",
      " [-0.06085016]\n",
      " [ 0.10417046]]\n",
      "Iteration 6431 | Cost: 0.31967349524643873 | Gradient: [[ 0.03036347]\n",
      " [-0.06084505]\n",
      " [ 0.10416248]]\n",
      "Iteration 6432 | Cost: 0.319658021942049 | Gradient: [[ 0.03036296]\n",
      " [-0.06083993]\n",
      " [ 0.10415451]]\n",
      "Iteration 6433 | Cost: 0.31964255095251354 | Gradient: [[ 0.03036246]\n",
      " [-0.06083482]\n",
      " [ 0.10414653]]\n",
      "Iteration 6434 | Cost: 0.3196270822773291 | Gradient: [[ 0.03036195]\n",
      " [-0.06082972]\n",
      " [ 0.10413855]]\n",
      "Iteration 6435 | Cost: 0.3196116159159926 | Gradient: [[ 0.03036144]\n",
      " [-0.06082461]\n",
      " [ 0.10413057]]\n",
      "Iteration 6436 | Cost: 0.3195961518680009 | Gradient: [[ 0.03036093]\n",
      " [-0.06081951]\n",
      " [ 0.1041226 ]]\n",
      "Iteration 6437 | Cost: 0.3195806901328513 | Gradient: [[ 0.03036042]\n",
      " [-0.0608144 ]\n",
      " [ 0.10411462]]\n",
      "Iteration 6438 | Cost: 0.31956523071004095 | Gradient: [[ 0.03035991]\n",
      " [-0.0608093 ]\n",
      " [ 0.10410665]]\n",
      "Iteration 6439 | Cost: 0.3195497735990675 | Gradient: [[ 0.0303594 ]\n",
      " [-0.0608042 ]\n",
      " [ 0.10409867]]\n",
      "Iteration 6440 | Cost: 0.31953431879942856 | Gradient: [[ 0.03035888]\n",
      " [-0.0607991 ]\n",
      " [ 0.1040907 ]]\n",
      "Iteration 6441 | Cost: 0.3195188663106218 | Gradient: [[ 0.03035837]\n",
      " [-0.06079401]\n",
      " [ 0.10408273]]\n",
      "Iteration 6442 | Cost: 0.31950341613214533 | Gradient: [[ 0.03035786]\n",
      " [-0.06078891]\n",
      " [ 0.10407476]]\n",
      "Iteration 6443 | Cost: 0.3194879682634971 | Gradient: [[ 0.03035735]\n",
      " [-0.06078382]\n",
      " [ 0.10406678]]\n",
      "Iteration 6444 | Cost: 0.31947252270417537 | Gradient: [[ 0.03035683]\n",
      " [-0.06077872]\n",
      " [ 0.10405881]]\n",
      "Iteration 6445 | Cost: 0.3194570794536785 | Gradient: [[ 0.03035632]\n",
      " [-0.06077363]\n",
      " [ 0.10405085]]\n",
      "Iteration 6446 | Cost: 0.3194416385115051 | Gradient: [[ 0.0303558 ]\n",
      " [-0.06076855]\n",
      " [ 0.10404288]]\n",
      "Iteration 6447 | Cost: 0.31942619987715376 | Gradient: [[ 0.03035529]\n",
      " [-0.06076346]\n",
      " [ 0.10403491]]\n",
      "Iteration 6448 | Cost: 0.31941076355012343 | Gradient: [[ 0.03035477]\n",
      " [-0.06075837]\n",
      " [ 0.10402694]]\n",
      "Iteration 6449 | Cost: 0.31939532952991306 | Gradient: [[ 0.03035425]\n",
      " [-0.06075329]\n",
      " [ 0.10401898]]\n",
      "Iteration 6450 | Cost: 0.3193798978160218 | Gradient: [[ 0.03035374]\n",
      " [-0.06074821]\n",
      " [ 0.10401101]]\n",
      "Iteration 6451 | Cost: 0.31936446840794885 | Gradient: [[ 0.03035322]\n",
      " [-0.06074312]\n",
      " [ 0.10400305]]\n",
      "Iteration 6452 | Cost: 0.31934904130519387 | Gradient: [[ 0.0303527 ]\n",
      " [-0.06073804]\n",
      " [ 0.10399508]]\n",
      "Iteration 6453 | Cost: 0.3193336165072563 | Gradient: [[ 0.03035218]\n",
      " [-0.06073297]\n",
      " [ 0.10398712]]\n",
      "Iteration 6454 | Cost: 0.31931819401363587 | Gradient: [[ 0.03035166]\n",
      " [-0.06072789]\n",
      " [ 0.10397916]]\n",
      "Iteration 6455 | Cost: 0.31930277382383265 | Gradient: [[ 0.03035114]\n",
      " [-0.06072281]\n",
      " [ 0.1039712 ]]\n",
      "Iteration 6456 | Cost: 0.31928735593734653 | Gradient: [[ 0.03035062]\n",
      " [-0.06071774]\n",
      " [ 0.10396324]]\n",
      "Iteration 6457 | Cost: 0.3192719403536778 | Gradient: [[ 0.0303501 ]\n",
      " [-0.06071267]\n",
      " [ 0.10395528]]\n",
      "Iteration 6458 | Cost: 0.31925652707232677 | Gradient: [[ 0.03034958]\n",
      " [-0.0607076 ]\n",
      " [ 0.10394732]]\n",
      "Iteration 6459 | Cost: 0.31924111609279404 | Gradient: [[ 0.03034906]\n",
      " [-0.06070253]\n",
      " [ 0.10393936]]\n",
      "Iteration 6460 | Cost: 0.3192257074145801 | Gradient: [[ 0.03034854]\n",
      " [-0.06069746]\n",
      " [ 0.1039314 ]]\n",
      "Iteration 6461 | Cost: 0.31921030103718595 | Gradient: [[ 0.03034801]\n",
      " [-0.0606924 ]\n",
      " [ 0.10392345]]\n",
      "Iteration 6462 | Cost: 0.3191948969601125 | Gradient: [[ 0.03034749]\n",
      " [-0.06068733]\n",
      " [ 0.10391549]]\n",
      "Iteration 6463 | Cost: 0.3191794951828607 | Gradient: [[ 0.03034697]\n",
      " [-0.06068227]\n",
      " [ 0.10390754]]\n",
      "Iteration 6464 | Cost: 0.31916409570493204 | Gradient: [[ 0.03034644]\n",
      " [-0.06067721]\n",
      " [ 0.10389958]]\n",
      "Iteration 6465 | Cost: 0.3191486985258277 | Gradient: [[ 0.03034592]\n",
      " [-0.06067215]\n",
      " [ 0.10389163]]\n",
      "Iteration 6466 | Cost: 0.31913330364504955 | Gradient: [[ 0.03034539]\n",
      " [-0.06066709]\n",
      " [ 0.10388368]]\n",
      "Iteration 6467 | Cost: 0.31911791106209897 | Gradient: [[ 0.03034487]\n",
      " [-0.06066204]\n",
      " [ 0.10387573]]\n",
      "Iteration 6468 | Cost: 0.31910252077647805 | Gradient: [[ 0.03034434]\n",
      " [-0.06065698]\n",
      " [ 0.10386777]]\n",
      "Iteration 6469 | Cost: 0.3190871327876887 | Gradient: [[ 0.03034381]\n",
      " [-0.06065193]\n",
      " [ 0.10385982]]\n",
      "Iteration 6470 | Cost: 0.31907174709523317 | Gradient: [[ 0.03034328]\n",
      " [-0.06064688]\n",
      " [ 0.10385187]]\n",
      "Iteration 6471 | Cost: 0.31905636369861373 | Gradient: [[ 0.03034276]\n",
      " [-0.06064183]\n",
      " [ 0.10384393]]\n",
      "Iteration 6472 | Cost: 0.31904098259733277 | Gradient: [[ 0.03034223]\n",
      " [-0.06063678]\n",
      " [ 0.10383598]]\n",
      "Iteration 6473 | Cost: 0.319025603790893 | Gradient: [[ 0.0303417 ]\n",
      " [-0.06063173]\n",
      " [ 0.10382803]]\n",
      "Iteration 6474 | Cost: 0.3190102272787971 | Gradient: [[ 0.03034117]\n",
      " [-0.06062669]\n",
      " [ 0.10382008]]\n",
      "Iteration 6475 | Cost: 0.31899485306054803 | Gradient: [[ 0.03034064]\n",
      " [-0.06062164]\n",
      " [ 0.10381214]]\n",
      "Iteration 6476 | Cost: 0.31897948113564895 | Gradient: [[ 0.03034011]\n",
      " [-0.0606166 ]\n",
      " [ 0.10380419]]\n",
      "Iteration 6477 | Cost: 0.318964111503603 | Gradient: [[ 0.03033957]\n",
      " [-0.06061156]\n",
      " [ 0.10379625]]\n",
      "Iteration 6478 | Cost: 0.31894874416391344 | Gradient: [[ 0.03033904]\n",
      " [-0.06060652]\n",
      " [ 0.10378831]]\n",
      "Iteration 6479 | Cost: 0.3189333791160839 | Gradient: [[ 0.03033851]\n",
      " [-0.06060148]\n",
      " [ 0.10378037]]\n",
      "Iteration 6480 | Cost: 0.318918016359618 | Gradient: [[ 0.03033798]\n",
      " [-0.06059645]\n",
      " [ 0.10377242]]\n",
      "Iteration 6481 | Cost: 0.3189026558940195 | Gradient: [[ 0.03033744]\n",
      " [-0.06059141]\n",
      " [ 0.10376448]]\n",
      "Iteration 6482 | Cost: 0.31888729771879254 | Gradient: [[ 0.03033691]\n",
      " [-0.06058638]\n",
      " [ 0.10375654]]\n",
      "Iteration 6483 | Cost: 0.31887194183344103 | Gradient: [[ 0.03033638]\n",
      " [-0.06058135]\n",
      " [ 0.1037486 ]]\n",
      "Iteration 6484 | Cost: 0.3188565882374694 | Gradient: [[ 0.03033584]\n",
      " [-0.06057632]\n",
      " [ 0.10374067]]\n",
      "Iteration 6485 | Cost: 0.3188412369303819 | Gradient: [[ 0.03033531]\n",
      " [-0.06057129]\n",
      " [ 0.10373273]]\n",
      "Iteration 6486 | Cost: 0.31882588791168315 | Gradient: [[ 0.03033477]\n",
      " [-0.06056626]\n",
      " [ 0.10372479]]\n",
      "Iteration 6487 | Cost: 0.3188105411808779 | Gradient: [[ 0.03033423]\n",
      " [-0.06056124]\n",
      " [ 0.10371686]]\n",
      "Iteration 6488 | Cost: 0.318795196737471 | Gradient: [[ 0.0303337 ]\n",
      " [-0.06055621]\n",
      " [ 0.10370892]]\n",
      "Iteration 6489 | Cost: 0.31877985458096736 | Gradient: [[ 0.03033316]\n",
      " [-0.06055119]\n",
      " [ 0.10370099]]\n",
      "Iteration 6490 | Cost: 0.3187645147108723 | Gradient: [[ 0.03033262]\n",
      " [-0.06054617]\n",
      " [ 0.10369305]]\n",
      "Iteration 6491 | Cost: 0.3187491771266909 | Gradient: [[ 0.03033208]\n",
      " [-0.06054115]\n",
      " [ 0.10368512]]\n",
      "Iteration 6492 | Cost: 0.3187338418279287 | Gradient: [[ 0.03033154]\n",
      " [-0.06053613]\n",
      " [ 0.10367719]]\n",
      "Iteration 6493 | Cost: 0.3187185088140914 | Gradient: [[ 0.030331  ]\n",
      " [-0.06053112]\n",
      " [ 0.10366926]]\n",
      "Iteration 6494 | Cost: 0.31870317808468474 | Gradient: [[ 0.03033046]\n",
      " [-0.0605261 ]\n",
      " [ 0.10366133]]\n",
      "Iteration 6495 | Cost: 0.3186878496392144 | Gradient: [[ 0.03032992]\n",
      " [-0.06052109]\n",
      " [ 0.1036534 ]]\n",
      "Iteration 6496 | Cost: 0.3186725234771868 | Gradient: [[ 0.03032938]\n",
      " [-0.06051608]\n",
      " [ 0.10364547]]\n",
      "Iteration 6497 | Cost: 0.3186571995981077 | Gradient: [[ 0.03032884]\n",
      " [-0.06051107]\n",
      " [ 0.10363754]]\n",
      "Iteration 6498 | Cost: 0.3186418780014837 | Gradient: [[ 0.0303283 ]\n",
      " [-0.06050606]\n",
      " [ 0.10362961]]\n",
      "Iteration 6499 | Cost: 0.3186265586868212 | Gradient: [[ 0.03032775]\n",
      " [-0.06050105]\n",
      " [ 0.10362169]]\n",
      "Iteration 6500 | Cost: 0.318611241653627 | Gradient: [[ 0.03032721]\n",
      " [-0.06049605]\n",
      " [ 0.10361376]]\n",
      "Iteration 6501 | Cost: 0.3185959269014076 | Gradient: [[ 0.03032667]\n",
      " [-0.06049104]\n",
      " [ 0.10360583]]\n",
      "Iteration 6502 | Cost: 0.3185806144296702 | Gradient: [[ 0.03032612]\n",
      " [-0.06048604]\n",
      " [ 0.10359791]]\n",
      "Iteration 6503 | Cost: 0.31856530423792173 | Gradient: [[ 0.03032558]\n",
      " [-0.06048104]\n",
      " [ 0.10358999]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6504 | Cost: 0.31854999632566944 | Gradient: [[ 0.03032503]\n",
      " [-0.06047604]\n",
      " [ 0.10358207]]\n",
      "Iteration 6505 | Cost: 0.3185346906924208 | Gradient: [[ 0.03032449]\n",
      " [-0.06047104]\n",
      " [ 0.10357414]]\n",
      "Iteration 6506 | Cost: 0.31851938733768315 | Gradient: [[ 0.03032394]\n",
      " [-0.06046604]\n",
      " [ 0.10356622]]\n",
      "Iteration 6507 | Cost: 0.3185040862609643 | Gradient: [[ 0.03032339]\n",
      " [-0.06046105]\n",
      " [ 0.1035583 ]]\n",
      "Iteration 6508 | Cost: 0.31848878746177206 | Gradient: [[ 0.03032284]\n",
      " [-0.06045606]\n",
      " [ 0.10355038]]\n",
      "Iteration 6509 | Cost: 0.3184734909396144 | Gradient: [[ 0.0303223 ]\n",
      " [-0.06045106]\n",
      " [ 0.10354246]]\n",
      "Iteration 6510 | Cost: 0.3184581966939994 | Gradient: [[ 0.03032175]\n",
      " [-0.06044607]\n",
      " [ 0.10353455]]\n",
      "Iteration 6511 | Cost: 0.31844290472443526 | Gradient: [[ 0.0303212 ]\n",
      " [-0.06044108]\n",
      " [ 0.10352663]]\n",
      "Iteration 6512 | Cost: 0.3184276150304305 | Gradient: [[ 0.03032065]\n",
      " [-0.0604361 ]\n",
      " [ 0.10351871]]\n",
      "Iteration 6513 | Cost: 0.31841232761149363 | Gradient: [[ 0.0303201 ]\n",
      " [-0.06043111]\n",
      " [ 0.1035108 ]]\n",
      "Iteration 6514 | Cost: 0.31839704246713335 | Gradient: [[ 0.03031955]\n",
      " [-0.06042613]\n",
      " [ 0.10350288]]\n",
      "Iteration 6515 | Cost: 0.3183817595968585 | Gradient: [[ 0.030319  ]\n",
      " [-0.06042114]\n",
      " [ 0.10349497]]\n",
      "Iteration 6516 | Cost: 0.3183664790001781 | Gradient: [[ 0.03031845]\n",
      " [-0.06041616]\n",
      " [ 0.10348706]]\n",
      "Iteration 6517 | Cost: 0.3183512006766013 | Gradient: [[ 0.0303179 ]\n",
      " [-0.06041118]\n",
      " [ 0.10347914]]\n",
      "Iteration 6518 | Cost: 0.3183359246256373 | Gradient: [[ 0.03031734]\n",
      " [-0.0604062 ]\n",
      " [ 0.10347123]]\n",
      "Iteration 6519 | Cost: 0.3183206508467956 | Gradient: [[ 0.03031679]\n",
      " [-0.06040123]\n",
      " [ 0.10346332]]\n",
      "Iteration 6520 | Cost: 0.3183053793395859 | Gradient: [[ 0.03031624]\n",
      " [-0.06039625]\n",
      " [ 0.10345541]]\n",
      "Iteration 6521 | Cost: 0.31829011010351776 | Gradient: [[ 0.03031568]\n",
      " [-0.06039128]\n",
      " [ 0.1034475 ]]\n",
      "Iteration 6522 | Cost: 0.3182748431381011 | Gradient: [[ 0.03031513]\n",
      " [-0.06038631]\n",
      " [ 0.10343959]]\n",
      "Iteration 6523 | Cost: 0.31825957844284597 | Gradient: [[ 0.03031457]\n",
      " [-0.06038134]\n",
      " [ 0.10343169]]\n",
      "Iteration 6524 | Cost: 0.31824431601726255 | Gradient: [[ 0.03031402]\n",
      " [-0.06037637]\n",
      " [ 0.10342378]]\n",
      "Iteration 6525 | Cost: 0.3182290558608611 | Gradient: [[ 0.03031346]\n",
      " [-0.0603714 ]\n",
      " [ 0.10341587]]\n",
      "Iteration 6526 | Cost: 0.31821379797315213 | Gradient: [[ 0.0303129 ]\n",
      " [-0.06036643]\n",
      " [ 0.10340797]]\n",
      "Iteration 6527 | Cost: 0.31819854235364625 | Gradient: [[ 0.03031235]\n",
      " [-0.06036147]\n",
      " [ 0.10340007]]\n",
      "Iteration 6528 | Cost: 0.31818328900185416 | Gradient: [[ 0.03031179]\n",
      " [-0.0603565 ]\n",
      " [ 0.10339216]]\n",
      "Iteration 6529 | Cost: 0.31816803791728676 | Gradient: [[ 0.03031123]\n",
      " [-0.06035154]\n",
      " [ 0.10338426]]\n",
      "Iteration 6530 | Cost: 0.31815278909945516 | Gradient: [[ 0.03031067]\n",
      " [-0.06034658]\n",
      " [ 0.10337636]]\n",
      "Iteration 6531 | Cost: 0.3181375425478706 | Gradient: [[ 0.03031011]\n",
      " [-0.06034162]\n",
      " [ 0.10336846]]\n",
      "Iteration 6532 | Cost: 0.3181222982620443 | Gradient: [[ 0.03030955]\n",
      " [-0.06033667]\n",
      " [ 0.10336056]]\n",
      "Iteration 6533 | Cost: 0.3181070562414877 | Gradient: [[ 0.03030899]\n",
      " [-0.06033171]\n",
      " [ 0.10335266]]\n",
      "Iteration 6534 | Cost: 0.31809181648571255 | Gradient: [[ 0.03030843]\n",
      " [-0.06032676]\n",
      " [ 0.10334476]]\n",
      "Iteration 6535 | Cost: 0.3180765789942307 | Gradient: [[ 0.03030787]\n",
      " [-0.0603218 ]\n",
      " [ 0.10333686]]\n",
      "Iteration 6536 | Cost: 0.3180613437665538 | Gradient: [[ 0.03030731]\n",
      " [-0.06031685]\n",
      " [ 0.10332896]]\n",
      "Iteration 6537 | Cost: 0.31804611080219425 | Gradient: [[ 0.03030675]\n",
      " [-0.0603119 ]\n",
      " [ 0.10332107]]\n",
      "Iteration 6538 | Cost: 0.31803088010066394 | Gradient: [[ 0.03030619]\n",
      " [-0.06030695]\n",
      " [ 0.10331317]]\n",
      "Iteration 6539 | Cost: 0.31801565166147544 | Gradient: [[ 0.03030562]\n",
      " [-0.06030201]\n",
      " [ 0.10330528]]\n",
      "Iteration 6540 | Cost: 0.31800042548414115 | Gradient: [[ 0.03030506]\n",
      " [-0.06029706]\n",
      " [ 0.10329738]]\n",
      "Iteration 6541 | Cost: 0.3179852015681737 | Gradient: [[ 0.0303045 ]\n",
      " [-0.06029212]\n",
      " [ 0.10328949]]\n",
      "Iteration 6542 | Cost: 0.317969979913086 | Gradient: [[ 0.03030393]\n",
      " [-0.06028717]\n",
      " [ 0.1032816 ]]\n",
      "Iteration 6543 | Cost: 0.317954760518391 | Gradient: [[ 0.03030337]\n",
      " [-0.06028223]\n",
      " [ 0.1032737 ]]\n",
      "Iteration 6544 | Cost: 0.31793954338360164 | Gradient: [[ 0.0303028 ]\n",
      " [-0.06027729]\n",
      " [ 0.10326581]]\n",
      "Iteration 6545 | Cost: 0.31792432850823116 | Gradient: [[ 0.03030223]\n",
      " [-0.06027236]\n",
      " [ 0.10325792]]\n",
      "Iteration 6546 | Cost: 0.31790911589179305 | Gradient: [[ 0.03030167]\n",
      " [-0.06026742]\n",
      " [ 0.10325003]]\n",
      "Iteration 6547 | Cost: 0.31789390553380076 | Gradient: [[ 0.0303011 ]\n",
      " [-0.06026248]\n",
      " [ 0.10324215]]\n",
      "Iteration 6548 | Cost: 0.3178786974337679 | Gradient: [[ 0.03030053]\n",
      " [-0.06025755]\n",
      " [ 0.10323426]]\n",
      "Iteration 6549 | Cost: 0.31786349159120836 | Gradient: [[ 0.03029997]\n",
      " [-0.06025262]\n",
      " [ 0.10322637]]\n",
      "Iteration 6550 | Cost: 0.3178482880056361 | Gradient: [[ 0.0302994 ]\n",
      " [-0.06024769]\n",
      " [ 0.10321849]]\n",
      "Iteration 6551 | Cost: 0.3178330866765651 | Gradient: [[ 0.03029883]\n",
      " [-0.06024276]\n",
      " [ 0.1032106 ]]\n",
      "Iteration 6552 | Cost: 0.31781788760350976 | Gradient: [[ 0.03029826]\n",
      " [-0.06023783]\n",
      " [ 0.10320272]]\n",
      "Iteration 6553 | Cost: 0.3178026907859843 | Gradient: [[ 0.03029769]\n",
      " [-0.06023291]\n",
      " [ 0.10319483]]\n",
      "Iteration 6554 | Cost: 0.31778749622350333 | Gradient: [[ 0.03029712]\n",
      " [-0.06022798]\n",
      " [ 0.10318695]]\n",
      "Iteration 6555 | Cost: 0.31777230391558164 | Gradient: [[ 0.03029655]\n",
      " [-0.06022306]\n",
      " [ 0.10317907]]\n",
      "Iteration 6556 | Cost: 0.31775711386173383 | Gradient: [[ 0.03029598]\n",
      " [-0.06021814]\n",
      " [ 0.10317119]]\n",
      "Iteration 6557 | Cost: 0.31774192606147494 | Gradient: [[ 0.0302954 ]\n",
      " [-0.06021322]\n",
      " [ 0.1031633 ]]\n",
      "Iteration 6558 | Cost: 0.3177267405143201 | Gradient: [[ 0.03029483]\n",
      " [-0.0602083 ]\n",
      " [ 0.10315543]]\n",
      "Iteration 6559 | Cost: 0.31771155721978467 | Gradient: [[ 0.03029426]\n",
      " [-0.06020338]\n",
      " [ 0.10314755]]\n",
      "Iteration 6560 | Cost: 0.31769637617738383 | Gradient: [[ 0.03029368]\n",
      " [-0.06019846]\n",
      " [ 0.10313967]]\n",
      "Iteration 6561 | Cost: 0.31768119738663325 | Gradient: [[ 0.03029311]\n",
      " [-0.06019355]\n",
      " [ 0.10313179]]\n",
      "Iteration 6562 | Cost: 0.3176660208470486 | Gradient: [[ 0.03029254]\n",
      " [-0.06018864]\n",
      " [ 0.10312391]]\n",
      "Iteration 6563 | Cost: 0.3176508465581457 | Gradient: [[ 0.03029196]\n",
      " [-0.06018373]\n",
      " [ 0.10311604]]\n",
      "Iteration 6564 | Cost: 0.31763567451944047 | Gradient: [[ 0.03029139]\n",
      " [-0.06017882]\n",
      " [ 0.10310816]]\n",
      "Iteration 6565 | Cost: 0.31762050473044906 | Gradient: [[ 0.03029081]\n",
      " [-0.06017391]\n",
      " [ 0.10310029]]\n",
      "Iteration 6566 | Cost: 0.3176053371906877 | Gradient: [[ 0.03029023]\n",
      " [-0.060169  ]\n",
      " [ 0.10309242]]\n",
      "Iteration 6567 | Cost: 0.3175901718996728 | Gradient: [[ 0.03028966]\n",
      " [-0.0601641 ]\n",
      " [ 0.10308454]]\n",
      "Iteration 6568 | Cost: 0.31757500885692097 | Gradient: [[ 0.03028908]\n",
      " [-0.06015919]\n",
      " [ 0.10307667]]\n",
      "Iteration 6569 | Cost: 0.31755984806194887 | Gradient: [[ 0.0302885 ]\n",
      " [-0.06015429]\n",
      " [ 0.1030688 ]]\n",
      "Iteration 6570 | Cost: 0.3175446895142733 | Gradient: [[ 0.03028792]\n",
      " [-0.06014939]\n",
      " [ 0.10306093]]\n",
      "Iteration 6571 | Cost: 0.31752953321341115 | Gradient: [[ 0.03028734]\n",
      " [-0.06014449]\n",
      " [ 0.10305306]]\n",
      "Iteration 6572 | Cost: 0.3175143791588796 | Gradient: [[ 0.03028676]\n",
      " [-0.06013959]\n",
      " [ 0.10304519]]\n",
      "Iteration 6573 | Cost: 0.31749922735019603 | Gradient: [[ 0.03028618]\n",
      " [-0.06013469]\n",
      " [ 0.10303733]]\n",
      "Iteration 6574 | Cost: 0.31748407778687765 | Gradient: [[ 0.0302856 ]\n",
      " [-0.0601298 ]\n",
      " [ 0.10302946]]\n",
      "Iteration 6575 | Cost: 0.3174689304684421 | Gradient: [[ 0.03028502]\n",
      " [-0.0601249 ]\n",
      " [ 0.10302159]]\n",
      "Iteration 6576 | Cost: 0.31745378539440716 | Gradient: [[ 0.03028444]\n",
      " [-0.06012001]\n",
      " [ 0.10301373]]\n",
      "Iteration 6577 | Cost: 0.3174386425642905 | Gradient: [[ 0.03028386]\n",
      " [-0.06011512]\n",
      " [ 0.10300586]]\n",
      "Iteration 6578 | Cost: 0.31742350197761005 | Gradient: [[ 0.03028328]\n",
      " [-0.06011023]\n",
      " [ 0.102998  ]]\n",
      "Iteration 6579 | Cost: 0.31740836363388414 | Gradient: [[ 0.0302827 ]\n",
      " [-0.06010534]\n",
      " [ 0.10299014]]\n",
      "Iteration 6580 | Cost: 0.31739322753263094 | Gradient: [[ 0.03028211]\n",
      " [-0.06010046]\n",
      " [ 0.10298227]]\n",
      "Iteration 6581 | Cost: 0.3173780936733688 | Gradient: [[ 0.03028153]\n",
      " [-0.06009557]\n",
      " [ 0.10297441]]\n",
      "Iteration 6582 | Cost: 0.3173629620556163 | Gradient: [[ 0.03028094]\n",
      " [-0.06009069]\n",
      " [ 0.10296655]]\n",
      "Iteration 6583 | Cost: 0.3173478326788921 | Gradient: [[ 0.03028036]\n",
      " [-0.06008581]\n",
      " [ 0.10295869]]\n",
      "Iteration 6584 | Cost: 0.3173327055427151 | Gradient: [[ 0.03027977]\n",
      " [-0.06008092]\n",
      " [ 0.10295083]]\n",
      "Iteration 6585 | Cost: 0.31731758064660415 | Gradient: [[ 0.03027919]\n",
      " [-0.06007605]\n",
      " [ 0.10294297]]\n",
      "Iteration 6586 | Cost: 0.3173024579900785 | Gradient: [[ 0.0302786 ]\n",
      " [-0.06007117]\n",
      " [ 0.10293512]]\n",
      "Iteration 6587 | Cost: 0.3172873375726573 | Gradient: [[ 0.03027802]\n",
      " [-0.06006629]\n",
      " [ 0.10292726]]\n",
      "Iteration 6588 | Cost: 0.31727221939386 | Gradient: [[ 0.03027743]\n",
      " [-0.06006142]\n",
      " [ 0.1029194 ]]\n",
      "Iteration 6589 | Cost: 0.3172571034532061 | Gradient: [[ 0.03027684]\n",
      " [-0.06005654]\n",
      " [ 0.10291155]]\n",
      "Iteration 6590 | Cost: 0.31724198975021534 | Gradient: [[ 0.03027625]\n",
      " [-0.06005167]\n",
      " [ 0.10290369]]\n",
      "Iteration 6591 | Cost: 0.3172268782844075 | Gradient: [[ 0.03027566]\n",
      " [-0.0600468 ]\n",
      " [ 0.10289584]]\n",
      "Iteration 6592 | Cost: 0.3172117690553025 | Gradient: [[ 0.03027508]\n",
      " [-0.06004193]\n",
      " [ 0.10288799]]\n",
      "Iteration 6593 | Cost: 0.31719666206242053 | Gradient: [[ 0.03027449]\n",
      " [-0.06003706]\n",
      " [ 0.10288014]]\n",
      "Iteration 6594 | Cost: 0.31718155730528186 | Gradient: [[ 0.0302739 ]\n",
      " [-0.0600322 ]\n",
      " [ 0.10287229]]\n",
      "Iteration 6595 | Cost: 0.3171664547834067 | Gradient: [[ 0.03027331]\n",
      " [-0.06002733]\n",
      " [ 0.10286444]]\n",
      "Iteration 6596 | Cost: 0.3171513544963158 | Gradient: [[ 0.03027272]\n",
      " [-0.06002247]\n",
      " [ 0.10285659]]\n",
      "Iteration 6597 | Cost: 0.3171362564435298 | Gradient: [[ 0.03027212]\n",
      " [-0.06001761]\n",
      " [ 0.10284874]]\n",
      "Iteration 6598 | Cost: 0.31712116062456935 | Gradient: [[ 0.03027153]\n",
      " [-0.06001275]\n",
      " [ 0.10284089]]\n",
      "Iteration 6599 | Cost: 0.31710606703895555 | Gradient: [[ 0.03027094]\n",
      " [-0.06000789]\n",
      " [ 0.10283304]]\n",
      "Iteration 6600 | Cost: 0.31709097568620953 | Gradient: [[ 0.03027035]\n",
      " [-0.06000303]\n",
      " [ 0.1028252 ]]\n",
      "Iteration 6601 | Cost: 0.31707588656585234 | Gradient: [[ 0.03026975]\n",
      " [-0.05999817]\n",
      " [ 0.10281735]]\n",
      "Iteration 6602 | Cost: 0.3170607996774055 | Gradient: [[ 0.03026916]\n",
      " [-0.05999332]\n",
      " [ 0.10280951]]\n",
      "Iteration 6603 | Cost: 0.31704571502039053 | Gradient: [[ 0.03026857]\n",
      " [-0.05998847]\n",
      " [ 0.10280166]]\n",
      "Iteration 6604 | Cost: 0.31703063259432906 | Gradient: [[ 0.03026797]\n",
      " [-0.05998361]\n",
      " [ 0.10279382]]\n",
      "Iteration 6605 | Cost: 0.31701555239874296 | Gradient: [[ 0.03026738]\n",
      " [-0.05997876]\n",
      " [ 0.10278598]]\n",
      "Iteration 6606 | Cost: 0.317000474433154 | Gradient: [[ 0.03026678]\n",
      " [-0.05997391]\n",
      " [ 0.10277813]]\n",
      "Iteration 6607 | Cost: 0.31698539869708453 | Gradient: [[ 0.03026618]\n",
      " [-0.05996907]\n",
      " [ 0.10277029]]\n",
      "Iteration 6608 | Cost: 0.3169703251900565 | Gradient: [[ 0.03026559]\n",
      " [-0.05996422]\n",
      " [ 0.10276245]]\n",
      "Iteration 6609 | Cost: 0.3169552539115924 | Gradient: [[ 0.03026499]\n",
      " [-0.05995938]\n",
      " [ 0.10275462]]\n",
      "Iteration 6610 | Cost: 0.31694018486121484 | Gradient: [[ 0.03026439]\n",
      " [-0.05995453]\n",
      " [ 0.10274678]]\n",
      "Iteration 6611 | Cost: 0.31692511803844636 | Gradient: [[ 0.03026379]\n",
      " [-0.05994969]\n",
      " [ 0.10273894]]\n",
      "Iteration 6612 | Cost: 0.31691005344280965 | Gradient: [[ 0.0302632 ]\n",
      " [-0.05994485]\n",
      " [ 0.1027311 ]]\n",
      "Iteration 6613 | Cost: 0.3168949910738278 | Gradient: [[ 0.0302626 ]\n",
      " [-0.05994001]\n",
      " [ 0.10272327]]\n",
      "Iteration 6614 | Cost: 0.31687993093102385 | Gradient: [[ 0.030262  ]\n",
      " [-0.05993517]\n",
      " [ 0.10271543]]\n",
      "Iteration 6615 | Cost: 0.31686487301392097 | Gradient: [[ 0.0302614 ]\n",
      " [-0.05993034]\n",
      " [ 0.1027076 ]]\n",
      "Iteration 6616 | Cost: 0.3168498173220424 | Gradient: [[ 0.0302608 ]\n",
      " [-0.0599255 ]\n",
      " [ 0.10269976]]\n",
      "Iteration 6617 | Cost: 0.3168347638549118 | Gradient: [[ 0.0302602 ]\n",
      " [-0.05992067]\n",
      " [ 0.10269193]]\n",
      "Iteration 6618 | Cost: 0.31681971261205283 | Gradient: [[ 0.03025959]\n",
      " [-0.05991584]\n",
      " [ 0.1026841 ]]\n",
      "Iteration 6619 | Cost: 0.3168046635929892 | Gradient: [[ 0.03025899]\n",
      " [-0.05991101]\n",
      " [ 0.10267627]]\n",
      "Iteration 6620 | Cost: 0.31678961679724466 | Gradient: [[ 0.03025839]\n",
      " [-0.05990618]\n",
      " [ 0.10266844]]\n",
      "Iteration 6621 | Cost: 0.3167745722243435 | Gradient: [[ 0.03025779]\n",
      " [-0.05990135]\n",
      " [ 0.10266061]]\n",
      "Iteration 6622 | Cost: 0.31675952987380973 | Gradient: [[ 0.03025718]\n",
      " [-0.05989653]\n",
      " [ 0.10265278]]\n",
      "Iteration 6623 | Cost: 0.31674448974516783 | Gradient: [[ 0.03025658]\n",
      " [-0.0598917 ]\n",
      " [ 0.10264495]]\n",
      "Iteration 6624 | Cost: 0.31672945183794216 | Gradient: [[ 0.03025598]\n",
      " [-0.05988688]\n",
      " [ 0.10263712]]\n",
      "Iteration 6625 | Cost: 0.31671441615165735 | Gradient: [[ 0.03025537]\n",
      " [-0.05988206]\n",
      " [ 0.1026293 ]]\n",
      "Iteration 6626 | Cost: 0.3166993826858382 | Gradient: [[ 0.03025477]\n",
      " [-0.05987723]\n",
      " [ 0.10262147]]\n",
      "Iteration 6627 | Cost: 0.31668435144000956 | Gradient: [[ 0.03025416]\n",
      " [-0.05987242]\n",
      " [ 0.10261365]]\n",
      "Iteration 6628 | Cost: 0.31666932241369644 | Gradient: [[ 0.03025356]\n",
      " [-0.0598676 ]\n",
      " [ 0.10260582]]\n",
      "Iteration 6629 | Cost: 0.31665429560642405 | Gradient: [[ 0.03025295]\n",
      " [-0.05986278]\n",
      " [ 0.102598  ]]\n",
      "Iteration 6630 | Cost: 0.3166392710177176 | Gradient: [[ 0.03025234]\n",
      " [-0.05985797]\n",
      " [ 0.10259018]]\n",
      "Iteration 6631 | Cost: 0.3166242486471027 | Gradient: [[ 0.03025173]\n",
      " [-0.05985315]\n",
      " [ 0.10258236]]\n",
      "Iteration 6632 | Cost: 0.3166092284941047 | Gradient: [[ 0.03025113]\n",
      " [-0.05984834]\n",
      " [ 0.10257454]]\n",
      "Iteration 6633 | Cost: 0.31659421055824966 | Gradient: [[ 0.03025052]\n",
      " [-0.05984353]\n",
      " [ 0.10256672]]\n",
      "Iteration 6634 | Cost: 0.3165791948390631 | Gradient: [[ 0.03024991]\n",
      " [-0.05983872]\n",
      " [ 0.1025589 ]]\n",
      "Iteration 6635 | Cost: 0.3165641813360712 | Gradient: [[ 0.0302493 ]\n",
      " [-0.05983391]\n",
      " [ 0.10255108]]\n",
      "Iteration 6636 | Cost: 0.3165491700488001 | Gradient: [[ 0.03024869]\n",
      " [-0.05982911]\n",
      " [ 0.10254326]]\n",
      "Iteration 6637 | Cost: 0.3165341609767761 | Gradient: [[ 0.03024808]\n",
      " [-0.0598243 ]\n",
      " [ 0.10253544]]\n",
      "Iteration 6638 | Cost: 0.3165191541195255 | Gradient: [[ 0.03024747]\n",
      " [-0.0598195 ]\n",
      " [ 0.10252763]]\n",
      "Iteration 6639 | Cost: 0.31650414947657496 | Gradient: [[ 0.03024686]\n",
      " [-0.0598147 ]\n",
      " [ 0.10251981]]\n",
      "Iteration 6640 | Cost: 0.3164891470474512 | Gradient: [[ 0.03024625]\n",
      " [-0.0598099 ]\n",
      " [ 0.102512  ]]\n",
      "Iteration 6641 | Cost: 0.3164741468316809 | Gradient: [[ 0.03024563]\n",
      " [-0.0598051 ]\n",
      " [ 0.10250419]]\n",
      "Iteration 6642 | Cost: 0.31645914882879117 | Gradient: [[ 0.03024502]\n",
      " [-0.0598003 ]\n",
      " [ 0.10249637]]\n",
      "Iteration 6643 | Cost: 0.31644415303830914 | Gradient: [[ 0.03024441]\n",
      " [-0.0597955 ]\n",
      " [ 0.10248856]]\n",
      "Iteration 6644 | Cost: 0.31642915945976197 | Gradient: [[ 0.03024379]\n",
      " [-0.05979071]\n",
      " [ 0.10248075]]\n",
      "Iteration 6645 | Cost: 0.3164141680926772 | Gradient: [[ 0.03024318]\n",
      " [-0.05978591]\n",
      " [ 0.10247294]]\n",
      "Iteration 6646 | Cost: 0.31639917893658215 | Gradient: [[ 0.03024257]\n",
      " [-0.05978112]\n",
      " [ 0.10246513]]\n",
      "Iteration 6647 | Cost: 0.3163841919910046 | Gradient: [[ 0.03024195]\n",
      " [-0.05977633]\n",
      " [ 0.10245732]]\n",
      "Iteration 6648 | Cost: 0.31636920725547235 | Gradient: [[ 0.03024134]\n",
      " [-0.05977154]\n",
      " [ 0.10244951]]\n",
      "Iteration 6649 | Cost: 0.3163542247295133 | Gradient: [[ 0.03024072]\n",
      " [-0.05976675]\n",
      " [ 0.10244171]]\n",
      "Iteration 6650 | Cost: 0.3163392444126556 | Gradient: [[ 0.0302401 ]\n",
      " [-0.05976197]\n",
      " [ 0.1024339 ]]\n",
      "Iteration 6651 | Cost: 0.31632426630442745 | Gradient: [[ 0.03023949]\n",
      " [-0.05975718]\n",
      " [ 0.10242609]]\n",
      "Iteration 6652 | Cost: 0.3163092904043572 | Gradient: [[ 0.03023887]\n",
      " [-0.0597524 ]\n",
      " [ 0.10241829]]\n",
      "Iteration 6653 | Cost: 0.3162943167119733 | Gradient: [[ 0.03023825]\n",
      " [-0.05974762]\n",
      " [ 0.10241048]]\n",
      "Iteration 6654 | Cost: 0.3162793452268044 | Gradient: [[ 0.03023763]\n",
      " [-0.05974283]\n",
      " [ 0.10240268]]\n",
      "Iteration 6655 | Cost: 0.3162643759483794 | Gradient: [[ 0.03023702]\n",
      " [-0.05973805]\n",
      " [ 0.10239488]]\n",
      "Iteration 6656 | Cost: 0.316249408876227 | Gradient: [[ 0.0302364 ]\n",
      " [-0.05973328]\n",
      " [ 0.10238708]]\n",
      "Iteration 6657 | Cost: 0.3162344440098764 | Gradient: [[ 0.03023578]\n",
      " [-0.0597285 ]\n",
      " [ 0.10237928]]\n",
      "Iteration 6658 | Cost: 0.3162194813488567 | Gradient: [[ 0.03023516]\n",
      " [-0.05972372]\n",
      " [ 0.10237148]]\n",
      "Iteration 6659 | Cost: 0.31620452089269724 | Gradient: [[ 0.03023454]\n",
      " [-0.05971895]\n",
      " [ 0.10236368]]\n",
      "Iteration 6660 | Cost: 0.3161895626409275 | Gradient: [[ 0.03023392]\n",
      " [-0.05971418]\n",
      " [ 0.10235588]]\n",
      "Iteration 6661 | Cost: 0.3161746065930771 | Gradient: [[ 0.0302333 ]\n",
      " [-0.05970941]\n",
      " [ 0.10234808]]\n",
      "Iteration 6662 | Cost: 0.3161596527486757 | Gradient: [[ 0.03023267]\n",
      " [-0.05970464]\n",
      " [ 0.10234029]]\n",
      "Iteration 6663 | Cost: 0.31614470110725323 | Gradient: [[ 0.03023205]\n",
      " [-0.05969987]\n",
      " [ 0.10233249]]\n",
      "Iteration 6664 | Cost: 0.3161297516683397 | Gradient: [[ 0.03023143]\n",
      " [-0.0596951 ]\n",
      " [ 0.10232469]]\n",
      "Iteration 6665 | Cost: 0.3161148044314652 | Gradient: [[ 0.03023081]\n",
      " [-0.05969033]\n",
      " [ 0.1023169 ]]\n",
      "Iteration 6666 | Cost: 0.3160998593961601 | Gradient: [[ 0.03023018]\n",
      " [-0.05968557]\n",
      " [ 0.10230911]]\n",
      "Iteration 6667 | Cost: 0.31608491656195475 | Gradient: [[ 0.03022956]\n",
      " [-0.05968081]\n",
      " [ 0.10230131]]\n",
      "Iteration 6668 | Cost: 0.31606997592837965 | Gradient: [[ 0.03022893]\n",
      " [-0.05967605]\n",
      " [ 0.10229352]]\n",
      "Iteration 6669 | Cost: 0.3160550374949656 | Gradient: [[ 0.03022831]\n",
      " [-0.05967129]\n",
      " [ 0.10228573]]\n",
      "Iteration 6670 | Cost: 0.31604010126124354 | Gradient: [[ 0.03022768]\n",
      " [-0.05966653]\n",
      " [ 0.10227794]]\n",
      "Iteration 6671 | Cost: 0.3160251672267441 | Gradient: [[ 0.03022706]\n",
      " [-0.05966177]\n",
      " [ 0.10227015]]\n",
      "Iteration 6672 | Cost: 0.31601023539099865 | Gradient: [[ 0.03022643]\n",
      " [-0.05965701]\n",
      " [ 0.10226236]]\n",
      "Iteration 6673 | Cost: 0.31599530575353846 | Gradient: [[ 0.0302258 ]\n",
      " [-0.05965226]\n",
      " [ 0.10225457]]\n",
      "Iteration 6674 | Cost: 0.3159803783138947 | Gradient: [[ 0.03022518]\n",
      " [-0.05964751]\n",
      " [ 0.10224679]]\n",
      "Iteration 6675 | Cost: 0.315965453071599 | Gradient: [[ 0.03022455]\n",
      " [-0.05964275]\n",
      " [ 0.102239  ]]\n",
      "Iteration 6676 | Cost: 0.31595053002618306 | Gradient: [[ 0.03022392]\n",
      " [-0.059638  ]\n",
      " [ 0.10223121]]\n",
      "Iteration 6677 | Cost: 0.3159356091771786 | Gradient: [[ 0.03022329]\n",
      " [-0.05963325]\n",
      " [ 0.10222343]]\n",
      "Iteration 6678 | Cost: 0.3159206905241176 | Gradient: [[ 0.03022266]\n",
      " [-0.05962851]\n",
      " [ 0.10221565]]\n",
      "Iteration 6679 | Cost: 0.315905774066532 | Gradient: [[ 0.03022204]\n",
      " [-0.05962376]\n",
      " [ 0.10220786]]\n",
      "Iteration 6680 | Cost: 0.3158908598039541 | Gradient: [[ 0.03022141]\n",
      " [-0.05961901]\n",
      " [ 0.10220008]]\n",
      "Iteration 6681 | Cost: 0.31587594773591615 | Gradient: [[ 0.03022078]\n",
      " [-0.05961427]\n",
      " [ 0.1021923 ]]\n",
      "Iteration 6682 | Cost: 0.31586103786195074 | Gradient: [[ 0.03022014]\n",
      " [-0.05960953]\n",
      " [ 0.10218452]]\n",
      "Iteration 6683 | Cost: 0.3158461301815904 | Gradient: [[ 0.03021951]\n",
      " [-0.05960479]\n",
      " [ 0.10217674]]\n",
      "Iteration 6684 | Cost: 0.31583122469436786 | Gradient: [[ 0.03021888]\n",
      " [-0.05960005]\n",
      " [ 0.10216896]]\n",
      "Iteration 6685 | Cost: 0.315816321399816 | Gradient: [[ 0.03021825]\n",
      " [-0.05959531]\n",
      " [ 0.10216118]]\n",
      "Iteration 6686 | Cost: 0.31580142029746794 | Gradient: [[ 0.03021762]\n",
      " [-0.05959057]\n",
      " [ 0.1021534 ]]\n",
      "Iteration 6687 | Cost: 0.31578652138685664 | Gradient: [[ 0.03021698]\n",
      " [-0.05958584]\n",
      " [ 0.10214563]]\n",
      "Iteration 6688 | Cost: 0.3157716246675155 | Gradient: [[ 0.03021635]\n",
      " [-0.0595811 ]\n",
      " [ 0.10213785]]\n",
      "Iteration 6689 | Cost: 0.31575673013897804 | Gradient: [[ 0.03021572]\n",
      " [-0.05957637]\n",
      " [ 0.10213007]]\n",
      "Iteration 6690 | Cost: 0.3157418378007775 | Gradient: [[ 0.03021508]\n",
      " [-0.05957164]\n",
      " [ 0.1021223 ]]\n",
      "Iteration 6691 | Cost: 0.3157269476524479 | Gradient: [[ 0.03021445]\n",
      " [-0.05956691]\n",
      " [ 0.10211453]]\n",
      "Iteration 6692 | Cost: 0.3157120596935229 | Gradient: [[ 0.03021381]\n",
      " [-0.05956218]\n",
      " [ 0.10210675]]\n",
      "Iteration 6693 | Cost: 0.3156971739235365 | Gradient: [[ 0.03021318]\n",
      " [-0.05955745]\n",
      " [ 0.10209898]]\n",
      "Iteration 6694 | Cost: 0.31568229034202283 | Gradient: [[ 0.03021254]\n",
      " [-0.05955273]\n",
      " [ 0.10209121]]\n",
      "Iteration 6695 | Cost: 0.3156674089485161 | Gradient: [[ 0.0302119 ]\n",
      " [-0.059548  ]\n",
      " [ 0.10208344]]\n",
      "Iteration 6696 | Cost: 0.3156525297425506 | Gradient: [[ 0.03021127]\n",
      " [-0.05954328]\n",
      " [ 0.10207567]]\n",
      "Iteration 6697 | Cost: 0.31563765272366096 | Gradient: [[ 0.03021063]\n",
      " [-0.05953856]\n",
      " [ 0.1020679 ]]\n",
      "Iteration 6698 | Cost: 0.31562277789138177 | Gradient: [[ 0.03020999]\n",
      " [-0.05953384]\n",
      " [ 0.10206013]]\n",
      "Iteration 6699 | Cost: 0.31560790524524773 | Gradient: [[ 0.03020935]\n",
      " [-0.05952912]\n",
      " [ 0.10205237]]\n",
      "Iteration 6700 | Cost: 0.3155930347847939 | Gradient: [[ 0.03020871]\n",
      " [-0.0595244 ]\n",
      " [ 0.1020446 ]]\n",
      "Iteration 6701 | Cost: 0.3155781665095552 | Gradient: [[ 0.03020808]\n",
      " [-0.05951969]\n",
      " [ 0.10203684]]\n",
      "Iteration 6702 | Cost: 0.31556330041906683 | Gradient: [[ 0.03020744]\n",
      " [-0.05951497]\n",
      " [ 0.10202907]]\n",
      "Iteration 6703 | Cost: 0.3155484365128642 | Gradient: [[ 0.0302068 ]\n",
      " [-0.05951026]\n",
      " [ 0.10202131]]\n",
      "Iteration 6704 | Cost: 0.3155335747904826 | Gradient: [[ 0.03020615]\n",
      " [-0.05950555]\n",
      " [ 0.10201354]]\n",
      "Iteration 6705 | Cost: 0.3155187152514577 | Gradient: [[ 0.03020551]\n",
      " [-0.05950083]\n",
      " [ 0.10200578]]\n",
      "Iteration 6706 | Cost: 0.3155038578953252 | Gradient: [[ 0.03020487]\n",
      " [-0.05949612]\n",
      " [ 0.10199802]]\n",
      "Iteration 6707 | Cost: 0.315489002721621 | Gradient: [[ 0.03020423]\n",
      " [-0.05949142]\n",
      " [ 0.10199026]]\n",
      "Iteration 6708 | Cost: 0.3154741497298811 | Gradient: [[ 0.03020359]\n",
      " [-0.05948671]\n",
      " [ 0.1019825 ]]\n",
      "Iteration 6709 | Cost: 0.3154592989196415 | Gradient: [[ 0.03020295]\n",
      " [-0.059482  ]\n",
      " [ 0.10197474]]\n",
      "Iteration 6710 | Cost: 0.31544445029043855 | Gradient: [[ 0.0302023 ]\n",
      " [-0.0594773 ]\n",
      " [ 0.10196698]]\n",
      "Iteration 6711 | Cost: 0.3154296038418087 | Gradient: [[ 0.03020166]\n",
      " [-0.0594726 ]\n",
      " [ 0.10195922]]\n",
      "Iteration 6712 | Cost: 0.31541475957328835 | Gradient: [[ 0.03020101]\n",
      " [-0.0594679 ]\n",
      " [ 0.10195147]]\n",
      "Iteration 6713 | Cost: 0.3153999174844142 | Gradient: [[ 0.03020037]\n",
      " [-0.0594632 ]\n",
      " [ 0.10194371]]\n",
      "Iteration 6714 | Cost: 0.31538507757472306 | Gradient: [[ 0.03019973]\n",
      " [-0.0594585 ]\n",
      " [ 0.10193596]]\n",
      "Iteration 6715 | Cost: 0.3153702398437519 | Gradient: [[ 0.03019908]\n",
      " [-0.0594538 ]\n",
      " [ 0.1019282 ]]\n",
      "Iteration 6716 | Cost: 0.3153554042910377 | Gradient: [[ 0.03019843]\n",
      " [-0.0594491 ]\n",
      " [ 0.10192045]]\n",
      "Iteration 6717 | Cost: 0.31534057091611767 | Gradient: [[ 0.03019779]\n",
      " [-0.05944441]\n",
      " [ 0.1019127 ]]\n",
      "Iteration 6718 | Cost: 0.3153257397185292 | Gradient: [[ 0.03019714]\n",
      " [-0.05943972]\n",
      " [ 0.10190494]]\n",
      "Iteration 6719 | Cost: 0.31531091069780975 | Gradient: [[ 0.03019649]\n",
      " [-0.05943502]\n",
      " [ 0.10189719]]\n",
      "Iteration 6720 | Cost: 0.3152960838534968 | Gradient: [[ 0.03019585]\n",
      " [-0.05943033]\n",
      " [ 0.10188944]]\n",
      "Iteration 6721 | Cost: 0.31528125918512817 | Gradient: [[ 0.0301952 ]\n",
      " [-0.05942565]\n",
      " [ 0.10188169]]\n",
      "Iteration 6722 | Cost: 0.3152664366922418 | Gradient: [[ 0.03019455]\n",
      " [-0.05942096]\n",
      " [ 0.10187394]]\n",
      "Iteration 6723 | Cost: 0.3152516163743756 | Gradient: [[ 0.0301939 ]\n",
      " [-0.05941627]\n",
      " [ 0.1018662 ]]\n",
      "Iteration 6724 | Cost: 0.31523679823106765 | Gradient: [[ 0.03019325]\n",
      " [-0.05941159]\n",
      " [ 0.10185845]]\n",
      "Iteration 6725 | Cost: 0.3152219822618563 | Gradient: [[ 0.0301926]\n",
      " [-0.0594069]\n",
      " [ 0.1018507]]\n",
      "Iteration 6726 | Cost: 0.31520716846628 | Gradient: [[ 0.03019195]\n",
      " [-0.05940222]\n",
      " [ 0.10184296]]\n",
      "Iteration 6727 | Cost: 0.3151923568438772 | Gradient: [[ 0.0301913 ]\n",
      " [-0.05939754]\n",
      " [ 0.10183521]]\n",
      "Iteration 6728 | Cost: 0.31517754739418663 | Gradient: [[ 0.03019065]\n",
      " [-0.05939286]\n",
      " [ 0.10182747]]\n",
      "Iteration 6729 | Cost: 0.315162740116747 | Gradient: [[ 0.03019   ]\n",
      " [-0.05938818]\n",
      " [ 0.10181973]]\n",
      "Iteration 6730 | Cost: 0.3151479350110972 | Gradient: [[ 0.03018935]\n",
      " [-0.0593835 ]\n",
      " [ 0.10181198]]\n",
      "Iteration 6731 | Cost: 0.3151331320767765 | Gradient: [[ 0.03018869]\n",
      " [-0.05937883]\n",
      " [ 0.10180424]]\n",
      "Iteration 6732 | Cost: 0.315118331313324 | Gradient: [[ 0.03018804]\n",
      " [-0.05937415]\n",
      " [ 0.1017965 ]]\n",
      "Iteration 6733 | Cost: 0.31510353272027897 | Gradient: [[ 0.03018739]\n",
      " [-0.05936948]\n",
      " [ 0.10178876]]\n",
      "Iteration 6734 | Cost: 0.315088736297181 | Gradient: [[ 0.03018674]\n",
      " [-0.05936481]\n",
      " [ 0.10178102]]\n",
      "Iteration 6735 | Cost: 0.3150739420435695 | Gradient: [[ 0.03018608]\n",
      " [-0.05936014]\n",
      " [ 0.10177328]]\n",
      "Iteration 6736 | Cost: 0.3150591499589843 | Gradient: [[ 0.03018543]\n",
      " [-0.05935547]\n",
      " [ 0.10176555]]\n",
      "Iteration 6737 | Cost: 0.31504436004296543 | Gradient: [[ 0.03018477]\n",
      " [-0.0593508 ]\n",
      " [ 0.10175781]]\n",
      "Iteration 6738 | Cost: 0.31502957229505274 | Gradient: [[ 0.03018412]\n",
      " [-0.05934613]\n",
      " [ 0.10175007]]\n",
      "Iteration 6739 | Cost: 0.3150147867147863 | Gradient: [[ 0.03018346]\n",
      " [-0.05934147]\n",
      " [ 0.10174234]]\n",
      "Iteration 6740 | Cost: 0.31500000330170647 | Gradient: [[ 0.0301828 ]\n",
      " [-0.0593368 ]\n",
      " [ 0.10173461]]\n",
      "Iteration 6741 | Cost: 0.31498522205535356 | Gradient: [[ 0.03018215]\n",
      " [-0.05933214]\n",
      " [ 0.10172687]]\n",
      "Iteration 6742 | Cost: 0.31497044297526816 | Gradient: [[ 0.03018149]\n",
      " [-0.05932748]\n",
      " [ 0.10171914]]\n",
      "Iteration 6743 | Cost: 0.314955666060991 | Gradient: [[ 0.03018083]\n",
      " [-0.05932282]\n",
      " [ 0.10171141]]\n",
      "Iteration 6744 | Cost: 0.3149408913120627 | Gradient: [[ 0.03018018]\n",
      " [-0.05931816]\n",
      " [ 0.10170368]]\n",
      "Iteration 6745 | Cost: 0.3149261187280244 | Gradient: [[ 0.03017952]\n",
      " [-0.05931351]\n",
      " [ 0.10169595]]\n",
      "Iteration 6746 | Cost: 0.31491134830841694 | Gradient: [[ 0.03017886]\n",
      " [-0.05930885]\n",
      " [ 0.10168822]]\n",
      "Iteration 6747 | Cost: 0.3148965800527817 | Gradient: [[ 0.0301782 ]\n",
      " [-0.0593042 ]\n",
      " [ 0.10168049]]\n",
      "Iteration 6748 | Cost: 0.31488181396065995 | Gradient: [[ 0.03017754]\n",
      " [-0.05929954]\n",
      " [ 0.10167276]]\n",
      "Iteration 6749 | Cost: 0.314867050031593 | Gradient: [[ 0.03017688]\n",
      " [-0.05929489]\n",
      " [ 0.10166503]]\n",
      "Iteration 6750 | Cost: 0.3148522882651226 | Gradient: [[ 0.03017622]\n",
      " [-0.05929024]\n",
      " [ 0.10165731]]\n",
      "Iteration 6751 | Cost: 0.31483752866079046 | Gradient: [[ 0.03017556]\n",
      " [-0.05928559]\n",
      " [ 0.10164958]]\n",
      "Iteration 6752 | Cost: 0.31482277121813845 | Gradient: [[ 0.0301749 ]\n",
      " [-0.05928094]\n",
      " [ 0.10164186]]\n",
      "Iteration 6753 | Cost: 0.3148080159367083 | Gradient: [[ 0.03017424]\n",
      " [-0.0592763 ]\n",
      " [ 0.10163413]]\n",
      "Iteration 6754 | Cost: 0.3147932628160425 | Gradient: [[ 0.03017357]\n",
      " [-0.05927165]\n",
      " [ 0.10162641]]\n",
      "Iteration 6755 | Cost: 0.31477851185568306 | Gradient: [[ 0.03017291]\n",
      " [-0.05926701]\n",
      " [ 0.10161869]]\n",
      "Iteration 6756 | Cost: 0.31476376305517245 | Gradient: [[ 0.03017225]\n",
      " [-0.05926237]\n",
      " [ 0.10161097]]\n",
      "Iteration 6757 | Cost: 0.3147490164140531 | Gradient: [[ 0.03017158]\n",
      " [-0.05925772]\n",
      " [ 0.10160325]]\n",
      "Iteration 6758 | Cost: 0.3147342719318678 | Gradient: [[ 0.03017092]\n",
      " [-0.05925308]\n",
      " [ 0.10159553]]\n",
      "Iteration 6759 | Cost: 0.3147195296081592 | Gradient: [[ 0.03017026]\n",
      " [-0.05924845]\n",
      " [ 0.10158781]]\n",
      "Iteration 6760 | Cost: 0.3147047894424702 | Gradient: [[ 0.03016959]\n",
      " [-0.05924381]\n",
      " [ 0.10158009]]\n",
      "Iteration 6761 | Cost: 0.31469005143434386 | Gradient: [[ 0.03016893]\n",
      " [-0.05923917]\n",
      " [ 0.10157237]]\n",
      "Iteration 6762 | Cost: 0.31467531558332335 | Gradient: [[ 0.03016826]\n",
      " [-0.05923454]\n",
      " [ 0.10156465]]\n",
      "Iteration 6763 | Cost: 0.314660581888952 | Gradient: [[ 0.03016759]\n",
      " [-0.0592299 ]\n",
      " [ 0.10155694]]\n",
      "Iteration 6764 | Cost: 0.31464585035077336 | Gradient: [[ 0.03016693]\n",
      " [-0.05922527]\n",
      " [ 0.10154922]]\n",
      "Iteration 6765 | Cost: 0.31463112096833074 | Gradient: [[ 0.03016626]\n",
      " [-0.05922064]\n",
      " [ 0.10154151]]\n",
      "Iteration 6766 | Cost: 0.31461639374116795 | Gradient: [[ 0.03016559]\n",
      " [-0.05921601]\n",
      " [ 0.1015338 ]]\n",
      "Iteration 6767 | Cost: 0.31460166866882877 | Gradient: [[ 0.03016493]\n",
      " [-0.05921138]\n",
      " [ 0.10152608]]\n",
      "Iteration 6768 | Cost: 0.31458694575085727 | Gradient: [[ 0.03016426]\n",
      " [-0.05920676]\n",
      " [ 0.10151837]]\n",
      "Iteration 6769 | Cost: 0.3145722249867975 | Gradient: [[ 0.03016359]\n",
      " [-0.05920213]\n",
      " [ 0.10151066]]\n",
      "Iteration 6770 | Cost: 0.3145575063761936 | Gradient: [[ 0.03016292]\n",
      " [-0.05919751]\n",
      " [ 0.10150295]]\n",
      "Iteration 6771 | Cost: 0.31454278991859 | Gradient: [[ 0.03016225]\n",
      " [-0.05919288]\n",
      " [ 0.10149524]]\n",
      "Iteration 6772 | Cost: 0.31452807561353113 | Gradient: [[ 0.03016158]\n",
      " [-0.05918826]\n",
      " [ 0.10148753]]\n",
      "Iteration 6773 | Cost: 0.3145133634605617 | Gradient: [[ 0.03016091]\n",
      " [-0.05918364]\n",
      " [ 0.10147983]]\n",
      "Iteration 6774 | Cost: 0.3144986534592263 | Gradient: [[ 0.03016024]\n",
      " [-0.05917902]\n",
      " [ 0.10147212]]\n",
      "Iteration 6775 | Cost: 0.3144839456090698 | Gradient: [[ 0.03015957]\n",
      " [-0.05917441]\n",
      " [ 0.10146441]]\n",
      "Iteration 6776 | Cost: 0.3144692399096374 | Gradient: [[ 0.0301589 ]\n",
      " [-0.05916979]\n",
      " [ 0.10145671]]\n",
      "Iteration 6777 | Cost: 0.31445453636047405 | Gradient: [[ 0.03015823]\n",
      " [-0.05916518]\n",
      " [ 0.101449  ]]\n",
      "Iteration 6778 | Cost: 0.3144398349611251 | Gradient: [[ 0.03015755]\n",
      " [-0.05916056]\n",
      " [ 0.1014413 ]]\n",
      "Iteration 6779 | Cost: 0.3144251357111359 | Gradient: [[ 0.03015688]\n",
      " [-0.05915595]\n",
      " [ 0.1014336 ]]\n",
      "Iteration 6780 | Cost: 0.31441043861005197 | Gradient: [[ 0.03015621]\n",
      " [-0.05915134]\n",
      " [ 0.10142589]]\n",
      "Iteration 6781 | Cost: 0.31439574365741907 | Gradient: [[ 0.03015554]\n",
      " [-0.05914673]\n",
      " [ 0.10141819]]\n",
      "Iteration 6782 | Cost: 0.3143810508527829 | Gradient: [[ 0.03015486]\n",
      " [-0.05914212]\n",
      " [ 0.10141049]]\n",
      "Iteration 6783 | Cost: 0.31436636019568936 | Gradient: [[ 0.03015419]\n",
      " [-0.05913751]\n",
      " [ 0.10140279]]\n",
      "Iteration 6784 | Cost: 0.31435167168568456 | Gradient: [[ 0.03015351]\n",
      " [-0.05913291]\n",
      " [ 0.10139509]]\n",
      "Iteration 6785 | Cost: 0.3143369853223145 | Gradient: [[ 0.03015284]\n",
      " [-0.0591283 ]\n",
      " [ 0.1013874 ]]\n",
      "Iteration 6786 | Cost: 0.3143223011051258 | Gradient: [[ 0.03015216]\n",
      " [-0.0591237 ]\n",
      " [ 0.1013797 ]]\n",
      "Iteration 6787 | Cost: 0.31430761903366466 | Gradient: [[ 0.03015149]\n",
      " [-0.0591191 ]\n",
      " [ 0.101372  ]]\n",
      "Iteration 6788 | Cost: 0.31429293910747763 | Gradient: [[ 0.03015081]\n",
      " [-0.0591145 ]\n",
      " [ 0.10136431]]\n",
      "Iteration 6789 | Cost: 0.31427826132611153 | Gradient: [[ 0.03015013]\n",
      " [-0.0591099 ]\n",
      " [ 0.10135661]]\n",
      "Iteration 6790 | Cost: 0.3142635856891132 | Gradient: [[ 0.03014945]\n",
      " [-0.0591053 ]\n",
      " [ 0.10134892]]\n",
      "Iteration 6791 | Cost: 0.3142489121960295 | Gradient: [[ 0.03014878]\n",
      " [-0.0591007 ]\n",
      " [ 0.10134122]]\n",
      "Iteration 6792 | Cost: 0.3142342408464076 | Gradient: [[ 0.0301481 ]\n",
      " [-0.05909611]\n",
      " [ 0.10133353]]\n",
      "Iteration 6793 | Cost: 0.3142195716397946 | Gradient: [[ 0.03014742]\n",
      " [-0.05909151]\n",
      " [ 0.10132584]]\n",
      "Iteration 6794 | Cost: 0.31420490457573796 | Gradient: [[ 0.03014674]\n",
      " [-0.05908692]\n",
      " [ 0.10131815]]\n",
      "Iteration 6795 | Cost: 0.314190239653785 | Gradient: [[ 0.03014606]\n",
      " [-0.05908233]\n",
      " [ 0.10131046]]\n",
      "Iteration 6796 | Cost: 0.3141755768734836 | Gradient: [[ 0.03014538]\n",
      " [-0.05907774]\n",
      " [ 0.10130277]]\n",
      "Iteration 6797 | Cost: 0.3141609162343812 | Gradient: [[ 0.0301447 ]\n",
      " [-0.05907315]\n",
      " [ 0.10129508]]\n",
      "Iteration 6798 | Cost: 0.31414625773602584 | Gradient: [[ 0.03014402]\n",
      " [-0.05906856]\n",
      " [ 0.10128739]]\n",
      "Iteration 6799 | Cost: 0.3141316013779655 | Gradient: [[ 0.03014334]\n",
      " [-0.05906397]\n",
      " [ 0.10127971]]\n",
      "Iteration 6800 | Cost: 0.3141169471597482 | Gradient: [[ 0.03014266]\n",
      " [-0.05905939]\n",
      " [ 0.10127202]]\n",
      "Iteration 6801 | Cost: 0.31410229508092224 | Gradient: [[ 0.03014198]\n",
      " [-0.05905481]\n",
      " [ 0.10126434]]\n",
      "Iteration 6802 | Cost: 0.3140876451410361 | Gradient: [[ 0.0301413 ]\n",
      " [-0.05905022]\n",
      " [ 0.10125665]]\n",
      "Iteration 6803 | Cost: 0.31407299733963817 | Gradient: [[ 0.03014061]\n",
      " [-0.05904564]\n",
      " [ 0.10124897]]\n",
      "Iteration 6804 | Cost: 0.31405835167627716 | Gradient: [[ 0.03013993]\n",
      " [-0.05904106]\n",
      " [ 0.10124128]]\n",
      "Iteration 6805 | Cost: 0.31404370815050175 | Gradient: [[ 0.03013925]\n",
      " [-0.05903648]\n",
      " [ 0.1012336 ]]\n",
      "Iteration 6806 | Cost: 0.31402906676186093 | Gradient: [[ 0.03013856]\n",
      " [-0.05903191]\n",
      " [ 0.10122592]]\n",
      "Iteration 6807 | Cost: 0.3140144275099036 | Gradient: [[ 0.03013788]\n",
      " [-0.05902733]\n",
      " [ 0.10121824]]\n",
      "Iteration 6808 | Cost: 0.3139997903941791 | Gradient: [[ 0.03013719]\n",
      " [-0.05902275]\n",
      " [ 0.10121056]]\n",
      "Iteration 6809 | Cost: 0.3139851554142366 | Gradient: [[ 0.03013651]\n",
      " [-0.05901818]\n",
      " [ 0.10120288]]\n",
      "Iteration 6810 | Cost: 0.3139705225696255 | Gradient: [[ 0.03013582]\n",
      " [-0.05901361]\n",
      " [ 0.10119521]]\n",
      "Iteration 6811 | Cost: 0.31395589185989536 | Gradient: [[ 0.03013514]\n",
      " [-0.05900904]\n",
      " [ 0.10118753]]\n",
      "Iteration 6812 | Cost: 0.3139412632845958 | Gradient: [[ 0.03013445]\n",
      " [-0.05900447]\n",
      " [ 0.10117985]]\n",
      "Iteration 6813 | Cost: 0.3139266368432768 | Gradient: [[ 0.03013377]\n",
      " [-0.0589999 ]\n",
      " [ 0.10117218]]\n",
      "Iteration 6814 | Cost: 0.31391201253548817 | Gradient: [[ 0.03013308]\n",
      " [-0.05899533]\n",
      " [ 0.1011645 ]]\n",
      "Iteration 6815 | Cost: 0.31389739036077985 | Gradient: [[ 0.03013239]\n",
      " [-0.05899077]\n",
      " [ 0.10115683]]\n",
      "Iteration 6816 | Cost: 0.31388277031870215 | Gradient: [[ 0.0301317 ]\n",
      " [-0.0589862 ]\n",
      " [ 0.10114915]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6817 | Cost: 0.31386815240880545 | Gradient: [[ 0.03013101]\n",
      " [-0.05898164]\n",
      " [ 0.10114148]]\n",
      "Iteration 6818 | Cost: 0.31385353663064003 | Gradient: [[ 0.03013033]\n",
      " [-0.05897708]\n",
      " [ 0.10113381]]\n",
      "Iteration 6819 | Cost: 0.3138389229837565 | Gradient: [[ 0.03012964]\n",
      " [-0.05897252]\n",
      " [ 0.10112614]]\n",
      "Iteration 6820 | Cost: 0.3138243114677056 | Gradient: [[ 0.03012895]\n",
      " [-0.05896796]\n",
      " [ 0.10111847]]\n",
      "Iteration 6821 | Cost: 0.3138097020820382 | Gradient: [[ 0.03012826]\n",
      " [-0.0589634 ]\n",
      " [ 0.1011108 ]]\n",
      "Iteration 6822 | Cost: 0.3137950948263052 | Gradient: [[ 0.03012757]\n",
      " [-0.05895884]\n",
      " [ 0.10110313]]\n",
      "Iteration 6823 | Cost: 0.31378048970005756 | Gradient: [[ 0.03012688]\n",
      " [-0.05895428]\n",
      " [ 0.10109546]]\n",
      "Iteration 6824 | Cost: 0.31376588670284666 | Gradient: [[ 0.03012619]\n",
      " [-0.05894973]\n",
      " [ 0.1010878 ]]\n",
      "Iteration 6825 | Cost: 0.31375128583422385 | Gradient: [[ 0.03012549]\n",
      " [-0.05894518]\n",
      " [ 0.10108013]]\n",
      "Iteration 6826 | Cost: 0.3137366870937404 | Gradient: [[ 0.0301248 ]\n",
      " [-0.05894063]\n",
      " [ 0.10107247]]\n",
      "Iteration 6827 | Cost: 0.3137220904809482 | Gradient: [[ 0.03012411]\n",
      " [-0.05893607]\n",
      " [ 0.1010648 ]]\n",
      "Iteration 6828 | Cost: 0.31370749599539866 | Gradient: [[ 0.03012342]\n",
      " [-0.05893153]\n",
      " [ 0.10105714]]\n",
      "Iteration 6829 | Cost: 0.31369290363664376 | Gradient: [[ 0.03012272]\n",
      " [-0.05892698]\n",
      " [ 0.10104948]]\n",
      "Iteration 6830 | Cost: 0.3136783134042355 | Gradient: [[ 0.03012203]\n",
      " [-0.05892243]\n",
      " [ 0.10104182]]\n",
      "Iteration 6831 | Cost: 0.313663725297726 | Gradient: [[ 0.03012134]\n",
      " [-0.05891789]\n",
      " [ 0.10103415]]\n",
      "Iteration 6832 | Cost: 0.31364913931666744 | Gradient: [[ 0.03012064]\n",
      " [-0.05891334]\n",
      " [ 0.10102649]]\n",
      "Iteration 6833 | Cost: 0.31363455546061214 | Gradient: [[ 0.03011995]\n",
      " [-0.0589088 ]\n",
      " [ 0.10101883]]\n",
      "Iteration 6834 | Cost: 0.31361997372911266 | Gradient: [[ 0.03011925]\n",
      " [-0.05890426]\n",
      " [ 0.10101118]]\n",
      "Iteration 6835 | Cost: 0.3136053941217217 | Gradient: [[ 0.03011856]\n",
      " [-0.05889972]\n",
      " [ 0.10100352]]\n",
      "Iteration 6836 | Cost: 0.3135908166379918 | Gradient: [[ 0.03011786]\n",
      " [-0.05889518]\n",
      " [ 0.10099586]]\n",
      "Iteration 6837 | Cost: 0.3135762412774759 | Gradient: [[ 0.03011716]\n",
      " [-0.05889064]\n",
      " [ 0.1009882 ]]\n",
      "Iteration 6838 | Cost: 0.313561668039727 | Gradient: [[ 0.03011647]\n",
      " [-0.0588861 ]\n",
      " [ 0.10098055]]\n",
      "Iteration 6839 | Cost: 0.3135470969242983 | Gradient: [[ 0.03011577]\n",
      " [-0.05888157]\n",
      " [ 0.10097289]]\n",
      "Iteration 6840 | Cost: 0.31353252793074293 | Gradient: [[ 0.03011507]\n",
      " [-0.05887703]\n",
      " [ 0.10096524]]\n",
      "Iteration 6841 | Cost: 0.3135179610586144 | Gradient: [[ 0.03011438]\n",
      " [-0.0588725 ]\n",
      " [ 0.10095759]]\n",
      "Iteration 6842 | Cost: 0.31350339630746604 | Gradient: [[ 0.03011368]\n",
      " [-0.05886797]\n",
      " [ 0.10094994]]\n",
      "Iteration 6843 | Cost: 0.31348883367685165 | Gradient: [[ 0.03011298]\n",
      " [-0.05886344]\n",
      " [ 0.10094228]]\n",
      "Iteration 6844 | Cost: 0.3134742731663249 | Gradient: [[ 0.03011228]\n",
      " [-0.05885891]\n",
      " [ 0.10093463]]\n",
      "Iteration 6845 | Cost: 0.3134597147754397 | Gradient: [[ 0.03011158]\n",
      " [-0.05885438]\n",
      " [ 0.10092698]]\n",
      "Iteration 6846 | Cost: 0.31344515850375 | Gradient: [[ 0.03011088]\n",
      " [-0.05884985]\n",
      " [ 0.10091933]]\n",
      "Iteration 6847 | Cost: 0.31343060435081005 | Gradient: [[ 0.03011018]\n",
      " [-0.05884533]\n",
      " [ 0.10091169]]\n",
      "Iteration 6848 | Cost: 0.313416052316174 | Gradient: [[ 0.03010948]\n",
      " [-0.0588408 ]\n",
      " [ 0.10090404]]\n",
      "Iteration 6849 | Cost: 0.31340150239939624 | Gradient: [[ 0.03010878]\n",
      " [-0.05883628]\n",
      " [ 0.10089639]]\n",
      "Iteration 6850 | Cost: 0.3133869546000314 | Gradient: [[ 0.03010808]\n",
      " [-0.05883176]\n",
      " [ 0.10088875]]\n",
      "Iteration 6851 | Cost: 0.31337240891763407 | Gradient: [[ 0.03010737]\n",
      " [-0.05882724]\n",
      " [ 0.1008811 ]]\n",
      "Iteration 6852 | Cost: 0.313357865351759 | Gradient: [[ 0.03010667]\n",
      " [-0.05882272]\n",
      " [ 0.10087346]]\n",
      "Iteration 6853 | Cost: 0.31334332390196107 | Gradient: [[ 0.03010597]\n",
      " [-0.0588182 ]\n",
      " [ 0.10086581]]\n",
      "Iteration 6854 | Cost: 0.3133287845677954 | Gradient: [[ 0.03010527]\n",
      " [-0.05881369]\n",
      " [ 0.10085817]]\n",
      "Iteration 6855 | Cost: 0.31331424734881697 | Gradient: [[ 0.03010456]\n",
      " [-0.05880917]\n",
      " [ 0.10085053]]\n",
      "Iteration 6856 | Cost: 0.31329971224458125 | Gradient: [[ 0.03010386]\n",
      " [-0.05880466]\n",
      " [ 0.10084289]]\n",
      "Iteration 6857 | Cost: 0.31328517925464355 | Gradient: [[ 0.03010316]\n",
      " [-0.05880014]\n",
      " [ 0.10083525]]\n",
      "Iteration 6858 | Cost: 0.3132706483785594 | Gradient: [[ 0.03010245]\n",
      " [-0.05879563]\n",
      " [ 0.10082761]]\n",
      "Iteration 6859 | Cost: 0.31325611961588434 | Gradient: [[ 0.03010175]\n",
      " [-0.05879112]\n",
      " [ 0.10081997]]\n",
      "Iteration 6860 | Cost: 0.3132415929661744 | Gradient: [[ 0.03010104]\n",
      " [-0.05878661]\n",
      " [ 0.10081233]]\n",
      "Iteration 6861 | Cost: 0.3132270684289852 | Gradient: [[ 0.03010033]\n",
      " [-0.05878211]\n",
      " [ 0.1008047 ]]\n",
      "Iteration 6862 | Cost: 0.313212546003873 | Gradient: [[ 0.03009963]\n",
      " [-0.0587776 ]\n",
      " [ 0.10079706]]\n",
      "Iteration 6863 | Cost: 0.3131980256903939 | Gradient: [[ 0.03009892]\n",
      " [-0.05877309]\n",
      " [ 0.10078943]]\n",
      "Iteration 6864 | Cost: 0.3131835074881042 | Gradient: [[ 0.03009822]\n",
      " [-0.05876859]\n",
      " [ 0.10078179]]\n",
      "Iteration 6865 | Cost: 0.3131689913965602 | Gradient: [[ 0.03009751]\n",
      " [-0.05876409]\n",
      " [ 0.10077416]]\n",
      "Iteration 6866 | Cost: 0.3131544774153185 | Gradient: [[ 0.0300968 ]\n",
      " [-0.05875959]\n",
      " [ 0.10076653]]\n",
      "Iteration 6867 | Cost: 0.3131399655439357 | Gradient: [[ 0.03009609]\n",
      " [-0.05875508]\n",
      " [ 0.10075889]]\n",
      "Iteration 6868 | Cost: 0.31312545578196876 | Gradient: [[ 0.03009538]\n",
      " [-0.05875059]\n",
      " [ 0.10075126]]\n",
      "Iteration 6869 | Cost: 0.31311094812897444 | Gradient: [[ 0.03009467]\n",
      " [-0.05874609]\n",
      " [ 0.10074363]]\n",
      "Iteration 6870 | Cost: 0.31309644258450986 | Gradient: [[ 0.03009397]\n",
      " [-0.05874159]\n",
      " [ 0.100736  ]]\n",
      "Iteration 6871 | Cost: 0.31308193914813215 | Gradient: [[ 0.03009326]\n",
      " [-0.0587371 ]\n",
      " [ 0.10072837]]\n",
      "Iteration 6872 | Cost: 0.3130674378193986 | Gradient: [[ 0.03009255]\n",
      " [-0.0587326 ]\n",
      " [ 0.10072074]]\n",
      "Iteration 6873 | Cost: 0.3130529385978666 | Gradient: [[ 0.03009184]\n",
      " [-0.05872811]\n",
      " [ 0.10071312]]\n",
      "Iteration 6874 | Cost: 0.31303844148309373 | Gradient: [[ 0.03009112]\n",
      " [-0.05872362]\n",
      " [ 0.10070549]]\n",
      "Iteration 6875 | Cost: 0.31302394647463755 | Gradient: [[ 0.03009041]\n",
      " [-0.05871913]\n",
      " [ 0.10069787]]\n",
      "Iteration 6876 | Cost: 0.313009453572056 | Gradient: [[ 0.0300897 ]\n",
      " [-0.05871464]\n",
      " [ 0.10069024]]\n",
      "Iteration 6877 | Cost: 0.3129949627749069 | Gradient: [[ 0.03008899]\n",
      " [-0.05871015]\n",
      " [ 0.10068262]]\n",
      "Iteration 6878 | Cost: 0.3129804740827483 | Gradient: [[ 0.03008828]\n",
      " [-0.05870566]\n",
      " [ 0.10067499]]\n",
      "Iteration 6879 | Cost: 0.3129659874951385 | Gradient: [[ 0.03008756]\n",
      " [-0.05870118]\n",
      " [ 0.10066737]]\n",
      "Iteration 6880 | Cost: 0.3129515030116356 | Gradient: [[ 0.03008685]\n",
      " [-0.05869669]\n",
      " [ 0.10065975]]\n",
      "Iteration 6881 | Cost: 0.31293702063179807 | Gradient: [[ 0.03008614]\n",
      " [-0.05869221]\n",
      " [ 0.10065213]]\n",
      "Iteration 6882 | Cost: 0.31292254035518446 | Gradient: [[ 0.03008542]\n",
      " [-0.05868773]\n",
      " [ 0.10064451]]\n",
      "Iteration 6883 | Cost: 0.3129080621813535 | Gradient: [[ 0.03008471]\n",
      " [-0.05868325]\n",
      " [ 0.10063689]]\n",
      "Iteration 6884 | Cost: 0.3128935861098639 | Gradient: [[ 0.03008399]\n",
      " [-0.05867877]\n",
      " [ 0.10062927]]\n",
      "Iteration 6885 | Cost: 0.3128791121402746 | Gradient: [[ 0.03008328]\n",
      " [-0.05867429]\n",
      " [ 0.10062165]]\n",
      "Iteration 6886 | Cost: 0.31286464027214456 | Gradient: [[ 0.03008256]\n",
      " [-0.05866981]\n",
      " [ 0.10061404]]\n",
      "Iteration 6887 | Cost: 0.3128501705050331 | Gradient: [[ 0.03008185]\n",
      " [-0.05866534]\n",
      " [ 0.10060642]]\n",
      "Iteration 6888 | Cost: 0.3128357028384994 | Gradient: [[ 0.03008113]\n",
      " [-0.05866086]\n",
      " [ 0.10059881]]\n",
      "Iteration 6889 | Cost: 0.312821237272103 | Gradient: [[ 0.03008042]\n",
      " [-0.05865639]\n",
      " [ 0.10059119]]\n",
      "Iteration 6890 | Cost: 0.31280677380540317 | Gradient: [[ 0.0300797 ]\n",
      " [-0.05865192]\n",
      " [ 0.10058358]]\n",
      "Iteration 6891 | Cost: 0.3127923124379598 | Gradient: [[ 0.03007898]\n",
      " [-0.05864745]\n",
      " [ 0.10057597]]\n",
      "Iteration 6892 | Cost: 0.3127778531693326 | Gradient: [[ 0.03007826]\n",
      " [-0.05864298]\n",
      " [ 0.10056835]]\n",
      "Iteration 6893 | Cost: 0.31276339599908154 | Gradient: [[ 0.03007755]\n",
      " [-0.05863851]\n",
      " [ 0.10056074]]\n",
      "Iteration 6894 | Cost: 0.3127489409267666 | Gradient: [[ 0.03007683]\n",
      " [-0.05863404]\n",
      " [ 0.10055313]]\n",
      "Iteration 6895 | Cost: 0.3127344879519479 | Gradient: [[ 0.03007611]\n",
      " [-0.05862958]\n",
      " [ 0.10054552]]\n",
      "Iteration 6896 | Cost: 0.3127200370741858 | Gradient: [[ 0.03007539]\n",
      " [-0.05862511]\n",
      " [ 0.10053791]]\n",
      "Iteration 6897 | Cost: 0.3127055882930407 | Gradient: [[ 0.03007467]\n",
      " [-0.05862065]\n",
      " [ 0.10053031]]\n",
      "Iteration 6898 | Cost: 0.31269114160807304 | Gradient: [[ 0.03007395]\n",
      " [-0.05861619]\n",
      " [ 0.1005227 ]]\n",
      "Iteration 6899 | Cost: 0.3126766970188436 | Gradient: [[ 0.03007323]\n",
      " [-0.05861173]\n",
      " [ 0.10051509]]\n",
      "Iteration 6900 | Cost: 0.3126622545249131 | Gradient: [[ 0.03007251]\n",
      " [-0.05860727]\n",
      " [ 0.10050749]]\n",
      "Iteration 6901 | Cost: 0.31264781412584236 | Gradient: [[ 0.03007179]\n",
      " [-0.05860281]\n",
      " [ 0.10049988]]\n",
      "Iteration 6902 | Cost: 0.3126333758211926 | Gradient: [[ 0.03007107]\n",
      " [-0.05859835]\n",
      " [ 0.10049228]]\n",
      "Iteration 6903 | Cost: 0.3126189396105248 | Gradient: [[ 0.03007034]\n",
      " [-0.0585939 ]\n",
      " [ 0.10048468]]\n",
      "Iteration 6904 | Cost: 0.3126045054934003 | Gradient: [[ 0.03006962]\n",
      " [-0.05858944]\n",
      " [ 0.10047707]]\n",
      "Iteration 6905 | Cost: 0.3125900734693805 | Gradient: [[ 0.0300689 ]\n",
      " [-0.05858499]\n",
      " [ 0.10046947]]\n",
      "Iteration 6906 | Cost: 0.31257564353802697 | Gradient: [[ 0.03006818]\n",
      " [-0.05858053]\n",
      " [ 0.10046187]]\n",
      "Iteration 6907 | Cost: 0.3125612156989012 | Gradient: [[ 0.03006745]\n",
      " [-0.05857608]\n",
      " [ 0.10045427]]\n",
      "Iteration 6908 | Cost: 0.31254678995156515 | Gradient: [[ 0.03006673]\n",
      " [-0.05857163]\n",
      " [ 0.10044667]]\n",
      "Iteration 6909 | Cost: 0.31253236629558057 | Gradient: [[ 0.030066  ]\n",
      " [-0.05856719]\n",
      " [ 0.10043908]]\n",
      "Iteration 6910 | Cost: 0.3125179447305095 | Gradient: [[ 0.03006528]\n",
      " [-0.05856274]\n",
      " [ 0.10043148]]\n",
      "Iteration 6911 | Cost: 0.3125035252559142 | Gradient: [[ 0.03006455]\n",
      " [-0.05855829]\n",
      " [ 0.10042388]]\n",
      "Iteration 6912 | Cost: 0.3124891078713567 | Gradient: [[ 0.03006383]\n",
      " [-0.05855385]\n",
      " [ 0.10041629]]\n",
      "Iteration 6913 | Cost: 0.31247469257639954 | Gradient: [[ 0.0300631 ]\n",
      " [-0.0585494 ]\n",
      " [ 0.10040869]]\n",
      "Iteration 6914 | Cost: 0.3124602793706053 | Gradient: [[ 0.03006238]\n",
      " [-0.05854496]\n",
      " [ 0.1004011 ]]\n",
      "Iteration 6915 | Cost: 0.31244586825353643 | Gradient: [[ 0.03006165]\n",
      " [-0.05854052]\n",
      " [ 0.1003935 ]]\n",
      "Iteration 6916 | Cost: 0.31243145922475585 | Gradient: [[ 0.03006092]\n",
      " [-0.05853608]\n",
      " [ 0.10038591]]\n",
      "Iteration 6917 | Cost: 0.3124170522838263 | Gradient: [[ 0.0300602 ]\n",
      " [-0.05853164]\n",
      " [ 0.10037832]]\n",
      "Iteration 6918 | Cost: 0.31240264743031093 | Gradient: [[ 0.03005947]\n",
      " [-0.0585272 ]\n",
      " [ 0.10037073]]\n",
      "Iteration 6919 | Cost: 0.3123882446637727 | Gradient: [[ 0.03005874]\n",
      " [-0.05852276]\n",
      " [ 0.10036314]]\n",
      "Iteration 6920 | Cost: 0.31237384398377493 | Gradient: [[ 0.03005801]\n",
      " [-0.05851833]\n",
      " [ 0.10035555]]\n",
      "Iteration 6921 | Cost: 0.31235944538988103 | Gradient: [[ 0.03005728]\n",
      " [-0.0585139 ]\n",
      " [ 0.10034796]]\n",
      "Iteration 6922 | Cost: 0.3123450488816545 | Gradient: [[ 0.03005656]\n",
      " [-0.05850946]\n",
      " [ 0.10034037]]\n",
      "Iteration 6923 | Cost: 0.3123306544586589 | Gradient: [[ 0.03005583]\n",
      " [-0.05850503]\n",
      " [ 0.10033279]]\n",
      "Iteration 6924 | Cost: 0.31231626212045793 | Gradient: [[ 0.0300551]\n",
      " [-0.0585006]\n",
      " [ 0.1003252]]\n",
      "Iteration 6925 | Cost: 0.31230187186661557 | Gradient: [[ 0.03005437]\n",
      " [-0.05849617]\n",
      " [ 0.10031762]]\n",
      "Iteration 6926 | Cost: 0.3122874836966956 | Gradient: [[ 0.03005364]\n",
      " [-0.05849174]\n",
      " [ 0.10031003]]\n",
      "Iteration 6927 | Cost: 0.31227309761026245 | Gradient: [[ 0.0300529 ]\n",
      " [-0.05848732]\n",
      " [ 0.10030245]]\n",
      "Iteration 6928 | Cost: 0.31225871360688007 | Gradient: [[ 0.03005217]\n",
      " [-0.05848289]\n",
      " [ 0.10029486]]\n",
      "Iteration 6929 | Cost: 0.3122443316861129 | Gradient: [[ 0.03005144]\n",
      " [-0.05847847]\n",
      " [ 0.10028728]]\n",
      "Iteration 6930 | Cost: 0.3122299518475254 | Gradient: [[ 0.03005071]\n",
      " [-0.05847404]\n",
      " [ 0.1002797 ]]\n",
      "Iteration 6931 | Cost: 0.31221557409068224 | Gradient: [[ 0.03004998]\n",
      " [-0.05846962]\n",
      " [ 0.10027212]]\n",
      "Iteration 6932 | Cost: 0.31220119841514804 | Gradient: [[ 0.03004924]\n",
      " [-0.0584652 ]\n",
      " [ 0.10026454]]\n",
      "Iteration 6933 | Cost: 0.3121868248204877 | Gradient: [[ 0.03004851]\n",
      " [-0.05846078]\n",
      " [ 0.10025696]]\n",
      "Iteration 6934 | Cost: 0.3121724533062661 | Gradient: [[ 0.03004778]\n",
      " [-0.05845636]\n",
      " [ 0.10024938]]\n",
      "Iteration 6935 | Cost: 0.31215808387204846 | Gradient: [[ 0.03004704]\n",
      " [-0.05845194]\n",
      " [ 0.10024181]]\n",
      "Iteration 6936 | Cost: 0.31214371651739986 | Gradient: [[ 0.03004631]\n",
      " [-0.05844753]\n",
      " [ 0.10023423]]\n",
      "Iteration 6937 | Cost: 0.31212935124188573 | Gradient: [[ 0.03004557]\n",
      " [-0.05844311]\n",
      " [ 0.10022666]]\n",
      "Iteration 6938 | Cost: 0.31211498804507143 | Gradient: [[ 0.03004484]\n",
      " [-0.0584387 ]\n",
      " [ 0.10021908]]\n",
      "Iteration 6939 | Cost: 0.3121006269265225 | Gradient: [[ 0.0300441 ]\n",
      " [-0.05843429]\n",
      " [ 0.10021151]]\n",
      "Iteration 6940 | Cost: 0.3120862678858049 | Gradient: [[ 0.03004337]\n",
      " [-0.05842988]\n",
      " [ 0.10020393]]\n",
      "Iteration 6941 | Cost: 0.31207191092248415 | Gradient: [[ 0.03004263]\n",
      " [-0.05842546]\n",
      " [ 0.10019636]]\n",
      "Iteration 6942 | Cost: 0.3120575560361263 | Gradient: [[ 0.0300419 ]\n",
      " [-0.05842106]\n",
      " [ 0.10018879]]\n",
      "Iteration 6943 | Cost: 0.31204320322629747 | Gradient: [[ 0.03004116]\n",
      " [-0.05841665]\n",
      " [ 0.10018122]]\n",
      "Iteration 6944 | Cost: 0.3120288524925637 | Gradient: [[ 0.03004042]\n",
      " [-0.05841224]\n",
      " [ 0.10017365]]\n",
      "Iteration 6945 | Cost: 0.31201450383449136 | Gradient: [[ 0.03003968]\n",
      " [-0.05840784]\n",
      " [ 0.10016608]]\n",
      "Iteration 6946 | Cost: 0.31200015725164687 | Gradient: [[ 0.03003895]\n",
      " [-0.05840343]\n",
      " [ 0.10015851]]\n",
      "Iteration 6947 | Cost: 0.31198581274359694 | Gradient: [[ 0.03003821]\n",
      " [-0.05839903]\n",
      " [ 0.10015094]]\n",
      "Iteration 6948 | Cost: 0.311971470309908 | Gradient: [[ 0.03003747]\n",
      " [-0.05839463]\n",
      " [ 0.10014338]]\n",
      "Iteration 6949 | Cost: 0.31195712995014685 | Gradient: [[ 0.03003673]\n",
      " [-0.05839023]\n",
      " [ 0.10013581]]\n",
      "Iteration 6950 | Cost: 0.3119427916638806 | Gradient: [[ 0.03003599]\n",
      " [-0.05838583]\n",
      " [ 0.10012825]]\n",
      "Iteration 6951 | Cost: 0.3119284554506761 | Gradient: [[ 0.03003525]\n",
      " [-0.05838143]\n",
      " [ 0.10012068]]\n",
      "Iteration 6952 | Cost: 0.3119141213101006 | Gradient: [[ 0.03003451]\n",
      " [-0.05837703]\n",
      " [ 0.10011312]]\n",
      "Iteration 6953 | Cost: 0.31189978924172135 | Gradient: [[ 0.03003377]\n",
      " [-0.05837264]\n",
      " [ 0.10010556]]\n",
      "Iteration 6954 | Cost: 0.31188545924510575 | Gradient: [[ 0.03003303]\n",
      " [-0.05836824]\n",
      " [ 0.10009799]]\n",
      "Iteration 6955 | Cost: 0.31187113131982125 | Gradient: [[ 0.03003229]\n",
      " [-0.05836385]\n",
      " [ 0.10009043]]\n",
      "Iteration 6956 | Cost: 0.3118568054654356 | Gradient: [[ 0.03003155]\n",
      " [-0.05835946]\n",
      " [ 0.10008287]]\n",
      "Iteration 6957 | Cost: 0.31184248168151646 | Gradient: [[ 0.0300308 ]\n",
      " [-0.05835506]\n",
      " [ 0.10007531]]\n",
      "Iteration 6958 | Cost: 0.3118281599676318 | Gradient: [[ 0.03003006]\n",
      " [-0.05835067]\n",
      " [ 0.10006776]]\n",
      "Iteration 6959 | Cost: 0.3118138403233495 | Gradient: [[ 0.03002932]\n",
      " [-0.05834629]\n",
      " [ 0.1000602 ]]\n",
      "Iteration 6960 | Cost: 0.3117995227482378 | Gradient: [[ 0.03002858]\n",
      " [-0.0583419 ]\n",
      " [ 0.10005264]]\n",
      "Iteration 6961 | Cost: 0.31178520724186487 | Gradient: [[ 0.03002783]\n",
      " [-0.05833751]\n",
      " [ 0.10004508]]\n",
      "Iteration 6962 | Cost: 0.3117708938037992 | Gradient: [[ 0.03002709]\n",
      " [-0.05833313]\n",
      " [ 0.10003753]]\n",
      "Iteration 6963 | Cost: 0.31175658243360915 | Gradient: [[ 0.03002635]\n",
      " [-0.05832874]\n",
      " [ 0.10002997]]\n",
      "Iteration 6964 | Cost: 0.31174227313086333 | Gradient: [[ 0.0300256 ]\n",
      " [-0.05832436]\n",
      " [ 0.10002242]]\n",
      "Iteration 6965 | Cost: 0.31172796589513047 | Gradient: [[ 0.03002486]\n",
      " [-0.05831998]\n",
      " [ 0.10001487]]\n",
      "Iteration 6966 | Cost: 0.3117136607259795 | Gradient: [[ 0.03002411]\n",
      " [-0.0583156 ]\n",
      " [ 0.10000732]]\n",
      "Iteration 6967 | Cost: 0.3116993576229793 | Gradient: [[ 0.03002337]\n",
      " [-0.05831122]\n",
      " [ 0.09999976]]\n",
      "Iteration 6968 | Cost: 0.311685056585699 | Gradient: [[ 0.03002262]\n",
      " [-0.05830684]\n",
      " [ 0.09999221]]\n",
      "Iteration 6969 | Cost: 0.3116707576137077 | Gradient: [[ 0.03002187]\n",
      " [-0.05830246]\n",
      " [ 0.09998466]]\n",
      "Iteration 6970 | Cost: 0.31165646070657493 | Gradient: [[ 0.03002113]\n",
      " [-0.05829809]\n",
      " [ 0.09997712]]\n",
      "Iteration 6971 | Cost: 0.31164216586387 | Gradient: [[ 0.03002038]\n",
      " [-0.05829371]\n",
      " [ 0.09996957]]\n",
      "Iteration 6972 | Cost: 0.3116278730851625 | Gradient: [[ 0.03001963]\n",
      " [-0.05828934]\n",
      " [ 0.09996202]]\n",
      "Iteration 6973 | Cost: 0.3116135823700221 | Gradient: [[ 0.03001888]\n",
      " [-0.05828497]\n",
      " [ 0.09995447]]\n",
      "Iteration 6974 | Cost: 0.3115992937180187 | Gradient: [[ 0.03001814]\n",
      " [-0.0582806 ]\n",
      " [ 0.09994693]]\n",
      "Iteration 6975 | Cost: 0.31158500712872217 | Gradient: [[ 0.03001739]\n",
      " [-0.05827623]\n",
      " [ 0.09993938]]\n",
      "Iteration 6976 | Cost: 0.31157072260170254 | Gradient: [[ 0.03001664]\n",
      " [-0.05827186]\n",
      " [ 0.09993184]]\n",
      "Iteration 6977 | Cost: 0.31155644013653 | Gradient: [[ 0.03001589]\n",
      " [-0.05826749]\n",
      " [ 0.0999243 ]]\n",
      "Iteration 6978 | Cost: 0.3115421597327748 | Gradient: [[ 0.03001514]\n",
      " [-0.05826312]\n",
      " [ 0.09991675]]\n",
      "Iteration 6979 | Cost: 0.3115278813900075 | Gradient: [[ 0.03001439]\n",
      " [-0.05825876]\n",
      " [ 0.09990921]]\n",
      "Iteration 6980 | Cost: 0.3115136051077984 | Gradient: [[ 0.03001364]\n",
      " [-0.0582544 ]\n",
      " [ 0.09990167]]\n",
      "Iteration 6981 | Cost: 0.31149933088571835 | Gradient: [[ 0.03001289]\n",
      " [-0.05825003]\n",
      " [ 0.09989413]]\n",
      "Iteration 6982 | Cost: 0.31148505872333804 | Gradient: [[ 0.03001214]\n",
      " [-0.05824567]\n",
      " [ 0.09988659]]\n",
      "Iteration 6983 | Cost: 0.3114707886202283 | Gradient: [[ 0.03001139]\n",
      " [-0.05824131]\n",
      " [ 0.09987905]]\n",
      "Iteration 6984 | Cost: 0.3114565205759603 | Gradient: [[ 0.03001064]\n",
      " [-0.05823695]\n",
      " [ 0.09987152]]\n",
      "Iteration 6985 | Cost: 0.311442254590105 | Gradient: [[ 0.03000988]\n",
      " [-0.05823259]\n",
      " [ 0.09986398]]\n",
      "Iteration 6986 | Cost: 0.3114279906622337 | Gradient: [[ 0.03000913]\n",
      " [-0.05822824]\n",
      " [ 0.09985644]]\n",
      "Iteration 6987 | Cost: 0.31141372879191787 | Gradient: [[ 0.03000838]\n",
      " [-0.05822388]\n",
      " [ 0.09984891]]\n",
      "Iteration 6988 | Cost: 0.3113994689787289 | Gradient: [[ 0.03000763]\n",
      " [-0.05821953]\n",
      " [ 0.09984137]]\n",
      "Iteration 6989 | Cost: 0.31138521122223833 | Gradient: [[ 0.03000687]\n",
      " [-0.05821517]\n",
      " [ 0.09983384]]\n",
      "Iteration 6990 | Cost: 0.3113709555220181 | Gradient: [[ 0.03000612]\n",
      " [-0.05821082]\n",
      " [ 0.09982631]]\n",
      "Iteration 6991 | Cost: 0.3113567018776398 | Gradient: [[ 0.03000536]\n",
      " [-0.05820647]\n",
      " [ 0.09981878]]\n",
      "Iteration 6992 | Cost: 0.3113424502886756 | Gradient: [[ 0.03000461]\n",
      " [-0.05820212]\n",
      " [ 0.09981124]]\n",
      "Iteration 6993 | Cost: 0.31132820075469747 | Gradient: [[ 0.03000386]\n",
      " [-0.05819777]\n",
      " [ 0.09980371]]\n",
      "Iteration 6994 | Cost: 0.31131395327527767 | Gradient: [[ 0.0300031 ]\n",
      " [-0.05819342]\n",
      " [ 0.09979618]]\n",
      "Iteration 6995 | Cost: 0.3112997078499885 | Gradient: [[ 0.03000234]\n",
      " [-0.05818908]\n",
      " [ 0.09978866]]\n",
      "Iteration 6996 | Cost: 0.31128546447840233 | Gradient: [[ 0.03000159]\n",
      " [-0.05818473]\n",
      " [ 0.09978113]]\n",
      "Iteration 6997 | Cost: 0.3112712231600919 | Gradient: [[ 0.03000083]\n",
      " [-0.05818039]\n",
      " [ 0.0997736 ]]\n",
      "Iteration 6998 | Cost: 0.3112569838946298 | Gradient: [[ 0.03000008]\n",
      " [-0.05817604]\n",
      " [ 0.09976607]]\n",
      "Iteration 6999 | Cost: 0.31124274668158874 | Gradient: [[ 0.02999932]\n",
      " [-0.0581717 ]\n",
      " [ 0.09975855]]\n",
      "Iteration 7000 | Cost: 0.31122851152054176 | Gradient: [[ 0.02999856]\n",
      " [-0.05816736]\n",
      " [ 0.09975102]]\n",
      "Iteration 7001 | Cost: 0.31121427841106186 | Gradient: [[ 0.0299978 ]\n",
      " [-0.05816302]\n",
      " [ 0.0997435 ]]\n",
      "Iteration 7002 | Cost: 0.3112000473527222 | Gradient: [[ 0.02999705]\n",
      " [-0.05815868]\n",
      " [ 0.09973598]]\n",
      "Iteration 7003 | Cost: 0.31118581834509595 | Gradient: [[ 0.02999629]\n",
      " [-0.05815434]\n",
      " [ 0.09972846]]\n",
      "Iteration 7004 | Cost: 0.31117159138775674 | Gradient: [[ 0.02999553]\n",
      " [-0.05815001]\n",
      " [ 0.09972093]]\n",
      "Iteration 7005 | Cost: 0.3111573664802779 | Gradient: [[ 0.02999477]\n",
      " [-0.05814567]\n",
      " [ 0.09971341]]\n",
      "Iteration 7006 | Cost: 0.3111431436222331 | Gradient: [[ 0.02999401]\n",
      " [-0.05814134]\n",
      " [ 0.09970589]]\n",
      "Iteration 7007 | Cost: 0.31112892281319604 | Gradient: [[ 0.02999325]\n",
      " [-0.05813701]\n",
      " [ 0.09969837]]\n",
      "Iteration 7008 | Cost: 0.31111470405274066 | Gradient: [[ 0.02999249]\n",
      " [-0.05813268]\n",
      " [ 0.09969086]]\n",
      "Iteration 7009 | Cost: 0.311100487340441 | Gradient: [[ 0.02999173]\n",
      " [-0.05812835]\n",
      " [ 0.09968334]]\n",
      "Iteration 7010 | Cost: 0.311086272675871 | Gradient: [[ 0.02999097]\n",
      " [-0.05812402]\n",
      " [ 0.09967582]]\n",
      "Iteration 7011 | Cost: 0.31107206005860505 | Gradient: [[ 0.02999021]\n",
      " [-0.05811969]\n",
      " [ 0.09966831]]\n",
      "Iteration 7012 | Cost: 0.31105784948821735 | Gradient: [[ 0.02998945]\n",
      " [-0.05811536]\n",
      " [ 0.09966079]]\n",
      "Iteration 7013 | Cost: 0.31104364096428255 | Gradient: [[ 0.02998869]\n",
      " [-0.05811104]\n",
      " [ 0.09965328]]\n",
      "Iteration 7014 | Cost: 0.31102943448637493 | Gradient: [[ 0.02998792]\n",
      " [-0.05810671]\n",
      " [ 0.09964576]]\n",
      "Iteration 7015 | Cost: 0.31101523005406956 | Gradient: [[ 0.02998716]\n",
      " [-0.05810239]\n",
      " [ 0.09963825]]\n",
      "Iteration 7016 | Cost: 0.311001027666941 | Gradient: [[ 0.0299864 ]\n",
      " [-0.05809807]\n",
      " [ 0.09963074]]\n",
      "Iteration 7017 | Cost: 0.31098682732456423 | Gradient: [[ 0.02998563]\n",
      " [-0.05809374]\n",
      " [ 0.09962323]]\n",
      "Iteration 7018 | Cost: 0.31097262902651424 | Gradient: [[ 0.02998487]\n",
      " [-0.05808942]\n",
      " [ 0.09961572]]\n",
      "Iteration 7019 | Cost: 0.3109584327723664 | Gradient: [[ 0.02998411]\n",
      " [-0.05808511]\n",
      " [ 0.09960821]]\n",
      "Iteration 7020 | Cost: 0.31094423856169584 | Gradient: [[ 0.02998334]\n",
      " [-0.05808079]\n",
      " [ 0.0996007 ]]\n",
      "Iteration 7021 | Cost: 0.31093004639407795 | Gradient: [[ 0.02998258]\n",
      " [-0.05807647]\n",
      " [ 0.09959319]]\n",
      "Iteration 7022 | Cost: 0.3109158562690884 | Gradient: [[ 0.02998181]\n",
      " [-0.05807216]\n",
      " [ 0.09958569]]\n",
      "Iteration 7023 | Cost: 0.31090166818630266 | Gradient: [[ 0.02998105]\n",
      " [-0.05806784]\n",
      " [ 0.09957818]]\n",
      "Iteration 7024 | Cost: 0.31088748214529666 | Gradient: [[ 0.02998028]\n",
      " [-0.05806353]\n",
      " [ 0.09957067]]\n",
      "Iteration 7025 | Cost: 0.31087329814564607 | Gradient: [[ 0.02997952]\n",
      " [-0.05805922]\n",
      " [ 0.09956317]]\n",
      "Iteration 7026 | Cost: 0.3108591161869271 | Gradient: [[ 0.02997875]\n",
      " [-0.05805491]\n",
      " [ 0.09955567]]\n",
      "Iteration 7027 | Cost: 0.3108449362687156 | Gradient: [[ 0.02997798]\n",
      " [-0.0580506 ]\n",
      " [ 0.09954816]]\n",
      "Iteration 7028 | Cost: 0.31083075839058805 | Gradient: [[ 0.02997722]\n",
      " [-0.05804629]\n",
      " [ 0.09954066]]\n",
      "Iteration 7029 | Cost: 0.31081658255212075 | Gradient: [[ 0.02997645]\n",
      " [-0.05804198]\n",
      " [ 0.09953316]]\n",
      "Iteration 7030 | Cost: 0.3108024087528901 | Gradient: [[ 0.02997568]\n",
      " [-0.05803767]\n",
      " [ 0.09952566]]\n",
      "Iteration 7031 | Cost: 0.31078823699247277 | Gradient: [[ 0.02997491]\n",
      " [-0.05803337]\n",
      " [ 0.09951816]]\n",
      "Iteration 7032 | Cost: 0.31077406727044526 | Gradient: [[ 0.02997414]\n",
      " [-0.05802907]\n",
      " [ 0.09951066]]\n",
      "Iteration 7033 | Cost: 0.31075989958638456 | Gradient: [[ 0.02997338]\n",
      " [-0.05802476]\n",
      " [ 0.09950316]]\n",
      "Iteration 7034 | Cost: 0.31074573393986765 | Gradient: [[ 0.02997261]\n",
      " [-0.05802046]\n",
      " [ 0.09949567]]\n",
      "Iteration 7035 | Cost: 0.31073157033047144 | Gradient: [[ 0.02997184]\n",
      " [-0.05801616]\n",
      " [ 0.09948817]]\n",
      "Iteration 7036 | Cost: 0.3107174087577731 | Gradient: [[ 0.02997107]\n",
      " [-0.05801186]\n",
      " [ 0.09948067]]\n",
      "Iteration 7037 | Cost: 0.31070324922135 | Gradient: [[ 0.0299703 ]\n",
      " [-0.05800756]\n",
      " [ 0.09947318]]\n",
      "Iteration 7038 | Cost: 0.31068909172077963 | Gradient: [[ 0.02996953]\n",
      " [-0.05800327]\n",
      " [ 0.09946569]]\n",
      "Iteration 7039 | Cost: 0.3106749362556393 | Gradient: [[ 0.02996876]\n",
      " [-0.05799897]\n",
      " [ 0.09945819]]\n",
      "Iteration 7040 | Cost: 0.3106607828255068 | Gradient: [[ 0.02996799]\n",
      " [-0.05799467]\n",
      " [ 0.0994507 ]]\n",
      "Iteration 7041 | Cost: 0.31064663142995974 | Gradient: [[ 0.02996721]\n",
      " [-0.05799038]\n",
      " [ 0.09944321]]\n",
      "Iteration 7042 | Cost: 0.31063248206857613 | Gradient: [[ 0.02996644]\n",
      " [-0.05798609]\n",
      " [ 0.09943572]]\n",
      "Iteration 7043 | Cost: 0.310618334740934 | Gradient: [[ 0.02996567]\n",
      " [-0.0579818 ]\n",
      " [ 0.09942823]]\n",
      "Iteration 7044 | Cost: 0.3106041894466112 | Gradient: [[ 0.0299649 ]\n",
      " [-0.05797751]\n",
      " [ 0.09942074]]\n",
      "Iteration 7045 | Cost: 0.3105900461851862 | Gradient: [[ 0.02996412]\n",
      " [-0.05797322]\n",
      " [ 0.09941325]]\n",
      "Iteration 7046 | Cost: 0.3105759049562373 | Gradient: [[ 0.02996335]\n",
      " [-0.05796893]\n",
      " [ 0.09940576]]\n",
      "Iteration 7047 | Cost: 0.31056176575934286 | Gradient: [[ 0.02996258]\n",
      " [-0.05796464]\n",
      " [ 0.09939828]]\n",
      "Iteration 7048 | Cost: 0.3105476285940815 | Gradient: [[ 0.0299618 ]\n",
      " [-0.05796036]\n",
      " [ 0.09939079]]\n",
      "Iteration 7049 | Cost: 0.31053349346003195 | Gradient: [[ 0.02996103]\n",
      " [-0.05795607]\n",
      " [ 0.09938331]]\n",
      "Iteration 7050 | Cost: 0.31051936035677297 | Gradient: [[ 0.02996026]\n",
      " [-0.05795179]\n",
      " [ 0.09937582]]\n",
      "Iteration 7051 | Cost: 0.31050522928388347 | Gradient: [[ 0.02995948]\n",
      " [-0.05794751]\n",
      " [ 0.09936834]]\n",
      "Iteration 7052 | Cost: 0.3104911002409425 | Gradient: [[ 0.02995871]\n",
      " [-0.05794322]\n",
      " [ 0.09936086]]\n",
      "Iteration 7053 | Cost: 0.31047697322752926 | Gradient: [[ 0.02995793]\n",
      " [-0.05793894]\n",
      " [ 0.09935337]]\n",
      "Iteration 7054 | Cost: 0.310462848243223 | Gradient: [[ 0.02995715]\n",
      " [-0.05793466]\n",
      " [ 0.09934589]]\n",
      "Iteration 7055 | Cost: 0.31044872528760303 | Gradient: [[ 0.02995638]\n",
      " [-0.05793039]\n",
      " [ 0.09933841]]\n",
      "Iteration 7056 | Cost: 0.310434604360249 | Gradient: [[ 0.0299556 ]\n",
      " [-0.05792611]\n",
      " [ 0.09933093]]\n",
      "Iteration 7057 | Cost: 0.31042048546074047 | Gradient: [[ 0.02995482]\n",
      " [-0.05792183]\n",
      " [ 0.09932345]]\n",
      "Iteration 7058 | Cost: 0.31040636858865706 | Gradient: [[ 0.02995405]\n",
      " [-0.05791756]\n",
      " [ 0.09931598]]\n",
      "Iteration 7059 | Cost: 0.31039225374357876 | Gradient: [[ 0.02995327]\n",
      " [-0.05791329]\n",
      " [ 0.0993085 ]]\n",
      "Iteration 7060 | Cost: 0.31037814092508553 | Gradient: [[ 0.02995249]\n",
      " [-0.05790901]\n",
      " [ 0.09930102]]\n",
      "Iteration 7061 | Cost: 0.3103640301327574 | Gradient: [[ 0.02995171]\n",
      " [-0.05790474]\n",
      " [ 0.09929355]]\n",
      "Iteration 7062 | Cost: 0.3103499213661746 | Gradient: [[ 0.02995094]\n",
      " [-0.05790047]\n",
      " [ 0.09928607]]\n",
      "Iteration 7063 | Cost: 0.31033581462491744 | Gradient: [[ 0.02995016]\n",
      " [-0.0578962 ]\n",
      " [ 0.0992786 ]]\n",
      "Iteration 7064 | Cost: 0.31032170990856633 | Gradient: [[ 0.02994938]\n",
      " [-0.05789194]\n",
      " [ 0.09927113]]\n",
      "Iteration 7065 | Cost: 0.31030760721670186 | Gradient: [[ 0.0299486 ]\n",
      " [-0.05788767]\n",
      " [ 0.09926365]]\n",
      "Iteration 7066 | Cost: 0.3102935065489047 | Gradient: [[ 0.02994782]\n",
      " [-0.0578834 ]\n",
      " [ 0.09925618]]\n",
      "Iteration 7067 | Cost: 0.3102794079047556 | Gradient: [[ 0.02994704]\n",
      " [-0.05787914]\n",
      " [ 0.09924871]]\n",
      "Iteration 7068 | Cost: 0.31026531128383544 | Gradient: [[ 0.02994626]\n",
      " [-0.05787488]\n",
      " [ 0.09924124]]\n",
      "Iteration 7069 | Cost: 0.3102512166857253 | Gradient: [[ 0.02994548]\n",
      " [-0.05787061]\n",
      " [ 0.09923377]]\n",
      "Iteration 7070 | Cost: 0.3102371241100062 | Gradient: [[ 0.02994469]\n",
      " [-0.05786635]\n",
      " [ 0.09922631]]\n",
      "Iteration 7071 | Cost: 0.3102230335562596 | Gradient: [[ 0.02994391]\n",
      " [-0.05786209]\n",
      " [ 0.09921884]]\n",
      "Iteration 7072 | Cost: 0.31020894502406654 | Gradient: [[ 0.02994313]\n",
      " [-0.05785783]\n",
      " [ 0.09921137]]\n",
      "Iteration 7073 | Cost: 0.3101948585130087 | Gradient: [[ 0.02994235]\n",
      " [-0.05785358]\n",
      " [ 0.09920391]]\n",
      "Iteration 7074 | Cost: 0.31018077402266764 | Gradient: [[ 0.02994157]\n",
      " [-0.05784932]\n",
      " [ 0.09919644]]\n",
      "Iteration 7075 | Cost: 0.3101666915526251 | Gradient: [[ 0.02994078]\n",
      " [-0.05784506]\n",
      " [ 0.09918898]]\n",
      "Iteration 7076 | Cost: 0.31015261110246284 | Gradient: [[ 0.02994   ]\n",
      " [-0.05784081]\n",
      " [ 0.09918151]]\n",
      "Iteration 7077 | Cost: 0.3101385326717628 | Gradient: [[ 0.02993922]\n",
      " [-0.05783656]\n",
      " [ 0.09917405]]\n",
      "Iteration 7078 | Cost: 0.3101244562601071 | Gradient: [[ 0.02993843]\n",
      " [-0.0578323 ]\n",
      " [ 0.09916659]]\n",
      "Iteration 7079 | Cost: 0.3101103818670778 | Gradient: [[ 0.02993765]\n",
      " [-0.05782805]\n",
      " [ 0.09915913]]\n",
      "Iteration 7080 | Cost: 0.3100963094922572 | Gradient: [[ 0.02993686]\n",
      " [-0.0578238 ]\n",
      " [ 0.09915167]]\n",
      "Iteration 7081 | Cost: 0.31008223913522776 | Gradient: [[ 0.02993608]\n",
      " [-0.05781955]\n",
      " [ 0.09914421]]\n",
      "Iteration 7082 | Cost: 0.310068170795572 | Gradient: [[ 0.02993529]\n",
      " [-0.05781531]\n",
      " [ 0.09913675]]\n",
      "Iteration 7083 | Cost: 0.31005410447287246 | Gradient: [[ 0.02993451]\n",
      " [-0.05781106]\n",
      " [ 0.09912929]]\n",
      "Iteration 7084 | Cost: 0.31004004016671194 | Gradient: [[ 0.02993372]\n",
      " [-0.05780681]\n",
      " [ 0.09912184]]\n",
      "Iteration 7085 | Cost: 0.31002597787667324 | Gradient: [[ 0.02993294]\n",
      " [-0.05780257]\n",
      " [ 0.09911438]]\n",
      "Iteration 7086 | Cost: 0.3100119176023395 | Gradient: [[ 0.02993215]\n",
      " [-0.05779833]\n",
      " [ 0.09910693]]\n",
      "Iteration 7087 | Cost: 0.3099978593432936 | Gradient: [[ 0.02993136]\n",
      " [-0.05779408]\n",
      " [ 0.09909947]]\n",
      "Iteration 7088 | Cost: 0.3099838030991189 | Gradient: [[ 0.02993058]\n",
      " [-0.05778984]\n",
      " [ 0.09909202]]\n",
      "Iteration 7089 | Cost: 0.3099697488693986 | Gradient: [[ 0.02992979]\n",
      " [-0.0577856 ]\n",
      " [ 0.09908457]]\n",
      "Iteration 7090 | Cost: 0.30995569665371614 | Gradient: [[ 0.029929  ]\n",
      " [-0.05778136]\n",
      " [ 0.09907711]]\n",
      "Iteration 7091 | Cost: 0.3099416464516552 | Gradient: [[ 0.02992821]\n",
      " [-0.05777713]\n",
      " [ 0.09906966]]\n",
      "Iteration 7092 | Cost: 0.30992759826279925 | Gradient: [[ 0.02992743]\n",
      " [-0.05777289]\n",
      " [ 0.09906221]]\n",
      "Iteration 7093 | Cost: 0.3099135520867322 | Gradient: [[ 0.02992664]\n",
      " [-0.05776865]\n",
      " [ 0.09905476]]\n",
      "Iteration 7094 | Cost: 0.3098995079230379 | Gradient: [[ 0.02992585]\n",
      " [-0.05776442]\n",
      " [ 0.09904731]]\n",
      "Iteration 7095 | Cost: 0.30988546577130033 | Gradient: [[ 0.02992506]\n",
      " [-0.05776019]\n",
      " [ 0.09903987]]\n",
      "Iteration 7096 | Cost: 0.3098714256311037 | Gradient: [[ 0.02992427]\n",
      " [-0.05775595]\n",
      " [ 0.09903242]]\n",
      "Iteration 7097 | Cost: 0.3098573875020321 | Gradient: [[ 0.02992348]\n",
      " [-0.05775172]\n",
      " [ 0.09902497]]\n",
      "Iteration 7098 | Cost: 0.30984335138367 | Gradient: [[ 0.02992269]\n",
      " [-0.05774749]\n",
      " [ 0.09901753]]\n",
      "Iteration 7099 | Cost: 0.30982931727560187 | Gradient: [[ 0.0299219 ]\n",
      " [-0.05774326]\n",
      " [ 0.09901008]]\n",
      "Iteration 7100 | Cost: 0.30981528517741214 | Gradient: [[ 0.02992111]\n",
      " [-0.05773903]\n",
      " [ 0.09900264]]\n",
      "Iteration 7101 | Cost: 0.3098012550886856 | Gradient: [[ 0.02992031]\n",
      " [-0.05773481]\n",
      " [ 0.0989952 ]]\n",
      "Iteration 7102 | Cost: 0.30978722700900707 | Gradient: [[ 0.02991952]\n",
      " [-0.05773058]\n",
      " [ 0.09898775]]\n",
      "Iteration 7103 | Cost: 0.3097732009379614 | Gradient: [[ 0.02991873]\n",
      " [-0.05772636]\n",
      " [ 0.09898031]]\n",
      "Iteration 7104 | Cost: 0.3097591768751337 | Gradient: [[ 0.02991794]\n",
      " [-0.05772213]\n",
      " [ 0.09897287]]\n",
      "Iteration 7105 | Cost: 0.3097451548201091 | Gradient: [[ 0.02991715]\n",
      " [-0.05771791]\n",
      " [ 0.09896543]]\n",
      "Iteration 7106 | Cost: 0.3097311347724728 | Gradient: [[ 0.02991635]\n",
      " [-0.05771369]\n",
      " [ 0.09895799]]\n",
      "Iteration 7107 | Cost: 0.30971711673181035 | Gradient: [[ 0.02991556]\n",
      " [-0.05770947]\n",
      " [ 0.09895055]]\n",
      "Iteration 7108 | Cost: 0.309703100697707 | Gradient: [[ 0.02991477]\n",
      " [-0.05770525]\n",
      " [ 0.09894312]]\n",
      "Iteration 7109 | Cost: 0.3096890866697486 | Gradient: [[ 0.02991397]\n",
      " [-0.05770103]\n",
      " [ 0.09893568]]\n",
      "Iteration 7110 | Cost: 0.30967507464752053 | Gradient: [[ 0.02991318]\n",
      " [-0.05769682]\n",
      " [ 0.09892824]]\n",
      "Iteration 7111 | Cost: 0.3096610646306089 | Gradient: [[ 0.02991238]\n",
      " [-0.0576926 ]\n",
      " [ 0.09892081]]\n",
      "Iteration 7112 | Cost: 0.3096470566185996 | Gradient: [[ 0.02991159]\n",
      " [-0.05768839]\n",
      " [ 0.09891337]]\n",
      "Iteration 7113 | Cost: 0.30963305061107865 | Gradient: [[ 0.02991079]\n",
      " [-0.05768417]\n",
      " [ 0.09890594]]\n",
      "Iteration 7114 | Cost: 0.3096190466076323 | Gradient: [[ 0.02991   ]\n",
      " [-0.05767996]\n",
      " [ 0.09889851]]\n",
      "Iteration 7115 | Cost: 0.3096050446078467 | Gradient: [[ 0.0299092 ]\n",
      " [-0.05767575]\n",
      " [ 0.09889108]]\n",
      "Iteration 7116 | Cost: 0.30959104461130826 | Gradient: [[ 0.02990841]\n",
      " [-0.05767154]\n",
      " [ 0.09888365]]\n",
      "Iteration 7117 | Cost: 0.30957704661760366 | Gradient: [[ 0.02990761]\n",
      " [-0.05766733]\n",
      " [ 0.09887622]]\n",
      "Iteration 7118 | Cost: 0.3095630506263194 | Gradient: [[ 0.02990681]\n",
      " [-0.05766312]\n",
      " [ 0.09886879]]\n",
      "Iteration 7119 | Cost: 0.3095490566370422 | Gradient: [[ 0.02990601]\n",
      " [-0.05765891]\n",
      " [ 0.09886136]]\n",
      "Iteration 7120 | Cost: 0.30953506464935904 | Gradient: [[ 0.02990522]\n",
      " [-0.05765471]\n",
      " [ 0.09885393]]\n",
      "Iteration 7121 | Cost: 0.3095210746628567 | Gradient: [[ 0.02990442]\n",
      " [-0.0576505 ]\n",
      " [ 0.0988465 ]]\n",
      "Iteration 7122 | Cost: 0.3095070866771224 | Gradient: [[ 0.02990362]\n",
      " [-0.0576463 ]\n",
      " [ 0.09883908]]\n",
      "Iteration 7123 | Cost: 0.3094931006917433 | Gradient: [[ 0.02990282]\n",
      " [-0.05764209]\n",
      " [ 0.09883165]]\n",
      "Iteration 7124 | Cost: 0.3094791167063066 | Gradient: [[ 0.02990202]\n",
      " [-0.05763789]\n",
      " [ 0.09882423]]\n",
      "Iteration 7125 | Cost: 0.30946513472039994 | Gradient: [[ 0.02990122]\n",
      " [-0.05763369]\n",
      " [ 0.0988168 ]]\n",
      "Iteration 7126 | Cost: 0.3094511547336106 | Gradient: [[ 0.02990043]\n",
      " [-0.05762949]\n",
      " [ 0.09880938]]\n",
      "Iteration 7127 | Cost: 0.30943717674552645 | Gradient: [[ 0.02989963]\n",
      " [-0.05762529]\n",
      " [ 0.09880196]]\n",
      "Iteration 7128 | Cost: 0.30942320075573515 | Gradient: [[ 0.02989883]\n",
      " [-0.0576211 ]\n",
      " [ 0.09879454]]\n",
      "Iteration 7129 | Cost: 0.30940922676382454 | Gradient: [[ 0.02989803]\n",
      " [-0.0576169 ]\n",
      " [ 0.09878712]]\n",
      "Iteration 7130 | Cost: 0.3093952547693827 | Gradient: [[ 0.02989722]\n",
      " [-0.05761271]\n",
      " [ 0.0987797 ]]\n",
      "Iteration 7131 | Cost: 0.30938128477199756 | Gradient: [[ 0.02989642]\n",
      " [-0.05760851]\n",
      " [ 0.09877228]]\n",
      "Iteration 7132 | Cost: 0.3093673167712575 | Gradient: [[ 0.02989562]\n",
      " [-0.05760432]\n",
      " [ 0.09876486]]\n",
      "Iteration 7133 | Cost: 0.30935335076675075 | Gradient: [[ 0.02989482]\n",
      " [-0.05760013]\n",
      " [ 0.09875744]]\n",
      "Iteration 7134 | Cost: 0.3093393867580658 | Gradient: [[ 0.02989402]\n",
      " [-0.05759594]\n",
      " [ 0.09875003]]\n",
      "Iteration 7135 | Cost: 0.3093254247447912 | Gradient: [[ 0.02989322]\n",
      " [-0.05759175]\n",
      " [ 0.09874261]]\n",
      "Iteration 7136 | Cost: 0.3093114647265155 | Gradient: [[ 0.02989241]\n",
      " [-0.05758756]\n",
      " [ 0.0987352 ]]\n",
      "Iteration 7137 | Cost: 0.30929750670282763 | Gradient: [[ 0.02989161]\n",
      " [-0.05758337]\n",
      " [ 0.09872778]]\n",
      "Iteration 7138 | Cost: 0.3092835506733163 | Gradient: [[ 0.02989081]\n",
      " [-0.05757918]\n",
      " [ 0.09872037]]\n",
      "Iteration 7139 | Cost: 0.3092695966375707 | Gradient: [[ 0.02989   ]\n",
      " [-0.057575  ]\n",
      " [ 0.09871296]]\n",
      "Iteration 7140 | Cost: 0.3092556445951799 | Gradient: [[ 0.0298892 ]\n",
      " [-0.05757081]\n",
      " [ 0.09870555]]\n",
      "Iteration 7141 | Cost: 0.3092416945457329 | Gradient: [[ 0.0298884 ]\n",
      " [-0.05756663]\n",
      " [ 0.09869814]]\n",
      "Iteration 7142 | Cost: 0.3092277464888194 | Gradient: [[ 0.02988759]\n",
      " [-0.05756245]\n",
      " [ 0.09869073]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7143 | Cost: 0.30921380042402846 | Gradient: [[ 0.02988679]\n",
      " [-0.05755827]\n",
      " [ 0.09868332]]\n",
      "Iteration 7144 | Cost: 0.30919985635095004 | Gradient: [[ 0.02988598]\n",
      " [-0.05755409]\n",
      " [ 0.09867591]]\n",
      "Iteration 7145 | Cost: 0.3091859142691735 | Gradient: [[ 0.02988518]\n",
      " [-0.05754991]\n",
      " [ 0.0986685 ]]\n",
      "Iteration 7146 | Cost: 0.30917197417828884 | Gradient: [[ 0.02988437]\n",
      " [-0.05754573]\n",
      " [ 0.09866109]]\n",
      "Iteration 7147 | Cost: 0.30915803607788583 | Gradient: [[ 0.02988357]\n",
      " [-0.05754155]\n",
      " [ 0.09865369]]\n",
      "Iteration 7148 | Cost: 0.30914409996755443 | Gradient: [[ 0.02988276]\n",
      " [-0.05753738]\n",
      " [ 0.09864628]]\n",
      "Iteration 7149 | Cost: 0.3091301658468849 | Gradient: [[ 0.02988195]\n",
      " [-0.0575332 ]\n",
      " [ 0.09863888]]\n",
      "Iteration 7150 | Cost: 0.3091162337154675 | Gradient: [[ 0.02988115]\n",
      " [-0.05752903]\n",
      " [ 0.09863147]]\n",
      "Iteration 7151 | Cost: 0.30910230357289237 | Gradient: [[ 0.02988034]\n",
      " [-0.05752486]\n",
      " [ 0.09862407]]\n",
      "Iteration 7152 | Cost: 0.30908837541875017 | Gradient: [[ 0.02987953]\n",
      " [-0.05752068]\n",
      " [ 0.09861667]]\n",
      "Iteration 7153 | Cost: 0.30907444925263133 | Gradient: [[ 0.02987872]\n",
      " [-0.05751651]\n",
      " [ 0.09860927]]\n",
      "Iteration 7154 | Cost: 0.3090605250741266 | Gradient: [[ 0.02987791]\n",
      " [-0.05751234]\n",
      " [ 0.09860187]]\n",
      "Iteration 7155 | Cost: 0.30904660288282687 | Gradient: [[ 0.02987711]\n",
      " [-0.05750818]\n",
      " [ 0.09859447]]\n",
      "Iteration 7156 | Cost: 0.30903268267832285 | Gradient: [[ 0.0298763 ]\n",
      " [-0.05750401]\n",
      " [ 0.09858707]]\n",
      "Iteration 7157 | Cost: 0.30901876446020565 | Gradient: [[ 0.02987549]\n",
      " [-0.05749984]\n",
      " [ 0.09857967]]\n",
      "Iteration 7158 | Cost: 0.3090048482280664 | Gradient: [[ 0.02987468]\n",
      " [-0.05749568]\n",
      " [ 0.09857228]]\n",
      "Iteration 7159 | Cost: 0.30899093398149635 | Gradient: [[ 0.02987387]\n",
      " [-0.05749151]\n",
      " [ 0.09856488]]\n",
      "Iteration 7160 | Cost: 0.3089770217200869 | Gradient: [[ 0.02987306]\n",
      " [-0.05748735]\n",
      " [ 0.09855748]]\n",
      "Iteration 7161 | Cost: 0.3089631114434294 | Gradient: [[ 0.02987225]\n",
      " [-0.05748319]\n",
      " [ 0.09855009]]\n",
      "Iteration 7162 | Cost: 0.3089492031511155 | Gradient: [[ 0.02987144]\n",
      " [-0.05747903]\n",
      " [ 0.0985427 ]]\n",
      "Iteration 7163 | Cost: 0.3089352968427369 | Gradient: [[ 0.02987063]\n",
      " [-0.05747487]\n",
      " [ 0.0985353 ]]\n",
      "Iteration 7164 | Cost: 0.30892139251788536 | Gradient: [[ 0.02986982]\n",
      " [-0.05747071]\n",
      " [ 0.09852791]]\n",
      "Iteration 7165 | Cost: 0.3089074901761528 | Gradient: [[ 0.029869  ]\n",
      " [-0.05746655]\n",
      " [ 0.09852052]]\n",
      "Iteration 7166 | Cost: 0.3088935898171312 | Gradient: [[ 0.02986819]\n",
      " [-0.05746239]\n",
      " [ 0.09851313]]\n",
      "Iteration 7167 | Cost: 0.30887969144041283 | Gradient: [[ 0.02986738]\n",
      " [-0.05745824]\n",
      " [ 0.09850574]]\n",
      "Iteration 7168 | Cost: 0.30886579504558975 | Gradient: [[ 0.02986657]\n",
      " [-0.05745408]\n",
      " [ 0.09849835]]\n",
      "Iteration 7169 | Cost: 0.30885190063225443 | Gradient: [[ 0.02986575]\n",
      " [-0.05744993]\n",
      " [ 0.09849096]]\n",
      "Iteration 7170 | Cost: 0.30883800819999935 | Gradient: [[ 0.02986494]\n",
      " [-0.05744578]\n",
      " [ 0.09848357]]\n",
      "Iteration 7171 | Cost: 0.30882411774841706 | Gradient: [[ 0.02986413]\n",
      " [-0.05744163]\n",
      " [ 0.09847619]]\n",
      "Iteration 7172 | Cost: 0.3088102292771002 | Gradient: [[ 0.02986331]\n",
      " [-0.05743748]\n",
      " [ 0.0984688 ]]\n",
      "Iteration 7173 | Cost: 0.3087963427856416 | Gradient: [[ 0.0298625 ]\n",
      " [-0.05743333]\n",
      " [ 0.09846142]]\n",
      "Iteration 7174 | Cost: 0.30878245827363426 | Gradient: [[ 0.02986169]\n",
      " [-0.05742918]\n",
      " [ 0.09845403]]\n",
      "Iteration 7175 | Cost: 0.30876857574067107 | Gradient: [[ 0.02986087]\n",
      " [-0.05742503]\n",
      " [ 0.09844665]]\n",
      "Iteration 7176 | Cost: 0.3087546951863452 | Gradient: [[ 0.02986006]\n",
      " [-0.05742089]\n",
      " [ 0.09843927]]\n",
      "Iteration 7177 | Cost: 0.30874081661025 | Gradient: [[ 0.02985924]\n",
      " [-0.05741674]\n",
      " [ 0.09843189]]\n",
      "Iteration 7178 | Cost: 0.30872694001197865 | Gradient: [[ 0.02985843]\n",
      " [-0.0574126 ]\n",
      " [ 0.09842451]]\n",
      "Iteration 7179 | Cost: 0.3087130653911247 | Gradient: [[ 0.02985761]\n",
      " [-0.05740845]\n",
      " [ 0.09841713]]\n",
      "Iteration 7180 | Cost: 0.3086991927472817 | Gradient: [[ 0.02985679]\n",
      " [-0.05740431]\n",
      " [ 0.09840975]]\n",
      "Iteration 7181 | Cost: 0.30868532208004346 | Gradient: [[ 0.02985598]\n",
      " [-0.05740017]\n",
      " [ 0.09840237]]\n",
      "Iteration 7182 | Cost: 0.3086714533890036 | Gradient: [[ 0.02985516]\n",
      " [-0.05739603]\n",
      " [ 0.09839499]]\n",
      "Iteration 7183 | Cost: 0.3086575866737562 | Gradient: [[ 0.02985434]\n",
      " [-0.05739189]\n",
      " [ 0.09838761]]\n",
      "Iteration 7184 | Cost: 0.30864372193389517 | Gradient: [[ 0.02985353]\n",
      " [-0.05738776]\n",
      " [ 0.09838024]]\n",
      "Iteration 7185 | Cost: 0.30862985916901464 | Gradient: [[ 0.02985271]\n",
      " [-0.05738362]\n",
      " [ 0.09837286]]\n",
      "Iteration 7186 | Cost: 0.3086159983787088 | Gradient: [[ 0.02985189]\n",
      " [-0.05737948]\n",
      " [ 0.09836549]]\n",
      "Iteration 7187 | Cost: 0.3086021395625722 | Gradient: [[ 0.02985107]\n",
      " [-0.05737535]\n",
      " [ 0.09835811]]\n",
      "Iteration 7188 | Cost: 0.3085882827201991 | Gradient: [[ 0.02985025]\n",
      " [-0.05737122]\n",
      " [ 0.09835074]]\n",
      "Iteration 7189 | Cost: 0.3085744278511842 | Gradient: [[ 0.02984943]\n",
      " [-0.05736708]\n",
      " [ 0.09834337]]\n",
      "Iteration 7190 | Cost: 0.30856057495512207 | Gradient: [[ 0.02984861]\n",
      " [-0.05736295]\n",
      " [ 0.098336  ]]\n",
      "Iteration 7191 | Cost: 0.3085467240316076 | Gradient: [[ 0.02984779]\n",
      " [-0.05735882]\n",
      " [ 0.09832863]]\n",
      "Iteration 7192 | Cost: 0.30853287508023564 | Gradient: [[ 0.02984698]\n",
      " [-0.05735469]\n",
      " [ 0.09832126]]\n",
      "Iteration 7193 | Cost: 0.30851902810060117 | Gradient: [[ 0.02984615]\n",
      " [-0.05735057]\n",
      " [ 0.09831389]]\n",
      "Iteration 7194 | Cost: 0.30850518309229946 | Gradient: [[ 0.02984533]\n",
      " [-0.05734644]\n",
      " [ 0.09830652]]\n",
      "Iteration 7195 | Cost: 0.30849134005492557 | Gradient: [[ 0.02984451]\n",
      " [-0.05734231]\n",
      " [ 0.09829915]]\n",
      "Iteration 7196 | Cost: 0.30847749898807497 | Gradient: [[ 0.02984369]\n",
      " [-0.05733819]\n",
      " [ 0.09829179]]\n",
      "Iteration 7197 | Cost: 0.308463659891343 | Gradient: [[ 0.02984287]\n",
      " [-0.05733406]\n",
      " [ 0.09828442]]\n",
      "Iteration 7198 | Cost: 0.3084498227643253 | Gradient: [[ 0.02984205]\n",
      " [-0.05732994]\n",
      " [ 0.09827706]]\n",
      "Iteration 7199 | Cost: 0.30843598760661756 | Gradient: [[ 0.02984123]\n",
      " [-0.05732582]\n",
      " [ 0.09826969]]\n",
      "Iteration 7200 | Cost: 0.3084221544178155 | Gradient: [[ 0.02984041]\n",
      " [-0.0573217 ]\n",
      " [ 0.09826233]]\n",
      "Iteration 7201 | Cost: 0.3084083231975151 | Gradient: [[ 0.02983958]\n",
      " [-0.05731758]\n",
      " [ 0.09825497]]\n",
      "Iteration 7202 | Cost: 0.3083944939453122 | Gradient: [[ 0.02983876]\n",
      " [-0.05731346]\n",
      " [ 0.09824761]]\n",
      "Iteration 7203 | Cost: 0.3083806666608031 | Gradient: [[ 0.02983794]\n",
      " [-0.05730934]\n",
      " [ 0.09824025]]\n",
      "Iteration 7204 | Cost: 0.30836684134358394 | Gradient: [[ 0.02983711]\n",
      " [-0.05730522]\n",
      " [ 0.09823289]]\n",
      "Iteration 7205 | Cost: 0.308353017993251 | Gradient: [[ 0.02983629]\n",
      " [-0.05730111]\n",
      " [ 0.09822553]]\n",
      "Iteration 7206 | Cost: 0.30833919660940085 | Gradient: [[ 0.02983547]\n",
      " [-0.05729699]\n",
      " [ 0.09821817]]\n",
      "Iteration 7207 | Cost: 0.3083253771916299 | Gradient: [[ 0.02983464]\n",
      " [-0.05729288]\n",
      " [ 0.09821081]]\n",
      "Iteration 7208 | Cost: 0.3083115597395349 | Gradient: [[ 0.02983382]\n",
      " [-0.05728877]\n",
      " [ 0.09820345]]\n",
      "Iteration 7209 | Cost: 0.3082977442527126 | Gradient: [[ 0.02983299]\n",
      " [-0.05728466]\n",
      " [ 0.0981961 ]]\n",
      "Iteration 7210 | Cost: 0.30828393073075994 | Gradient: [[ 0.02983217]\n",
      " [-0.05728055]\n",
      " [ 0.09818874]]\n",
      "Iteration 7211 | Cost: 0.3082701191732738 | Gradient: [[ 0.02983134]\n",
      " [-0.05727644]\n",
      " [ 0.09818139]]\n",
      "Iteration 7212 | Cost: 0.3082563095798513 | Gradient: [[ 0.02983052]\n",
      " [-0.05727233]\n",
      " [ 0.09817404]]\n",
      "Iteration 7213 | Cost: 0.30824250195008973 | Gradient: [[ 0.02982969]\n",
      " [-0.05726822]\n",
      " [ 0.09816668]]\n",
      "Iteration 7214 | Cost: 0.3082286962835863 | Gradient: [[ 0.02982886]\n",
      " [-0.05726412]\n",
      " [ 0.09815933]]\n",
      "Iteration 7215 | Cost: 0.30821489257993856 | Gradient: [[ 0.02982804]\n",
      " [-0.05726001]\n",
      " [ 0.09815198]]\n",
      "Iteration 7216 | Cost: 0.3082010908387439 | Gradient: [[ 0.02982721]\n",
      " [-0.05725591]\n",
      " [ 0.09814463]]\n",
      "Iteration 7217 | Cost: 0.3081872910596002 | Gradient: [[ 0.02982638]\n",
      " [-0.0572518 ]\n",
      " [ 0.09813728]]\n",
      "Iteration 7218 | Cost: 0.30817349324210486 | Gradient: [[ 0.02982555]\n",
      " [-0.0572477 ]\n",
      " [ 0.09812993]]\n",
      "Iteration 7219 | Cost: 0.3081596973858561 | Gradient: [[ 0.02982473]\n",
      " [-0.0572436 ]\n",
      " [ 0.09812258]]\n",
      "Iteration 7220 | Cost: 0.3081459034904516 | Gradient: [[ 0.0298239 ]\n",
      " [-0.0572395 ]\n",
      " [ 0.09811524]]\n",
      "Iteration 7221 | Cost: 0.3081321115554897 | Gradient: [[ 0.02982307]\n",
      " [-0.0572354 ]\n",
      " [ 0.09810789]]\n",
      "Iteration 7222 | Cost: 0.30811832158056845 | Gradient: [[ 0.02982224]\n",
      " [-0.0572313 ]\n",
      " [ 0.09810055]]\n",
      "Iteration 7223 | Cost: 0.30810453356528616 | Gradient: [[ 0.02982141]\n",
      " [-0.05722721]\n",
      " [ 0.0980932 ]]\n",
      "Iteration 7224 | Cost: 0.3080907475092412 | Gradient: [[ 0.02982058]\n",
      " [-0.05722311]\n",
      " [ 0.09808586]]\n",
      "Iteration 7225 | Cost: 0.3080769634120322 | Gradient: [[ 0.02981975]\n",
      " [-0.05721901]\n",
      " [ 0.09807851]]\n",
      "Iteration 7226 | Cost: 0.30806318127325766 | Gradient: [[ 0.02981892]\n",
      " [-0.05721492]\n",
      " [ 0.09807117]]\n",
      "Iteration 7227 | Cost: 0.3080494010925165 | Gradient: [[ 0.02981809]\n",
      " [-0.05721083]\n",
      " [ 0.09806383]]\n",
      "Iteration 7228 | Cost: 0.30803562286940733 | Gradient: [[ 0.02981726]\n",
      " [-0.05720674]\n",
      " [ 0.09805649]]\n",
      "Iteration 7229 | Cost: 0.30802184660352927 | Gradient: [[ 0.02981643]\n",
      " [-0.05720264]\n",
      " [ 0.09804915]]\n",
      "Iteration 7230 | Cost: 0.30800807229448135 | Gradient: [[ 0.0298156 ]\n",
      " [-0.05719856]\n",
      " [ 0.09804181]]\n",
      "Iteration 7231 | Cost: 0.30799429994186267 | Gradient: [[ 0.02981477]\n",
      " [-0.05719447]\n",
      " [ 0.09803447]]\n",
      "Iteration 7232 | Cost: 0.30798052954527266 | Gradient: [[ 0.02981394]\n",
      " [-0.05719038]\n",
      " [ 0.09802714]]\n",
      "Iteration 7233 | Cost: 0.30796676110431054 | Gradient: [[ 0.02981311]\n",
      " [-0.05718629]\n",
      " [ 0.0980198 ]]\n",
      "Iteration 7234 | Cost: 0.30795299461857584 | Gradient: [[ 0.02981227]\n",
      " [-0.05718221]\n",
      " [ 0.09801246]]\n",
      "Iteration 7235 | Cost: 0.30793923008766827 | Gradient: [[ 0.02981144]\n",
      " [-0.05717812]\n",
      " [ 0.09800513]]\n",
      "Iteration 7236 | Cost: 0.30792546751118743 | Gradient: [[ 0.02981061]\n",
      " [-0.05717404]\n",
      " [ 0.0979978 ]]\n",
      "Iteration 7237 | Cost: 0.3079117068887332 | Gradient: [[ 0.02980977]\n",
      " [-0.05716996]\n",
      " [ 0.09799046]]\n",
      "Iteration 7238 | Cost: 0.30789794821990546 | Gradient: [[ 0.02980894]\n",
      " [-0.05716587]\n",
      " [ 0.09798313]]\n",
      "Iteration 7239 | Cost: 0.30788419150430435 | Gradient: [[ 0.02980811]\n",
      " [-0.05716179]\n",
      " [ 0.0979758 ]]\n",
      "Iteration 7240 | Cost: 0.30787043674152986 | Gradient: [[ 0.02980727]\n",
      " [-0.05715771]\n",
      " [ 0.09796847]]\n",
      "Iteration 7241 | Cost: 0.3078566839311824 | Gradient: [[ 0.02980644]\n",
      " [-0.05715364]\n",
      " [ 0.09796114]]\n",
      "Iteration 7242 | Cost: 0.30784293307286226 | Gradient: [[ 0.0298056 ]\n",
      " [-0.05714956]\n",
      " [ 0.09795381]]\n",
      "Iteration 7243 | Cost: 0.30782918416616983 | Gradient: [[ 0.02980477]\n",
      " [-0.05714548]\n",
      " [ 0.09794648]]\n",
      "Iteration 7244 | Cost: 0.3078154372107059 | Gradient: [[ 0.02980393]\n",
      " [-0.05714141]\n",
      " [ 0.09793915]]\n",
      "Iteration 7245 | Cost: 0.307801692206071 | Gradient: [[ 0.0298031 ]\n",
      " [-0.05713733]\n",
      " [ 0.09793183]]\n",
      "Iteration 7246 | Cost: 0.30778794915186597 | Gradient: [[ 0.02980226]\n",
      " [-0.05713326]\n",
      " [ 0.0979245 ]]\n",
      "Iteration 7247 | Cost: 0.3077742080476917 | Gradient: [[ 0.02980143]\n",
      " [-0.05712919]\n",
      " [ 0.09791717]]\n",
      "Iteration 7248 | Cost: 0.3077604688931491 | Gradient: [[ 0.02980059]\n",
      " [-0.05712511]\n",
      " [ 0.09790985]]\n",
      "Iteration 7249 | Cost: 0.30774673168783945 | Gradient: [[ 0.02979975]\n",
      " [-0.05712104]\n",
      " [ 0.09790253]]\n",
      "Iteration 7250 | Cost: 0.307732996431364 | Gradient: [[ 0.02979892]\n",
      " [-0.05711697]\n",
      " [ 0.0978952 ]]\n",
      "Iteration 7251 | Cost: 0.30771926312332387 | Gradient: [[ 0.02979808]\n",
      " [-0.05711291]\n",
      " [ 0.09788788]]\n",
      "Iteration 7252 | Cost: 0.3077055317633207 | Gradient: [[ 0.02979724]\n",
      " [-0.05710884]\n",
      " [ 0.09788056]]\n",
      "Iteration 7253 | Cost: 0.307691802350956 | Gradient: [[ 0.0297964 ]\n",
      " [-0.05710477]\n",
      " [ 0.09787324]]\n",
      "Iteration 7254 | Cost: 0.3076780748858314 | Gradient: [[ 0.02979557]\n",
      " [-0.05710071]\n",
      " [ 0.09786592]]\n",
      "Iteration 7255 | Cost: 0.30766434936754866 | Gradient: [[ 0.02979473]\n",
      " [-0.05709664]\n",
      " [ 0.0978586 ]]\n",
      "Iteration 7256 | Cost: 0.3076506257957096 | Gradient: [[ 0.02979389]\n",
      " [-0.05709258]\n",
      " [ 0.09785128]]\n",
      "Iteration 7257 | Cost: 0.3076369041699163 | Gradient: [[ 0.02979305]\n",
      " [-0.05708852]\n",
      " [ 0.09784397]]\n",
      "Iteration 7258 | Cost: 0.30762318448977083 | Gradient: [[ 0.02979221]\n",
      " [-0.05708446]\n",
      " [ 0.09783665]]\n",
      "Iteration 7259 | Cost: 0.3076094667548754 | Gradient: [[ 0.02979137]\n",
      " [-0.0570804 ]\n",
      " [ 0.09782933]]\n",
      "Iteration 7260 | Cost: 0.30759575096483216 | Gradient: [[ 0.02979053]\n",
      " [-0.05707634]\n",
      " [ 0.09782202]]\n",
      "Iteration 7261 | Cost: 0.3075820371192438 | Gradient: [[ 0.02978969]\n",
      " [-0.05707228]\n",
      " [ 0.09781471]]\n",
      "Iteration 7262 | Cost: 0.3075683252177126 | Gradient: [[ 0.02978885]\n",
      " [-0.05706822]\n",
      " [ 0.09780739]]\n",
      "Iteration 7263 | Cost: 0.3075546152598413 | Gradient: [[ 0.02978801]\n",
      " [-0.05706417]\n",
      " [ 0.09780008]]\n",
      "Iteration 7264 | Cost: 0.30754090724523253 | Gradient: [[ 0.02978717]\n",
      " [-0.05706011]\n",
      " [ 0.09779277]]\n",
      "Iteration 7265 | Cost: 0.3075272011734892 | Gradient: [[ 0.02978633]\n",
      " [-0.05705606]\n",
      " [ 0.09778546]]\n",
      "Iteration 7266 | Cost: 0.30751349704421427 | Gradient: [[ 0.02978549]\n",
      " [-0.057052  ]\n",
      " [ 0.09777815]]\n",
      "Iteration 7267 | Cost: 0.3074997948570108 | Gradient: [[ 0.02978465]\n",
      " [-0.05704795]\n",
      " [ 0.09777084]]\n",
      "Iteration 7268 | Cost: 0.30748609461148185 | Gradient: [[ 0.0297838 ]\n",
      " [-0.0570439 ]\n",
      " [ 0.09776353]]\n",
      "Iteration 7269 | Cost: 0.3074723963072309 | Gradient: [[ 0.02978296]\n",
      " [-0.05703985]\n",
      " [ 0.09775622]]\n",
      "Iteration 7270 | Cost: 0.3074586999438611 | Gradient: [[ 0.02978212]\n",
      " [-0.0570358 ]\n",
      " [ 0.09774892]]\n",
      "Iteration 7271 | Cost: 0.307445005520976 | Gradient: [[ 0.02978128]\n",
      " [-0.05703175]\n",
      " [ 0.09774161]]\n",
      "Iteration 7272 | Cost: 0.3074313130381793 | Gradient: [[ 0.02978043]\n",
      " [-0.05702771]\n",
      " [ 0.09773431]]\n",
      "Iteration 7273 | Cost: 0.30741762249507454 | Gradient: [[ 0.02977959]\n",
      " [-0.05702366]\n",
      " [ 0.097727  ]]\n",
      "Iteration 7274 | Cost: 0.30740393389126563 | Gradient: [[ 0.02977875]\n",
      " [-0.05701961]\n",
      " [ 0.0977197 ]]\n",
      "Iteration 7275 | Cost: 0.30739024722635644 | Gradient: [[ 0.0297779 ]\n",
      " [-0.05701557]\n",
      " [ 0.0977124 ]]\n",
      "Iteration 7276 | Cost: 0.30737656249995093 | Gradient: [[ 0.02977706]\n",
      " [-0.05701153]\n",
      " [ 0.09770509]]\n",
      "Iteration 7277 | Cost: 0.3073628797116534 | Gradient: [[ 0.02977621]\n",
      " [-0.05700749]\n",
      " [ 0.09769779]]\n",
      "Iteration 7278 | Cost: 0.3073491988610679 | Gradient: [[ 0.02977537]\n",
      " [-0.05700344]\n",
      " [ 0.09769049]]\n",
      "Iteration 7279 | Cost: 0.30733551994779873 | Gradient: [[ 0.02977452]\n",
      " [-0.0569994 ]\n",
      " [ 0.09768319]]\n",
      "Iteration 7280 | Cost: 0.30732184297145054 | Gradient: [[ 0.02977368]\n",
      " [-0.05699537]\n",
      " [ 0.09767589]]\n",
      "Iteration 7281 | Cost: 0.3073081679316278 | Gradient: [[ 0.02977283]\n",
      " [-0.05699133]\n",
      " [ 0.0976686 ]]\n",
      "Iteration 7282 | Cost: 0.3072944948279351 | Gradient: [[ 0.02977199]\n",
      " [-0.05698729]\n",
      " [ 0.0976613 ]]\n",
      "Iteration 7283 | Cost: 0.3072808236599773 | Gradient: [[ 0.02977114]\n",
      " [-0.05698325]\n",
      " [ 0.097654  ]]\n",
      "Iteration 7284 | Cost: 0.30726715442735913 | Gradient: [[ 0.02977029]\n",
      " [-0.05697922]\n",
      " [ 0.09764671]]\n",
      "Iteration 7285 | Cost: 0.30725348712968564 | Gradient: [[ 0.02976945]\n",
      " [-0.05697518]\n",
      " [ 0.09763941]]\n",
      "Iteration 7286 | Cost: 0.307239821766562 | Gradient: [[ 0.0297686 ]\n",
      " [-0.05697115]\n",
      " [ 0.09763212]]\n",
      "Iteration 7287 | Cost: 0.3072261583375933 | Gradient: [[ 0.02976775]\n",
      " [-0.05696712]\n",
      " [ 0.09762483]]\n",
      "Iteration 7288 | Cost: 0.30721249684238483 | Gradient: [[ 0.0297669 ]\n",
      " [-0.05696309]\n",
      " [ 0.09761753]]\n",
      "Iteration 7289 | Cost: 0.3071988372805421 | Gradient: [[ 0.02976606]\n",
      " [-0.05695906]\n",
      " [ 0.09761024]]\n",
      "Iteration 7290 | Cost: 0.3071851796516704 | Gradient: [[ 0.02976521]\n",
      " [-0.05695503]\n",
      " [ 0.09760295]]\n",
      "Iteration 7291 | Cost: 0.30717152395537556 | Gradient: [[ 0.02976436]\n",
      " [-0.056951  ]\n",
      " [ 0.09759566]]\n",
      "Iteration 7292 | Cost: 0.3071578701912632 | Gradient: [[ 0.02976351]\n",
      " [-0.05694697]\n",
      " [ 0.09758837]]\n",
      "Iteration 7293 | Cost: 0.30714421835893924 | Gradient: [[ 0.02976266]\n",
      " [-0.05694295]\n",
      " [ 0.09758109]]\n",
      "Iteration 7294 | Cost: 0.3071305684580094 | Gradient: [[ 0.02976181]\n",
      " [-0.05693892]\n",
      " [ 0.0975738 ]]\n",
      "Iteration 7295 | Cost: 0.3071169204880799 | Gradient: [[ 0.02976096]\n",
      " [-0.0569349 ]\n",
      " [ 0.09756651]]\n",
      "Iteration 7296 | Cost: 0.3071032744487569 | Gradient: [[ 0.02976011]\n",
      " [-0.05693088]\n",
      " [ 0.09755923]]\n",
      "Iteration 7297 | Cost: 0.30708963033964665 | Gradient: [[ 0.02975926]\n",
      " [-0.05692685]\n",
      " [ 0.09755194]]\n",
      "Iteration 7298 | Cost: 0.30707598816035536 | Gradient: [[ 0.02975841]\n",
      " [-0.05692283]\n",
      " [ 0.09754466]]\n",
      "Iteration 7299 | Cost: 0.3070623479104896 | Gradient: [[ 0.02975756]\n",
      " [-0.05691881]\n",
      " [ 0.09753737]]\n",
      "Iteration 7300 | Cost: 0.30704870958965585 | Gradient: [[ 0.02975671]\n",
      " [-0.05691479]\n",
      " [ 0.09753009]]\n",
      "Iteration 7301 | Cost: 0.3070350731974609 | Gradient: [[ 0.02975586]\n",
      " [-0.05691078]\n",
      " [ 0.09752281]]\n",
      "Iteration 7302 | Cost: 0.30702143873351145 | Gradient: [[ 0.02975501]\n",
      " [-0.05690676]\n",
      " [ 0.09751553]]\n",
      "Iteration 7303 | Cost: 0.30700780619741447 | Gradient: [[ 0.02975416]\n",
      " [-0.05690274]\n",
      " [ 0.09750825]]\n",
      "Iteration 7304 | Cost: 0.3069941755887769 | Gradient: [[ 0.0297533 ]\n",
      " [-0.05689873]\n",
      " [ 0.09750097]]\n",
      "Iteration 7305 | Cost: 0.30698054690720583 | Gradient: [[ 0.02975245]\n",
      " [-0.05689471]\n",
      " [ 0.09749369]]\n",
      "Iteration 7306 | Cost: 0.3069669201523085 | Gradient: [[ 0.0297516 ]\n",
      " [-0.0568907 ]\n",
      " [ 0.09748641]]\n",
      "Iteration 7307 | Cost: 0.30695329532369214 | Gradient: [[ 0.02975075]\n",
      " [-0.05688669]\n",
      " [ 0.09747914]]\n",
      "Iteration 7308 | Cost: 0.3069396724209642 | Gradient: [[ 0.02974989]\n",
      " [-0.05688268]\n",
      " [ 0.09747186]]\n",
      "Iteration 7309 | Cost: 0.30692605144373225 | Gradient: [[ 0.02974904]\n",
      " [-0.05687867]\n",
      " [ 0.09746459]]\n",
      "Iteration 7310 | Cost: 0.3069124323916038 | Gradient: [[ 0.02974819]\n",
      " [-0.05687466]\n",
      " [ 0.09745731]]\n",
      "Iteration 7311 | Cost: 0.3068988152641867 | Gradient: [[ 0.02974733]\n",
      " [-0.05687065]\n",
      " [ 0.09745004]]\n",
      "Iteration 7312 | Cost: 0.30688520006108877 | Gradient: [[ 0.02974648]\n",
      " [-0.05686664]\n",
      " [ 0.09744276]]\n",
      "Iteration 7313 | Cost: 0.30687158678191784 | Gradient: [[ 0.02974562]\n",
      " [-0.05686263]\n",
      " [ 0.09743549]]\n",
      "Iteration 7314 | Cost: 0.3068579754262821 | Gradient: [[ 0.02974477]\n",
      " [-0.05685863]\n",
      " [ 0.09742822]]\n",
      "Iteration 7315 | Cost: 0.30684436599378956 | Gradient: [[ 0.02974391]\n",
      " [-0.05685463]\n",
      " [ 0.09742095]]\n",
      "Iteration 7316 | Cost: 0.30683075848404867 | Gradient: [[ 0.02974306]\n",
      " [-0.05685062]\n",
      " [ 0.09741368]]\n",
      "Iteration 7317 | Cost: 0.30681715289666756 | Gradient: [[ 0.0297422 ]\n",
      " [-0.05684662]\n",
      " [ 0.09740641]]\n",
      "Iteration 7318 | Cost: 0.3068035492312548 | Gradient: [[ 0.02974135]\n",
      " [-0.05684262]\n",
      " [ 0.09739914]]\n",
      "Iteration 7319 | Cost: 0.306789947487419 | Gradient: [[ 0.02974049]\n",
      " [-0.05683862]\n",
      " [ 0.09739188]]\n",
      "Iteration 7320 | Cost: 0.30677634766476886 | Gradient: [[ 0.02973963]\n",
      " [-0.05683462]\n",
      " [ 0.09738461]]\n",
      "Iteration 7321 | Cost: 0.306762749762913 | Gradient: [[ 0.02973878]\n",
      " [-0.05683062]\n",
      " [ 0.09737735]]\n",
      "Iteration 7322 | Cost: 0.3067491537814605 | Gradient: [[ 0.02973792]\n",
      " [-0.05682662]\n",
      " [ 0.09737008]]\n",
      "Iteration 7323 | Cost: 0.3067355597200202 | Gradient: [[ 0.02973706]\n",
      " [-0.05682263]\n",
      " [ 0.09736282]]\n",
      "Iteration 7324 | Cost: 0.3067219675782013 | Gradient: [[ 0.0297362 ]\n",
      " [-0.05681863]\n",
      " [ 0.09735555]]\n",
      "Iteration 7325 | Cost: 0.30670837735561296 | Gradient: [[ 0.02973535]\n",
      " [-0.05681464]\n",
      " [ 0.09734829]]\n",
      "Iteration 7326 | Cost: 0.3066947890518646 | Gradient: [[ 0.02973449]\n",
      " [-0.05681064]\n",
      " [ 0.09734103]]\n",
      "Iteration 7327 | Cost: 0.30668120266656534 | Gradient: [[ 0.02973363]\n",
      " [-0.05680665]\n",
      " [ 0.09733377]]\n",
      "Iteration 7328 | Cost: 0.306667618199325 | Gradient: [[ 0.02973277]\n",
      " [-0.05680266]\n",
      " [ 0.09732651]]\n",
      "Iteration 7329 | Cost: 0.3066540356497529 | Gradient: [[ 0.02973191]\n",
      " [-0.05679867]\n",
      " [ 0.09731925]]\n",
      "Iteration 7330 | Cost: 0.3066404550174591 | Gradient: [[ 0.02973105]\n",
      " [-0.05679468]\n",
      " [ 0.09731199]]\n",
      "Iteration 7331 | Cost: 0.30662687630205326 | Gradient: [[ 0.02973019]\n",
      " [-0.05679069]\n",
      " [ 0.09730473]]\n",
      "Iteration 7332 | Cost: 0.3066132995031453 | Gradient: [[ 0.02972933]\n",
      " [-0.0567867 ]\n",
      " [ 0.09729748]]\n",
      "Iteration 7333 | Cost: 0.3065997246203453 | Gradient: [[ 0.02972847]\n",
      " [-0.05678272]\n",
      " [ 0.09729022]]\n",
      "Iteration 7334 | Cost: 0.3065861516532633 | Gradient: [[ 0.02972761]\n",
      " [-0.05677873]\n",
      " [ 0.09728297]]\n",
      "Iteration 7335 | Cost: 0.30657258060150966 | Gradient: [[ 0.02972675]\n",
      " [-0.05677474]\n",
      " [ 0.09727571]]\n",
      "Iteration 7336 | Cost: 0.3065590114646948 | Gradient: [[ 0.02972589]\n",
      " [-0.05677076]\n",
      " [ 0.09726846]]\n",
      "Iteration 7337 | Cost: 0.30654544424242897 | Gradient: [[ 0.02972503]\n",
      " [-0.05676678]\n",
      " [ 0.09726121]]\n",
      "Iteration 7338 | Cost: 0.30653187893432293 | Gradient: [[ 0.02972417]\n",
      " [-0.0567628 ]\n",
      " [ 0.09725395]]\n",
      "Iteration 7339 | Cost: 0.30651831553998726 | Gradient: [[ 0.02972331]\n",
      " [-0.05675882]\n",
      " [ 0.0972467 ]]\n",
      "Iteration 7340 | Cost: 0.30650475405903266 | Gradient: [[ 0.02972245]\n",
      " [-0.05675484]\n",
      " [ 0.09723945]]\n",
      "Iteration 7341 | Cost: 0.30649119449107015 | Gradient: [[ 0.02972158]\n",
      " [-0.05675086]\n",
      " [ 0.0972322 ]]\n",
      "Iteration 7342 | Cost: 0.30647763683571055 | Gradient: [[ 0.02972072]\n",
      " [-0.05674688]\n",
      " [ 0.09722495]]\n",
      "Iteration 7343 | Cost: 0.30646408109256507 | Gradient: [[ 0.02971986]\n",
      " [-0.0567429 ]\n",
      " [ 0.09721771]]\n",
      "Iteration 7344 | Cost: 0.30645052726124483 | Gradient: [[ 0.029719  ]\n",
      " [-0.05673893]\n",
      " [ 0.09721046]]\n",
      "Iteration 7345 | Cost: 0.30643697534136105 | Gradient: [[ 0.02971813]\n",
      " [-0.05673495]\n",
      " [ 0.09720321]]\n",
      "Iteration 7346 | Cost: 0.3064234253325253 | Gradient: [[ 0.02971727]\n",
      " [-0.05673098]\n",
      " [ 0.09719597]]\n",
      "Iteration 7347 | Cost: 0.30640987723434904 | Gradient: [[ 0.02971641]\n",
      " [-0.056727  ]\n",
      " [ 0.09718872]]\n",
      "Iteration 7348 | Cost: 0.30639633104644376 | Gradient: [[ 0.02971554]\n",
      " [-0.05672303]\n",
      " [ 0.09718148]]\n",
      "Iteration 7349 | Cost: 0.30638278676842123 | Gradient: [[ 0.02971468]\n",
      " [-0.05671906]\n",
      " [ 0.09717424]]\n",
      "Iteration 7350 | Cost: 0.30636924439989327 | Gradient: [[ 0.02971381]\n",
      " [-0.05671509]\n",
      " [ 0.09716699]]\n",
      "Iteration 7351 | Cost: 0.3063557039404718 | Gradient: [[ 0.02971295]\n",
      " [-0.05671112]\n",
      " [ 0.09715975]]\n",
      "Iteration 7352 | Cost: 0.3063421653897688 | Gradient: [[ 0.02971208]\n",
      " [-0.05670715]\n",
      " [ 0.09715251]]\n",
      "Iteration 7353 | Cost: 0.3063286287473964 | Gradient: [[ 0.02971122]\n",
      " [-0.05670319]\n",
      " [ 0.09714527]]\n",
      "Iteration 7354 | Cost: 0.3063150940129668 | Gradient: [[ 0.02971035]\n",
      " [-0.05669922]\n",
      " [ 0.09713803]]\n",
      "Iteration 7355 | Cost: 0.3063015611860924 | Gradient: [[ 0.02970949]\n",
      " [-0.05669525]\n",
      " [ 0.09713079]]\n",
      "Iteration 7356 | Cost: 0.3062880302663856 | Gradient: [[ 0.02970862]\n",
      " [-0.05669129]\n",
      " [ 0.09712356]]\n",
      "Iteration 7357 | Cost: 0.306274501253459 | Gradient: [[ 0.02970775]\n",
      " [-0.05668733]\n",
      " [ 0.09711632]]\n",
      "Iteration 7358 | Cost: 0.3062609741469251 | Gradient: [[ 0.02970689]\n",
      " [-0.05668336]\n",
      " [ 0.09710908]]\n",
      "Iteration 7359 | Cost: 0.3062474489463967 | Gradient: [[ 0.02970602]\n",
      " [-0.0566794 ]\n",
      " [ 0.09710185]]\n",
      "Iteration 7360 | Cost: 0.3062339256514867 | Gradient: [[ 0.02970515]\n",
      " [-0.05667544]\n",
      " [ 0.09709461]]\n",
      "Iteration 7361 | Cost: 0.3062204042618081 | Gradient: [[ 0.02970429]\n",
      " [-0.05667148]\n",
      " [ 0.09708738]]\n",
      "Iteration 7362 | Cost: 0.3062068847769737 | Gradient: [[ 0.02970342]\n",
      " [-0.05666752]\n",
      " [ 0.09708015]]\n",
      "Iteration 7363 | Cost: 0.3061933671965969 | Gradient: [[ 0.02970255]\n",
      " [-0.05666357]\n",
      " [ 0.09707292]]\n",
      "Iteration 7364 | Cost: 0.3061798515202909 | Gradient: [[ 0.02970168]\n",
      " [-0.05665961]\n",
      " [ 0.09706569]]\n",
      "Iteration 7365 | Cost: 0.3061663377476691 | Gradient: [[ 0.02970081]\n",
      " [-0.05665565]\n",
      " [ 0.09705846]]\n",
      "Iteration 7366 | Cost: 0.30615282587834486 | Gradient: [[ 0.02969994]\n",
      " [-0.0566517 ]\n",
      " [ 0.09705123]]\n",
      "Iteration 7367 | Cost: 0.30613931591193183 | Gradient: [[ 0.02969908]\n",
      " [-0.05664774]\n",
      " [ 0.097044  ]]\n",
      "Iteration 7368 | Cost: 0.3061258078480436 | Gradient: [[ 0.02969821]\n",
      " [-0.05664379]\n",
      " [ 0.09703677]]\n",
      "Iteration 7369 | Cost: 0.30611230168629405 | Gradient: [[ 0.02969734]\n",
      " [-0.05663984]\n",
      " [ 0.09702954]]\n",
      "Iteration 7370 | Cost: 0.30609879742629703 | Gradient: [[ 0.02969647]\n",
      " [-0.05663589]\n",
      " [ 0.09702232]]\n",
      "Iteration 7371 | Cost: 0.3060852950676665 | Gradient: [[ 0.0296956 ]\n",
      " [-0.05663194]\n",
      " [ 0.09701509]]\n",
      "Iteration 7372 | Cost: 0.30607179461001655 | Gradient: [[ 0.02969473]\n",
      " [-0.05662799]\n",
      " [ 0.09700787]]\n",
      "Iteration 7373 | Cost: 0.3060582960529614 | Gradient: [[ 0.02969386]\n",
      " [-0.05662404]\n",
      " [ 0.09700064]]\n",
      "Iteration 7374 | Cost: 0.30604479939611523 | Gradient: [[ 0.02969299]\n",
      " [-0.05662009]\n",
      " [ 0.09699342]]\n",
      "Iteration 7375 | Cost: 0.30603130463909256 | Gradient: [[ 0.02969211]\n",
      " [-0.05661615]\n",
      " [ 0.0969862 ]]\n",
      "Iteration 7376 | Cost: 0.30601781178150794 | Gradient: [[ 0.02969124]\n",
      " [-0.0566122 ]\n",
      " [ 0.09697898]]\n",
      "Iteration 7377 | Cost: 0.30600432082297585 | Gradient: [[ 0.02969037]\n",
      " [-0.05660826]\n",
      " [ 0.09697176]]\n",
      "Iteration 7378 | Cost: 0.3059908317631109 | Gradient: [[ 0.0296895 ]\n",
      " [-0.05660431]\n",
      " [ 0.09696454]]\n",
      "Iteration 7379 | Cost: 0.30597734460152815 | Gradient: [[ 0.02968863]\n",
      " [-0.05660037]\n",
      " [ 0.09695732]]\n",
      "Iteration 7380 | Cost: 0.3059638593378423 | Gradient: [[ 0.02968775]\n",
      " [-0.05659643]\n",
      " [ 0.0969501 ]]\n",
      "Iteration 7381 | Cost: 0.3059503759716685 | Gradient: [[ 0.02968688]\n",
      " [-0.05659249]\n",
      " [ 0.09694288]]\n",
      "Iteration 7382 | Cost: 0.30593689450262185 | Gradient: [[ 0.02968601]\n",
      " [-0.05658855]\n",
      " [ 0.09693567]]\n",
      "Iteration 7383 | Cost: 0.30592341493031733 | Gradient: [[ 0.02968514]\n",
      " [-0.05658461]\n",
      " [ 0.09692845]]\n",
      "Iteration 7384 | Cost: 0.3059099372543706 | Gradient: [[ 0.02968426]\n",
      " [-0.05658067]\n",
      " [ 0.09692123]]\n",
      "Iteration 7385 | Cost: 0.3058964614743969 | Gradient: [[ 0.02968339]\n",
      " [-0.05657674]\n",
      " [ 0.09691402]]\n",
      "Iteration 7386 | Cost: 0.30588298759001187 | Gradient: [[ 0.02968251]\n",
      " [-0.0565728 ]\n",
      " [ 0.09690681]]\n",
      "Iteration 7387 | Cost: 0.3058695156008309 | Gradient: [[ 0.02968164]\n",
      " [-0.05656887]\n",
      " [ 0.09689959]]\n",
      "Iteration 7388 | Cost: 0.30585604550646994 | Gradient: [[ 0.02968077]\n",
      " [-0.05656493]\n",
      " [ 0.09689238]]\n",
      "Iteration 7389 | Cost: 0.30584257730654485 | Gradient: [[ 0.02967989]\n",
      " [-0.056561  ]\n",
      " [ 0.09688517]]\n",
      "Iteration 7390 | Cost: 0.30582911100067134 | Gradient: [[ 0.02967902]\n",
      " [-0.05655707]\n",
      " [ 0.09687796]]\n",
      "Iteration 7391 | Cost: 0.30581564658846566 | Gradient: [[ 0.02967814]\n",
      " [-0.05655314]\n",
      " [ 0.09687075]]\n",
      "Iteration 7392 | Cost: 0.30580218406954385 | Gradient: [[ 0.02967727]\n",
      " [-0.05654921]\n",
      " [ 0.09686354]]\n",
      "Iteration 7393 | Cost: 0.3057887234435221 | Gradient: [[ 0.02967639]\n",
      " [-0.05654528]\n",
      " [ 0.09685634]]\n",
      "Iteration 7394 | Cost: 0.3057752647100168 | Gradient: [[ 0.02967551]\n",
      " [-0.05654135]\n",
      " [ 0.09684913]]\n",
      "Iteration 7395 | Cost: 0.30576180786864454 | Gradient: [[ 0.02967464]\n",
      " [-0.05653742]\n",
      " [ 0.09684192]]\n",
      "Iteration 7396 | Cost: 0.3057483529190217 | Gradient: [[ 0.02967376]\n",
      " [-0.0565335 ]\n",
      " [ 0.09683472]]\n",
      "Iteration 7397 | Cost: 0.30573489986076496 | Gradient: [[ 0.02967288]\n",
      " [-0.05652957]\n",
      " [ 0.09682751]]\n",
      "Iteration 7398 | Cost: 0.3057214486934911 | Gradient: [[ 0.02967201]\n",
      " [-0.05652565]\n",
      " [ 0.09682031]]\n",
      "Iteration 7399 | Cost: 0.305707999416817 | Gradient: [[ 0.02967113]\n",
      " [-0.05652172]\n",
      " [ 0.09681311]]\n",
      "Iteration 7400 | Cost: 0.3056945520303595 | Gradient: [[ 0.02967025]\n",
      " [-0.0565178 ]\n",
      " [ 0.0968059 ]]\n",
      "Iteration 7401 | Cost: 0.3056811065337357 | Gradient: [[ 0.02966938]\n",
      " [-0.05651388]\n",
      " [ 0.0967987 ]]\n",
      "Iteration 7402 | Cost: 0.30566766292656283 | Gradient: [[ 0.0296685 ]\n",
      " [-0.05650996]\n",
      " [ 0.0967915 ]]\n",
      "Iteration 7403 | Cost: 0.3056542212084582 | Gradient: [[ 0.02966762]\n",
      " [-0.05650604]\n",
      " [ 0.0967843 ]]\n",
      "Iteration 7404 | Cost: 0.30564078137903905 | Gradient: [[ 0.02966674]\n",
      " [-0.05650212]\n",
      " [ 0.0967771 ]]\n",
      "Iteration 7405 | Cost: 0.3056273434379228 | Gradient: [[ 0.02966586]\n",
      " [-0.0564982 ]\n",
      " [ 0.09676991]]\n",
      "Iteration 7406 | Cost: 0.3056139073847272 | Gradient: [[ 0.02966498]\n",
      " [-0.05649429]\n",
      " [ 0.09676271]]\n",
      "Iteration 7407 | Cost: 0.3056004732190698 | Gradient: [[ 0.0296641 ]\n",
      " [-0.05649037]\n",
      " [ 0.09675551]]\n",
      "Iteration 7408 | Cost: 0.3055870409405683 | Gradient: [[ 0.02966322]\n",
      " [-0.05648646]\n",
      " [ 0.09674832]]\n",
      "Iteration 7409 | Cost: 0.3055736105488408 | Gradient: [[ 0.02966234]\n",
      " [-0.05648254]\n",
      " [ 0.09674112]]\n",
      "Iteration 7410 | Cost: 0.30556018204350505 | Gradient: [[ 0.02966146]\n",
      " [-0.05647863]\n",
      " [ 0.09673393]]\n",
      "Iteration 7411 | Cost: 0.3055467554241792 | Gradient: [[ 0.02966058]\n",
      " [-0.05647472]\n",
      " [ 0.09672673]]\n",
      "Iteration 7412 | Cost: 0.3055333306904815 | Gradient: [[ 0.0296597 ]\n",
      " [-0.05647081]\n",
      " [ 0.09671954]]\n",
      "Iteration 7413 | Cost: 0.30551990784203015 | Gradient: [[ 0.02965882]\n",
      " [-0.0564669 ]\n",
      " [ 0.09671235]]\n",
      "Iteration 7414 | Cost: 0.3055064868784435 | Gradient: [[ 0.02965794]\n",
      " [-0.05646299]\n",
      " [ 0.09670516]]\n",
      "Iteration 7415 | Cost: 0.3054930677993401 | Gradient: [[ 0.02965706]\n",
      " [-0.05645908]\n",
      " [ 0.09669797]]\n",
      "Iteration 7416 | Cost: 0.3054796506043385 | Gradient: [[ 0.02965618]\n",
      " [-0.05645517]\n",
      " [ 0.09669078]]\n",
      "Iteration 7417 | Cost: 0.30546623529305744 | Gradient: [[ 0.0296553 ]\n",
      " [-0.05645126]\n",
      " [ 0.09668359]]\n",
      "Iteration 7418 | Cost: 0.30545282186511563 | Gradient: [[ 0.02965441]\n",
      " [-0.05644736]\n",
      " [ 0.0966764 ]]\n",
      "Iteration 7419 | Cost: 0.30543941032013194 | Gradient: [[ 0.02965353]\n",
      " [-0.05644345]\n",
      " [ 0.09666922]]\n",
      "Iteration 7420 | Cost: 0.30542600065772546 | Gradient: [[ 0.02965265]\n",
      " [-0.05643955]\n",
      " [ 0.09666203]]\n",
      "Iteration 7421 | Cost: 0.3054125928775153 | Gradient: [[ 0.02965177]\n",
      " [-0.05643565]\n",
      " [ 0.09665485]]\n",
      "Iteration 7422 | Cost: 0.3053991869791205 | Gradient: [[ 0.02965088]\n",
      " [-0.05643174]\n",
      " [ 0.09664766]]\n",
      "Iteration 7423 | Cost: 0.3053857829621604 | Gradient: [[ 0.02965   ]\n",
      " [-0.05642784]\n",
      " [ 0.09664048]]\n",
      "Iteration 7424 | Cost: 0.3053723808262544 | Gradient: [[ 0.02964912]\n",
      " [-0.05642394]\n",
      " [ 0.0966333 ]]\n",
      "Iteration 7425 | Cost: 0.305358980571022 | Gradient: [[ 0.02964823]\n",
      " [-0.05642004]\n",
      " [ 0.09662611]]\n",
      "Iteration 7426 | Cost: 0.3053455821960829 | Gradient: [[ 0.02964735]\n",
      " [-0.05641615]\n",
      " [ 0.09661893]]\n",
      "Iteration 7427 | Cost: 0.3053321857010567 | Gradient: [[ 0.02964646]\n",
      " [-0.05641225]\n",
      " [ 0.09661175]]\n",
      "Iteration 7428 | Cost: 0.30531879108556315 | Gradient: [[ 0.02964558]\n",
      " [-0.05640835]\n",
      " [ 0.09660457]]\n",
      "Iteration 7429 | Cost: 0.30530539834922216 | Gradient: [[ 0.02964469]\n",
      " [-0.05640446]\n",
      " [ 0.09659739]]\n",
      "Iteration 7430 | Cost: 0.30529200749165386 | Gradient: [[ 0.02964381]\n",
      " [-0.05640056]\n",
      " [ 0.09659022]]\n",
      "Iteration 7431 | Cost: 0.30527861851247823 | Gradient: [[ 0.02964292]\n",
      " [-0.05639667]\n",
      " [ 0.09658304]]\n",
      "Iteration 7432 | Cost: 0.30526523141131545 | Gradient: [[ 0.02964204]\n",
      " [-0.05639278]\n",
      " [ 0.09657586]]\n",
      "Iteration 7433 | Cost: 0.30525184618778584 | Gradient: [[ 0.02964115]\n",
      " [-0.05638889]\n",
      " [ 0.09656869]]\n",
      "Iteration 7434 | Cost: 0.3052384628415099 | Gradient: [[ 0.02964027]\n",
      " [-0.05638499]\n",
      " [ 0.09656151]]\n",
      "Iteration 7435 | Cost: 0.305225081372108 | Gradient: [[ 0.02963938]\n",
      " [-0.05638111]\n",
      " [ 0.09655434]]\n",
      "Iteration 7436 | Cost: 0.3052117017792008 | Gradient: [[ 0.02963849]\n",
      " [-0.05637722]\n",
      " [ 0.09654716]]\n",
      "Iteration 7437 | Cost: 0.3051983240624091 | Gradient: [[ 0.02963761]\n",
      " [-0.05637333]\n",
      " [ 0.09653999]]\n",
      "Iteration 7438 | Cost: 0.30518494822135356 | Gradient: [[ 0.02963672]\n",
      " [-0.05636944]\n",
      " [ 0.09653282]]\n",
      "Iteration 7439 | Cost: 0.3051715742556551 | Gradient: [[ 0.02963583]\n",
      " [-0.05636556]\n",
      " [ 0.09652565]]\n",
      "Iteration 7440 | Cost: 0.3051582021649348 | Gradient: [[ 0.02963495]\n",
      " [-0.05636167]\n",
      " [ 0.09651848]]\n",
      "Iteration 7441 | Cost: 0.3051448319488137 | Gradient: [[ 0.02963406]\n",
      " [-0.05635779]\n",
      " [ 0.09651131]]\n",
      "Iteration 7442 | Cost: 0.305131463606913 | Gradient: [[ 0.02963317]\n",
      " [-0.0563539 ]\n",
      " [ 0.09650414]]\n",
      "Iteration 7443 | Cost: 0.3051180971388542 | Gradient: [[ 0.02963228]\n",
      " [-0.05635002]\n",
      " [ 0.09649697]]\n",
      "Iteration 7444 | Cost: 0.30510473254425835 | Gradient: [[ 0.02963139]\n",
      " [-0.05634614]\n",
      " [ 0.09648981]]\n",
      "Iteration 7445 | Cost: 0.3050913698227473 | Gradient: [[ 0.0296305 ]\n",
      " [-0.05634226]\n",
      " [ 0.09648264]]\n",
      "Iteration 7446 | Cost: 0.30507800897394244 | Gradient: [[ 0.02962962]\n",
      " [-0.05633838]\n",
      " [ 0.09647548]]\n",
      "Iteration 7447 | Cost: 0.3050646499974655 | Gradient: [[ 0.02962873]\n",
      " [-0.0563345 ]\n",
      " [ 0.09646831]]\n",
      "Iteration 7448 | Cost: 0.3050512928929385 | Gradient: [[ 0.02962784]\n",
      " [-0.05633062]\n",
      " [ 0.09646115]]\n",
      "Iteration 7449 | Cost: 0.30503793765998294 | Gradient: [[ 0.02962695]\n",
      " [-0.05632675]\n",
      " [ 0.09645399]]\n",
      "Iteration 7450 | Cost: 0.30502458429822127 | Gradient: [[ 0.02962606]\n",
      " [-0.05632287]\n",
      " [ 0.09644682]]\n",
      "Iteration 7451 | Cost: 0.3050112328072753 | Gradient: [[ 0.02962517]\n",
      " [-0.05631899]\n",
      " [ 0.09643966]]\n",
      "Iteration 7452 | Cost: 0.30499788318676735 | Gradient: [[ 0.02962428]\n",
      " [-0.05631512]\n",
      " [ 0.0964325 ]]\n",
      "Iteration 7453 | Cost: 0.3049845354363198 | Gradient: [[ 0.02962339]\n",
      " [-0.05631125]\n",
      " [ 0.09642534]]\n",
      "Iteration 7454 | Cost: 0.3049711895555549 | Gradient: [[ 0.02962249]\n",
      " [-0.05630737]\n",
      " [ 0.09641818]]\n",
      "Iteration 7455 | Cost: 0.3049578455440953 | Gradient: [[ 0.0296216 ]\n",
      " [-0.0563035 ]\n",
      " [ 0.09641103]]\n",
      "Iteration 7456 | Cost: 0.3049445034015634 | Gradient: [[ 0.02962071]\n",
      " [-0.05629963]\n",
      " [ 0.09640387]]\n",
      "Iteration 7457 | Cost: 0.3049311631275822 | Gradient: [[ 0.02961982]\n",
      " [-0.05629576]\n",
      " [ 0.09639671]]\n",
      "Iteration 7458 | Cost: 0.30491782472177437 | Gradient: [[ 0.02961893]\n",
      " [-0.05629189]\n",
      " [ 0.09638956]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7459 | Cost: 0.30490448818376276 | Gradient: [[ 0.02961804]\n",
      " [-0.05628803]\n",
      " [ 0.0963824 ]]\n",
      "Iteration 7460 | Cost: 0.3048911535131704 | Gradient: [[ 0.02961714]\n",
      " [-0.05628416]\n",
      " [ 0.09637525]]\n",
      "Iteration 7461 | Cost: 0.30487782070962044 | Gradient: [[ 0.02961625]\n",
      " [-0.05628029]\n",
      " [ 0.09636809]]\n",
      "Iteration 7462 | Cost: 0.30486448977273606 | Gradient: [[ 0.02961536]\n",
      " [-0.05627643]\n",
      " [ 0.09636094]]\n",
      "Iteration 7463 | Cost: 0.30485116070214063 | Gradient: [[ 0.02961447]\n",
      " [-0.05627257]\n",
      " [ 0.09635379]]\n",
      "Iteration 7464 | Cost: 0.3048378334974575 | Gradient: [[ 0.02961357]\n",
      " [-0.0562687 ]\n",
      " [ 0.09634664]]\n",
      "Iteration 7465 | Cost: 0.3048245081583102 | Gradient: [[ 0.02961268]\n",
      " [-0.05626484]\n",
      " [ 0.09633949]]\n",
      "Iteration 7466 | Cost: 0.3048111846843223 | Gradient: [[ 0.02961178]\n",
      " [-0.05626098]\n",
      " [ 0.09633234]]\n",
      "Iteration 7467 | Cost: 0.30479786307511747 | Gradient: [[ 0.02961089]\n",
      " [-0.05625712]\n",
      " [ 0.09632519]]\n",
      "Iteration 7468 | Cost: 0.30478454333031957 | Gradient: [[ 0.02961   ]\n",
      " [-0.05625326]\n",
      " [ 0.09631804]]\n",
      "Iteration 7469 | Cost: 0.3047712254495526 | Gradient: [[ 0.0296091]\n",
      " [-0.0562494]\n",
      " [ 0.0963109]]\n",
      "Iteration 7470 | Cost: 0.3047579094324404 | Gradient: [[ 0.02960821]\n",
      " [-0.05624554]\n",
      " [ 0.09630375]]\n",
      "Iteration 7471 | Cost: 0.30474459527860714 | Gradient: [[ 0.02960731]\n",
      " [-0.05624169]\n",
      " [ 0.09629661]]\n",
      "Iteration 7472 | Cost: 0.30473128298767704 | Gradient: [[ 0.02960642]\n",
      " [-0.05623783]\n",
      " [ 0.09628946]]\n",
      "Iteration 7473 | Cost: 0.30471797255927435 | Gradient: [[ 0.02960552]\n",
      " [-0.05623398]\n",
      " [ 0.09628232]]\n",
      "Iteration 7474 | Cost: 0.3047046639930236 | Gradient: [[ 0.02960462]\n",
      " [-0.05623012]\n",
      " [ 0.09627518]]\n",
      "Iteration 7475 | Cost: 0.30469135728854907 | Gradient: [[ 0.02960373]\n",
      " [-0.05622627]\n",
      " [ 0.09626803]]\n",
      "Iteration 7476 | Cost: 0.3046780524454756 | Gradient: [[ 0.02960283]\n",
      " [-0.05622242]\n",
      " [ 0.09626089]]\n",
      "Iteration 7477 | Cost: 0.3046647494634277 | Gradient: [[ 0.02960194]\n",
      " [-0.05621856]\n",
      " [ 0.09625375]]\n",
      "Iteration 7478 | Cost: 0.3046514483420303 | Gradient: [[ 0.02960104]\n",
      " [-0.05621471]\n",
      " [ 0.09624661]]\n",
      "Iteration 7479 | Cost: 0.3046381490809082 | Gradient: [[ 0.02960014]\n",
      " [-0.05621086]\n",
      " [ 0.09623947]]\n",
      "Iteration 7480 | Cost: 0.30462485167968645 | Gradient: [[ 0.02959925]\n",
      " [-0.05620702]\n",
      " [ 0.09623234]]\n",
      "Iteration 7481 | Cost: 0.3046115561379902 | Gradient: [[ 0.02959835]\n",
      " [-0.05620317]\n",
      " [ 0.0962252 ]]\n",
      "Iteration 7482 | Cost: 0.30459826245544447 | Gradient: [[ 0.02959745]\n",
      " [-0.05619932]\n",
      " [ 0.09621806]]\n",
      "Iteration 7483 | Cost: 0.3045849706316747 | Gradient: [[ 0.02959655]\n",
      " [-0.05619548]\n",
      " [ 0.09621093]]\n",
      "Iteration 7484 | Cost: 0.3045716806663062 | Gradient: [[ 0.02959565]\n",
      " [-0.05619163]\n",
      " [ 0.09620379]]\n",
      "Iteration 7485 | Cost: 0.30455839255896455 | Gradient: [[ 0.02959476]\n",
      " [-0.05618779]\n",
      " [ 0.09619666]]\n",
      "Iteration 7486 | Cost: 0.30454510630927534 | Gradient: [[ 0.02959386]\n",
      " [-0.05618394]\n",
      " [ 0.09618953]]\n",
      "Iteration 7487 | Cost: 0.3045318219168641 | Gradient: [[ 0.02959296]\n",
      " [-0.0561801 ]\n",
      " [ 0.09618239]]\n",
      "Iteration 7488 | Cost: 0.30451853938135687 | Gradient: [[ 0.02959206]\n",
      " [-0.05617626]\n",
      " [ 0.09617526]]\n",
      "Iteration 7489 | Cost: 0.30450525870237927 | Gradient: [[ 0.02959116]\n",
      " [-0.05617242]\n",
      " [ 0.09616813]]\n",
      "Iteration 7490 | Cost: 0.3044919798795575 | Gradient: [[ 0.02959026]\n",
      " [-0.05616858]\n",
      " [ 0.096161  ]]\n",
      "Iteration 7491 | Cost: 0.3044787029125175 | Gradient: [[ 0.02958936]\n",
      " [-0.05616474]\n",
      " [ 0.09615387]]\n",
      "Iteration 7492 | Cost: 0.3044654278008855 | Gradient: [[ 0.02958846]\n",
      " [-0.0561609 ]\n",
      " [ 0.09614674]]\n",
      "Iteration 7493 | Cost: 0.3044521545442878 | Gradient: [[ 0.02958756]\n",
      " [-0.05615707]\n",
      " [ 0.09613962]]\n",
      "Iteration 7494 | Cost: 0.3044388831423508 | Gradient: [[ 0.02958666]\n",
      " [-0.05615323]\n",
      " [ 0.09613249]]\n",
      "Iteration 7495 | Cost: 0.3044256135947009 | Gradient: [[ 0.02958576]\n",
      " [-0.0561494 ]\n",
      " [ 0.09612536]]\n",
      "Iteration 7496 | Cost: 0.3044123459009647 | Gradient: [[ 0.02958486]\n",
      " [-0.05614556]\n",
      " [ 0.09611824]]\n",
      "Iteration 7497 | Cost: 0.30439908006076905 | Gradient: [[ 0.02958396]\n",
      " [-0.05614173]\n",
      " [ 0.09611111]]\n",
      "Iteration 7498 | Cost: 0.30438581607374043 | Gradient: [[ 0.02958305]\n",
      " [-0.0561379 ]\n",
      " [ 0.09610399]]\n",
      "Iteration 7499 | Cost: 0.3043725539395059 | Gradient: [[ 0.02958215]\n",
      " [-0.05613406]\n",
      " [ 0.09609687]]\n",
      "Iteration 7500 | Cost: 0.3043592936576923 | Gradient: [[ 0.02958125]\n",
      " [-0.05613023]\n",
      " [ 0.09608975]]\n",
      "Iteration 7501 | Cost: 0.3043460352279269 | Gradient: [[ 0.02958035]\n",
      " [-0.0561264 ]\n",
      " [ 0.09608262]]\n",
      "Iteration 7502 | Cost: 0.3043327786498367 | Gradient: [[ 0.02957945]\n",
      " [-0.05612258]\n",
      " [ 0.0960755 ]]\n",
      "Iteration 7503 | Cost: 0.304319523923049 | Gradient: [[ 0.02957854]\n",
      " [-0.05611875]\n",
      " [ 0.09606838]]\n",
      "Iteration 7504 | Cost: 0.30430627104719116 | Gradient: [[ 0.02957764]\n",
      " [-0.05611492]\n",
      " [ 0.09606127]]\n",
      "Iteration 7505 | Cost: 0.3042930200218907 | Gradient: [[ 0.02957674]\n",
      " [-0.05611109]\n",
      " [ 0.09605415]]\n",
      "Iteration 7506 | Cost: 0.30427977084677515 | Gradient: [[ 0.02957583]\n",
      " [-0.05610727]\n",
      " [ 0.09604703]]\n",
      "Iteration 7507 | Cost: 0.3042665235214721 | Gradient: [[ 0.02957493]\n",
      " [-0.05610345]\n",
      " [ 0.09603991]]\n",
      "Iteration 7508 | Cost: 0.30425327804560937 | Gradient: [[ 0.02957403]\n",
      " [-0.05609962]\n",
      " [ 0.0960328 ]]\n",
      "Iteration 7509 | Cost: 0.30424003441881486 | Gradient: [[ 0.02957312]\n",
      " [-0.0560958 ]\n",
      " [ 0.09602568]]\n",
      "Iteration 7510 | Cost: 0.3042267926407164 | Gradient: [[ 0.02957222]\n",
      " [-0.05609198]\n",
      " [ 0.09601857]]\n",
      "Iteration 7511 | Cost: 0.3042135527109422 | Gradient: [[ 0.02957131]\n",
      " [-0.05608816]\n",
      " [ 0.09601146]]\n",
      "Iteration 7512 | Cost: 0.30420031462912017 | Gradient: [[ 0.02957041]\n",
      " [-0.05608434]\n",
      " [ 0.09600434]]\n",
      "Iteration 7513 | Cost: 0.30418707839487874 | Gradient: [[ 0.02956951]\n",
      " [-0.05608052]\n",
      " [ 0.09599723]]\n",
      "Iteration 7514 | Cost: 0.3041738440078463 | Gradient: [[ 0.0295686 ]\n",
      " [-0.0560767 ]\n",
      " [ 0.09599012]]\n",
      "Iteration 7515 | Cost: 0.30416061146765117 | Gradient: [[ 0.02956769]\n",
      " [-0.05607288]\n",
      " [ 0.09598301]]\n",
      "Iteration 7516 | Cost: 0.3041473807739219 | Gradient: [[ 0.02956679]\n",
      " [-0.05606907]\n",
      " [ 0.0959759 ]]\n",
      "Iteration 7517 | Cost: 0.3041341519262872 | Gradient: [[ 0.02956588]\n",
      " [-0.05606525]\n",
      " [ 0.09596879]]\n",
      "Iteration 7518 | Cost: 0.30412092492437576 | Gradient: [[ 0.02956498]\n",
      " [-0.05606144]\n",
      " [ 0.09596169]]\n",
      "Iteration 7519 | Cost: 0.3041076997678164 | Gradient: [[ 0.02956407]\n",
      " [-0.05605762]\n",
      " [ 0.09595458]]\n",
      "Iteration 7520 | Cost: 0.304094476456238 | Gradient: [[ 0.02956316]\n",
      " [-0.05605381]\n",
      " [ 0.09594747]]\n",
      "Iteration 7521 | Cost: 0.3040812549892697 | Gradient: [[ 0.02956226]\n",
      " [-0.05605   ]\n",
      " [ 0.09594037]]\n",
      "Iteration 7522 | Cost: 0.30406803536654053 | Gradient: [[ 0.02956135]\n",
      " [-0.05604619]\n",
      " [ 0.09593326]]\n",
      "Iteration 7523 | Cost: 0.3040548175876797 | Gradient: [[ 0.02956044]\n",
      " [-0.05604238]\n",
      " [ 0.09592616]]\n",
      "Iteration 7524 | Cost: 0.3040416016523168 | Gradient: [[ 0.02955954]\n",
      " [-0.05603857]\n",
      " [ 0.09591906]]\n",
      "Iteration 7525 | Cost: 0.3040283875600809 | Gradient: [[ 0.02955863]\n",
      " [-0.05603476]\n",
      " [ 0.09591196]]\n",
      "Iteration 7526 | Cost: 0.3040151753106016 | Gradient: [[ 0.02955772]\n",
      " [-0.05603095]\n",
      " [ 0.09590485]]\n",
      "Iteration 7527 | Cost: 0.30400196490350867 | Gradient: [[ 0.02955681]\n",
      " [-0.05602715]\n",
      " [ 0.09589775]]\n",
      "Iteration 7528 | Cost: 0.30398875633843164 | Gradient: [[ 0.0295559 ]\n",
      " [-0.05602334]\n",
      " [ 0.09589065]]\n",
      "Iteration 7529 | Cost: 0.30397554961500045 | Gradient: [[ 0.02955499]\n",
      " [-0.05601954]\n",
      " [ 0.09588356]]\n",
      "Iteration 7530 | Cost: 0.3039623447328449 | Gradient: [[ 0.02955409]\n",
      " [-0.05601573]\n",
      " [ 0.09587646]]\n",
      "Iteration 7531 | Cost: 0.30394914169159504 | Gradient: [[ 0.02955318]\n",
      " [-0.05601193]\n",
      " [ 0.09586936]]\n",
      "Iteration 7532 | Cost: 0.30393594049088096 | Gradient: [[ 0.02955227]\n",
      " [-0.05600813]\n",
      " [ 0.09586226]]\n",
      "Iteration 7533 | Cost: 0.3039227411303329 | Gradient: [[ 0.02955136]\n",
      " [-0.05600433]\n",
      " [ 0.09585517]]\n",
      "Iteration 7534 | Cost: 0.30390954360958106 | Gradient: [[ 0.02955045]\n",
      " [-0.05600053]\n",
      " [ 0.09584807]]\n",
      "Iteration 7535 | Cost: 0.3038963479282559 | Gradient: [[ 0.02954954]\n",
      " [-0.05599673]\n",
      " [ 0.09584098]]\n",
      "Iteration 7536 | Cost: 0.303883154085988 | Gradient: [[ 0.02954863]\n",
      " [-0.05599293]\n",
      " [ 0.09583389]]\n",
      "Iteration 7537 | Cost: 0.3038699620824077 | Gradient: [[ 0.02954772]\n",
      " [-0.05598913]\n",
      " [ 0.09582679]]\n",
      "Iteration 7538 | Cost: 0.30385677191714594 | Gradient: [[ 0.02954681]\n",
      " [-0.05598533]\n",
      " [ 0.0958197 ]]\n",
      "Iteration 7539 | Cost: 0.3038435835898333 | Gradient: [[ 0.0295459 ]\n",
      " [-0.05598154]\n",
      " [ 0.09581261]]\n",
      "Iteration 7540 | Cost: 0.3038303971001008 | Gradient: [[ 0.02954498]\n",
      " [-0.05597774]\n",
      " [ 0.09580552]]\n",
      "Iteration 7541 | Cost: 0.3038172124475793 | Gradient: [[ 0.02954407]\n",
      " [-0.05597395]\n",
      " [ 0.09579843]]\n",
      "Iteration 7542 | Cost: 0.3038040296319 | Gradient: [[ 0.02954316]\n",
      " [-0.05597015]\n",
      " [ 0.09579134]]\n",
      "Iteration 7543 | Cost: 0.3037908486526939 | Gradient: [[ 0.02954225]\n",
      " [-0.05596636]\n",
      " [ 0.09578426]]\n",
      "Iteration 7544 | Cost: 0.3037776695095924 | Gradient: [[ 0.02954134]\n",
      " [-0.05596257]\n",
      " [ 0.09577717]]\n",
      "Iteration 7545 | Cost: 0.3037644922022268 | Gradient: [[ 0.02954043]\n",
      " [-0.05595878]\n",
      " [ 0.09577008]]\n",
      "Iteration 7546 | Cost: 0.30375131673022854 | Gradient: [[ 0.02953951]\n",
      " [-0.05595499]\n",
      " [ 0.095763  ]]\n",
      "Iteration 7547 | Cost: 0.3037381430932293 | Gradient: [[ 0.0295386 ]\n",
      " [-0.0559512 ]\n",
      " [ 0.09575591]]\n",
      "Iteration 7548 | Cost: 0.30372497129086046 | Gradient: [[ 0.02953769]\n",
      " [-0.05594741]\n",
      " [ 0.09574883]]\n",
      "Iteration 7549 | Cost: 0.3037118013227541 | Gradient: [[ 0.02953677]\n",
      " [-0.05594363]\n",
      " [ 0.09574175]]\n",
      "Iteration 7550 | Cost: 0.30369863318854184 | Gradient: [[ 0.02953586]\n",
      " [-0.05593984]\n",
      " [ 0.09573467]]\n",
      "Iteration 7551 | Cost: 0.30368546688785575 | Gradient: [[ 0.02953495]\n",
      " [-0.05593605]\n",
      " [ 0.09572758]]\n",
      "Iteration 7552 | Cost: 0.30367230242032783 | Gradient: [[ 0.02953403]\n",
      " [-0.05593227]\n",
      " [ 0.0957205 ]]\n",
      "Iteration 7553 | Cost: 0.30365913978559006 | Gradient: [[ 0.02953312]\n",
      " [-0.05592849]\n",
      " [ 0.09571342]]\n",
      "Iteration 7554 | Cost: 0.30364597898327483 | Gradient: [[ 0.02953221]\n",
      " [-0.0559247 ]\n",
      " [ 0.09570635]]\n",
      "Iteration 7555 | Cost: 0.30363282001301445 | Gradient: [[ 0.02953129]\n",
      " [-0.05592092]\n",
      " [ 0.09569927]]\n",
      "Iteration 7556 | Cost: 0.30361966287444137 | Gradient: [[ 0.02953038]\n",
      " [-0.05591714]\n",
      " [ 0.09569219]]\n",
      "Iteration 7557 | Cost: 0.30360650756718804 | Gradient: [[ 0.02952946]\n",
      " [-0.05591336]\n",
      " [ 0.09568511]]\n",
      "Iteration 7558 | Cost: 0.3035933540908871 | Gradient: [[ 0.02952855]\n",
      " [-0.05590958]\n",
      " [ 0.09567804]]\n",
      "Iteration 7559 | Cost: 0.30358020244517125 | Gradient: [[ 0.02952763]\n",
      " [-0.0559058 ]\n",
      " [ 0.09567096]]\n",
      "Iteration 7560 | Cost: 0.3035670526296734 | Gradient: [[ 0.02952671]\n",
      " [-0.05590203]\n",
      " [ 0.09566389]]\n",
      "Iteration 7561 | Cost: 0.30355390464402626 | Gradient: [[ 0.0295258 ]\n",
      " [-0.05589825]\n",
      " [ 0.09565682]]\n",
      "Iteration 7562 | Cost: 0.30354075848786294 | Gradient: [[ 0.02952488]\n",
      " [-0.05589447]\n",
      " [ 0.09564974]]\n",
      "Iteration 7563 | Cost: 0.3035276141608166 | Gradient: [[ 0.02952397]\n",
      " [-0.0558907 ]\n",
      " [ 0.09564267]]\n",
      "Iteration 7564 | Cost: 0.3035144716625203 | Gradient: [[ 0.02952305]\n",
      " [-0.05588692]\n",
      " [ 0.0956356 ]]\n",
      "Iteration 7565 | Cost: 0.30350133099260745 | Gradient: [[ 0.02952213]\n",
      " [-0.05588315]\n",
      " [ 0.09562853]]\n",
      "Iteration 7566 | Cost: 0.30348819215071143 | Gradient: [[ 0.02952122]\n",
      " [-0.05587938]\n",
      " [ 0.09562146]]\n",
      "Iteration 7567 | Cost: 0.30347505513646567 | Gradient: [[ 0.0295203 ]\n",
      " [-0.05587561]\n",
      " [ 0.09561439]]\n",
      "Iteration 7568 | Cost: 0.30346191994950367 | Gradient: [[ 0.02951938]\n",
      " [-0.05587184]\n",
      " [ 0.09560733]]\n",
      "Iteration 7569 | Cost: 0.3034487865894592 | Gradient: [[ 0.02951846]\n",
      " [-0.05586807]\n",
      " [ 0.09560026]]\n",
      "Iteration 7570 | Cost: 0.30343565505596604 | Gradient: [[ 0.02951755]\n",
      " [-0.0558643 ]\n",
      " [ 0.09559319]]\n",
      "Iteration 7571 | Cost: 0.30342252534865805 | Gradient: [[ 0.02951663]\n",
      " [-0.05586053]\n",
      " [ 0.09558613]]\n",
      "Iteration 7572 | Cost: 0.3034093974671691 | Gradient: [[ 0.02951571]\n",
      " [-0.05585676]\n",
      " [ 0.09557906]]\n",
      "Iteration 7573 | Cost: 0.3033962714111334 | Gradient: [[ 0.02951479]\n",
      " [-0.055853  ]\n",
      " [ 0.095572  ]]\n",
      "Iteration 7574 | Cost: 0.303383147180185 | Gradient: [[ 0.02951387]\n",
      " [-0.05584923]\n",
      " [ 0.09556494]]\n",
      "Iteration 7575 | Cost: 0.3033700247739581 | Gradient: [[ 0.02951295]\n",
      " [-0.05584547]\n",
      " [ 0.09555787]]\n",
      "Iteration 7576 | Cost: 0.3033569041920872 | Gradient: [[ 0.02951203]\n",
      " [-0.0558417 ]\n",
      " [ 0.09555081]]\n",
      "Iteration 7577 | Cost: 0.30334378543420665 | Gradient: [[ 0.02951112]\n",
      " [-0.05583794]\n",
      " [ 0.09554375]]\n",
      "Iteration 7578 | Cost: 0.303330668499951 | Gradient: [[ 0.0295102 ]\n",
      " [-0.05583418]\n",
      " [ 0.09553669]]\n",
      "Iteration 7579 | Cost: 0.30331755338895483 | Gradient: [[ 0.02950928]\n",
      " [-0.05583042]\n",
      " [ 0.09552963]]\n",
      "Iteration 7580 | Cost: 0.30330444010085295 | Gradient: [[ 0.02950836]\n",
      " [-0.05582666]\n",
      " [ 0.09552258]]\n",
      "Iteration 7581 | Cost: 0.3032913286352801 | Gradient: [[ 0.02950744]\n",
      " [-0.0558229 ]\n",
      " [ 0.09551552]]\n",
      "Iteration 7582 | Cost: 0.3032782189918712 | Gradient: [[ 0.02950652]\n",
      " [-0.05581914]\n",
      " [ 0.09550846]]\n",
      "Iteration 7583 | Cost: 0.3032651111702614 | Gradient: [[ 0.02950559]\n",
      " [-0.05581538]\n",
      " [ 0.09550141]]\n",
      "Iteration 7584 | Cost: 0.3032520051700856 | Gradient: [[ 0.02950467]\n",
      " [-0.05581162]\n",
      " [ 0.09549435]]\n",
      "Iteration 7585 | Cost: 0.3032389009909792 | Gradient: [[ 0.02950375]\n",
      " [-0.05580787]\n",
      " [ 0.0954873 ]]\n",
      "Iteration 7586 | Cost: 0.3032257986325774 | Gradient: [[ 0.02950283]\n",
      " [-0.05580411]\n",
      " [ 0.09548024]]\n",
      "Iteration 7587 | Cost: 0.3032126980945156 | Gradient: [[ 0.02950191]\n",
      " [-0.05580036]\n",
      " [ 0.09547319]]\n",
      "Iteration 7588 | Cost: 0.3031995993764293 | Gradient: [[ 0.02950099]\n",
      " [-0.05579661]\n",
      " [ 0.09546614]]\n",
      "Iteration 7589 | Cost: 0.30318650247795415 | Gradient: [[ 0.02950007]\n",
      " [-0.05579285]\n",
      " [ 0.09545909]]\n",
      "Iteration 7590 | Cost: 0.30317340739872567 | Gradient: [[ 0.02949914]\n",
      " [-0.0557891 ]\n",
      " [ 0.09545204]]\n",
      "Iteration 7591 | Cost: 0.30316031413837974 | Gradient: [[ 0.02949822]\n",
      " [-0.05578535]\n",
      " [ 0.09544499]]\n",
      "Iteration 7592 | Cost: 0.3031472226965523 | Gradient: [[ 0.0294973 ]\n",
      " [-0.0557816 ]\n",
      " [ 0.09543794]]\n",
      "Iteration 7593 | Cost: 0.30313413307287923 | Gradient: [[ 0.02949638]\n",
      " [-0.05577785]\n",
      " [ 0.09543089]]\n",
      "Iteration 7594 | Cost: 0.30312104526699657 | Gradient: [[ 0.02949545]\n",
      " [-0.0557741 ]\n",
      " [ 0.09542385]]\n",
      "Iteration 7595 | Cost: 0.3031079592785405 | Gradient: [[ 0.02949453]\n",
      " [-0.05577036]\n",
      " [ 0.0954168 ]]\n",
      "Iteration 7596 | Cost: 0.30309487510714733 | Gradient: [[ 0.02949361]\n",
      " [-0.05576661]\n",
      " [ 0.09540975]]\n",
      "Iteration 7597 | Cost: 0.3030817927524534 | Gradient: [[ 0.02949268]\n",
      " [-0.05576286]\n",
      " [ 0.09540271]]\n",
      "Iteration 7598 | Cost: 0.30306871221409504 | Gradient: [[ 0.02949176]\n",
      " [-0.05575912]\n",
      " [ 0.09539567]]\n",
      "Iteration 7599 | Cost: 0.30305563349170894 | Gradient: [[ 0.02949083]\n",
      " [-0.05575538]\n",
      " [ 0.09538862]]\n",
      "Iteration 7600 | Cost: 0.3030425565849315 | Gradient: [[ 0.02948991]\n",
      " [-0.05575163]\n",
      " [ 0.09538158]]\n",
      "Iteration 7601 | Cost: 0.3030294814933997 | Gradient: [[ 0.02948899]\n",
      " [-0.05574789]\n",
      " [ 0.09537454]]\n",
      "Iteration 7602 | Cost: 0.30301640821675035 | Gradient: [[ 0.02948806]\n",
      " [-0.05574415]\n",
      " [ 0.0953675 ]]\n",
      "Iteration 7603 | Cost: 0.30300333675462016 | Gradient: [[ 0.02948714]\n",
      " [-0.05574041]\n",
      " [ 0.09536046]]\n",
      "Iteration 7604 | Cost: 0.3029902671066462 | Gradient: [[ 0.02948621]\n",
      " [-0.05573667]\n",
      " [ 0.09535342]]\n",
      "Iteration 7605 | Cost: 0.30297719927246586 | Gradient: [[ 0.02948529]\n",
      " [-0.05573293]\n",
      " [ 0.09534638]]\n",
      "Iteration 7606 | Cost: 0.3029641332517159 | Gradient: [[ 0.02948436]\n",
      " [-0.05572919]\n",
      " [ 0.09533934]]\n",
      "Iteration 7607 | Cost: 0.30295106904403396 | Gradient: [[ 0.02948343]\n",
      " [-0.05572545]\n",
      " [ 0.09533231]]\n",
      "Iteration 7608 | Cost: 0.3029380066490573 | Gradient: [[ 0.02948251]\n",
      " [-0.05572172]\n",
      " [ 0.09532527]]\n",
      "Iteration 7609 | Cost: 0.30292494606642334 | Gradient: [[ 0.02948158]\n",
      " [-0.05571798]\n",
      " [ 0.09531824]]\n",
      "Iteration 7610 | Cost: 0.30291188729576973 | Gradient: [[ 0.02948065]\n",
      " [-0.05571425]\n",
      " [ 0.0953112 ]]\n",
      "Iteration 7611 | Cost: 0.3028988303367342 | Gradient: [[ 0.02947973]\n",
      " [-0.05571051]\n",
      " [ 0.09530417]]\n",
      "Iteration 7612 | Cost: 0.30288577518895443 | Gradient: [[ 0.0294788 ]\n",
      " [-0.05570678]\n",
      " [ 0.09529714]]\n",
      "Iteration 7613 | Cost: 0.30287272185206837 | Gradient: [[ 0.02947787]\n",
      " [-0.05570305]\n",
      " [ 0.0952901 ]]\n",
      "Iteration 7614 | Cost: 0.30285967032571387 | Gradient: [[ 0.02947695]\n",
      " [-0.05569932]\n",
      " [ 0.09528307]]\n",
      "Iteration 7615 | Cost: 0.302846620609529 | Gradient: [[ 0.02947602]\n",
      " [-0.05569559]\n",
      " [ 0.09527604]]\n",
      "Iteration 7616 | Cost: 0.302833572703152 | Gradient: [[ 0.02947509]\n",
      " [-0.05569186]\n",
      " [ 0.09526901]]\n",
      "Iteration 7617 | Cost: 0.302820526606221 | Gradient: [[ 0.02947416]\n",
      " [-0.05568813]\n",
      " [ 0.09526199]]\n",
      "Iteration 7618 | Cost: 0.30280748231837445 | Gradient: [[ 0.02947324]\n",
      " [-0.0556844 ]\n",
      " [ 0.09525496]]\n",
      "Iteration 7619 | Cost: 0.30279443983925064 | Gradient: [[ 0.02947231]\n",
      " [-0.05568068]\n",
      " [ 0.09524793]]\n",
      "Iteration 7620 | Cost: 0.3027813991684882 | Gradient: [[ 0.02947138]\n",
      " [-0.05567695]\n",
      " [ 0.0952409 ]]\n",
      "Iteration 7621 | Cost: 0.30276836030572574 | Gradient: [[ 0.02947045]\n",
      " [-0.05567322]\n",
      " [ 0.09523388]]\n",
      "Iteration 7622 | Cost: 0.3027553232506019 | Gradient: [[ 0.02946952]\n",
      " [-0.0556695 ]\n",
      " [ 0.09522685]]\n",
      "Iteration 7623 | Cost: 0.30274228800275566 | Gradient: [[ 0.02946859]\n",
      " [-0.05566578]\n",
      " [ 0.09521983]]\n",
      "Iteration 7624 | Cost: 0.30272925456182564 | Gradient: [[ 0.02946766]\n",
      " [-0.05566205]\n",
      " [ 0.09521281]]\n",
      "Iteration 7625 | Cost: 0.3027162229274511 | Gradient: [[ 0.02946673]\n",
      " [-0.05565833]\n",
      " [ 0.09520578]]\n",
      "Iteration 7626 | Cost: 0.302703193099271 | Gradient: [[ 0.0294658 ]\n",
      " [-0.05565461]\n",
      " [ 0.09519876]]\n",
      "Iteration 7627 | Cost: 0.30269016507692453 | Gradient: [[ 0.02946487]\n",
      " [-0.05565089]\n",
      " [ 0.09519174]]\n",
      "Iteration 7628 | Cost: 0.30267713886005104 | Gradient: [[ 0.02946394]\n",
      " [-0.05564717]\n",
      " [ 0.09518472]]\n",
      "Iteration 7629 | Cost: 0.3026641144482898 | Gradient: [[ 0.02946301]\n",
      " [-0.05564345]\n",
      " [ 0.0951777 ]]\n",
      "Iteration 7630 | Cost: 0.30265109184128025 | Gradient: [[ 0.02946208]\n",
      " [-0.05563974]\n",
      " [ 0.09517069]]\n",
      "Iteration 7631 | Cost: 0.3026380710386621 | Gradient: [[ 0.02946115]\n",
      " [-0.05563602]\n",
      " [ 0.09516367]]\n",
      "Iteration 7632 | Cost: 0.3026250520400749 | Gradient: [[ 0.02946022]\n",
      " [-0.0556323 ]\n",
      " [ 0.09515665]]\n",
      "Iteration 7633 | Cost: 0.3026120348451584 | Gradient: [[ 0.02945929]\n",
      " [-0.05562859]\n",
      " [ 0.09514964]]\n",
      "Iteration 7634 | Cost: 0.30259901945355244 | Gradient: [[ 0.02945836]\n",
      " [-0.05562487]\n",
      " [ 0.09514262]]\n",
      "Iteration 7635 | Cost: 0.30258600586489703 | Gradient: [[ 0.02945742]\n",
      " [-0.05562116]\n",
      " [ 0.09513561]]\n",
      "Iteration 7636 | Cost: 0.3025729940788321 | Gradient: [[ 0.02945649]\n",
      " [-0.05561745]\n",
      " [ 0.09512859]]\n",
      "Iteration 7637 | Cost: 0.30255998409499774 | Gradient: [[ 0.02945556]\n",
      " [-0.05561374]\n",
      " [ 0.09512158]]\n",
      "Iteration 7638 | Cost: 0.3025469759130343 | Gradient: [[ 0.02945463]\n",
      " [-0.05561002]\n",
      " [ 0.09511457]]\n",
      "Iteration 7639 | Cost: 0.30253396953258205 | Gradient: [[ 0.02945369]\n",
      " [-0.05560631]\n",
      " [ 0.09510756]]\n",
      "Iteration 7640 | Cost: 0.30252096495328135 | Gradient: [[ 0.02945276]\n",
      " [-0.05560261]\n",
      " [ 0.09510055]]\n",
      "Iteration 7641 | Cost: 0.3025079621747727 | Gradient: [[ 0.02945183]\n",
      " [-0.0555989 ]\n",
      " [ 0.09509354]]\n",
      "Iteration 7642 | Cost: 0.30249496119669667 | Gradient: [[ 0.0294509 ]\n",
      " [-0.05559519]\n",
      " [ 0.09508653]]\n",
      "Iteration 7643 | Cost: 0.30248196201869404 | Gradient: [[ 0.02944996]\n",
      " [-0.05559148]\n",
      " [ 0.09507952]]\n",
      "Iteration 7644 | Cost: 0.3024689646404055 | Gradient: [[ 0.02944903]\n",
      " [-0.05558778]\n",
      " [ 0.09507251]]\n",
      "Iteration 7645 | Cost: 0.3024559690614719 | Gradient: [[ 0.02944809]\n",
      " [-0.05558407]\n",
      " [ 0.09506551]]\n",
      "Iteration 7646 | Cost: 0.30244297528153424 | Gradient: [[ 0.02944716]\n",
      " [-0.05558037]\n",
      " [ 0.0950585 ]]\n",
      "Iteration 7647 | Cost: 0.30242998330023363 | Gradient: [[ 0.02944623]\n",
      " [-0.05557666]\n",
      " [ 0.0950515 ]]\n",
      "Iteration 7648 | Cost: 0.3024169931172111 | Gradient: [[ 0.02944529]\n",
      " [-0.05557296]\n",
      " [ 0.09504449]]\n",
      "Iteration 7649 | Cost: 0.30240400473210804 | Gradient: [[ 0.02944436]\n",
      " [-0.05556926]\n",
      " [ 0.09503749]]\n",
      "Iteration 7650 | Cost: 0.3023910181445657 | Gradient: [[ 0.02944342]\n",
      " [-0.05556556]\n",
      " [ 0.09503049]]\n",
      "Iteration 7651 | Cost: 0.3023780333542255 | Gradient: [[ 0.02944249]\n",
      " [-0.05556186]\n",
      " [ 0.09502348]]\n",
      "Iteration 7652 | Cost: 0.302365050360729 | Gradient: [[ 0.02944155]\n",
      " [-0.05555816]\n",
      " [ 0.09501648]]\n",
      "Iteration 7653 | Cost: 0.30235206916371776 | Gradient: [[ 0.02944062]\n",
      " [-0.05555446]\n",
      " [ 0.09500948]]\n",
      "Iteration 7654 | Cost: 0.3023390897628336 | Gradient: [[ 0.02943968]\n",
      " [-0.05555076]\n",
      " [ 0.09500248]]\n",
      "Iteration 7655 | Cost: 0.30232611215771815 | Gradient: [[ 0.02943875]\n",
      " [-0.05554707]\n",
      " [ 0.09499549]]\n",
      "Iteration 7656 | Cost: 0.3023131363480135 | Gradient: [[ 0.02943781]\n",
      " [-0.05554337]\n",
      " [ 0.09498849]]\n",
      "Iteration 7657 | Cost: 0.3023001623333616 | Gradient: [[ 0.02943687]\n",
      " [-0.05553968]\n",
      " [ 0.09498149]]\n",
      "Iteration 7658 | Cost: 0.3022871901134043 | Gradient: [[ 0.02943594]\n",
      " [-0.05553598]\n",
      " [ 0.09497449]]\n",
      "Iteration 7659 | Cost: 0.3022742196877841 | Gradient: [[ 0.029435  ]\n",
      " [-0.05553229]\n",
      " [ 0.0949675 ]]\n",
      "Iteration 7660 | Cost: 0.3022612510561431 | Gradient: [[ 0.02943406]\n",
      " [-0.0555286 ]\n",
      " [ 0.0949605 ]]\n",
      "Iteration 7661 | Cost: 0.30224828421812366 | Gradient: [[ 0.02943313]\n",
      " [-0.0555249 ]\n",
      " [ 0.09495351]]\n",
      "Iteration 7662 | Cost: 0.30223531917336827 | Gradient: [[ 0.02943219]\n",
      " [-0.05552121]\n",
      " [ 0.09494652]]\n",
      "Iteration 7663 | Cost: 0.30222235592151947 | Gradient: [[ 0.02943125]\n",
      " [-0.05551752]\n",
      " [ 0.09493953]]\n",
      "Iteration 7664 | Cost: 0.30220939446221984 | Gradient: [[ 0.02943031]\n",
      " [-0.05551383]\n",
      " [ 0.09493253]]\n",
      "Iteration 7665 | Cost: 0.3021964347951122 | Gradient: [[ 0.02942938]\n",
      " [-0.05551014]\n",
      " [ 0.09492554]]\n",
      "Iteration 7666 | Cost: 0.30218347691983943 | Gradient: [[ 0.02942844]\n",
      " [-0.05550646]\n",
      " [ 0.09491855]]\n",
      "Iteration 7667 | Cost: 0.3021705208360443 | Gradient: [[ 0.0294275 ]\n",
      " [-0.05550277]\n",
      " [ 0.09491157]]\n",
      "Iteration 7668 | Cost: 0.30215756654336984 | Gradient: [[ 0.02942656]\n",
      " [-0.05549908]\n",
      " [ 0.09490458]]\n",
      "Iteration 7669 | Cost: 0.30214461404145926 | Gradient: [[ 0.02942562]\n",
      " [-0.0554954 ]\n",
      " [ 0.09489759]]\n",
      "Iteration 7670 | Cost: 0.3021316633299556 | Gradient: [[ 0.02942468]\n",
      " [-0.05549171]\n",
      " [ 0.0948906 ]]\n",
      "Iteration 7671 | Cost: 0.3021187144085023 | Gradient: [[ 0.02942374]\n",
      " [-0.05548803]\n",
      " [ 0.09488362]]\n",
      "Iteration 7672 | Cost: 0.30210576727674265 | Gradient: [[ 0.0294228 ]\n",
      " [-0.05548435]\n",
      " [ 0.09487663]]\n",
      "Iteration 7673 | Cost: 0.30209282193432024 | Gradient: [[ 0.02942186]\n",
      " [-0.05548067]\n",
      " [ 0.09486965]]\n",
      "Iteration 7674 | Cost: 0.30207987838087846 | Gradient: [[ 0.02942092]\n",
      " [-0.05547699]\n",
      " [ 0.09486266]]\n",
      "Iteration 7675 | Cost: 0.30206693661606104 | Gradient: [[ 0.02941998]\n",
      " [-0.05547331]\n",
      " [ 0.09485568]]\n",
      "Iteration 7676 | Cost: 0.3020539966395119 | Gradient: [[ 0.02941904]\n",
      " [-0.05546963]\n",
      " [ 0.0948487 ]]\n",
      "Iteration 7677 | Cost: 0.30204105845087464 | Gradient: [[ 0.0294181 ]\n",
      " [-0.05546595]\n",
      " [ 0.09484172]]\n",
      "Iteration 7678 | Cost: 0.3020281220497932 | Gradient: [[ 0.02941716]\n",
      " [-0.05546227]\n",
      " [ 0.09483474]]\n",
      "Iteration 7679 | Cost: 0.3020151874359118 | Gradient: [[ 0.02941622]\n",
      " [-0.05545859]\n",
      " [ 0.09482776]]\n",
      "Iteration 7680 | Cost: 0.3020022546088744 | Gradient: [[ 0.02941528]\n",
      " [-0.05545492]\n",
      " [ 0.09482078]]\n",
      "Iteration 7681 | Cost: 0.30198932356832536 | Gradient: [[ 0.02941434]\n",
      " [-0.05545124]\n",
      " [ 0.0948138 ]]\n",
      "Iteration 7682 | Cost: 0.3019763943139088 | Gradient: [[ 0.0294134 ]\n",
      " [-0.05544757]\n",
      " [ 0.09480683]]\n",
      "Iteration 7683 | Cost: 0.3019634668452693 | Gradient: [[ 0.02941246]\n",
      " [-0.05544389]\n",
      " [ 0.09479985]]\n",
      "Iteration 7684 | Cost: 0.3019505411620512 | Gradient: [[ 0.02941152]\n",
      " [-0.05544022]\n",
      " [ 0.09479287]]\n",
      "Iteration 7685 | Cost: 0.3019376172638991 | Gradient: [[ 0.02941057]\n",
      " [-0.05543655]\n",
      " [ 0.0947859 ]]\n",
      "Iteration 7686 | Cost: 0.3019246951504579 | Gradient: [[ 0.02940963]\n",
      " [-0.05543288]\n",
      " [ 0.09477893]]\n",
      "Iteration 7687 | Cost: 0.30191177482137205 | Gradient: [[ 0.02940869]\n",
      " [-0.05542921]\n",
      " [ 0.09477195]]\n",
      "Iteration 7688 | Cost: 0.30189885627628654 | Gradient: [[ 0.02940775]\n",
      " [-0.05542554]\n",
      " [ 0.09476498]]\n",
      "Iteration 7689 | Cost: 0.3018859395148464 | Gradient: [[ 0.0294068 ]\n",
      " [-0.05542187]\n",
      " [ 0.09475801]]\n",
      "Iteration 7690 | Cost: 0.30187302453669657 | Gradient: [[ 0.02940586]\n",
      " [-0.0554182 ]\n",
      " [ 0.09475104]]\n",
      "Iteration 7691 | Cost: 0.30186011134148216 | Gradient: [[ 0.02940492]\n",
      " [-0.05541453]\n",
      " [ 0.09474407]]\n",
      "Iteration 7692 | Cost: 0.30184719992884845 | Gradient: [[ 0.02940397]\n",
      " [-0.05541087]\n",
      " [ 0.0947371 ]]\n",
      "Iteration 7693 | Cost: 0.30183429029844083 | Gradient: [[ 0.02940303]\n",
      " [-0.0554072 ]\n",
      " [ 0.09473013]]\n",
      "Iteration 7694 | Cost: 0.30182138244990453 | Gradient: [[ 0.02940209]\n",
      " [-0.05540354]\n",
      " [ 0.09472316]]\n",
      "Iteration 7695 | Cost: 0.30180847638288527 | Gradient: [[ 0.02940114]\n",
      " [-0.05539987]\n",
      " [ 0.0947162 ]]\n",
      "Iteration 7696 | Cost: 0.3017955720970285 | Gradient: [[ 0.0294002 ]\n",
      " [-0.05539621]\n",
      " [ 0.09470923]]\n",
      "Iteration 7697 | Cost: 0.30178266959197986 | Gradient: [[ 0.02939926]\n",
      " [-0.05539255]\n",
      " [ 0.09470227]]\n",
      "Iteration 7698 | Cost: 0.30176976886738527 | Gradient: [[ 0.02939831]\n",
      " [-0.05538889]\n",
      " [ 0.0946953 ]]\n",
      "Iteration 7699 | Cost: 0.3017568699228905 | Gradient: [[ 0.02939737]\n",
      " [-0.05538523]\n",
      " [ 0.09468834]]\n",
      "Iteration 7700 | Cost: 0.3017439727581416 | Gradient: [[ 0.02939642]\n",
      " [-0.05538157]\n",
      " [ 0.09468137]]\n",
      "Iteration 7701 | Cost: 0.3017310773727845 | Gradient: [[ 0.02939548]\n",
      " [-0.05537791]\n",
      " [ 0.09467441]]\n",
      "Iteration 7702 | Cost: 0.3017181837664654 | Gradient: [[ 0.02939453]\n",
      " [-0.05537425]\n",
      " [ 0.09466745]]\n",
      "Iteration 7703 | Cost: 0.3017052919388306 | Gradient: [[ 0.02939358]\n",
      " [-0.05537059]\n",
      " [ 0.09466049]]\n",
      "Iteration 7704 | Cost: 0.3016924018895263 | Gradient: [[ 0.02939264]\n",
      " [-0.05536694]\n",
      " [ 0.09465353]]\n",
      "Iteration 7705 | Cost: 0.30167951361819906 | Gradient: [[ 0.02939169]\n",
      " [-0.05536328]\n",
      " [ 0.09464657]]\n",
      "Iteration 7706 | Cost: 0.3016666271244953 | Gradient: [[ 0.02939075]\n",
      " [-0.05535963]\n",
      " [ 0.09463961]]\n",
      "Iteration 7707 | Cost: 0.3016537424080617 | Gradient: [[ 0.0293898 ]\n",
      " [-0.05535597]\n",
      " [ 0.09463266]]\n",
      "Iteration 7708 | Cost: 0.3016408594685448 | Gradient: [[ 0.02938885]\n",
      " [-0.05535232]\n",
      " [ 0.0946257 ]]\n",
      "Iteration 7709 | Cost: 0.3016279783055915 | Gradient: [[ 0.02938791]\n",
      " [-0.05534867]\n",
      " [ 0.09461874]]\n",
      "Iteration 7710 | Cost: 0.3016150989188487 | Gradient: [[ 0.02938696]\n",
      " [-0.05534501]\n",
      " [ 0.09461179]]\n",
      "Iteration 7711 | Cost: 0.3016022213079633 | Gradient: [[ 0.02938601]\n",
      " [-0.05534136]\n",
      " [ 0.09460484]]\n",
      "Iteration 7712 | Cost: 0.30158934547258237 | Gradient: [[ 0.02938507]\n",
      " [-0.05533771]\n",
      " [ 0.09459788]]\n",
      "Iteration 7713 | Cost: 0.30157647141235305 | Gradient: [[ 0.02938412]\n",
      " [-0.05533406]\n",
      " [ 0.09459093]]\n",
      "Iteration 7714 | Cost: 0.30156359912692265 | Gradient: [[ 0.02938317]\n",
      " [-0.05533042]\n",
      " [ 0.09458398]]\n",
      "Iteration 7715 | Cost: 0.3015507286159384 | Gradient: [[ 0.02938222]\n",
      " [-0.05532677]\n",
      " [ 0.09457703]]\n",
      "Iteration 7716 | Cost: 0.3015378598790478 | Gradient: [[ 0.02938128]\n",
      " [-0.05532312]\n",
      " [ 0.09457008]]\n",
      "Iteration 7717 | Cost: 0.30152499291589835 | Gradient: [[ 0.02938033]\n",
      " [-0.05531948]\n",
      " [ 0.09456313]]\n",
      "Iteration 7718 | Cost: 0.30151212772613767 | Gradient: [[ 0.02937938]\n",
      " [-0.05531583]\n",
      " [ 0.09455618]]\n",
      "Iteration 7719 | Cost: 0.3014992643094134 | Gradient: [[ 0.02937843]\n",
      " [-0.05531219]\n",
      " [ 0.09454923]]\n",
      "Iteration 7720 | Cost: 0.30148640266537335 | Gradient: [[ 0.02937748]\n",
      " [-0.05530854]\n",
      " [ 0.09454228]]\n",
      "Iteration 7721 | Cost: 0.3014735427936654 | Gradient: [[ 0.02937653]\n",
      " [-0.0553049 ]\n",
      " [ 0.09453534]]\n",
      "Iteration 7722 | Cost: 0.3014606846939376 | Gradient: [[ 0.02937558]\n",
      " [-0.05530126]\n",
      " [ 0.09452839]]\n",
      "Iteration 7723 | Cost: 0.3014478283658379 | Gradient: [[ 0.02937463]\n",
      " [-0.05529762]\n",
      " [ 0.09452145]]\n",
      "Iteration 7724 | Cost: 0.3014349738090145 | Gradient: [[ 0.02937368]\n",
      " [-0.05529398]\n",
      " [ 0.0945145 ]]\n",
      "Iteration 7725 | Cost: 0.3014221210231156 | Gradient: [[ 0.02937273]\n",
      " [-0.05529034]\n",
      " [ 0.09450756]]\n",
      "Iteration 7726 | Cost: 0.3014092700077896 | Gradient: [[ 0.02937178]\n",
      " [-0.0552867 ]\n",
      " [ 0.09450062]]\n",
      "Iteration 7727 | Cost: 0.3013964207626849 | Gradient: [[ 0.02937083]\n",
      " [-0.05528306]\n",
      " [ 0.09449368]]\n",
      "Iteration 7728 | Cost: 0.30138357328744997 | Gradient: [[ 0.02936988]\n",
      " [-0.05527942]\n",
      " [ 0.09448674]]\n",
      "Iteration 7729 | Cost: 0.3013707275817335 | Gradient: [[ 0.02936893]\n",
      " [-0.05527579]\n",
      " [ 0.0944798 ]]\n",
      "Iteration 7730 | Cost: 0.3013578836451841 | Gradient: [[ 0.02936798]\n",
      " [-0.05527215]\n",
      " [ 0.09447286]]\n",
      "Iteration 7731 | Cost: 0.30134504147745067 | Gradient: [[ 0.02936703]\n",
      " [-0.05526852]\n",
      " [ 0.09446592]]\n",
      "Iteration 7732 | Cost: 0.30133220107818204 | Gradient: [[ 0.02936608]\n",
      " [-0.05526488]\n",
      " [ 0.09445898]]\n",
      "Iteration 7733 | Cost: 0.30131936244702706 | Gradient: [[ 0.02936513]\n",
      " [-0.05526125]\n",
      " [ 0.09445205]]\n",
      "Iteration 7734 | Cost: 0.30130652558363485 | Gradient: [[ 0.02936418]\n",
      " [-0.05525762]\n",
      " [ 0.09444511]]\n",
      "Iteration 7735 | Cost: 0.30129369048765475 | Gradient: [[ 0.02936323]\n",
      " [-0.05525399]\n",
      " [ 0.09443817]]\n",
      "Iteration 7736 | Cost: 0.30128085715873576 | Gradient: [[ 0.02936227]\n",
      " [-0.05525035]\n",
      " [ 0.09443124]]\n",
      "Iteration 7737 | Cost: 0.3012680255965273 | Gradient: [[ 0.02936132]\n",
      " [-0.05524672]\n",
      " [ 0.09442431]]\n",
      "Iteration 7738 | Cost: 0.3012551958006787 | Gradient: [[ 0.02936037]\n",
      " [-0.0552431 ]\n",
      " [ 0.09441737]]\n",
      "Iteration 7739 | Cost: 0.3012423677708398 | Gradient: [[ 0.02935942]\n",
      " [-0.05523947]\n",
      " [ 0.09441044]]\n",
      "Iteration 7740 | Cost: 0.30122954150665976 | Gradient: [[ 0.02935846]\n",
      " [-0.05523584]\n",
      " [ 0.09440351]]\n",
      "Iteration 7741 | Cost: 0.30121671700778857 | Gradient: [[ 0.02935751]\n",
      " [-0.05523221]\n",
      " [ 0.09439658]]\n",
      "Iteration 7742 | Cost: 0.3012038942738759 | Gradient: [[ 0.02935656]\n",
      " [-0.05522859]\n",
      " [ 0.09438965]]\n",
      "Iteration 7743 | Cost: 0.3011910733045717 | Gradient: [[ 0.02935561]\n",
      " [-0.05522496]\n",
      " [ 0.09438272]]\n",
      "Iteration 7744 | Cost: 0.3011782540995257 | Gradient: [[ 0.02935465]\n",
      " [-0.05522134]\n",
      " [ 0.09437579]]\n",
      "Iteration 7745 | Cost: 0.30116543665838835 | Gradient: [[ 0.0293537 ]\n",
      " [-0.05521771]\n",
      " [ 0.09436887]]\n",
      "Iteration 7746 | Cost: 0.30115262098080947 | Gradient: [[ 0.02935274]\n",
      " [-0.05521409]\n",
      " [ 0.09436194]]\n",
      "Iteration 7747 | Cost: 0.3011398070664394 | Gradient: [[ 0.02935179]\n",
      " [-0.05521047]\n",
      " [ 0.09435501]]\n",
      "Iteration 7748 | Cost: 0.30112699491492845 | Gradient: [[ 0.02935084]\n",
      " [-0.05520685]\n",
      " [ 0.09434809]]\n",
      "Iteration 7749 | Cost: 0.3011141845259271 | Gradient: [[ 0.02934988]\n",
      " [-0.05520323]\n",
      " [ 0.09434117]]\n",
      "Iteration 7750 | Cost: 0.3011013758990858 | Gradient: [[ 0.02934893]\n",
      " [-0.05519961]\n",
      " [ 0.09433424]]\n",
      "Iteration 7751 | Cost: 0.3010885690340551 | Gradient: [[ 0.02934797]\n",
      " [-0.05519599]\n",
      " [ 0.09432732]]\n",
      "Iteration 7752 | Cost: 0.30107576393048585 | Gradient: [[ 0.02934702]\n",
      " [-0.05519237]\n",
      " [ 0.0943204 ]]\n",
      "Iteration 7753 | Cost: 0.30106296058802867 | Gradient: [[ 0.02934606]\n",
      " [-0.05518875]\n",
      " [ 0.09431348]]\n",
      "Iteration 7754 | Cost: 0.3010501590063345 | Gradient: [[ 0.02934511]\n",
      " [-0.05518514]\n",
      " [ 0.09430656]]\n",
      "Iteration 7755 | Cost: 0.30103735918505414 | Gradient: [[ 0.02934415]\n",
      " [-0.05518152]\n",
      " [ 0.09429964]]\n",
      "Iteration 7756 | Cost: 0.30102456112383885 | Gradient: [[ 0.0293432 ]\n",
      " [-0.05517791]\n",
      " [ 0.09429272]]\n",
      "Iteration 7757 | Cost: 0.3010117648223397 | Gradient: [[ 0.02934224]\n",
      " [-0.05517429]\n",
      " [ 0.0942858 ]]\n",
      "Iteration 7758 | Cost: 0.3009989702802079 | Gradient: [[ 0.02934128]\n",
      " [-0.05517068]\n",
      " [ 0.09427888]]\n",
      "Iteration 7759 | Cost: 0.3009861774970947 | Gradient: [[ 0.02934033]\n",
      " [-0.05516707]\n",
      " [ 0.09427197]]\n",
      "Iteration 7760 | Cost: 0.3009733864726516 | Gradient: [[ 0.02933937]\n",
      " [-0.05516346]\n",
      " [ 0.09426505]]\n",
      "Iteration 7761 | Cost: 0.3009605972065301 | Gradient: [[ 0.02933841]\n",
      " [-0.05515985]\n",
      " [ 0.09425814]]\n",
      "Iteration 7762 | Cost: 0.3009478096983817 | Gradient: [[ 0.02933746]\n",
      " [-0.05515623]\n",
      " [ 0.09425122]]\n",
      "Iteration 7763 | Cost: 0.3009350239478581 | Gradient: [[ 0.0293365 ]\n",
      " [-0.05515263]\n",
      " [ 0.09424431]]\n",
      "Iteration 7764 | Cost: 0.30092223995461115 | Gradient: [[ 0.02933554]\n",
      " [-0.05514902]\n",
      " [ 0.0942374 ]]\n",
      "Iteration 7765 | Cost: 0.3009094577182926 | Gradient: [[ 0.02933459]\n",
      " [-0.05514541]\n",
      " [ 0.09423049]]\n",
      "Iteration 7766 | Cost: 0.3008966772385544 | Gradient: [[ 0.02933363]\n",
      " [-0.0551418 ]\n",
      " [ 0.09422358]]\n",
      "Iteration 7767 | Cost: 0.3008838985150486 | Gradient: [[ 0.02933267]\n",
      " [-0.0551382 ]\n",
      " [ 0.09421667]]\n",
      "Iteration 7768 | Cost: 0.3008711215474274 | Gradient: [[ 0.02933171]\n",
      " [-0.05513459]\n",
      " [ 0.09420976]]\n",
      "Iteration 7769 | Cost: 0.3008583463353429 | Gradient: [[ 0.02933076]\n",
      " [-0.05513099]\n",
      " [ 0.09420285]]\n",
      "Iteration 7770 | Cost: 0.3008455728784475 | Gradient: [[ 0.0293298 ]\n",
      " [-0.05512738]\n",
      " [ 0.09419594]]\n",
      "Iteration 7771 | Cost: 0.3008328011763935 | Gradient: [[ 0.02932884]\n",
      " [-0.05512378]\n",
      " [ 0.09418903]]\n",
      "Iteration 7772 | Cost: 0.3008200312288334 | Gradient: [[ 0.02932788]\n",
      " [-0.05512018]\n",
      " [ 0.09418213]]\n",
      "Iteration 7773 | Cost: 0.3008072630354198 | Gradient: [[ 0.02932692]\n",
      " [-0.05511658]\n",
      " [ 0.09417522]]\n",
      "Iteration 7774 | Cost: 0.3007944965958054 | Gradient: [[ 0.02932596]\n",
      " [-0.05511298]\n",
      " [ 0.09416832]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7775 | Cost: 0.30078173190964286 | Gradient: [[ 0.029325  ]\n",
      " [-0.05510938]\n",
      " [ 0.09416142]]\n",
      "Iteration 7776 | Cost: 0.3007689689765851 | Gradient: [[ 0.02932404]\n",
      " [-0.05510578]\n",
      " [ 0.09415451]]\n",
      "Iteration 7777 | Cost: 0.300756207796285 | Gradient: [[ 0.02932308]\n",
      " [-0.05510218]\n",
      " [ 0.09414761]]\n",
      "Iteration 7778 | Cost: 0.30074344836839556 | Gradient: [[ 0.02932212]\n",
      " [-0.05509858]\n",
      " [ 0.09414071]]\n",
      "Iteration 7779 | Cost: 0.30073069069256986 | Gradient: [[ 0.02932116]\n",
      " [-0.05509498]\n",
      " [ 0.09413381]]\n",
      "Iteration 7780 | Cost: 0.3007179347684612 | Gradient: [[ 0.0293202 ]\n",
      " [-0.05509139]\n",
      " [ 0.09412691]]\n",
      "Iteration 7781 | Cost: 0.3007051805957228 | Gradient: [[ 0.02931924]\n",
      " [-0.05508779]\n",
      " [ 0.09412001]]\n",
      "Iteration 7782 | Cost: 0.300692428174008 | Gradient: [[ 0.02931828]\n",
      " [-0.0550842 ]\n",
      " [ 0.09411311]]\n",
      "Iteration 7783 | Cost: 0.30067967750297037 | Gradient: [[ 0.02931732]\n",
      " [-0.05508061]\n",
      " [ 0.09410622]]\n",
      "Iteration 7784 | Cost: 0.3006669285822634 | Gradient: [[ 0.02931636]\n",
      " [-0.05507701]\n",
      " [ 0.09409932]]\n",
      "Iteration 7785 | Cost: 0.30065418141154066 | Gradient: [[ 0.0293154 ]\n",
      " [-0.05507342]\n",
      " [ 0.09409242]]\n",
      "Iteration 7786 | Cost: 0.300641435990456 | Gradient: [[ 0.02931444]\n",
      " [-0.05506983]\n",
      " [ 0.09408553]]\n",
      "Iteration 7787 | Cost: 0.3006286923186632 | Gradient: [[ 0.02931348]\n",
      " [-0.05506624]\n",
      " [ 0.09407863]]\n",
      "Iteration 7788 | Cost: 0.3006159503958161 | Gradient: [[ 0.02931252]\n",
      " [-0.05506265]\n",
      " [ 0.09407174]]\n",
      "Iteration 7789 | Cost: 0.30060321022156883 | Gradient: [[ 0.02931155]\n",
      " [-0.05505906]\n",
      " [ 0.09406485]]\n",
      "Iteration 7790 | Cost: 0.30059047179557535 | Gradient: [[ 0.02931059]\n",
      " [-0.05505547]\n",
      " [ 0.09405796]]\n",
      "Iteration 7791 | Cost: 0.30057773511748986 | Gradient: [[ 0.02930963]\n",
      " [-0.05505188]\n",
      " [ 0.09405107]]\n",
      "Iteration 7792 | Cost: 0.30056500018696664 | Gradient: [[ 0.02930867]\n",
      " [-0.0550483 ]\n",
      " [ 0.09404418]]\n",
      "Iteration 7793 | Cost: 0.30055226700366006 | Gradient: [[ 0.02930771]\n",
      " [-0.05504471]\n",
      " [ 0.09403729]]\n",
      "Iteration 7794 | Cost: 0.30053953556722457 | Gradient: [[ 0.02930674]\n",
      " [-0.05504113]\n",
      " [ 0.0940304 ]]\n",
      "Iteration 7795 | Cost: 0.3005268058773147 | Gradient: [[ 0.02930578]\n",
      " [-0.05503754]\n",
      " [ 0.09402351]]\n",
      "Iteration 7796 | Cost: 0.300514077933585 | Gradient: [[ 0.02930482]\n",
      " [-0.05503396]\n",
      " [ 0.09401662]]\n",
      "Iteration 7797 | Cost: 0.30050135173569026 | Gradient: [[ 0.02930385]\n",
      " [-0.05503038]\n",
      " [ 0.09400974]]\n",
      "Iteration 7798 | Cost: 0.30048862728328524 | Gradient: [[ 0.02930289]\n",
      " [-0.0550268 ]\n",
      " [ 0.09400285]]\n",
      "Iteration 7799 | Cost: 0.3004759045760248 | Gradient: [[ 0.02930193]\n",
      " [-0.05502321]\n",
      " [ 0.09399597]]\n",
      "Iteration 7800 | Cost: 0.30046318361356394 | Gradient: [[ 0.02930096]\n",
      " [-0.05501963]\n",
      " [ 0.09398908]]\n",
      "Iteration 7801 | Cost: 0.3004504643955577 | Gradient: [[ 0.0293    ]\n",
      " [-0.05501605]\n",
      " [ 0.0939822 ]]\n",
      "Iteration 7802 | Cost: 0.3004377469216613 | Gradient: [[ 0.02929903]\n",
      " [-0.05501248]\n",
      " [ 0.09397532]]\n",
      "Iteration 7803 | Cost: 0.30042503119152997 | Gradient: [[ 0.02929807]\n",
      " [-0.0550089 ]\n",
      " [ 0.09396844]]\n",
      "Iteration 7804 | Cost: 0.3004123172048189 | Gradient: [[ 0.02929711]\n",
      " [-0.05500532]\n",
      " [ 0.09396155]]\n",
      "Iteration 7805 | Cost: 0.3003996049611837 | Gradient: [[ 0.02929614]\n",
      " [-0.05500174]\n",
      " [ 0.09395467]]\n",
      "Iteration 7806 | Cost: 0.3003868944602797 | Gradient: [[ 0.02929518]\n",
      " [-0.05499817]\n",
      " [ 0.0939478 ]]\n",
      "Iteration 7807 | Cost: 0.3003741857017626 | Gradient: [[ 0.02929421]\n",
      " [-0.05499459]\n",
      " [ 0.09394092]]\n",
      "Iteration 7808 | Cost: 0.30036147868528806 | Gradient: [[ 0.02929325]\n",
      " [-0.05499102]\n",
      " [ 0.09393404]]\n",
      "Iteration 7809 | Cost: 0.30034877341051186 | Gradient: [[ 0.02929228]\n",
      " [-0.05498745]\n",
      " [ 0.09392716]]\n",
      "Iteration 7810 | Cost: 0.3003360698770899 | Gradient: [[ 0.02929132]\n",
      " [-0.05498387]\n",
      " [ 0.09392029]]\n",
      "Iteration 7811 | Cost: 0.30032336808467797 | Gradient: [[ 0.02929035]\n",
      " [-0.0549803 ]\n",
      " [ 0.09391341]]\n",
      "Iteration 7812 | Cost: 0.3003106680329322 | Gradient: [[ 0.02928938]\n",
      " [-0.05497673]\n",
      " [ 0.09390654]]\n",
      "Iteration 7813 | Cost: 0.3002979697215087 | Gradient: [[ 0.02928842]\n",
      " [-0.05497316]\n",
      " [ 0.09389966]]\n",
      "Iteration 7814 | Cost: 0.30028527315006376 | Gradient: [[ 0.02928745]\n",
      " [-0.05496959]\n",
      " [ 0.09389279]]\n",
      "Iteration 7815 | Cost: 0.30027257831825355 | Gradient: [[ 0.02928648]\n",
      " [-0.05496602]\n",
      " [ 0.09388592]]\n",
      "Iteration 7816 | Cost: 0.30025988522573455 | Gradient: [[ 0.02928552]\n",
      " [-0.05496245]\n",
      " [ 0.09387905]]\n",
      "Iteration 7817 | Cost: 0.30024719387216325 | Gradient: [[ 0.02928455]\n",
      " [-0.05495889]\n",
      " [ 0.09387218]]\n",
      "Iteration 7818 | Cost: 0.3002345042571961 | Gradient: [[ 0.02928358]\n",
      " [-0.05495532]\n",
      " [ 0.09386531]]\n",
      "Iteration 7819 | Cost: 0.30022181638048984 | Gradient: [[ 0.02928262]\n",
      " [-0.05495175]\n",
      " [ 0.09385844]]\n",
      "Iteration 7820 | Cost: 0.30020913024170126 | Gradient: [[ 0.02928165]\n",
      " [-0.05494819]\n",
      " [ 0.09385157]]\n",
      "Iteration 7821 | Cost: 0.30019644584048705 | Gradient: [[ 0.02928068]\n",
      " [-0.05494463]\n",
      " [ 0.0938447 ]]\n",
      "Iteration 7822 | Cost: 0.3001837631765042 | Gradient: [[ 0.02927971]\n",
      " [-0.05494106]\n",
      " [ 0.09383784]]\n",
      "Iteration 7823 | Cost: 0.30017108224940975 | Gradient: [[ 0.02927875]\n",
      " [-0.0549375 ]\n",
      " [ 0.09383097]]\n",
      "Iteration 7824 | Cost: 0.3001584030588607 | Gradient: [[ 0.02927778]\n",
      " [-0.05493394]\n",
      " [ 0.0938241 ]]\n",
      "Iteration 7825 | Cost: 0.30014572560451425 | Gradient: [[ 0.02927681]\n",
      " [-0.05493038]\n",
      " [ 0.09381724]]\n",
      "Iteration 7826 | Cost: 0.30013304988602785 | Gradient: [[ 0.02927584]\n",
      " [-0.05492682]\n",
      " [ 0.09381038]]\n",
      "Iteration 7827 | Cost: 0.30012037590305857 | Gradient: [[ 0.02927487]\n",
      " [-0.05492326]\n",
      " [ 0.09380351]]\n",
      "Iteration 7828 | Cost: 0.300107703655264 | Gradient: [[ 0.0292739 ]\n",
      " [-0.0549197 ]\n",
      " [ 0.09379665]]\n",
      "Iteration 7829 | Cost: 0.3000950331423016 | Gradient: [[ 0.02927294]\n",
      " [-0.05491614]\n",
      " [ 0.09378979]]\n",
      "Iteration 7830 | Cost: 0.3000823643638291 | Gradient: [[ 0.02927197]\n",
      " [-0.05491258]\n",
      " [ 0.09378293]]\n",
      "Iteration 7831 | Cost: 0.3000696973195042 | Gradient: [[ 0.029271  ]\n",
      " [-0.05490903]\n",
      " [ 0.09377607]]\n",
      "Iteration 7832 | Cost: 0.3000570320089846 | Gradient: [[ 0.02927003]\n",
      " [-0.05490547]\n",
      " [ 0.09376921]]\n",
      "Iteration 7833 | Cost: 0.3000443684319282 | Gradient: [[ 0.02926906]\n",
      " [-0.05490192]\n",
      " [ 0.09376235]]\n",
      "Iteration 7834 | Cost: 0.300031706587993 | Gradient: [[ 0.02926809]\n",
      " [-0.05489836]\n",
      " [ 0.0937555 ]]\n",
      "Iteration 7835 | Cost: 0.300019046476837 | Gradient: [[ 0.02926712]\n",
      " [-0.05489481]\n",
      " [ 0.09374864]]\n",
      "Iteration 7836 | Cost: 0.30000638809811847 | Gradient: [[ 0.02926615]\n",
      " [-0.05489125]\n",
      " [ 0.09374179]]\n",
      "Iteration 7837 | Cost: 0.29999373145149555 | Gradient: [[ 0.02926518]\n",
      " [-0.0548877 ]\n",
      " [ 0.09373493]]\n",
      "Iteration 7838 | Cost: 0.29998107653662653 | Gradient: [[ 0.02926421]\n",
      " [-0.05488415]\n",
      " [ 0.09372808]]\n",
      "Iteration 7839 | Cost: 0.2999684233531699 | Gradient: [[ 0.02926324]\n",
      " [-0.0548806 ]\n",
      " [ 0.09372122]]\n",
      "Iteration 7840 | Cost: 0.29995577190078404 | Gradient: [[ 0.02926227]\n",
      " [-0.05487705]\n",
      " [ 0.09371437]]\n",
      "Iteration 7841 | Cost: 0.2999431221791276 | Gradient: [[ 0.0292613 ]\n",
      " [-0.0548735 ]\n",
      " [ 0.09370752]]\n",
      "Iteration 7842 | Cost: 0.2999304741878594 | Gradient: [[ 0.02926032]\n",
      " [-0.05486995]\n",
      " [ 0.09370067]]\n",
      "Iteration 7843 | Cost: 0.2999178279266379 | Gradient: [[ 0.02925935]\n",
      " [-0.05486641]\n",
      " [ 0.09369382]]\n",
      "Iteration 7844 | Cost: 0.2999051833951221 | Gradient: [[ 0.02925838]\n",
      " [-0.05486286]\n",
      " [ 0.09368697]]\n",
      "Iteration 7845 | Cost: 0.299892540592971 | Gradient: [[ 0.02925741]\n",
      " [-0.05485932]\n",
      " [ 0.09368012]]\n",
      "Iteration 7846 | Cost: 0.29987989951984345 | Gradient: [[ 0.02925644]\n",
      " [-0.05485577]\n",
      " [ 0.09367327]]\n",
      "Iteration 7847 | Cost: 0.2998672601753987 | Gradient: [[ 0.02925547]\n",
      " [-0.05485223]\n",
      " [ 0.09366643]]\n",
      "Iteration 7848 | Cost: 0.2998546225592959 | Gradient: [[ 0.02925449]\n",
      " [-0.05484868]\n",
      " [ 0.09365958]]\n",
      "Iteration 7849 | Cost: 0.29984198667119427 | Gradient: [[ 0.02925352]\n",
      " [-0.05484514]\n",
      " [ 0.09365273]]\n",
      "Iteration 7850 | Cost: 0.2998293525107532 | Gradient: [[ 0.02925255]\n",
      " [-0.0548416 ]\n",
      " [ 0.09364589]]\n",
      "Iteration 7851 | Cost: 0.2998167200776322 | Gradient: [[ 0.02925158]\n",
      " [-0.05483806]\n",
      " [ 0.09363905]]\n",
      "Iteration 7852 | Cost: 0.29980408937149083 | Gradient: [[ 0.0292506 ]\n",
      " [-0.05483452]\n",
      " [ 0.0936322 ]]\n",
      "Iteration 7853 | Cost: 0.29979146039198856 | Gradient: [[ 0.02924963]\n",
      " [-0.05483098]\n",
      " [ 0.09362536]]\n",
      "Iteration 7854 | Cost: 0.29977883313878523 | Gradient: [[ 0.02924866]\n",
      " [-0.05482744]\n",
      " [ 0.09361852]]\n",
      "Iteration 7855 | Cost: 0.29976620761154066 | Gradient: [[ 0.02924768]\n",
      " [-0.0548239 ]\n",
      " [ 0.09361168]]\n",
      "Iteration 7856 | Cost: 0.2997535838099147 | Gradient: [[ 0.02924671]\n",
      " [-0.05482036]\n",
      " [ 0.09360484]]\n",
      "Iteration 7857 | Cost: 0.29974096173356723 | Gradient: [[ 0.02924574]\n",
      " [-0.05481682]\n",
      " [ 0.093598  ]]\n",
      "Iteration 7858 | Cost: 0.2997283413821585 | Gradient: [[ 0.02924476]\n",
      " [-0.05481329]\n",
      " [ 0.09359116]]\n",
      "Iteration 7859 | Cost: 0.2997157227553486 | Gradient: [[ 0.02924379]\n",
      " [-0.05480975]\n",
      " [ 0.09358432]]\n",
      "Iteration 7860 | Cost: 0.2997031058527975 | Gradient: [[ 0.02924281]\n",
      " [-0.05480622]\n",
      " [ 0.09357749]]\n",
      "Iteration 7861 | Cost: 0.299690490674166 | Gradient: [[ 0.02924184]\n",
      " [-0.05480269]\n",
      " [ 0.09357065]]\n",
      "Iteration 7862 | Cost: 0.29967787721911415 | Gradient: [[ 0.02924086]\n",
      " [-0.05479915]\n",
      " [ 0.09356381]]\n",
      "Iteration 7863 | Cost: 0.2996652654873027 | Gradient: [[ 0.02923989]\n",
      " [-0.05479562]\n",
      " [ 0.09355698]]\n",
      "Iteration 7864 | Cost: 0.2996526554783919 | Gradient: [[ 0.02923891]\n",
      " [-0.05479209]\n",
      " [ 0.09355015]]\n",
      "Iteration 7865 | Cost: 0.29964004719204274 | Gradient: [[ 0.02923794]\n",
      " [-0.05478856]\n",
      " [ 0.09354331]]\n",
      "Iteration 7866 | Cost: 0.2996274406279158 | Gradient: [[ 0.02923696]\n",
      " [-0.05478503]\n",
      " [ 0.09353648]]\n",
      "Iteration 7867 | Cost: 0.299614835785672 | Gradient: [[ 0.02923599]\n",
      " [-0.0547815 ]\n",
      " [ 0.09352965]]\n",
      "Iteration 7868 | Cost: 0.2996022326649722 | Gradient: [[ 0.02923501]\n",
      " [-0.05477797]\n",
      " [ 0.09352282]]\n",
      "Iteration 7869 | Cost: 0.2995896312654775 | Gradient: [[ 0.02923404]\n",
      " [-0.05477444]\n",
      " [ 0.09351599]]\n",
      "Iteration 7870 | Cost: 0.299577031586849 | Gradient: [[ 0.02923306]\n",
      " [-0.05477092]\n",
      " [ 0.09350916]]\n",
      "Iteration 7871 | Cost: 0.2995644336287478 | Gradient: [[ 0.02923209]\n",
      " [-0.05476739]\n",
      " [ 0.09350233]]\n",
      "Iteration 7872 | Cost: 0.2995518373908352 | Gradient: [[ 0.02923111]\n",
      " [-0.05476386]\n",
      " [ 0.09349551]]\n",
      "Iteration 7873 | Cost: 0.29953924287277267 | Gradient: [[ 0.02923013]\n",
      " [-0.05476034]\n",
      " [ 0.09348868]]\n",
      "Iteration 7874 | Cost: 0.2995266500742215 | Gradient: [[ 0.02922916]\n",
      " [-0.05475682]\n",
      " [ 0.09348185]]\n",
      "Iteration 7875 | Cost: 0.29951405899484335 | Gradient: [[ 0.02922818]\n",
      " [-0.05475329]\n",
      " [ 0.09347503]]\n",
      "Iteration 7876 | Cost: 0.29950146963429986 | Gradient: [[ 0.0292272 ]\n",
      " [-0.05474977]\n",
      " [ 0.0934682 ]]\n",
      "Iteration 7877 | Cost: 0.2994888819922526 | Gradient: [[ 0.02922622]\n",
      " [-0.05474625]\n",
      " [ 0.09346138]]\n",
      "Iteration 7878 | Cost: 0.29947629606836346 | Gradient: [[ 0.02922525]\n",
      " [-0.05474273]\n",
      " [ 0.09345456]]\n",
      "Iteration 7879 | Cost: 0.2994637118622943 | Gradient: [[ 0.02922427]\n",
      " [-0.05473921]\n",
      " [ 0.09344774]]\n",
      "Iteration 7880 | Cost: 0.2994511293737071 | Gradient: [[ 0.02922329]\n",
      " [-0.05473569]\n",
      " [ 0.09344091]]\n",
      "Iteration 7881 | Cost: 0.2994385486022638 | Gradient: [[ 0.02922231]\n",
      " [-0.05473217]\n",
      " [ 0.09343409]]\n",
      "Iteration 7882 | Cost: 0.2994259695476268 | Gradient: [[ 0.02922134]\n",
      " [-0.05472865]\n",
      " [ 0.09342727]]\n",
      "Iteration 7883 | Cost: 0.2994133922094581 | Gradient: [[ 0.02922036]\n",
      " [-0.05472513]\n",
      " [ 0.09342046]]\n",
      "Iteration 7884 | Cost: 0.29940081658742007 | Gradient: [[ 0.02921938]\n",
      " [-0.05472162]\n",
      " [ 0.09341364]]\n",
      "Iteration 7885 | Cost: 0.29938824268117514 | Gradient: [[ 0.0292184 ]\n",
      " [-0.0547181 ]\n",
      " [ 0.09340682]]\n",
      "Iteration 7886 | Cost: 0.29937567049038577 | Gradient: [[ 0.02921742]\n",
      " [-0.05471459]\n",
      " [ 0.0934    ]]\n",
      "Iteration 7887 | Cost: 0.2993631000147145 | Gradient: [[ 0.02921644]\n",
      " [-0.05471107]\n",
      " [ 0.09339319]]\n",
      "Iteration 7888 | Cost: 0.29935053125382405 | Gradient: [[ 0.02921546]\n",
      " [-0.05470756]\n",
      " [ 0.09338637]]\n",
      "Iteration 7889 | Cost: 0.2993379642073771 | Gradient: [[ 0.02921449]\n",
      " [-0.05470405]\n",
      " [ 0.09337956]]\n",
      "Iteration 7890 | Cost: 0.29932539887503656 | Gradient: [[ 0.02921351]\n",
      " [-0.05470053]\n",
      " [ 0.09337275]]\n",
      "Iteration 7891 | Cost: 0.2993128352564653 | Gradient: [[ 0.02921253]\n",
      " [-0.05469702]\n",
      " [ 0.09336593]]\n",
      "Iteration 7892 | Cost: 0.29930027335132625 | Gradient: [[ 0.02921155]\n",
      " [-0.05469351]\n",
      " [ 0.09335912]]\n",
      "Iteration 7893 | Cost: 0.2992877131592826 | Gradient: [[ 0.02921057]\n",
      " [-0.05469   ]\n",
      " [ 0.09335231]]\n",
      "Iteration 7894 | Cost: 0.29927515467999743 | Gradient: [[ 0.02920959]\n",
      " [-0.05468649]\n",
      " [ 0.0933455 ]]\n",
      "Iteration 7895 | Cost: 0.2992625979131342 | Gradient: [[ 0.02920861]\n",
      " [-0.05468298]\n",
      " [ 0.09333869]]\n",
      "Iteration 7896 | Cost: 0.29925004285835594 | Gradient: [[ 0.02920763]\n",
      " [-0.05467948]\n",
      " [ 0.09333188]]\n",
      "Iteration 7897 | Cost: 0.29923748951532625 | Gradient: [[ 0.02920665]\n",
      " [-0.05467597]\n",
      " [ 0.09332507]]\n",
      "Iteration 7898 | Cost: 0.29922493788370874 | Gradient: [[ 0.02920567]\n",
      " [-0.05467246]\n",
      " [ 0.09331827]]\n",
      "Iteration 7899 | Cost: 0.29921238796316685 | Gradient: [[ 0.02920468]\n",
      " [-0.05466896]\n",
      " [ 0.09331146]]\n",
      "Iteration 7900 | Cost: 0.29919983975336434 | Gradient: [[ 0.0292037 ]\n",
      " [-0.05466545]\n",
      " [ 0.09330466]]\n",
      "Iteration 7901 | Cost: 0.2991872932539649 | Gradient: [[ 0.02920272]\n",
      " [-0.05466195]\n",
      " [ 0.09329785]]\n",
      "Iteration 7902 | Cost: 0.29917474846463255 | Gradient: [[ 0.02920174]\n",
      " [-0.05465845]\n",
      " [ 0.09329105]]\n",
      "Iteration 7903 | Cost: 0.2991622053850311 | Gradient: [[ 0.02920076]\n",
      " [-0.05465494]\n",
      " [ 0.09328424]]\n",
      "Iteration 7904 | Cost: 0.29914966401482457 | Gradient: [[ 0.02919978]\n",
      " [-0.05465144]\n",
      " [ 0.09327744]]\n",
      "Iteration 7905 | Cost: 0.29913712435367723 | Gradient: [[ 0.0291988 ]\n",
      " [-0.05464794]\n",
      " [ 0.09327064]]\n",
      "Iteration 7906 | Cost: 0.29912458640125306 | Gradient: [[ 0.02919781]\n",
      " [-0.05464444]\n",
      " [ 0.09326384]]\n",
      "Iteration 7907 | Cost: 0.2991120501572166 | Gradient: [[ 0.02919683]\n",
      " [-0.05464094]\n",
      " [ 0.09325704]]\n",
      "Iteration 7908 | Cost: 0.29909951562123194 | Gradient: [[ 0.02919585]\n",
      " [-0.05463744]\n",
      " [ 0.09325024]]\n",
      "Iteration 7909 | Cost: 0.29908698279296375 | Gradient: [[ 0.02919487]\n",
      " [-0.05463395]\n",
      " [ 0.09324344]]\n",
      "Iteration 7910 | Cost: 0.29907445167207647 | Gradient: [[ 0.02919389]\n",
      " [-0.05463045]\n",
      " [ 0.09323664]]\n",
      "Iteration 7911 | Cost: 0.29906192225823475 | Gradient: [[ 0.0291929 ]\n",
      " [-0.05462695]\n",
      " [ 0.09322985]]\n",
      "Iteration 7912 | Cost: 0.2990493945511033 | Gradient: [[ 0.02919192]\n",
      " [-0.05462346]\n",
      " [ 0.09322305]]\n",
      "Iteration 7913 | Cost: 0.29903686855034695 | Gradient: [[ 0.02919094]\n",
      " [-0.05461996]\n",
      " [ 0.09321626]]\n",
      "Iteration 7914 | Cost: 0.2990243442556305 | Gradient: [[ 0.02918995]\n",
      " [-0.05461647]\n",
      " [ 0.09320946]]\n",
      "Iteration 7915 | Cost: 0.2990118216666191 | Gradient: [[ 0.02918897]\n",
      " [-0.05461297]\n",
      " [ 0.09320267]]\n",
      "Iteration 7916 | Cost: 0.2989993007829776 | Gradient: [[ 0.02918799]\n",
      " [-0.05460948]\n",
      " [ 0.09319587]]\n",
      "Iteration 7917 | Cost: 0.2989867816043712 | Gradient: [[ 0.029187  ]\n",
      " [-0.05460599]\n",
      " [ 0.09318908]]\n",
      "Iteration 7918 | Cost: 0.29897426413046513 | Gradient: [[ 0.02918602]\n",
      " [-0.0546025 ]\n",
      " [ 0.09318229]]\n",
      "Iteration 7919 | Cost: 0.29896174836092476 | Gradient: [[ 0.02918503]\n",
      " [-0.05459901]\n",
      " [ 0.0931755 ]]\n",
      "Iteration 7920 | Cost: 0.2989492342954154 | Gradient: [[ 0.02918405]\n",
      " [-0.05459552]\n",
      " [ 0.09316871]]\n",
      "Iteration 7921 | Cost: 0.2989367219336026 | Gradient: [[ 0.02918307]\n",
      " [-0.05459203]\n",
      " [ 0.09316192]]\n",
      "Iteration 7922 | Cost: 0.29892421127515195 | Gradient: [[ 0.02918208]\n",
      " [-0.05458854]\n",
      " [ 0.09315513]]\n",
      "Iteration 7923 | Cost: 0.2989117023197289 | Gradient: [[ 0.0291811 ]\n",
      " [-0.05458505]\n",
      " [ 0.09314834]]\n",
      "Iteration 7924 | Cost: 0.29889919506699947 | Gradient: [[ 0.02918011]\n",
      " [-0.05458156]\n",
      " [ 0.09314156]]\n",
      "Iteration 7925 | Cost: 0.2988866895166293 | Gradient: [[ 0.02917913]\n",
      " [-0.05457808]\n",
      " [ 0.09313477]]\n",
      "Iteration 7926 | Cost: 0.29887418566828433 | Gradient: [[ 0.02917814]\n",
      " [-0.05457459]\n",
      " [ 0.09312799]]\n",
      "Iteration 7927 | Cost: 0.2988616835216305 | Gradient: [[ 0.02917716]\n",
      " [-0.05457111]\n",
      " [ 0.0931212 ]]\n",
      "Iteration 7928 | Cost: 0.2988491830763339 | Gradient: [[ 0.02917617]\n",
      " [-0.05456762]\n",
      " [ 0.09311442]]\n",
      "Iteration 7929 | Cost: 0.29883668433206084 | Gradient: [[ 0.02917518]\n",
      " [-0.05456414]\n",
      " [ 0.09310764]]\n",
      "Iteration 7930 | Cost: 0.2988241872884773 | Gradient: [[ 0.0291742 ]\n",
      " [-0.05456066]\n",
      " [ 0.09310085]]\n",
      "Iteration 7931 | Cost: 0.29881169194524987 | Gradient: [[ 0.02917321]\n",
      " [-0.05455718]\n",
      " [ 0.09309407]]\n",
      "Iteration 7932 | Cost: 0.2987991983020449 | Gradient: [[ 0.02917223]\n",
      " [-0.0545537 ]\n",
      " [ 0.09308729]]\n",
      "Iteration 7933 | Cost: 0.2987867063585288 | Gradient: [[ 0.02917124]\n",
      " [-0.05455021]\n",
      " [ 0.09308051]]\n",
      "Iteration 7934 | Cost: 0.2987742161143681 | Gradient: [[ 0.02917025]\n",
      " [-0.05454673]\n",
      " [ 0.09307373]]\n",
      "Iteration 7935 | Cost: 0.29876172756922964 | Gradient: [[ 0.02916927]\n",
      " [-0.05454326]\n",
      " [ 0.09306696]]\n",
      "Iteration 7936 | Cost: 0.2987492407227801 | Gradient: [[ 0.02916828]\n",
      " [-0.05453978]\n",
      " [ 0.09306018]]\n",
      "Iteration 7937 | Cost: 0.2987367555746863 | Gradient: [[ 0.02916729]\n",
      " [-0.0545363 ]\n",
      " [ 0.0930534 ]]\n",
      "Iteration 7938 | Cost: 0.2987242721246152 | Gradient: [[ 0.02916631]\n",
      " [-0.05453282]\n",
      " [ 0.09304663]]\n",
      "Iteration 7939 | Cost: 0.2987117903722337 | Gradient: [[ 0.02916532]\n",
      " [-0.05452935]\n",
      " [ 0.09303985]]\n",
      "Iteration 7940 | Cost: 0.2986993103172091 | Gradient: [[ 0.02916433]\n",
      " [-0.05452587]\n",
      " [ 0.09303308]]\n",
      "Iteration 7941 | Cost: 0.29868683195920837 | Gradient: [[ 0.02916334]\n",
      " [-0.0545224 ]\n",
      " [ 0.0930263 ]]\n",
      "Iteration 7942 | Cost: 0.2986743552978988 | Gradient: [[ 0.02916236]\n",
      " [-0.05451892]\n",
      " [ 0.09301953]]\n",
      "Iteration 7943 | Cost: 0.2986618803329479 | Gradient: [[ 0.02916137]\n",
      " [-0.05451545]\n",
      " [ 0.09301276]]\n",
      "Iteration 7944 | Cost: 0.29864940706402293 | Gradient: [[ 0.02916038]\n",
      " [-0.05451198]\n",
      " [ 0.09300599]]\n",
      "Iteration 7945 | Cost: 0.2986369354907914 | Gradient: [[ 0.02915939]\n",
      " [-0.05450851]\n",
      " [ 0.09299922]]\n",
      "Iteration 7946 | Cost: 0.298624465612921 | Gradient: [[ 0.0291584 ]\n",
      " [-0.05450504]\n",
      " [ 0.09299245]]\n",
      "Iteration 7947 | Cost: 0.29861199743007943 | Gradient: [[ 0.02915742]\n",
      " [-0.05450157]\n",
      " [ 0.09298568]]\n",
      "Iteration 7948 | Cost: 0.2985995309419343 | Gradient: [[ 0.02915643]\n",
      " [-0.0544981 ]\n",
      " [ 0.09297891]]\n",
      "Iteration 7949 | Cost: 0.29858706614815367 | Gradient: [[ 0.02915544]\n",
      " [-0.05449463]\n",
      " [ 0.09297214]]\n",
      "Iteration 7950 | Cost: 0.2985746030484053 | Gradient: [[ 0.02915445]\n",
      " [-0.05449116]\n",
      " [ 0.09296538]]\n",
      "Iteration 7951 | Cost: 0.2985621416423573 | Gradient: [[ 0.02915346]\n",
      " [-0.05448769]\n",
      " [ 0.09295861]]\n",
      "Iteration 7952 | Cost: 0.29854968192967773 | Gradient: [[ 0.02915247]\n",
      " [-0.05448423]\n",
      " [ 0.09295185]]\n",
      "Iteration 7953 | Cost: 0.2985372239100348 | Gradient: [[ 0.02915148]\n",
      " [-0.05448076]\n",
      " [ 0.09294508]]\n",
      "Iteration 7954 | Cost: 0.2985247675830968 | Gradient: [[ 0.02915049]\n",
      " [-0.05447729]\n",
      " [ 0.09293832]]\n",
      "Iteration 7955 | Cost: 0.2985123129485321 | Gradient: [[ 0.0291495 ]\n",
      " [-0.05447383]\n",
      " [ 0.09293156]]\n",
      "Iteration 7956 | Cost: 0.2984998600060091 | Gradient: [[ 0.02914851]\n",
      " [-0.05447037]\n",
      " [ 0.09292479]]\n",
      "Iteration 7957 | Cost: 0.29848740875519636 | Gradient: [[ 0.02914752]\n",
      " [-0.0544669 ]\n",
      " [ 0.09291803]]\n",
      "Iteration 7958 | Cost: 0.2984749591957624 | Gradient: [[ 0.02914653]\n",
      " [-0.05446344]\n",
      " [ 0.09291127]]\n",
      "Iteration 7959 | Cost: 0.298462511327376 | Gradient: [[ 0.02914554]\n",
      " [-0.05445998]\n",
      " [ 0.09290451]]\n",
      "Iteration 7960 | Cost: 0.2984500651497059 | Gradient: [[ 0.02914455]\n",
      " [-0.05445652]\n",
      " [ 0.09289775]]\n",
      "Iteration 7961 | Cost: 0.298437620662421 | Gradient: [[ 0.02914356]\n",
      " [-0.05445306]\n",
      " [ 0.092891  ]]\n",
      "Iteration 7962 | Cost: 0.29842517786519024 | Gradient: [[ 0.02914257]\n",
      " [-0.0544496 ]\n",
      " [ 0.09288424]]\n",
      "Iteration 7963 | Cost: 0.29841273675768265 | Gradient: [[ 0.02914158]\n",
      " [-0.05444614]\n",
      " [ 0.09287748]]\n",
      "Iteration 7964 | Cost: 0.2984002973395672 | Gradient: [[ 0.02914059]\n",
      " [-0.05444268]\n",
      " [ 0.09287073]]\n",
      "Iteration 7965 | Cost: 0.2983878596105133 | Gradient: [[ 0.0291396 ]\n",
      " [-0.05443922]\n",
      " [ 0.09286397]]\n",
      "Iteration 7966 | Cost: 0.2983754235701901 | Gradient: [[ 0.0291386 ]\n",
      " [-0.05443577]\n",
      " [ 0.09285722]]\n",
      "Iteration 7967 | Cost: 0.298362989218267 | Gradient: [[ 0.02913761]\n",
      " [-0.05443231]\n",
      " [ 0.09285046]]\n",
      "Iteration 7968 | Cost: 0.29835055655441345 | Gradient: [[ 0.02913662]\n",
      " [-0.05442886]\n",
      " [ 0.09284371]]\n",
      "Iteration 7969 | Cost: 0.29833812557829903 | Gradient: [[ 0.02913563]\n",
      " [-0.0544254 ]\n",
      " [ 0.09283696]]\n",
      "Iteration 7970 | Cost: 0.2983256962895932 | Gradient: [[ 0.02913464]\n",
      " [-0.05442195]\n",
      " [ 0.09283021]]\n",
      "Iteration 7971 | Cost: 0.29831326868796587 | Gradient: [[ 0.02913364]\n",
      " [-0.0544185 ]\n",
      " [ 0.09282346]]\n",
      "Iteration 7972 | Cost: 0.2983008427730866 | Gradient: [[ 0.02913265]\n",
      " [-0.05441504]\n",
      " [ 0.09281671]]\n",
      "Iteration 7973 | Cost: 0.29828841854462546 | Gradient: [[ 0.02913166]\n",
      " [-0.05441159]\n",
      " [ 0.09280996]]\n",
      "Iteration 7974 | Cost: 0.29827599600225235 | Gradient: [[ 0.02913067]\n",
      " [-0.05440814]\n",
      " [ 0.09280321]]\n",
      "Iteration 7975 | Cost: 0.2982635751456372 | Gradient: [[ 0.02912967]\n",
      " [-0.05440469]\n",
      " [ 0.09279647]]\n",
      "Iteration 7976 | Cost: 0.2982511559744503 | Gradient: [[ 0.02912868]\n",
      " [-0.05440124]\n",
      " [ 0.09278972]]\n",
      "Iteration 7977 | Cost: 0.2982387384883617 | Gradient: [[ 0.02912769]\n",
      " [-0.05439779]\n",
      " [ 0.09278297]]\n",
      "Iteration 7978 | Cost: 0.2982263226870416 | Gradient: [[ 0.02912669]\n",
      " [-0.05439435]\n",
      " [ 0.09277623]]\n",
      "Iteration 7979 | Cost: 0.29821390857016056 | Gradient: [[ 0.0291257 ]\n",
      " [-0.0543909 ]\n",
      " [ 0.09276949]]\n",
      "Iteration 7980 | Cost: 0.2982014961373891 | Gradient: [[ 0.02912471]\n",
      " [-0.05438745]\n",
      " [ 0.09276274]]\n",
      "Iteration 7981 | Cost: 0.29818908538839745 | Gradient: [[ 0.02912371]\n",
      " [-0.05438401]\n",
      " [ 0.092756  ]]\n",
      "Iteration 7982 | Cost: 0.29817667632285644 | Gradient: [[ 0.02912272]\n",
      " [-0.05438056]\n",
      " [ 0.09274926]]\n",
      "Iteration 7983 | Cost: 0.29816426894043685 | Gradient: [[ 0.02912172]\n",
      " [-0.05437712]\n",
      " [ 0.09274252]]\n",
      "Iteration 7984 | Cost: 0.2981518632408092 | Gradient: [[ 0.02912073]\n",
      " [-0.05437367]\n",
      " [ 0.09273578]]\n",
      "Iteration 7985 | Cost: 0.29813945922364454 | Gradient: [[ 0.02911974]\n",
      " [-0.05437023]\n",
      " [ 0.09272904]]\n",
      "Iteration 7986 | Cost: 0.2981270568886139 | Gradient: [[ 0.02911874]\n",
      " [-0.05436679]\n",
      " [ 0.0927223 ]]\n",
      "Iteration 7987 | Cost: 0.2981146562353881 | Gradient: [[ 0.02911775]\n",
      " [-0.05436335]\n",
      " [ 0.09271556]]\n",
      "Iteration 7988 | Cost: 0.2981022572636383 | Gradient: [[ 0.02911675]\n",
      " [-0.05435991]\n",
      " [ 0.09270883]]\n",
      "Iteration 7989 | Cost: 0.2980898599730359 | Gradient: [[ 0.02911576]\n",
      " [-0.05435647]\n",
      " [ 0.09270209]]\n",
      "Iteration 7990 | Cost: 0.298077464363252 | Gradient: [[ 0.02911476]\n",
      " [-0.05435303]\n",
      " [ 0.09269535]]\n",
      "Iteration 7991 | Cost: 0.298065070433958 | Gradient: [[ 0.02911377]\n",
      " [-0.05434959]\n",
      " [ 0.09268862]]\n",
      "Iteration 7992 | Cost: 0.2980526781848254 | Gradient: [[ 0.02911277]\n",
      " [-0.05434615]\n",
      " [ 0.09268189]]\n",
      "Iteration 7993 | Cost: 0.29804028761552565 | Gradient: [[ 0.02911178]\n",
      " [-0.05434271]\n",
      " [ 0.09267515]]\n",
      "Iteration 7994 | Cost: 0.29802789872573043 | Gradient: [[ 0.02911078]\n",
      " [-0.05433928]\n",
      " [ 0.09266842]]\n",
      "Iteration 7995 | Cost: 0.29801551151511135 | Gradient: [[ 0.02910978]\n",
      " [-0.05433584]\n",
      " [ 0.09266169]]\n",
      "Iteration 7996 | Cost: 0.2980031259833404 | Gradient: [[ 0.02910879]\n",
      " [-0.0543324 ]\n",
      " [ 0.09265496]]\n",
      "Iteration 7997 | Cost: 0.2979907421300893 | Gradient: [[ 0.02910779]\n",
      " [-0.05432897]\n",
      " [ 0.09264823]]\n",
      "Iteration 7998 | Cost: 0.29797835995502986 | Gradient: [[ 0.0291068 ]\n",
      " [-0.05432554]\n",
      " [ 0.0926415 ]]\n",
      "Iteration 7999 | Cost: 0.2979659794578345 | Gradient: [[ 0.0291058 ]\n",
      " [-0.0543221 ]\n",
      " [ 0.09263477]]\n",
      "Iteration 8000 | Cost: 0.29795360063817494 | Gradient: [[ 0.0291048 ]\n",
      " [-0.05431867]\n",
      " [ 0.09262804]]\n",
      "Iteration 8001 | Cost: 0.29794122349572355 | Gradient: [[ 0.02910381]\n",
      " [-0.05431524]\n",
      " [ 0.09262132]]\n",
      "Iteration 8002 | Cost: 0.2979288480301526 | Gradient: [[ 0.02910281]\n",
      " [-0.05431181]\n",
      " [ 0.09261459]]\n",
      "Iteration 8003 | Cost: 0.29791647424113443 | Gradient: [[ 0.02910181]\n",
      " [-0.05430838]\n",
      " [ 0.09260786]]\n",
      "Iteration 8004 | Cost: 0.29790410212834156 | Gradient: [[ 0.02910081]\n",
      " [-0.05430495]\n",
      " [ 0.09260114]]\n",
      "Iteration 8005 | Cost: 0.29789173169144645 | Gradient: [[ 0.02909982]\n",
      " [-0.05430152]\n",
      " [ 0.09259442]]\n",
      "Iteration 8006 | Cost: 0.29787936293012174 | Gradient: [[ 0.02909882]\n",
      " [-0.05429809]\n",
      " [ 0.09258769]]\n",
      "Iteration 8007 | Cost: 0.29786699584404003 | Gradient: [[ 0.02909782]\n",
      " [-0.05429466]\n",
      " [ 0.09258097]]\n",
      "Iteration 8008 | Cost: 0.2978546304328743 | Gradient: [[ 0.02909682]\n",
      " [-0.05429124]\n",
      " [ 0.09257425]]\n",
      "Iteration 8009 | Cost: 0.2978422666962972 | Gradient: [[ 0.02909583]\n",
      " [-0.05428781]\n",
      " [ 0.09256753]]\n",
      "Iteration 8010 | Cost: 0.29782990463398173 | Gradient: [[ 0.02909483]\n",
      " [-0.05428439]\n",
      " [ 0.09256081]]\n",
      "Iteration 8011 | Cost: 0.2978175442456011 | Gradient: [[ 0.02909383]\n",
      " [-0.05428096]\n",
      " [ 0.09255409]]\n",
      "Iteration 8012 | Cost: 0.2978051855308282 | Gradient: [[ 0.02909283]\n",
      " [-0.05427754]\n",
      " [ 0.09254737]]\n",
      "Iteration 8013 | Cost: 0.2977928284893362 | Gradient: [[ 0.02909183]\n",
      " [-0.05427411]\n",
      " [ 0.09254065]]\n",
      "Iteration 8014 | Cost: 0.29778047312079853 | Gradient: [[ 0.02909083]\n",
      " [-0.05427069]\n",
      " [ 0.09253394]]\n",
      "Iteration 8015 | Cost: 0.29776811942488846 | Gradient: [[ 0.02908983]\n",
      " [-0.05426727]\n",
      " [ 0.09252722]]\n",
      "Iteration 8016 | Cost: 0.2977557674012794 | Gradient: [[ 0.02908884]\n",
      " [-0.05426385]\n",
      " [ 0.09252051]]\n",
      "Iteration 8017 | Cost: 0.29774341704964497 | Gradient: [[ 0.02908784]\n",
      " [-0.05426043]\n",
      " [ 0.09251379]]\n",
      "Iteration 8018 | Cost: 0.29773106836965874 | Gradient: [[ 0.02908684]\n",
      " [-0.05425701]\n",
      " [ 0.09250708]]\n",
      "Iteration 8019 | Cost: 0.2977187213609943 | Gradient: [[ 0.02908584]\n",
      " [-0.05425359]\n",
      " [ 0.09250036]]\n",
      "Iteration 8020 | Cost: 0.2977063760233255 | Gradient: [[ 0.02908484]\n",
      " [-0.05425017]\n",
      " [ 0.09249365]]\n",
      "Iteration 8021 | Cost: 0.2976940323563262 | Gradient: [[ 0.02908384]\n",
      " [-0.05424675]\n",
      " [ 0.09248694]]\n",
      "Iteration 8022 | Cost: 0.29768169035967024 | Gradient: [[ 0.02908284]\n",
      " [-0.05424334]\n",
      " [ 0.09248023]]\n",
      "Iteration 8023 | Cost: 0.2976693500330318 | Gradient: [[ 0.02908184]\n",
      " [-0.05423992]\n",
      " [ 0.09247352]]\n",
      "Iteration 8024 | Cost: 0.2976570113760848 | Gradient: [[ 0.02908084]\n",
      " [-0.05423651]\n",
      " [ 0.09246681]]\n",
      "Iteration 8025 | Cost: 0.2976446743885035 | Gradient: [[ 0.02907984]\n",
      " [-0.05423309]\n",
      " [ 0.0924601 ]]\n",
      "Iteration 8026 | Cost: 0.2976323390699622 | Gradient: [[ 0.02907884]\n",
      " [-0.05422968]\n",
      " [ 0.0924534 ]]\n",
      "Iteration 8027 | Cost: 0.2976200054201352 | Gradient: [[ 0.02907784]\n",
      " [-0.05422626]\n",
      " [ 0.09244669]]\n",
      "Iteration 8028 | Cost: 0.29760767343869693 | Gradient: [[ 0.02907684]\n",
      " [-0.05422285]\n",
      " [ 0.09243998]]\n",
      "Iteration 8029 | Cost: 0.2975953431253219 | Gradient: [[ 0.02907583]\n",
      " [-0.05421944]\n",
      " [ 0.09243328]]\n",
      "Iteration 8030 | Cost: 0.29758301447968466 | Gradient: [[ 0.02907483]\n",
      " [-0.05421603]\n",
      " [ 0.09242657]]\n",
      "Iteration 8031 | Cost: 0.29757068750145993 | Gradient: [[ 0.02907383]\n",
      " [-0.05421262]\n",
      " [ 0.09241987]]\n",
      "Iteration 8032 | Cost: 0.29755836219032245 | Gradient: [[ 0.02907283]\n",
      " [-0.05420921]\n",
      " [ 0.09241317]]\n",
      "Iteration 8033 | Cost: 0.2975460385459471 | Gradient: [[ 0.02907183]\n",
      " [-0.0542058 ]\n",
      " [ 0.09240646]]\n",
      "Iteration 8034 | Cost: 0.2975337165680087 | Gradient: [[ 0.02907083]\n",
      " [-0.05420239]\n",
      " [ 0.09239976]]\n",
      "Iteration 8035 | Cost: 0.2975213962561823 | Gradient: [[ 0.02906983]\n",
      " [-0.05419898]\n",
      " [ 0.09239306]]\n",
      "Iteration 8036 | Cost: 0.297509077610143 | Gradient: [[ 0.02906882]\n",
      " [-0.05419557]\n",
      " [ 0.09238636]]\n",
      "Iteration 8037 | Cost: 0.297496760629566 | Gradient: [[ 0.02906782]\n",
      " [-0.05419217]\n",
      " [ 0.09237966]]\n",
      "Iteration 8038 | Cost: 0.29748444531412643 | Gradient: [[ 0.02906682]\n",
      " [-0.05418876]\n",
      " [ 0.09237297]]\n",
      "Iteration 8039 | Cost: 0.2974721316634997 | Gradient: [[ 0.02906582]\n",
      " [-0.05418536]\n",
      " [ 0.09236627]]\n",
      "Iteration 8040 | Cost: 0.29745981967736124 | Gradient: [[ 0.02906481]\n",
      " [-0.05418195]\n",
      " [ 0.09235957]]\n",
      "Iteration 8041 | Cost: 0.2974475093553864 | Gradient: [[ 0.02906381]\n",
      " [-0.05417855]\n",
      " [ 0.09235288]]\n",
      "Iteration 8042 | Cost: 0.29743520069725093 | Gradient: [[ 0.02906281]\n",
      " [-0.05417515]\n",
      " [ 0.09234618]]\n",
      "Iteration 8043 | Cost: 0.2974228937026305 | Gradient: [[ 0.02906181]\n",
      " [-0.05417174]\n",
      " [ 0.09233949]]\n",
      "Iteration 8044 | Cost: 0.2974105883712006 | Gradient: [[ 0.0290608 ]\n",
      " [-0.05416834]\n",
      " [ 0.09233279]]\n",
      "Iteration 8045 | Cost: 0.2973982847026373 | Gradient: [[ 0.0290598 ]\n",
      " [-0.05416494]\n",
      " [ 0.0923261 ]]\n",
      "Iteration 8046 | Cost: 0.2973859826966163 | Gradient: [[ 0.0290588 ]\n",
      " [-0.05416154]\n",
      " [ 0.09231941]]\n",
      "Iteration 8047 | Cost: 0.2973736823528138 | Gradient: [[ 0.02905779]\n",
      " [-0.05415814]\n",
      " [ 0.09231272]]\n",
      "Iteration 8048 | Cost: 0.29736138367090575 | Gradient: [[ 0.02905679]\n",
      " [-0.05415474]\n",
      " [ 0.09230603]]\n",
      "Iteration 8049 | Cost: 0.2973490866505683 | Gradient: [[ 0.02905579]\n",
      " [-0.05415135]\n",
      " [ 0.09229934]]\n",
      "Iteration 8050 | Cost: 0.2973367912914776 | Gradient: [[ 0.02905478]\n",
      " [-0.05414795]\n",
      " [ 0.09229265]]\n",
      "Iteration 8051 | Cost: 0.2973244975933101 | Gradient: [[ 0.02905378]\n",
      " [-0.05414455]\n",
      " [ 0.09228596]]\n",
      "Iteration 8052 | Cost: 0.29731220555574206 | Gradient: [[ 0.02905277]\n",
      " [-0.05414116]\n",
      " [ 0.09227927]]\n",
      "Iteration 8053 | Cost: 0.29729991517845006 | Gradient: [[ 0.02905177]\n",
      " [-0.05413776]\n",
      " [ 0.09227259]]\n",
      "Iteration 8054 | Cost: 0.2972876264611106 | Gradient: [[ 0.02905076]\n",
      " [-0.05413437]\n",
      " [ 0.0922659 ]]\n",
      "Iteration 8055 | Cost: 0.29727533940340034 | Gradient: [[ 0.02904976]\n",
      " [-0.05413097]\n",
      " [ 0.09225921]]\n",
      "Iteration 8056 | Cost: 0.2972630540049959 | Gradient: [[ 0.02904875]\n",
      " [-0.05412758]\n",
      " [ 0.09225253]]\n",
      "Iteration 8057 | Cost: 0.2972507702655742 | Gradient: [[ 0.02904775]\n",
      " [-0.05412419]\n",
      " [ 0.09224585]]\n",
      "Iteration 8058 | Cost: 0.297238488184812 | Gradient: [[ 0.02904674]\n",
      " [-0.05412079]\n",
      " [ 0.09223916]]\n",
      "Iteration 8059 | Cost: 0.2972262077623864 | Gradient: [[ 0.02904574]\n",
      " [-0.0541174 ]\n",
      " [ 0.09223248]]\n",
      "Iteration 8060 | Cost: 0.2972139289979744 | Gradient: [[ 0.02904473]\n",
      " [-0.05411401]\n",
      " [ 0.0922258 ]]\n",
      "Iteration 8061 | Cost: 0.29720165189125297 | Gradient: [[ 0.02904373]\n",
      " [-0.05411062]\n",
      " [ 0.09221912]]\n",
      "Iteration 8062 | Cost: 0.2971893764418995 | Gradient: [[ 0.02904272]\n",
      " [-0.05410723]\n",
      " [ 0.09221244]]\n",
      "Iteration 8063 | Cost: 0.29717710264959124 | Gradient: [[ 0.02904172]\n",
      " [-0.05410384]\n",
      " [ 0.09220576]]\n",
      "Iteration 8064 | Cost: 0.2971648305140055 | Gradient: [[ 0.02904071]\n",
      " [-0.05410046]\n",
      " [ 0.09219908]]\n",
      "Iteration 8065 | Cost: 0.2971525600348197 | Gradient: [[ 0.0290397 ]\n",
      " [-0.05409707]\n",
      " [ 0.09219241]]\n",
      "Iteration 8066 | Cost: 0.2971402912117115 | Gradient: [[ 0.0290387 ]\n",
      " [-0.05409368]\n",
      " [ 0.09218573]]\n",
      "Iteration 8067 | Cost: 0.2971280240443583 | Gradient: [[ 0.02903769]\n",
      " [-0.0540903 ]\n",
      " [ 0.09217905]]\n",
      "Iteration 8068 | Cost: 0.29711575853243805 | Gradient: [[ 0.02903669]\n",
      " [-0.05408691]\n",
      " [ 0.09217238]]\n",
      "Iteration 8069 | Cost: 0.2971034946756283 | Gradient: [[ 0.02903568]\n",
      " [-0.05408353]\n",
      " [ 0.0921657 ]]\n",
      "Iteration 8070 | Cost: 0.2970912324736071 | Gradient: [[ 0.02903467]\n",
      " [-0.05408014]\n",
      " [ 0.09215903]]\n",
      "Iteration 8071 | Cost: 0.2970789719260522 | Gradient: [[ 0.02903367]\n",
      " [-0.05407676]\n",
      " [ 0.09215236]]\n",
      "Iteration 8072 | Cost: 0.29706671303264165 | Gradient: [[ 0.02903266]\n",
      " [-0.05407338]\n",
      " [ 0.09214569]]\n",
      "Iteration 8073 | Cost: 0.2970544557930537 | Gradient: [[ 0.02903165]\n",
      " [-0.05407   ]\n",
      " [ 0.09213902]]\n",
      "Iteration 8074 | Cost: 0.29704220020696626 | Gradient: [[ 0.02903064]\n",
      " [-0.05406662]\n",
      " [ 0.09213234]]\n",
      "Iteration 8075 | Cost: 0.2970299462740578 | Gradient: [[ 0.02902964]\n",
      " [-0.05406324]\n",
      " [ 0.09212567]]\n",
      "Iteration 8076 | Cost: 0.29701769399400657 | Gradient: [[ 0.02902863]\n",
      " [-0.05405986]\n",
      " [ 0.09211901]]\n",
      "Iteration 8077 | Cost: 0.2970054433664911 | Gradient: [[ 0.02902762]\n",
      " [-0.05405648]\n",
      " [ 0.09211234]]\n",
      "Iteration 8078 | Cost: 0.2969931943911897 | Gradient: [[ 0.02902661]\n",
      " [-0.0540531 ]\n",
      " [ 0.09210567]]\n",
      "Iteration 8079 | Cost: 0.2969809470677811 | Gradient: [[ 0.0290256 ]\n",
      " [-0.05404972]\n",
      " [ 0.092099  ]]\n",
      "Iteration 8080 | Cost: 0.296968701395944 | Gradient: [[ 0.0290246 ]\n",
      " [-0.05404634]\n",
      " [ 0.09209234]]\n",
      "Iteration 8081 | Cost: 0.296956457375357 | Gradient: [[ 0.02902359]\n",
      " [-0.05404297]\n",
      " [ 0.09208567]]\n",
      "Iteration 8082 | Cost: 0.2969442150056989 | Gradient: [[ 0.02902258]\n",
      " [-0.05403959]\n",
      " [ 0.09207901]]\n",
      "Iteration 8083 | Cost: 0.29693197428664875 | Gradient: [[ 0.02902157]\n",
      " [-0.05403622]\n",
      " [ 0.09207235]]\n",
      "Iteration 8084 | Cost: 0.2969197352178855 | Gradient: [[ 0.02902056]\n",
      " [-0.05403284]\n",
      " [ 0.09206568]]\n",
      "Iteration 8085 | Cost: 0.2969074977990881 | Gradient: [[ 0.02901955]\n",
      " [-0.05402947]\n",
      " [ 0.09205902]]\n",
      "Iteration 8086 | Cost: 0.2968952620299359 | Gradient: [[ 0.02901854]\n",
      " [-0.0540261 ]\n",
      " [ 0.09205236]]\n",
      "Iteration 8087 | Cost: 0.2968830279101079 | Gradient: [[ 0.02901754]\n",
      " [-0.05402273]\n",
      " [ 0.0920457 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8088 | Cost: 0.2968707954392835 | Gradient: [[ 0.02901653]\n",
      " [-0.05401935]\n",
      " [ 0.09203904]]\n",
      "Iteration 8089 | Cost: 0.29685856461714216 | Gradient: [[ 0.02901552]\n",
      " [-0.05401598]\n",
      " [ 0.09203238]]\n",
      "Iteration 8090 | Cost: 0.29684633544336336 | Gradient: [[ 0.02901451]\n",
      " [-0.05401261]\n",
      " [ 0.09202572]]\n",
      "Iteration 8091 | Cost: 0.2968341079176265 | Gradient: [[ 0.0290135 ]\n",
      " [-0.05400924]\n",
      " [ 0.09201907]]\n",
      "Iteration 8092 | Cost: 0.2968218820396113 | Gradient: [[ 0.02901249]\n",
      " [-0.05400588]\n",
      " [ 0.09201241]]\n",
      "Iteration 8093 | Cost: 0.2968096578089974 | Gradient: [[ 0.02901148]\n",
      " [-0.05400251]\n",
      " [ 0.09200575]]\n",
      "Iteration 8094 | Cost: 0.2967974352254647 | Gradient: [[ 0.02901047]\n",
      " [-0.05399914]\n",
      " [ 0.0919991 ]]\n",
      "Iteration 8095 | Cost: 0.296785214288693 | Gradient: [[ 0.02900946]\n",
      " [-0.05399577]\n",
      " [ 0.09199244]]\n",
      "Iteration 8096 | Cost: 0.29677299499836224 | Gradient: [[ 0.02900845]\n",
      " [-0.05399241]\n",
      " [ 0.09198579]]\n",
      "Iteration 8097 | Cost: 0.2967607773541525 | Gradient: [[ 0.02900744]\n",
      " [-0.05398904]\n",
      " [ 0.09197914]]\n",
      "Iteration 8098 | Cost: 0.2967485613557439 | Gradient: [[ 0.02900643]\n",
      " [-0.05398568]\n",
      " [ 0.09197249]]\n",
      "Iteration 8099 | Cost: 0.29673634700281654 | Gradient: [[ 0.02900541]\n",
      " [-0.05398231]\n",
      " [ 0.09196583]]\n",
      "Iteration 8100 | Cost: 0.2967241342950508 | Gradient: [[ 0.0290044 ]\n",
      " [-0.05397895]\n",
      " [ 0.09195918]]\n",
      "Iteration 8101 | Cost: 0.296711923232127 | Gradient: [[ 0.02900339]\n",
      " [-0.05397559]\n",
      " [ 0.09195253]]\n",
      "Iteration 8102 | Cost: 0.29669971381372556 | Gradient: [[ 0.02900238]\n",
      " [-0.05397223]\n",
      " [ 0.09194589]]\n",
      "Iteration 8103 | Cost: 0.2966875060395269 | Gradient: [[ 0.02900137]\n",
      " [-0.05396886]\n",
      " [ 0.09193924]]\n",
      "Iteration 8104 | Cost: 0.2966752999092117 | Gradient: [[ 0.02900036]\n",
      " [-0.0539655 ]\n",
      " [ 0.09193259]]\n",
      "Iteration 8105 | Cost: 0.2966630954224607 | Gradient: [[ 0.02899935]\n",
      " [-0.05396214]\n",
      " [ 0.09192594]]\n",
      "Iteration 8106 | Cost: 0.2966508925789546 | Gradient: [[ 0.02899834]\n",
      " [-0.05395878]\n",
      " [ 0.0919193 ]]\n",
      "Iteration 8107 | Cost: 0.2966386913783742 | Gradient: [[ 0.02899732]\n",
      " [-0.05395543]\n",
      " [ 0.09191265]]\n",
      "Iteration 8108 | Cost: 0.2966264918204004 | Gradient: [[ 0.02899631]\n",
      " [-0.05395207]\n",
      " [ 0.09190601]]\n",
      "Iteration 8109 | Cost: 0.2966142939047143 | Gradient: [[ 0.0289953 ]\n",
      " [-0.05394871]\n",
      " [ 0.09189937]]\n",
      "Iteration 8110 | Cost: 0.2966020976309968 | Gradient: [[ 0.02899429]\n",
      " [-0.05394535]\n",
      " [ 0.09189272]]\n",
      "Iteration 8111 | Cost: 0.2965899029989292 | Gradient: [[ 0.02899327]\n",
      " [-0.053942  ]\n",
      " [ 0.09188608]]\n",
      "Iteration 8112 | Cost: 0.29657771000819266 | Gradient: [[ 0.02899226]\n",
      " [-0.05393864]\n",
      " [ 0.09187944]]\n",
      "Iteration 8113 | Cost: 0.29656551865846853 | Gradient: [[ 0.02899125]\n",
      " [-0.05393529]\n",
      " [ 0.0918728 ]]\n",
      "Iteration 8114 | Cost: 0.2965533289494382 | Gradient: [[ 0.02899024]\n",
      " [-0.05393193]\n",
      " [ 0.09186616]]\n",
      "Iteration 8115 | Cost: 0.29654114088078315 | Gradient: [[ 0.02898922]\n",
      " [-0.05392858]\n",
      " [ 0.09185952]]\n",
      "Iteration 8116 | Cost: 0.29652895445218486 | Gradient: [[ 0.02898821]\n",
      " [-0.05392523]\n",
      " [ 0.09185288]]\n",
      "Iteration 8117 | Cost: 0.2965167696633251 | Gradient: [[ 0.0289872 ]\n",
      " [-0.05392188]\n",
      " [ 0.09184625]]\n",
      "Iteration 8118 | Cost: 0.29650458651388545 | Gradient: [[ 0.02898618]\n",
      " [-0.05391853]\n",
      " [ 0.09183961]]\n",
      "Iteration 8119 | Cost: 0.29649240500354773 | Gradient: [[ 0.02898517]\n",
      " [-0.05391518]\n",
      " [ 0.09183297]]\n",
      "Iteration 8120 | Cost: 0.29648022513199385 | Gradient: [[ 0.02898416]\n",
      " [-0.05391183]\n",
      " [ 0.09182634]]\n",
      "Iteration 8121 | Cost: 0.29646804689890577 | Gradient: [[ 0.02898314]\n",
      " [-0.05390848]\n",
      " [ 0.0918197 ]]\n",
      "Iteration 8122 | Cost: 0.2964558703039654 | Gradient: [[ 0.02898213]\n",
      " [-0.05390513]\n",
      " [ 0.09181307]]\n",
      "Iteration 8123 | Cost: 0.29644369534685505 | Gradient: [[ 0.02898112]\n",
      " [-0.05390178]\n",
      " [ 0.09180644]]\n",
      "Iteration 8124 | Cost: 0.2964315220272568 | Gradient: [[ 0.0289801 ]\n",
      " [-0.05389843]\n",
      " [ 0.09179981]]\n",
      "Iteration 8125 | Cost: 0.2964193503448529 | Gradient: [[ 0.02897909]\n",
      " [-0.05389509]\n",
      " [ 0.09179317]]\n",
      "Iteration 8126 | Cost: 0.2964071802993257 | Gradient: [[ 0.02897807]\n",
      " [-0.05389174]\n",
      " [ 0.09178654]]\n",
      "Iteration 8127 | Cost: 0.2963950118903577 | Gradient: [[ 0.02897706]\n",
      " [-0.05388839]\n",
      " [ 0.09177991]]\n",
      "Iteration 8128 | Cost: 0.29638284511763135 | Gradient: [[ 0.02897604]\n",
      " [-0.05388505]\n",
      " [ 0.09177329]]\n",
      "Iteration 8129 | Cost: 0.29637067998082933 | Gradient: [[ 0.02897503]\n",
      " [-0.05388171]\n",
      " [ 0.09176666]]\n",
      "Iteration 8130 | Cost: 0.29635851647963407 | Gradient: [[ 0.02897401]\n",
      " [-0.05387836]\n",
      " [ 0.09176003]]\n",
      "Iteration 8131 | Cost: 0.29634635461372866 | Gradient: [[ 0.028973  ]\n",
      " [-0.05387502]\n",
      " [ 0.0917534 ]]\n",
      "Iteration 8132 | Cost: 0.2963341943827956 | Gradient: [[ 0.02897198]\n",
      " [-0.05387168]\n",
      " [ 0.09174678]]\n",
      "Iteration 8133 | Cost: 0.29632203578651806 | Gradient: [[ 0.02897097]\n",
      " [-0.05386834]\n",
      " [ 0.09174015]]\n",
      "Iteration 8134 | Cost: 0.29630987882457877 | Gradient: [[ 0.02896995]\n",
      " [-0.053865  ]\n",
      " [ 0.09173353]]\n",
      "Iteration 8135 | Cost: 0.29629772349666106 | Gradient: [[ 0.02896894]\n",
      " [-0.05386166]\n",
      " [ 0.09172691]]\n",
      "Iteration 8136 | Cost: 0.29628556980244786 | Gradient: [[ 0.02896792]\n",
      " [-0.05385832]\n",
      " [ 0.09172028]]\n",
      "Iteration 8137 | Cost: 0.2962734177416225 | Gradient: [[ 0.02896691]\n",
      " [-0.05385498]\n",
      " [ 0.09171366]]\n",
      "Iteration 8138 | Cost: 0.2962612673138683 | Gradient: [[ 0.02896589]\n",
      " [-0.05385164]\n",
      " [ 0.09170704]]\n",
      "Iteration 8139 | Cost: 0.2962491185188686 | Gradient: [[ 0.02896487]\n",
      " [-0.0538483 ]\n",
      " [ 0.09170042]]\n",
      "Iteration 8140 | Cost: 0.2962369713563069 | Gradient: [[ 0.02896386]\n",
      " [-0.05384497]\n",
      " [ 0.0916938 ]]\n",
      "Iteration 8141 | Cost: 0.29622482582586657 | Gradient: [[ 0.02896284]\n",
      " [-0.05384163]\n",
      " [ 0.09168718]]\n",
      "Iteration 8142 | Cost: 0.2962126819272315 | Gradient: [[ 0.02896182]\n",
      " [-0.0538383 ]\n",
      " [ 0.09168056]]\n",
      "Iteration 8143 | Cost: 0.29620053966008514 | Gradient: [[ 0.02896081]\n",
      " [-0.05383496]\n",
      " [ 0.09167394]]\n",
      "Iteration 8144 | Cost: 0.29618839902411154 | Gradient: [[ 0.02895979]\n",
      " [-0.05383163]\n",
      " [ 0.09166733]]\n",
      "Iteration 8145 | Cost: 0.2961762600189943 | Gradient: [[ 0.02895877]\n",
      " [-0.0538283 ]\n",
      " [ 0.09166071]]\n",
      "Iteration 8146 | Cost: 0.2961641226444175 | Gradient: [[ 0.02895776]\n",
      " [-0.05382496]\n",
      " [ 0.0916541 ]]\n",
      "Iteration 8147 | Cost: 0.29615198690006506 | Gradient: [[ 0.02895674]\n",
      " [-0.05382163]\n",
      " [ 0.09164748]]\n",
      "Iteration 8148 | Cost: 0.2961398527856212 | Gradient: [[ 0.02895572]\n",
      " [-0.0538183 ]\n",
      " [ 0.09164087]]\n",
      "Iteration 8149 | Cost: 0.29612772030076995 | Gradient: [[ 0.02895471]\n",
      " [-0.05381497]\n",
      " [ 0.09163426]]\n",
      "Iteration 8150 | Cost: 0.29611558944519567 | Gradient: [[ 0.02895369]\n",
      " [-0.05381164]\n",
      " [ 0.09162764]]\n",
      "Iteration 8151 | Cost: 0.2961034602185827 | Gradient: [[ 0.02895267]\n",
      " [-0.05380831]\n",
      " [ 0.09162103]]\n",
      "Iteration 8152 | Cost: 0.2960913326206153 | Gradient: [[ 0.02895165]\n",
      " [-0.05380498]\n",
      " [ 0.09161442]]\n",
      "Iteration 8153 | Cost: 0.29607920665097814 | Gradient: [[ 0.02895063]\n",
      " [-0.05380165]\n",
      " [ 0.09160781]]\n",
      "Iteration 8154 | Cost: 0.29606708230935574 | Gradient: [[ 0.02894962]\n",
      " [-0.05379833]\n",
      " [ 0.0916012 ]]\n",
      "Iteration 8155 | Cost: 0.2960549595954327 | Gradient: [[ 0.0289486]\n",
      " [-0.053795 ]\n",
      " [ 0.0915946]]\n",
      "Iteration 8156 | Cost: 0.29604283850889374 | Gradient: [[ 0.02894758]\n",
      " [-0.05379167]\n",
      " [ 0.09158799]]\n",
      "Iteration 8157 | Cost: 0.2960307190494237 | Gradient: [[ 0.02894656]\n",
      " [-0.05378835]\n",
      " [ 0.09158138]]\n",
      "Iteration 8158 | Cost: 0.2960186012167075 | Gradient: [[ 0.02894554]\n",
      " [-0.05378502]\n",
      " [ 0.09157478]]\n",
      "Iteration 8159 | Cost: 0.29600648501043003 | Gradient: [[ 0.02894452]\n",
      " [-0.0537817 ]\n",
      " [ 0.09156817]]\n",
      "Iteration 8160 | Cost: 0.2959943704302763 | Gradient: [[ 0.02894351]\n",
      " [-0.05377838]\n",
      " [ 0.09156157]]\n",
      "Iteration 8161 | Cost: 0.29598225747593154 | Gradient: [[ 0.02894249]\n",
      " [-0.05377505]\n",
      " [ 0.09155496]]\n",
      "Iteration 8162 | Cost: 0.2959701461470809 | Gradient: [[ 0.02894147]\n",
      " [-0.05377173]\n",
      " [ 0.09154836]]\n",
      "Iteration 8163 | Cost: 0.2959580364434096 | Gradient: [[ 0.02894045]\n",
      " [-0.05376841]\n",
      " [ 0.09154176]]\n",
      "Iteration 8164 | Cost: 0.2959459283646031 | Gradient: [[ 0.02893943]\n",
      " [-0.05376509]\n",
      " [ 0.09153516]]\n",
      "Iteration 8165 | Cost: 0.2959338219103468 | Gradient: [[ 0.02893841]\n",
      " [-0.05376177]\n",
      " [ 0.09152856]]\n",
      "Iteration 8166 | Cost: 0.2959217170803262 | Gradient: [[ 0.02893739]\n",
      " [-0.05375845]\n",
      " [ 0.09152196]]\n",
      "Iteration 8167 | Cost: 0.2959096138742269 | Gradient: [[ 0.02893637]\n",
      " [-0.05375513]\n",
      " [ 0.09151536]]\n",
      "Iteration 8168 | Cost: 0.2958975122917345 | Gradient: [[ 0.02893535]\n",
      " [-0.05375181]\n",
      " [ 0.09150876]]\n",
      "Iteration 8169 | Cost: 0.29588541233253485 | Gradient: [[ 0.02893433]\n",
      " [-0.05374849]\n",
      " [ 0.09150216]]\n",
      "Iteration 8170 | Cost: 0.2958733139963138 | Gradient: [[ 0.02893331]\n",
      " [-0.05374518]\n",
      " [ 0.09149557]]\n",
      "Iteration 8171 | Cost: 0.29586121728275705 | Gradient: [[ 0.02893229]\n",
      " [-0.05374186]\n",
      " [ 0.09148897]]\n",
      "Iteration 8172 | Cost: 0.2958491221915508 | Gradient: [[ 0.02893127]\n",
      " [-0.05373855]\n",
      " [ 0.09148238]]\n",
      "Iteration 8173 | Cost: 0.295837028722381 | Gradient: [[ 0.02893025]\n",
      " [-0.05373523]\n",
      " [ 0.09147578]]\n",
      "Iteration 8174 | Cost: 0.29582493687493383 | Gradient: [[ 0.02892923]\n",
      " [-0.05373192]\n",
      " [ 0.09146919]]\n",
      "Iteration 8175 | Cost: 0.2958128466488955 | Gradient: [[ 0.02892821]\n",
      " [-0.0537286 ]\n",
      " [ 0.09146259]]\n",
      "Iteration 8176 | Cost: 0.29580075804395234 | Gradient: [[ 0.02892719]\n",
      " [-0.05372529]\n",
      " [ 0.091456  ]]\n",
      "Iteration 8177 | Cost: 0.29578867105979073 | Gradient: [[ 0.02892617]\n",
      " [-0.05372198]\n",
      " [ 0.09144941]]\n",
      "Iteration 8178 | Cost: 0.29577658569609705 | Gradient: [[ 0.02892514]\n",
      " [-0.05371867]\n",
      " [ 0.09144282]]\n",
      "Iteration 8179 | Cost: 0.2957645019525578 | Gradient: [[ 0.02892412]\n",
      " [-0.05371536]\n",
      " [ 0.09143623]]\n",
      "Iteration 8180 | Cost: 0.29575241982885986 | Gradient: [[ 0.0289231 ]\n",
      " [-0.05371205]\n",
      " [ 0.09142964]]\n",
      "Iteration 8181 | Cost: 0.29574033932468957 | Gradient: [[ 0.02892208]\n",
      " [-0.05370874]\n",
      " [ 0.09142305]]\n",
      "Iteration 8182 | Cost: 0.2957282604397339 | Gradient: [[ 0.02892106]\n",
      " [-0.05370543]\n",
      " [ 0.09141647]]\n",
      "Iteration 8183 | Cost: 0.29571618317367965 | Gradient: [[ 0.02892004]\n",
      " [-0.05370212]\n",
      " [ 0.09140988]]\n",
      "Iteration 8184 | Cost: 0.2957041075262137 | Gradient: [[ 0.02891902]\n",
      " [-0.05369881]\n",
      " [ 0.09140329]]\n",
      "Iteration 8185 | Cost: 0.2956920334970232 | Gradient: [[ 0.02891799]\n",
      " [-0.0536955 ]\n",
      " [ 0.09139671]]\n",
      "Iteration 8186 | Cost: 0.295679961085795 | Gradient: [[ 0.02891697]\n",
      " [-0.0536922 ]\n",
      " [ 0.09139012]]\n",
      "Iteration 8187 | Cost: 0.2956678902922164 | Gradient: [[ 0.02891595]\n",
      " [-0.05368889]\n",
      " [ 0.09138354]]\n",
      "Iteration 8188 | Cost: 0.29565582111597466 | Gradient: [[ 0.02891493]\n",
      " [-0.05368559]\n",
      " [ 0.09137696]]\n",
      "Iteration 8189 | Cost: 0.2956437535567571 | Gradient: [[ 0.0289139 ]\n",
      " [-0.05368228]\n",
      " [ 0.09137037]]\n",
      "Iteration 8190 | Cost: 0.2956316876142509 | Gradient: [[ 0.02891288]\n",
      " [-0.05367898]\n",
      " [ 0.09136379]]\n",
      "Iteration 8191 | Cost: 0.2956196232881438 | Gradient: [[ 0.02891186]\n",
      " [-0.05367568]\n",
      " [ 0.09135721]]\n",
      "Iteration 8192 | Cost: 0.2956075605781232 | Gradient: [[ 0.02891084]\n",
      " [-0.05367237]\n",
      " [ 0.09135063]]\n",
      "Iteration 8193 | Cost: 0.29559549948387676 | Gradient: [[ 0.02890981]\n",
      " [-0.05366907]\n",
      " [ 0.09134405]]\n",
      "Iteration 8194 | Cost: 0.2955834400050922 | Gradient: [[ 0.02890879]\n",
      " [-0.05366577]\n",
      " [ 0.09133748]]\n",
      "Iteration 8195 | Cost: 0.29557138214145734 | Gradient: [[ 0.02890777]\n",
      " [-0.05366247]\n",
      " [ 0.0913309 ]]\n",
      "Iteration 8196 | Cost: 0.2955593258926599 | Gradient: [[ 0.02890674]\n",
      " [-0.05365917]\n",
      " [ 0.09132432]]\n",
      "Iteration 8197 | Cost: 0.2955472712583879 | Gradient: [[ 0.02890572]\n",
      " [-0.05365587]\n",
      " [ 0.09131774]]\n",
      "Iteration 8198 | Cost: 0.2955352182383294 | Gradient: [[ 0.0289047 ]\n",
      " [-0.05365257]\n",
      " [ 0.09131117]]\n",
      "Iteration 8199 | Cost: 0.2955231668321724 | Gradient: [[ 0.02890367]\n",
      " [-0.05364927]\n",
      " [ 0.0913046 ]]\n",
      "Iteration 8200 | Cost: 0.2955111170396052 | Gradient: [[ 0.02890265]\n",
      " [-0.05364598]\n",
      " [ 0.09129802]]\n",
      "Iteration 8201 | Cost: 0.2954990688603159 | Gradient: [[ 0.02890162]\n",
      " [-0.05364268]\n",
      " [ 0.09129145]]\n",
      "Iteration 8202 | Cost: 0.29548702229399293 | Gradient: [[ 0.0289006 ]\n",
      " [-0.05363938]\n",
      " [ 0.09128488]]\n",
      "Iteration 8203 | Cost: 0.2954749773403246 | Gradient: [[ 0.02889958]\n",
      " [-0.05363609]\n",
      " [ 0.0912783 ]]\n",
      "Iteration 8204 | Cost: 0.29546293399899953 | Gradient: [[ 0.02889855]\n",
      " [-0.05363279]\n",
      " [ 0.09127173]]\n",
      "Iteration 8205 | Cost: 0.2954508922697061 | Gradient: [[ 0.02889753]\n",
      " [-0.0536295 ]\n",
      " [ 0.09126516]]\n",
      "Iteration 8206 | Cost: 0.2954388521521331 | Gradient: [[ 0.0288965 ]\n",
      " [-0.05362621]\n",
      " [ 0.09125859]]\n",
      "Iteration 8207 | Cost: 0.29542681364596923 | Gradient: [[ 0.02889548]\n",
      " [-0.05362291]\n",
      " [ 0.09125203]]\n",
      "Iteration 8208 | Cost: 0.2954147767509031 | Gradient: [[ 0.02889445]\n",
      " [-0.05361962]\n",
      " [ 0.09124546]]\n",
      "Iteration 8209 | Cost: 0.2954027414666239 | Gradient: [[ 0.02889343]\n",
      " [-0.05361633]\n",
      " [ 0.09123889]]\n",
      "Iteration 8210 | Cost: 0.2953907077928202 | Gradient: [[ 0.0288924 ]\n",
      " [-0.05361304]\n",
      " [ 0.09123233]]\n",
      "Iteration 8211 | Cost: 0.29537867572918136 | Gradient: [[ 0.02889138]\n",
      " [-0.05360975]\n",
      " [ 0.09122576]]\n",
      "Iteration 8212 | Cost: 0.29536664527539624 | Gradient: [[ 0.02889035]\n",
      " [-0.05360646]\n",
      " [ 0.0912192 ]]\n",
      "Iteration 8213 | Cost: 0.2953546164311542 | Gradient: [[ 0.02888933]\n",
      " [-0.05360317]\n",
      " [ 0.09121263]]\n",
      "Iteration 8214 | Cost: 0.29534258919614426 | Gradient: [[ 0.0288883 ]\n",
      " [-0.05359988]\n",
      " [ 0.09120607]]\n",
      "Iteration 8215 | Cost: 0.29533056357005605 | Gradient: [[ 0.02888728]\n",
      " [-0.05359659]\n",
      " [ 0.09119951]]\n",
      "Iteration 8216 | Cost: 0.29531853955257875 | Gradient: [[ 0.02888625]\n",
      " [-0.05359331]\n",
      " [ 0.09119295]]\n",
      "Iteration 8217 | Cost: 0.29530651714340195 | Gradient: [[ 0.02888522]\n",
      " [-0.05359002]\n",
      " [ 0.09118638]]\n",
      "Iteration 8218 | Cost: 0.2952944963422152 | Gradient: [[ 0.0288842 ]\n",
      " [-0.05358673]\n",
      " [ 0.09117982]]\n",
      "Iteration 8219 | Cost: 0.29528247714870814 | Gradient: [[ 0.02888317]\n",
      " [-0.05358345]\n",
      " [ 0.09117327]]\n",
      "Iteration 8220 | Cost: 0.29527045956257053 | Gradient: [[ 0.02888215]\n",
      " [-0.05358016]\n",
      " [ 0.09116671]]\n",
      "Iteration 8221 | Cost: 0.29525844358349207 | Gradient: [[ 0.02888112]\n",
      " [-0.05357688]\n",
      " [ 0.09116015]]\n",
      "Iteration 8222 | Cost: 0.2952464292111627 | Gradient: [[ 0.02888009]\n",
      " [-0.0535736 ]\n",
      " [ 0.09115359]]\n",
      "Iteration 8223 | Cost: 0.2952344164452724 | Gradient: [[ 0.02887907]\n",
      " [-0.05357031]\n",
      " [ 0.09114704]]\n",
      "Iteration 8224 | Cost: 0.2952224052855111 | Gradient: [[ 0.02887804]\n",
      " [-0.05356703]\n",
      " [ 0.09114048]]\n",
      "Iteration 8225 | Cost: 0.29521039573156893 | Gradient: [[ 0.02887701]\n",
      " [-0.05356375]\n",
      " [ 0.09113393]]\n",
      "Iteration 8226 | Cost: 0.2951983877831361 | Gradient: [[ 0.02887599]\n",
      " [-0.05356047]\n",
      " [ 0.09112737]]\n",
      "Iteration 8227 | Cost: 0.295186381439903 | Gradient: [[ 0.02887496]\n",
      " [-0.05355719]\n",
      " [ 0.09112082]]\n",
      "Iteration 8228 | Cost: 0.2951743767015598 | Gradient: [[ 0.02887393]\n",
      " [-0.05355391]\n",
      " [ 0.09111427]]\n",
      "Iteration 8229 | Cost: 0.2951623735677969 | Gradient: [[ 0.0288729 ]\n",
      " [-0.05355063]\n",
      " [ 0.09110771]]\n",
      "Iteration 8230 | Cost: 0.2951503720383049 | Gradient: [[ 0.02887188]\n",
      " [-0.05354735]\n",
      " [ 0.09110116]]\n",
      "Iteration 8231 | Cost: 0.2951383721127744 | Gradient: [[ 0.02887085]\n",
      " [-0.05354408]\n",
      " [ 0.09109461]]\n",
      "Iteration 8232 | Cost: 0.29512637379089585 | Gradient: [[ 0.02886982]\n",
      " [-0.0535408 ]\n",
      " [ 0.09108806]]\n",
      "Iteration 8233 | Cost: 0.29511437707236005 | Gradient: [[ 0.02886879]\n",
      " [-0.05353752]\n",
      " [ 0.09108152]]\n",
      "Iteration 8234 | Cost: 0.29510238195685795 | Gradient: [[ 0.02886777]\n",
      " [-0.05353425]\n",
      " [ 0.09107497]]\n",
      "Iteration 8235 | Cost: 0.2950903884440802 | Gradient: [[ 0.02886674]\n",
      " [-0.05353097]\n",
      " [ 0.09106842]]\n",
      "Iteration 8236 | Cost: 0.295078396533718 | Gradient: [[ 0.02886571]\n",
      " [-0.0535277 ]\n",
      " [ 0.09106187]]\n",
      "Iteration 8237 | Cost: 0.2950664062254621 | Gradient: [[ 0.02886468]\n",
      " [-0.05352443]\n",
      " [ 0.09105533]]\n",
      "Iteration 8238 | Cost: 0.2950544175190038 | Gradient: [[ 0.02886365]\n",
      " [-0.05352115]\n",
      " [ 0.09104878]]\n",
      "Iteration 8239 | Cost: 0.29504243041403416 | Gradient: [[ 0.02886262]\n",
      " [-0.05351788]\n",
      " [ 0.09104224]]\n",
      "Iteration 8240 | Cost: 0.2950304449102446 | Gradient: [[ 0.0288616 ]\n",
      " [-0.05351461]\n",
      " [ 0.0910357 ]]\n",
      "Iteration 8241 | Cost: 0.2950184610073263 | Gradient: [[ 0.02886057]\n",
      " [-0.05351134]\n",
      " [ 0.09102915]]\n",
      "Iteration 8242 | Cost: 0.29500647870497076 | Gradient: [[ 0.02885954]\n",
      " [-0.05350807]\n",
      " [ 0.09102261]]\n",
      "Iteration 8243 | Cost: 0.29499449800286953 | Gradient: [[ 0.02885851]\n",
      " [-0.0535048 ]\n",
      " [ 0.09101607]]\n",
      "Iteration 8244 | Cost: 0.29498251890071403 | Gradient: [[ 0.02885748]\n",
      " [-0.05350153]\n",
      " [ 0.09100953]]\n",
      "Iteration 8245 | Cost: 0.29497054139819595 | Gradient: [[ 0.02885645]\n",
      " [-0.05349826]\n",
      " [ 0.09100299]]\n",
      "Iteration 8246 | Cost: 0.29495856549500704 | Gradient: [[ 0.02885542]\n",
      " [-0.05349499]\n",
      " [ 0.09099645]]\n",
      "Iteration 8247 | Cost: 0.29494659119083905 | Gradient: [[ 0.02885439]\n",
      " [-0.05349172]\n",
      " [ 0.09098991]]\n",
      "Iteration 8248 | Cost: 0.2949346184853839 | Gradient: [[ 0.02885336]\n",
      " [-0.05348846]\n",
      " [ 0.09098338]]\n",
      "Iteration 8249 | Cost: 0.29492264737833357 | Gradient: [[ 0.02885233]\n",
      " [-0.05348519]\n",
      " [ 0.09097684]]\n",
      "Iteration 8250 | Cost: 0.29491067786938 | Gradient: [[ 0.0288513 ]\n",
      " [-0.05348193]\n",
      " [ 0.09097031]]\n",
      "Iteration 8251 | Cost: 0.2948987099582154 | Gradient: [[ 0.02885027]\n",
      " [-0.05347866]\n",
      " [ 0.09096377]]\n",
      "Iteration 8252 | Cost: 0.29488674364453177 | Gradient: [[ 0.02884924]\n",
      " [-0.0534754 ]\n",
      " [ 0.09095724]]\n",
      "Iteration 8253 | Cost: 0.29487477892802155 | Gradient: [[ 0.02884821]\n",
      " [-0.05347213]\n",
      " [ 0.0909507 ]]\n",
      "Iteration 8254 | Cost: 0.2948628158083769 | Gradient: [[ 0.02884718]\n",
      " [-0.05346887]\n",
      " [ 0.09094417]]\n",
      "Iteration 8255 | Cost: 0.29485085428529045 | Gradient: [[ 0.02884615]\n",
      " [-0.05346561]\n",
      " [ 0.09093764]]\n",
      "Iteration 8256 | Cost: 0.2948388943584545 | Gradient: [[ 0.02884512]\n",
      " [-0.05346235]\n",
      " [ 0.09093111]]\n",
      "Iteration 8257 | Cost: 0.2948269360275617 | Gradient: [[ 0.02884409]\n",
      " [-0.05345909]\n",
      " [ 0.09092458]]\n",
      "Iteration 8258 | Cost: 0.29481497929230466 | Gradient: [[ 0.02884306]\n",
      " [-0.05345583]\n",
      " [ 0.09091805]]\n",
      "Iteration 8259 | Cost: 0.29480302415237614 | Gradient: [[ 0.02884203]\n",
      " [-0.05345257]\n",
      " [ 0.09091152]]\n",
      "Iteration 8260 | Cost: 0.2947910706074688 | Gradient: [[ 0.028841  ]\n",
      " [-0.05344931]\n",
      " [ 0.09090499]]\n",
      "Iteration 8261 | Cost: 0.29477911865727563 | Gradient: [[ 0.02883997]\n",
      " [-0.05344605]\n",
      " [ 0.09089846]]\n",
      "Iteration 8262 | Cost: 0.2947671683014895 | Gradient: [[ 0.02883894]\n",
      " [-0.05344279]\n",
      " [ 0.09089194]]\n",
      "Iteration 8263 | Cost: 0.29475521953980355 | Gradient: [[ 0.0288379 ]\n",
      " [-0.05343953]\n",
      " [ 0.09088541]]\n",
      "Iteration 8264 | Cost: 0.2947432723719106 | Gradient: [[ 0.02883687]\n",
      " [-0.05343628]\n",
      " [ 0.09087889]]\n",
      "Iteration 8265 | Cost: 0.29473132679750413 | Gradient: [[ 0.02883584]\n",
      " [-0.05343302]\n",
      " [ 0.09087236]]\n",
      "Iteration 8266 | Cost: 0.2947193828162773 | Gradient: [[ 0.02883481]\n",
      " [-0.05342976]\n",
      " [ 0.09086584]]\n",
      "Iteration 8267 | Cost: 0.2947074404279233 | Gradient: [[ 0.02883378]\n",
      " [-0.05342651]\n",
      " [ 0.09085932]]\n",
      "Iteration 8268 | Cost: 0.2946954996321357 | Gradient: [[ 0.02883275]\n",
      " [-0.05342326]\n",
      " [ 0.09085279]]\n",
      "Iteration 8269 | Cost: 0.2946835604286079 | Gradient: [[ 0.02883171]\n",
      " [-0.05342   ]\n",
      " [ 0.09084627]]\n",
      "Iteration 8270 | Cost: 0.2946716228170334 | Gradient: [[ 0.02883068]\n",
      " [-0.05341675]\n",
      " [ 0.09083975]]\n",
      "Iteration 8271 | Cost: 0.2946596867971059 | Gradient: [[ 0.02882965]\n",
      " [-0.0534135 ]\n",
      " [ 0.09083323]]\n",
      "Iteration 8272 | Cost: 0.2946477523685191 | Gradient: [[ 0.02882862]\n",
      " [-0.05341025]\n",
      " [ 0.09082671]]\n",
      "Iteration 8273 | Cost: 0.29463581953096674 | Gradient: [[ 0.02882759]\n",
      " [-0.05340699]\n",
      " [ 0.09082019]]\n",
      "Iteration 8274 | Cost: 0.2946238882841427 | Gradient: [[ 0.02882655]\n",
      " [-0.05340374]\n",
      " [ 0.09081368]]\n",
      "Iteration 8275 | Cost: 0.29461195862774087 | Gradient: [[ 0.02882552]\n",
      " [-0.05340049]\n",
      " [ 0.09080716]]\n",
      "Iteration 8276 | Cost: 0.2946000305614554 | Gradient: [[ 0.02882449]\n",
      " [-0.05339725]\n",
      " [ 0.09080064]]\n",
      "Iteration 8277 | Cost: 0.29458810408498015 | Gradient: [[ 0.02882345]\n",
      " [-0.053394  ]\n",
      " [ 0.09079413]]\n",
      "Iteration 8278 | Cost: 0.29457617919800944 | Gradient: [[ 0.02882242]\n",
      " [-0.05339075]\n",
      " [ 0.09078761]]\n",
      "Iteration 8279 | Cost: 0.29456425590023755 | Gradient: [[ 0.02882139]\n",
      " [-0.0533875 ]\n",
      " [ 0.0907811 ]]\n",
      "Iteration 8280 | Cost: 0.29455233419135857 | Gradient: [[ 0.02882035]\n",
      " [-0.05338425]\n",
      " [ 0.09077459]]\n",
      "Iteration 8281 | Cost: 0.294540414071067 | Gradient: [[ 0.02881932]\n",
      " [-0.05338101]\n",
      " [ 0.09076808]]\n",
      "Iteration 8282 | Cost: 0.2945284955390574 | Gradient: [[ 0.02881829]\n",
      " [-0.05337776]\n",
      " [ 0.09076156]]\n",
      "Iteration 8283 | Cost: 0.2945165785950242 | Gradient: [[ 0.02881725]\n",
      " [-0.05337452]\n",
      " [ 0.09075505]]\n",
      "Iteration 8284 | Cost: 0.29450466323866203 | Gradient: [[ 0.02881622]\n",
      " [-0.05337127]\n",
      " [ 0.09074854]]\n",
      "Iteration 8285 | Cost: 0.29449274946966564 | Gradient: [[ 0.02881519]\n",
      " [-0.05336803]\n",
      " [ 0.09074204]]\n",
      "Iteration 8286 | Cost: 0.29448083728772967 | Gradient: [[ 0.02881415]\n",
      " [-0.05336479]\n",
      " [ 0.09073553]]\n",
      "Iteration 8287 | Cost: 0.29446892669254915 | Gradient: [[ 0.02881312]\n",
      " [-0.05336155]\n",
      " [ 0.09072902]]\n",
      "Iteration 8288 | Cost: 0.29445701768381877 | Gradient: [[ 0.02881208]\n",
      " [-0.0533583 ]\n",
      " [ 0.09072251]]\n",
      "Iteration 8289 | Cost: 0.29444511026123366 | Gradient: [[ 0.02881105]\n",
      " [-0.05335506]\n",
      " [ 0.09071601]]\n",
      "Iteration 8290 | Cost: 0.2944332044244889 | Gradient: [[ 0.02881002]\n",
      " [-0.05335182]\n",
      " [ 0.0907095 ]]\n",
      "Iteration 8291 | Cost: 0.2944213001732795 | Gradient: [[ 0.02880898]\n",
      " [-0.05334858]\n",
      " [ 0.090703  ]]\n",
      "Iteration 8292 | Cost: 0.2944093975073009 | Gradient: [[ 0.02880795]\n",
      " [-0.05334534]\n",
      " [ 0.09069649]]\n",
      "Iteration 8293 | Cost: 0.29439749642624813 | Gradient: [[ 0.02880691]\n",
      " [-0.05334211]\n",
      " [ 0.09068999]]\n",
      "Iteration 8294 | Cost: 0.2943855969298167 | Gradient: [[ 0.02880588]\n",
      " [-0.05333887]\n",
      " [ 0.09068349]]\n",
      "Iteration 8295 | Cost: 0.29437369901770216 | Gradient: [[ 0.02880484]\n",
      " [-0.05333563]\n",
      " [ 0.09067699]]\n",
      "Iteration 8296 | Cost: 0.2943618026895998 | Gradient: [[ 0.02880381]\n",
      " [-0.05333239]\n",
      " [ 0.09067048]]\n",
      "Iteration 8297 | Cost: 0.2943499079452054 | Gradient: [[ 0.02880277]\n",
      " [-0.05332916]\n",
      " [ 0.09066398]]\n",
      "Iteration 8298 | Cost: 0.2943380147842145 | Gradient: [[ 0.02880174]\n",
      " [-0.05332592]\n",
      " [ 0.09065749]]\n",
      "Iteration 8299 | Cost: 0.29432612320632295 | Gradient: [[ 0.0288007 ]\n",
      " [-0.05332269]\n",
      " [ 0.09065099]]\n",
      "Iteration 8300 | Cost: 0.2943142332112265 | Gradient: [[ 0.02879967]\n",
      " [-0.05331945]\n",
      " [ 0.09064449]]\n",
      "Iteration 8301 | Cost: 0.2943023447986211 | Gradient: [[ 0.02879863]\n",
      " [-0.05331622]\n",
      " [ 0.09063799]]\n",
      "Iteration 8302 | Cost: 0.29429045796820275 | Gradient: [[ 0.02879759]\n",
      " [-0.05331299]\n",
      " [ 0.0906315 ]]\n",
      "Iteration 8303 | Cost: 0.2942785727196674 | Gradient: [[ 0.02879656]\n",
      " [-0.05330975]\n",
      " [ 0.090625  ]]\n",
      "Iteration 8304 | Cost: 0.2942666890527112 | Gradient: [[ 0.02879552]\n",
      " [-0.05330652]\n",
      " [ 0.09061851]]\n",
      "Iteration 8305 | Cost: 0.2942548069670304 | Gradient: [[ 0.02879449]\n",
      " [-0.05330329]\n",
      " [ 0.09061201]]\n",
      "Iteration 8306 | Cost: 0.2942429264623212 | Gradient: [[ 0.02879345]\n",
      " [-0.05330006]\n",
      " [ 0.09060552]]\n",
      "Iteration 8307 | Cost: 0.29423104753828 | Gradient: [[ 0.02879241]\n",
      " [-0.05329683]\n",
      " [ 0.09059903]]\n",
      "Iteration 8308 | Cost: 0.2942191701946032 | Gradient: [[ 0.02879138]\n",
      " [-0.0532936 ]\n",
      " [ 0.09059253]]\n",
      "Iteration 8309 | Cost: 0.2942072944309873 | Gradient: [[ 0.02879034]\n",
      " [-0.05329037]\n",
      " [ 0.09058604]]\n",
      "Iteration 8310 | Cost: 0.2941954202471289 | Gradient: [[ 0.0287893 ]\n",
      " [-0.05328714]\n",
      " [ 0.09057955]]\n",
      "Iteration 8311 | Cost: 0.29418354764272464 | Gradient: [[ 0.02878827]\n",
      " [-0.05328392]\n",
      " [ 0.09057306]]\n",
      "Iteration 8312 | Cost: 0.29417167661747123 | Gradient: [[ 0.02878723]\n",
      " [-0.05328069]\n",
      " [ 0.09056657]]\n",
      "Iteration 8313 | Cost: 0.29415980717106543 | Gradient: [[ 0.02878619]\n",
      " [-0.05327746]\n",
      " [ 0.09056009]]\n",
      "Iteration 8314 | Cost: 0.2941479393032042 | Gradient: [[ 0.02878516]\n",
      " [-0.05327424]\n",
      " [ 0.0905536 ]]\n",
      "Iteration 8315 | Cost: 0.29413607301358446 | Gradient: [[ 0.02878412]\n",
      " [-0.05327101]\n",
      " [ 0.09054711]]\n",
      "Iteration 8316 | Cost: 0.29412420830190306 | Gradient: [[ 0.02878308]\n",
      " [-0.05326779]\n",
      " [ 0.09054063]]\n",
      "Iteration 8317 | Cost: 0.29411234516785745 | Gradient: [[ 0.02878205]\n",
      " [-0.05326456]\n",
      " [ 0.09053414]]\n",
      "Iteration 8318 | Cost: 0.29410048361114455 | Gradient: [[ 0.02878101]\n",
      " [-0.05326134]\n",
      " [ 0.09052766]]\n",
      "Iteration 8319 | Cost: 0.2940886236314616 | Gradient: [[ 0.02877997]\n",
      " [-0.05325812]\n",
      " [ 0.09052118]]\n",
      "Iteration 8320 | Cost: 0.294076765228506 | Gradient: [[ 0.02877893]\n",
      " [-0.0532549 ]\n",
      " [ 0.09051469]]\n",
      "Iteration 8321 | Cost: 0.29406490840197524 | Gradient: [[ 0.02877789]\n",
      " [-0.05325168]\n",
      " [ 0.09050821]]\n",
      "Iteration 8322 | Cost: 0.2940530531515666 | Gradient: [[ 0.02877686]\n",
      " [-0.05324845]\n",
      " [ 0.09050173]]\n",
      "Iteration 8323 | Cost: 0.2940411994769778 | Gradient: [[ 0.02877582]\n",
      " [-0.05324523]\n",
      " [ 0.09049525]]\n",
      "Iteration 8324 | Cost: 0.2940293473779062 | Gradient: [[ 0.02877478]\n",
      " [-0.05324202]\n",
      " [ 0.09048877]]\n",
      "Iteration 8325 | Cost: 0.2940174968540498 | Gradient: [[ 0.02877374]\n",
      " [-0.0532388 ]\n",
      " [ 0.09048229]]\n",
      "Iteration 8326 | Cost: 0.2940056479051063 | Gradient: [[ 0.0287727 ]\n",
      " [-0.05323558]\n",
      " [ 0.09047581]]\n",
      "Iteration 8327 | Cost: 0.2939938005307734 | Gradient: [[ 0.02877167]\n",
      " [-0.05323236]\n",
      " [ 0.09046934]]\n",
      "Iteration 8328 | Cost: 0.2939819547307491 | Gradient: [[ 0.02877063]\n",
      " [-0.05322914]\n",
      " [ 0.09046286]]\n",
      "Iteration 8329 | Cost: 0.2939701105047315 | Gradient: [[ 0.02876959]\n",
      " [-0.05322593]\n",
      " [ 0.09045638]]\n",
      "Iteration 8330 | Cost: 0.2939582678524185 | Gradient: [[ 0.02876855]\n",
      " [-0.05322271]\n",
      " [ 0.09044991]]\n",
      "Iteration 8331 | Cost: 0.2939464267735084 | Gradient: [[ 0.02876751]\n",
      " [-0.0532195 ]\n",
      " [ 0.09044343]]\n",
      "Iteration 8332 | Cost: 0.29393458726769933 | Gradient: [[ 0.02876647]\n",
      " [-0.05321628]\n",
      " [ 0.09043696]]\n",
      "Iteration 8333 | Cost: 0.2939227493346896 | Gradient: [[ 0.02876543]\n",
      " [-0.05321307]\n",
      " [ 0.09043049]]\n",
      "Iteration 8334 | Cost: 0.29391091297417754 | Gradient: [[ 0.02876439]\n",
      " [-0.05320985]\n",
      " [ 0.09042401]]\n",
      "Iteration 8335 | Cost: 0.29389907818586164 | Gradient: [[ 0.02876335]\n",
      " [-0.05320664]\n",
      " [ 0.09041754]]\n",
      "Iteration 8336 | Cost: 0.2938872449694404 | Gradient: [[ 0.02876231]\n",
      " [-0.05320343]\n",
      " [ 0.09041107]]\n",
      "Iteration 8337 | Cost: 0.2938754133246124 | Gradient: [[ 0.02876128]\n",
      " [-0.05320022]\n",
      " [ 0.0904046 ]]\n",
      "Iteration 8338 | Cost: 0.29386358325107637 | Gradient: [[ 0.02876024]\n",
      " [-0.05319701]\n",
      " [ 0.09039813]]\n",
      "Iteration 8339 | Cost: 0.293851754748531 | Gradient: [[ 0.0287592 ]\n",
      " [-0.0531938 ]\n",
      " [ 0.09039167]]\n",
      "Iteration 8340 | Cost: 0.29383992781667506 | Gradient: [[ 0.02875816]\n",
      " [-0.05319059]\n",
      " [ 0.0903852 ]]\n",
      "Iteration 8341 | Cost: 0.2938281024552076 | Gradient: [[ 0.02875712]\n",
      " [-0.05318738]\n",
      " [ 0.09037873]]\n",
      "Iteration 8342 | Cost: 0.29381627866382737 | Gradient: [[ 0.02875608]\n",
      " [-0.05318417]\n",
      " [ 0.09037227]]\n",
      "Iteration 8343 | Cost: 0.2938044564422335 | Gradient: [[ 0.02875504]\n",
      " [-0.05318096]\n",
      " [ 0.0903658 ]]\n",
      "Iteration 8344 | Cost: 0.2937926357901252 | Gradient: [[ 0.028754  ]\n",
      " [-0.05317775]\n",
      " [ 0.09035934]]\n",
      "Iteration 8345 | Cost: 0.2937808167072016 | Gradient: [[ 0.02875296]\n",
      " [-0.05317455]\n",
      " [ 0.09035287]]\n",
      "Iteration 8346 | Cost: 0.2937689991931618 | Gradient: [[ 0.02875191]\n",
      " [-0.05317134]\n",
      " [ 0.09034641]]\n",
      "Iteration 8347 | Cost: 0.29375718324770533 | Gradient: [[ 0.02875087]\n",
      " [-0.05316813]\n",
      " [ 0.09033995]]\n",
      "Iteration 8348 | Cost: 0.2937453688705315 | Gradient: [[ 0.02874983]\n",
      " [-0.05316493]\n",
      " [ 0.09033348]]\n",
      "Iteration 8349 | Cost: 0.29373355606133994 | Gradient: [[ 0.02874879]\n",
      " [-0.05316173]\n",
      " [ 0.09032702]]\n",
      "Iteration 8350 | Cost: 0.29372174481983 | Gradient: [[ 0.02874775]\n",
      " [-0.05315852]\n",
      " [ 0.09032056]]\n",
      "Iteration 8351 | Cost: 0.2937099351457015 | Gradient: [[ 0.02874671]\n",
      " [-0.05315532]\n",
      " [ 0.0903141 ]]\n",
      "Iteration 8352 | Cost: 0.293698127038654 | Gradient: [[ 0.02874567]\n",
      " [-0.05315212]\n",
      " [ 0.09030765]]\n",
      "Iteration 8353 | Cost: 0.29368632049838733 | Gradient: [[ 0.02874463]\n",
      " [-0.05314891]\n",
      " [ 0.09030119]]\n",
      "Iteration 8354 | Cost: 0.29367451552460133 | Gradient: [[ 0.02874359]\n",
      " [-0.05314571]\n",
      " [ 0.09029473]]\n",
      "Iteration 8355 | Cost: 0.29366271211699596 | Gradient: [[ 0.02874255]\n",
      " [-0.05314251]\n",
      " [ 0.09028827]]\n",
      "Iteration 8356 | Cost: 0.29365091027527124 | Gradient: [[ 0.0287415 ]\n",
      " [-0.05313931]\n",
      " [ 0.09028182]]\n",
      "Iteration 8357 | Cost: 0.2936391099991272 | Gradient: [[ 0.02874046]\n",
      " [-0.05313611]\n",
      " [ 0.09027536]]\n",
      "Iteration 8358 | Cost: 0.293627311288264 | Gradient: [[ 0.02873942]\n",
      " [-0.05313291]\n",
      " [ 0.09026891]]\n",
      "Iteration 8359 | Cost: 0.2936155141423819 | Gradient: [[ 0.02873838]\n",
      " [-0.05312972]\n",
      " [ 0.09026246]]\n",
      "Iteration 8360 | Cost: 0.29360371856118117 | Gradient: [[ 0.02873734]\n",
      " [-0.05312652]\n",
      " [ 0.090256  ]]\n",
      "Iteration 8361 | Cost: 0.2935919245443622 | Gradient: [[ 0.0287363 ]\n",
      " [-0.05312332]\n",
      " [ 0.09024955]]\n",
      "Iteration 8362 | Cost: 0.29358013209162537 | Gradient: [[ 0.02873525]\n",
      " [-0.05312012]\n",
      " [ 0.0902431 ]]\n",
      "Iteration 8363 | Cost: 0.2935683412026713 | Gradient: [[ 0.02873421]\n",
      " [-0.05311693]\n",
      " [ 0.09023665]]\n",
      "Iteration 8364 | Cost: 0.2935565518772005 | Gradient: [[ 0.02873317]\n",
      " [-0.05311373]\n",
      " [ 0.0902302 ]]\n",
      "Iteration 8365 | Cost: 0.2935447641149137 | Gradient: [[ 0.02873213]\n",
      " [-0.05311054]\n",
      " [ 0.09022375]]\n",
      "Iteration 8366 | Cost: 0.29353297791551153 | Gradient: [[ 0.02873108]\n",
      " [-0.05310734]\n",
      " [ 0.09021731]]\n",
      "Iteration 8367 | Cost: 0.29352119327869497 | Gradient: [[ 0.02873004]\n",
      " [-0.05310415]\n",
      " [ 0.09021086]]\n",
      "Iteration 8368 | Cost: 0.2935094102041647 | Gradient: [[ 0.028729  ]\n",
      " [-0.05310096]\n",
      " [ 0.09020441]]\n",
      "Iteration 8369 | Cost: 0.293497628691622 | Gradient: [[ 0.02872796]\n",
      " [-0.05309777]\n",
      " [ 0.09019797]]\n",
      "Iteration 8370 | Cost: 0.29348584874076755 | Gradient: [[ 0.02872691]\n",
      " [-0.05309457]\n",
      " [ 0.09019152]]\n",
      "Iteration 8371 | Cost: 0.29347407035130274 | Gradient: [[ 0.02872587]\n",
      " [-0.05309138]\n",
      " [ 0.09018508]]\n",
      "Iteration 8372 | Cost: 0.2934622935229285 | Gradient: [[ 0.02872483]\n",
      " [-0.05308819]\n",
      " [ 0.09017863]]\n",
      "Iteration 8373 | Cost: 0.2934505182553463 | Gradient: [[ 0.02872378]\n",
      " [-0.053085  ]\n",
      " [ 0.09017219]]\n",
      "Iteration 8374 | Cost: 0.2934387445482574 | Gradient: [[ 0.02872274]\n",
      " [-0.05308181]\n",
      " [ 0.09016575]]\n",
      "Iteration 8375 | Cost: 0.29342697240136323 | Gradient: [[ 0.0287217 ]\n",
      " [-0.05307862]\n",
      " [ 0.09015931]]\n",
      "Iteration 8376 | Cost: 0.2934152018143652 | Gradient: [[ 0.02872065]\n",
      " [-0.05307544]\n",
      " [ 0.09015287]]\n",
      "Iteration 8377 | Cost: 0.29340343278696485 | Gradient: [[ 0.02871961]\n",
      " [-0.05307225]\n",
      " [ 0.09014643]]\n",
      "Iteration 8378 | Cost: 0.29339166531886396 | Gradient: [[ 0.02871856]\n",
      " [-0.05306906]\n",
      " [ 0.09013999]]\n",
      "Iteration 8379 | Cost: 0.293379899409764 | Gradient: [[ 0.02871752]\n",
      " [-0.05306588]\n",
      " [ 0.09013355]]\n",
      "Iteration 8380 | Cost: 0.293368135059367 | Gradient: [[ 0.02871648]\n",
      " [-0.05306269]\n",
      " [ 0.09012711]]\n",
      "Iteration 8381 | Cost: 0.29335637226737454 | Gradient: [[ 0.02871543]\n",
      " [-0.0530595 ]\n",
      " [ 0.09012068]]\n",
      "Iteration 8382 | Cost: 0.29334461103348874 | Gradient: [[ 0.02871439]\n",
      " [-0.05305632]\n",
      " [ 0.09011424]]\n",
      "Iteration 8383 | Cost: 0.29333285135741144 | Gradient: [[ 0.02871334]\n",
      " [-0.05305314]\n",
      " [ 0.0901078 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8384 | Cost: 0.2933210932388448 | Gradient: [[ 0.0287123 ]\n",
      " [-0.05304995]\n",
      " [ 0.09010137]]\n",
      "Iteration 8385 | Cost: 0.29330933667749104 | Gradient: [[ 0.02871126]\n",
      " [-0.05304677]\n",
      " [ 0.09009494]]\n",
      "Iteration 8386 | Cost: 0.29329758167305214 | Gradient: [[ 0.02871021]\n",
      " [-0.05304359]\n",
      " [ 0.0900885 ]]\n",
      "Iteration 8387 | Cost: 0.2932858282252306 | Gradient: [[ 0.02870917]\n",
      " [-0.05304041]\n",
      " [ 0.09008207]]\n",
      "Iteration 8388 | Cost: 0.29327407633372865 | Gradient: [[ 0.02870812]\n",
      " [-0.05303723]\n",
      " [ 0.09007564]]\n",
      "Iteration 8389 | Cost: 0.29326232599824886 | Gradient: [[ 0.02870708]\n",
      " [-0.05303405]\n",
      " [ 0.09006921]]\n",
      "Iteration 8390 | Cost: 0.2932505772184936 | Gradient: [[ 0.02870603]\n",
      " [-0.05303087]\n",
      " [ 0.09006278]]\n",
      "Iteration 8391 | Cost: 0.2932388299941655 | Gradient: [[ 0.02870499]\n",
      " [-0.05302769]\n",
      " [ 0.09005635]]\n",
      "Iteration 8392 | Cost: 0.29322708432496725 | Gradient: [[ 0.02870394]\n",
      " [-0.05302451]\n",
      " [ 0.09004992]]\n",
      "Iteration 8393 | Cost: 0.2932153402106014 | Gradient: [[ 0.0287029 ]\n",
      " [-0.05302133]\n",
      " [ 0.09004349]]\n",
      "Iteration 8394 | Cost: 0.293203597650771 | Gradient: [[ 0.02870185]\n",
      " [-0.05301815]\n",
      " [ 0.09003707]]\n",
      "Iteration 8395 | Cost: 0.29319185664517877 | Gradient: [[ 0.02870081]\n",
      " [-0.05301498]\n",
      " [ 0.09003064]]\n",
      "Iteration 8396 | Cost: 0.2931801171935276 | Gradient: [[ 0.02869976]\n",
      " [-0.0530118 ]\n",
      " [ 0.09002422]]\n",
      "Iteration 8397 | Cost: 0.2931683792955207 | Gradient: [[ 0.02869871]\n",
      " [-0.05300862]\n",
      " [ 0.09001779]]\n",
      "Iteration 8398 | Cost: 0.293156642950861 | Gradient: [[ 0.02869767]\n",
      " [-0.05300545]\n",
      " [ 0.09001137]]\n",
      "Iteration 8399 | Cost: 0.2931449081592517 | Gradient: [[ 0.02869662]\n",
      " [-0.05300227]\n",
      " [ 0.09000494]]\n",
      "Iteration 8400 | Cost: 0.29313317492039614 | Gradient: [[ 0.02869558]\n",
      " [-0.0529991 ]\n",
      " [ 0.08999852]]\n",
      "Iteration 8401 | Cost: 0.2931214432339974 | Gradient: [[ 0.02869453]\n",
      " [-0.05299593]\n",
      " [ 0.0899921 ]]\n",
      "Iteration 8402 | Cost: 0.29310971309975914 | Gradient: [[ 0.02869348]\n",
      " [-0.05299275]\n",
      " [ 0.08998568]]\n",
      "Iteration 8403 | Cost: 0.2930979845173846 | Gradient: [[ 0.02869244]\n",
      " [-0.05298958]\n",
      " [ 0.08997926]]\n",
      "Iteration 8404 | Cost: 0.29308625748657746 | Gradient: [[ 0.02869139]\n",
      " [-0.05298641]\n",
      " [ 0.08997284]]\n",
      "Iteration 8405 | Cost: 0.29307453200704114 | Gradient: [[ 0.02869034]\n",
      " [-0.05298324]\n",
      " [ 0.08996642]]\n",
      "Iteration 8406 | Cost: 0.2930628080784795 | Gradient: [[ 0.0286893 ]\n",
      " [-0.05298007]\n",
      " [ 0.08996   ]]\n",
      "Iteration 8407 | Cost: 0.29305108570059624 | Gradient: [[ 0.02868825]\n",
      " [-0.0529769 ]\n",
      " [ 0.08995358]]\n",
      "Iteration 8408 | Cost: 0.29303936487309507 | Gradient: [[ 0.0286872 ]\n",
      " [-0.05297373]\n",
      " [ 0.08994717]]\n",
      "Iteration 8409 | Cost: 0.29302764559568006 | Gradient: [[ 0.02868616]\n",
      " [-0.05297056]\n",
      " [ 0.08994075]]\n",
      "Iteration 8410 | Cost: 0.29301592786805497 | Gradient: [[ 0.02868511]\n",
      " [-0.05296739]\n",
      " [ 0.08993434]]\n",
      "Iteration 8411 | Cost: 0.29300421168992397 | Gradient: [[ 0.02868406]\n",
      " [-0.05296423]\n",
      " [ 0.08992792]]\n",
      "Iteration 8412 | Cost: 0.2929924970609912 | Gradient: [[ 0.02868302]\n",
      " [-0.05296106]\n",
      " [ 0.08992151]]\n",
      "Iteration 8413 | Cost: 0.2929807839809607 | Gradient: [[ 0.02868197]\n",
      " [-0.05295789]\n",
      " [ 0.0899151 ]]\n",
      "Iteration 8414 | Cost: 0.29296907244953685 | Gradient: [[ 0.02868092]\n",
      " [-0.05295473]\n",
      " [ 0.08990868]]\n",
      "Iteration 8415 | Cost: 0.292957362466424 | Gradient: [[ 0.02867987]\n",
      " [-0.05295156]\n",
      " [ 0.08990227]]\n",
      "Iteration 8416 | Cost: 0.29294565403132644 | Gradient: [[ 0.02867883]\n",
      " [-0.0529484 ]\n",
      " [ 0.08989586]]\n",
      "Iteration 8417 | Cost: 0.29293394714394866 | Gradient: [[ 0.02867778]\n",
      " [-0.05294524]\n",
      " [ 0.08988945]]\n",
      "Iteration 8418 | Cost: 0.29292224180399534 | Gradient: [[ 0.02867673]\n",
      " [-0.05294207]\n",
      " [ 0.08988304]]\n",
      "Iteration 8419 | Cost: 0.29291053801117095 | Gradient: [[ 0.02867568]\n",
      " [-0.05293891]\n",
      " [ 0.08987664]]\n",
      "Iteration 8420 | Cost: 0.29289883576518033 | Gradient: [[ 0.02867464]\n",
      " [-0.05293575]\n",
      " [ 0.08987023]]\n",
      "Iteration 8421 | Cost: 0.2928871350657281 | Gradient: [[ 0.02867359]\n",
      " [-0.05293259]\n",
      " [ 0.08986382]]\n",
      "Iteration 8422 | Cost: 0.2928754359125191 | Gradient: [[ 0.02867254]\n",
      " [-0.05292942]\n",
      " [ 0.08985742]]\n",
      "Iteration 8423 | Cost: 0.2928637383052583 | Gradient: [[ 0.02867149]\n",
      " [-0.05292626]\n",
      " [ 0.08985101]]\n",
      "Iteration 8424 | Cost: 0.2928520422436507 | Gradient: [[ 0.02867044]\n",
      " [-0.0529231 ]\n",
      " [ 0.08984461]]\n",
      "Iteration 8425 | Cost: 0.29284034772740136 | Gradient: [[ 0.02866939]\n",
      " [-0.05291995]\n",
      " [ 0.0898382 ]]\n",
      "Iteration 8426 | Cost: 0.2928286547562154 | Gradient: [[ 0.02866835]\n",
      " [-0.05291679]\n",
      " [ 0.0898318 ]]\n",
      "Iteration 8427 | Cost: 0.2928169633297979 | Gradient: [[ 0.0286673 ]\n",
      " [-0.05291363]\n",
      " [ 0.0898254 ]]\n",
      "Iteration 8428 | Cost: 0.29280527344785423 | Gradient: [[ 0.02866625]\n",
      " [-0.05291047]\n",
      " [ 0.089819  ]]\n",
      "Iteration 8429 | Cost: 0.2927935851100898 | Gradient: [[ 0.0286652 ]\n",
      " [-0.05290731]\n",
      " [ 0.08981259]]\n",
      "Iteration 8430 | Cost: 0.2927818983162099 | Gradient: [[ 0.02866415]\n",
      " [-0.05290416]\n",
      " [ 0.08980619]]\n",
      "Iteration 8431 | Cost: 0.29277021306592 | Gradient: [[ 0.0286631]\n",
      " [-0.052901 ]\n",
      " [ 0.0897998]]\n",
      "Iteration 8432 | Cost: 0.2927585293589259 | Gradient: [[ 0.02866205]\n",
      " [-0.05289785]\n",
      " [ 0.0897934 ]]\n",
      "Iteration 8433 | Cost: 0.292746847194933 | Gradient: [[ 0.028661  ]\n",
      " [-0.05289469]\n",
      " [ 0.089787  ]]\n",
      "Iteration 8434 | Cost: 0.292735166573647 | Gradient: [[ 0.02865995]\n",
      " [-0.05289154]\n",
      " [ 0.0897806 ]]\n",
      "Iteration 8435 | Cost: 0.29272348749477384 | Gradient: [[ 0.0286589 ]\n",
      " [-0.05288839]\n",
      " [ 0.08977421]]\n",
      "Iteration 8436 | Cost: 0.29271180995801926 | Gradient: [[ 0.02865786]\n",
      " [-0.05288523]\n",
      " [ 0.08976781]]\n",
      "Iteration 8437 | Cost: 0.29270013396308925 | Gradient: [[ 0.02865681]\n",
      " [-0.05288208]\n",
      " [ 0.08976142]]\n",
      "Iteration 8438 | Cost: 0.2926884595096897 | Gradient: [[ 0.02865576]\n",
      " [-0.05287893]\n",
      " [ 0.08975502]]\n",
      "Iteration 8439 | Cost: 0.2926767865975267 | Gradient: [[ 0.02865471]\n",
      " [-0.05287578]\n",
      " [ 0.08974863]]\n",
      "Iteration 8440 | Cost: 0.29266511522630645 | Gradient: [[ 0.02865366]\n",
      " [-0.05287263]\n",
      " [ 0.08974224]]\n",
      "Iteration 8441 | Cost: 0.2926534453957352 | Gradient: [[ 0.02865261]\n",
      " [-0.05286948]\n",
      " [ 0.08973584]]\n",
      "Iteration 8442 | Cost: 0.29264177710551903 | Gradient: [[ 0.02865156]\n",
      " [-0.05286633]\n",
      " [ 0.08972945]]\n",
      "Iteration 8443 | Cost: 0.2926301103553645 | Gradient: [[ 0.02865051]\n",
      " [-0.05286318]\n",
      " [ 0.08972306]]\n",
      "Iteration 8444 | Cost: 0.29261844514497803 | Gradient: [[ 0.02864946]\n",
      " [-0.05286003]\n",
      " [ 0.08971667]]\n",
      "Iteration 8445 | Cost: 0.292606781474066 | Gradient: [[ 0.02864841]\n",
      " [-0.05285688]\n",
      " [ 0.08971028]]\n",
      "Iteration 8446 | Cost: 0.29259511934233506 | Gradient: [[ 0.02864736]\n",
      " [-0.05285374]\n",
      " [ 0.0897039 ]]\n",
      "Iteration 8447 | Cost: 0.2925834587494919 | Gradient: [[ 0.0286463 ]\n",
      " [-0.05285059]\n",
      " [ 0.08969751]]\n",
      "Iteration 8448 | Cost: 0.29257179969524305 | Gradient: [[ 0.02864525]\n",
      " [-0.05284745]\n",
      " [ 0.08969112]]\n",
      "Iteration 8449 | Cost: 0.29256014217929543 | Gradient: [[ 0.0286442 ]\n",
      " [-0.0528443 ]\n",
      " [ 0.08968474]]\n",
      "Iteration 8450 | Cost: 0.2925484862013559 | Gradient: [[ 0.02864315]\n",
      " [-0.05284116]\n",
      " [ 0.08967835]]\n",
      "Iteration 8451 | Cost: 0.2925368317611313 | Gradient: [[ 0.0286421 ]\n",
      " [-0.05283801]\n",
      " [ 0.08967197]]\n",
      "Iteration 8452 | Cost: 0.29252517885832885 | Gradient: [[ 0.02864105]\n",
      " [-0.05283487]\n",
      " [ 0.08966558]]\n",
      "Iteration 8453 | Cost: 0.2925135274926554 | Gradient: [[ 0.02864   ]\n",
      " [-0.05283173]\n",
      " [ 0.0896592 ]]\n",
      "Iteration 8454 | Cost: 0.2925018776638182 | Gradient: [[ 0.02863895]\n",
      " [-0.05282858]\n",
      " [ 0.08965282]]\n",
      "Iteration 8455 | Cost: 0.29249022937152436 | Gradient: [[ 0.0286379 ]\n",
      " [-0.05282544]\n",
      " [ 0.08964644]]\n",
      "Iteration 8456 | Cost: 0.2924785826154813 | Gradient: [[ 0.02863685]\n",
      " [-0.0528223 ]\n",
      " [ 0.08964006]]\n",
      "Iteration 8457 | Cost: 0.29246693739539636 | Gradient: [[ 0.02863579]\n",
      " [-0.05281916]\n",
      " [ 0.08963368]]\n",
      "Iteration 8458 | Cost: 0.292455293710977 | Gradient: [[ 0.02863474]\n",
      " [-0.05281602]\n",
      " [ 0.0896273 ]]\n",
      "Iteration 8459 | Cost: 0.29244365156193053 | Gradient: [[ 0.02863369]\n",
      " [-0.05281288]\n",
      " [ 0.08962092]]\n",
      "Iteration 8460 | Cost: 0.2924320109479648 | Gradient: [[ 0.02863264]\n",
      " [-0.05280974]\n",
      " [ 0.08961454]]\n",
      "Iteration 8461 | Cost: 0.29242037186878717 | Gradient: [[ 0.02863159]\n",
      " [-0.0528066 ]\n",
      " [ 0.08960816]]\n",
      "Iteration 8462 | Cost: 0.29240873432410563 | Gradient: [[ 0.02863054]\n",
      " [-0.05280347]\n",
      " [ 0.08960179]]\n",
      "Iteration 8463 | Cost: 0.2923970983136278 | Gradient: [[ 0.02862948]\n",
      " [-0.05280033]\n",
      " [ 0.08959541]]\n",
      "Iteration 8464 | Cost: 0.29238546383706165 | Gradient: [[ 0.02862843]\n",
      " [-0.05279719]\n",
      " [ 0.08958904]]\n",
      "Iteration 8465 | Cost: 0.292373830894115 | Gradient: [[ 0.02862738]\n",
      " [-0.05279406]\n",
      " [ 0.08958266]]\n",
      "Iteration 8466 | Cost: 0.29236219948449593 | Gradient: [[ 0.02862633]\n",
      " [-0.05279092]\n",
      " [ 0.08957629]]\n",
      "Iteration 8467 | Cost: 0.29235056960791256 | Gradient: [[ 0.02862527]\n",
      " [-0.05278779]\n",
      " [ 0.08956992]]\n",
      "Iteration 8468 | Cost: 0.292338941264073 | Gradient: [[ 0.02862422]\n",
      " [-0.05278465]\n",
      " [ 0.08956355]]\n",
      "Iteration 8469 | Cost: 0.2923273144526854 | Gradient: [[ 0.02862317]\n",
      " [-0.05278152]\n",
      " [ 0.08955718]]\n",
      "Iteration 8470 | Cost: 0.2923156891734581 | Gradient: [[ 0.02862212]\n",
      " [-0.05277838]\n",
      " [ 0.08955081]]\n",
      "Iteration 8471 | Cost: 0.29230406542609944 | Gradient: [[ 0.02862106]\n",
      " [-0.05277525]\n",
      " [ 0.08954444]]\n",
      "Iteration 8472 | Cost: 0.2922924432103179 | Gradient: [[ 0.02862001]\n",
      " [-0.05277212]\n",
      " [ 0.08953807]]\n",
      "Iteration 8473 | Cost: 0.29228082252582205 | Gradient: [[ 0.02861896]\n",
      " [-0.05276899]\n",
      " [ 0.0895317 ]]\n",
      "Iteration 8474 | Cost: 0.2922692033723203 | Gradient: [[ 0.02861791]\n",
      " [-0.05276586]\n",
      " [ 0.08952533]]\n",
      "Iteration 8475 | Cost: 0.2922575857495215 | Gradient: [[ 0.02861685]\n",
      " [-0.05276273]\n",
      " [ 0.08951897]]\n",
      "Iteration 8476 | Cost: 0.29224596965713406 | Gradient: [[ 0.0286158]\n",
      " [-0.0527596]\n",
      " [ 0.0895126]]\n",
      "Iteration 8477 | Cost: 0.2922343550948671 | Gradient: [[ 0.02861475]\n",
      " [-0.05275647]\n",
      " [ 0.08950624]]\n",
      "Iteration 8478 | Cost: 0.2922227420624294 | Gradient: [[ 0.02861369]\n",
      " [-0.05275334]\n",
      " [ 0.08949987]]\n",
      "Iteration 8479 | Cost: 0.2922111305595297 | Gradient: [[ 0.02861264]\n",
      " [-0.05275021]\n",
      " [ 0.08949351]]\n",
      "Iteration 8480 | Cost: 0.2921995205858773 | Gradient: [[ 0.02861158]\n",
      " [-0.05274708]\n",
      " [ 0.08948715]]\n",
      "Iteration 8481 | Cost: 0.292187912141181 | Gradient: [[ 0.02861053]\n",
      " [-0.05274396]\n",
      " [ 0.08948078]]\n",
      "Iteration 8482 | Cost: 0.29217630522515015 | Gradient: [[ 0.02860948]\n",
      " [-0.05274083]\n",
      " [ 0.08947442]]\n",
      "Iteration 8483 | Cost: 0.2921646998374939 | Gradient: [[ 0.02860842]\n",
      " [-0.05273771]\n",
      " [ 0.08946806]]\n",
      "Iteration 8484 | Cost: 0.29215309597792144 | Gradient: [[ 0.02860737]\n",
      " [-0.05273458]\n",
      " [ 0.0894617 ]]\n",
      "Iteration 8485 | Cost: 0.2921414936461423 | Gradient: [[ 0.02860632]\n",
      " [-0.05273146]\n",
      " [ 0.08945534]]\n",
      "Iteration 8486 | Cost: 0.29212989284186586 | Gradient: [[ 0.02860526]\n",
      " [-0.05272833]\n",
      " [ 0.08944898]]\n",
      "Iteration 8487 | Cost: 0.29211829356480157 | Gradient: [[ 0.02860421]\n",
      " [-0.05272521]\n",
      " [ 0.08944263]]\n",
      "Iteration 8488 | Cost: 0.29210669581465903 | Gradient: [[ 0.02860315]\n",
      " [-0.05272209]\n",
      " [ 0.08943627]]\n",
      "Iteration 8489 | Cost: 0.2920950995911479 | Gradient: [[ 0.0286021 ]\n",
      " [-0.05271896]\n",
      " [ 0.08942991]]\n",
      "Iteration 8490 | Cost: 0.29208350489397783 | Gradient: [[ 0.02860104]\n",
      " [-0.05271584]\n",
      " [ 0.08942356]]\n",
      "Iteration 8491 | Cost: 0.29207191172285873 | Gradient: [[ 0.02859999]\n",
      " [-0.05271272]\n",
      " [ 0.0894172 ]]\n",
      "Iteration 8492 | Cost: 0.2920603200775004 | Gradient: [[ 0.02859893]\n",
      " [-0.0527096 ]\n",
      " [ 0.08941085]]\n",
      "Iteration 8493 | Cost: 0.29204872995761266 | Gradient: [[ 0.02859788]\n",
      " [-0.05270648]\n",
      " [ 0.0894045 ]]\n",
      "Iteration 8494 | Cost: 0.2920371413629057 | Gradient: [[ 0.02859683]\n",
      " [-0.05270336]\n",
      " [ 0.08939814]]\n",
      "Iteration 8495 | Cost: 0.29202555429308946 | Gradient: [[ 0.02859577]\n",
      " [-0.05270024]\n",
      " [ 0.08939179]]\n",
      "Iteration 8496 | Cost: 0.2920139687478741 | Gradient: [[ 0.02859472]\n",
      " [-0.05269712]\n",
      " [ 0.08938544]]\n",
      "Iteration 8497 | Cost: 0.29200238472696993 | Gradient: [[ 0.02859366]\n",
      " [-0.05269401]\n",
      " [ 0.08937909]]\n",
      "Iteration 8498 | Cost: 0.29199080223008705 | Gradient: [[ 0.0285926 ]\n",
      " [-0.05269089]\n",
      " [ 0.08937274]]\n",
      "Iteration 8499 | Cost: 0.29197922125693604 | Gradient: [[ 0.02859155]\n",
      " [-0.05268777]\n",
      " [ 0.08936639]]\n",
      "Iteration 8500 | Cost: 0.29196764180722723 | Gradient: [[ 0.02859049]\n",
      " [-0.05268466]\n",
      " [ 0.08936005]]\n",
      "Iteration 8501 | Cost: 0.29195606388067097 | Gradient: [[ 0.02858944]\n",
      " [-0.05268154]\n",
      " [ 0.0893537 ]]\n",
      "Iteration 8502 | Cost: 0.29194448747697804 | Gradient: [[ 0.02858838]\n",
      " [-0.05267843]\n",
      " [ 0.08934735]]\n",
      "Iteration 8503 | Cost: 0.29193291259585896 | Gradient: [[ 0.02858733]\n",
      " [-0.05267531]\n",
      " [ 0.08934101]]\n",
      "Iteration 8504 | Cost: 0.29192133923702446 | Gradient: [[ 0.02858627]\n",
      " [-0.0526722 ]\n",
      " [ 0.08933466]]\n",
      "Iteration 8505 | Cost: 0.29190976740018537 | Gradient: [[ 0.02858522]\n",
      " [-0.05266909]\n",
      " [ 0.08932832]]\n",
      "Iteration 8506 | Cost: 0.29189819708505244 | Gradient: [[ 0.02858416]\n",
      " [-0.05266597]\n",
      " [ 0.08932197]]\n",
      "Iteration 8507 | Cost: 0.2918866282913367 | Gradient: [[ 0.0285831 ]\n",
      " [-0.05266286]\n",
      " [ 0.08931563]]\n",
      "Iteration 8508 | Cost: 0.2918750610187491 | Gradient: [[ 0.02858205]\n",
      " [-0.05265975]\n",
      " [ 0.08930929]]\n",
      "Iteration 8509 | Cost: 0.2918634952670006 | Gradient: [[ 0.02858099]\n",
      " [-0.05265664]\n",
      " [ 0.08930295]]\n",
      "Iteration 8510 | Cost: 0.2918519310358026 | Gradient: [[ 0.02857994]\n",
      " [-0.05265353]\n",
      " [ 0.08929661]]\n",
      "Iteration 8511 | Cost: 0.29184036832486593 | Gradient: [[ 0.02857888]\n",
      " [-0.05265042]\n",
      " [ 0.08929027]]\n",
      "Iteration 8512 | Cost: 0.29182880713390214 | Gradient: [[ 0.02857782]\n",
      " [-0.05264731]\n",
      " [ 0.08928393]]\n",
      "Iteration 8513 | Cost: 0.2918172474626225 | Gradient: [[ 0.02857677]\n",
      " [-0.0526442 ]\n",
      " [ 0.08927759]]\n",
      "Iteration 8514 | Cost: 0.29180568931073847 | Gradient: [[ 0.02857571]\n",
      " [-0.05264109]\n",
      " [ 0.08927125]]\n",
      "Iteration 8515 | Cost: 0.29179413267796145 | Gradient: [[ 0.02857465]\n",
      " [-0.05263798]\n",
      " [ 0.08926492]]\n",
      "Iteration 8516 | Cost: 0.29178257756400294 | Gradient: [[ 0.0285736 ]\n",
      " [-0.05263488]\n",
      " [ 0.08925858]]\n",
      "Iteration 8517 | Cost: 0.29177102396857474 | Gradient: [[ 0.02857254]\n",
      " [-0.05263177]\n",
      " [ 0.08925225]]\n",
      "Iteration 8518 | Cost: 0.29175947189138846 | Gradient: [[ 0.02857148]\n",
      " [-0.05262867]\n",
      " [ 0.08924591]]\n",
      "Iteration 8519 | Cost: 0.2917479213321558 | Gradient: [[ 0.02857043]\n",
      " [-0.05262556]\n",
      " [ 0.08923958]]\n",
      "Iteration 8520 | Cost: 0.29173637229058874 | Gradient: [[ 0.02856937]\n",
      " [-0.05262246]\n",
      " [ 0.08923324]]\n",
      "Iteration 8521 | Cost: 0.29172482476639905 | Gradient: [[ 0.02856831]\n",
      " [-0.05261935]\n",
      " [ 0.08922691]]\n",
      "Iteration 8522 | Cost: 0.2917132787592988 | Gradient: [[ 0.02856725]\n",
      " [-0.05261625]\n",
      " [ 0.08922058]]\n",
      "Iteration 8523 | Cost: 0.291701734269 | Gradient: [[ 0.0285662 ]\n",
      " [-0.05261314]\n",
      " [ 0.08921425]]\n",
      "Iteration 8524 | Cost: 0.29169019129521473 | Gradient: [[ 0.02856514]\n",
      " [-0.05261004]\n",
      " [ 0.08920792]]\n",
      "Iteration 8525 | Cost: 0.2916786498376553 | Gradient: [[ 0.02856408]\n",
      " [-0.05260694]\n",
      " [ 0.08920159]]\n",
      "Iteration 8526 | Cost: 0.29166710989603384 | Gradient: [[ 0.02856302]\n",
      " [-0.05260384]\n",
      " [ 0.08919526]]\n",
      "Iteration 8527 | Cost: 0.29165557147006277 | Gradient: [[ 0.02856197]\n",
      " [-0.05260074]\n",
      " [ 0.08918893]]\n",
      "Iteration 8528 | Cost: 0.29164403455945437 | Gradient: [[ 0.02856091]\n",
      " [-0.05259764]\n",
      " [ 0.08918261]]\n",
      "Iteration 8529 | Cost: 0.29163249916392125 | Gradient: [[ 0.02855985]\n",
      " [-0.05259454]\n",
      " [ 0.08917628]]\n",
      "Iteration 8530 | Cost: 0.2916209652831759 | Gradient: [[ 0.02855879]\n",
      " [-0.05259144]\n",
      " [ 0.08916995]]\n",
      "Iteration 8531 | Cost: 0.29160943291693087 | Gradient: [[ 0.02855773]\n",
      " [-0.05258834]\n",
      " [ 0.08916363]]\n",
      "Iteration 8532 | Cost: 0.29159790206489883 | Gradient: [[ 0.02855668]\n",
      " [-0.05258524]\n",
      " [ 0.08915731]]\n",
      "Iteration 8533 | Cost: 0.2915863727267927 | Gradient: [[ 0.02855562]\n",
      " [-0.05258214]\n",
      " [ 0.08915098]]\n",
      "Iteration 8534 | Cost: 0.29157484490232516 | Gradient: [[ 0.02855456]\n",
      " [-0.05257905]\n",
      " [ 0.08914466]]\n",
      "Iteration 8535 | Cost: 0.2915633185912091 | Gradient: [[ 0.0285535 ]\n",
      " [-0.05257595]\n",
      " [ 0.08913834]]\n",
      "Iteration 8536 | Cost: 0.29155179379315743 | Gradient: [[ 0.02855244]\n",
      " [-0.05257286]\n",
      " [ 0.08913202]]\n",
      "Iteration 8537 | Cost: 0.2915402705078834 | Gradient: [[ 0.02855138]\n",
      " [-0.05256976]\n",
      " [ 0.0891257 ]]\n",
      "Iteration 8538 | Cost: 0.2915287487350999 | Gradient: [[ 0.02855033]\n",
      " [-0.05256667]\n",
      " [ 0.08911938]]\n",
      "Iteration 8539 | Cost: 0.2915172284745202 | Gradient: [[ 0.02854927]\n",
      " [-0.05256357]\n",
      " [ 0.08911306]]\n",
      "Iteration 8540 | Cost: 0.29150570972585743 | Gradient: [[ 0.02854821]\n",
      " [-0.05256048]\n",
      " [ 0.08910674]]\n",
      "Iteration 8541 | Cost: 0.29149419248882497 | Gradient: [[ 0.02854715]\n",
      " [-0.05255738]\n",
      " [ 0.08910042]]\n",
      "Iteration 8542 | Cost: 0.2914826767631363 | Gradient: [[ 0.02854609]\n",
      " [-0.05255429]\n",
      " [ 0.0890941 ]]\n",
      "Iteration 8543 | Cost: 0.2914711625485047 | Gradient: [[ 0.02854503]\n",
      " [-0.0525512 ]\n",
      " [ 0.08908779]]\n",
      "Iteration 8544 | Cost: 0.2914596498446438 | Gradient: [[ 0.02854397]\n",
      " [-0.05254811]\n",
      " [ 0.08908147]]\n",
      "Iteration 8545 | Cost: 0.29144813865126706 | Gradient: [[ 0.02854291]\n",
      " [-0.05254502]\n",
      " [ 0.08907516]]\n",
      "Iteration 8546 | Cost: 0.2914366289680883 | Gradient: [[ 0.02854185]\n",
      " [-0.05254193]\n",
      " [ 0.08906884]]\n",
      "Iteration 8547 | Cost: 0.29142512079482125 | Gradient: [[ 0.02854079]\n",
      " [-0.05253884]\n",
      " [ 0.08906253]]\n",
      "Iteration 8548 | Cost: 0.2914136141311795 | Gradient: [[ 0.02853973]\n",
      " [-0.05253575]\n",
      " [ 0.08905622]]\n",
      "Iteration 8549 | Cost: 0.29140210897687713 | Gradient: [[ 0.02853867]\n",
      " [-0.05253266]\n",
      " [ 0.08904991]]\n",
      "Iteration 8550 | Cost: 0.29139060533162797 | Gradient: [[ 0.02853761]\n",
      " [-0.05252957]\n",
      " [ 0.0890436 ]]\n",
      "Iteration 8551 | Cost: 0.2913791031951461 | Gradient: [[ 0.02853656]\n",
      " [-0.05252649]\n",
      " [ 0.08903729]]\n",
      "Iteration 8552 | Cost: 0.2913676025671455 | Gradient: [[ 0.0285355 ]\n",
      " [-0.0525234 ]\n",
      " [ 0.08903098]]\n",
      "Iteration 8553 | Cost: 0.2913561034473404 | Gradient: [[ 0.02853444]\n",
      " [-0.05252031]\n",
      " [ 0.08902467]]\n",
      "Iteration 8554 | Cost: 0.2913446058354451 | Gradient: [[ 0.02853338]\n",
      " [-0.05251723]\n",
      " [ 0.08901836]]\n",
      "Iteration 8555 | Cost: 0.29133310973117366 | Gradient: [[ 0.02853232]\n",
      " [-0.05251414]\n",
      " [ 0.08901205]]\n",
      "Iteration 8556 | Cost: 0.2913216151342406 | Gradient: [[ 0.02853125]\n",
      " [-0.05251106]\n",
      " [ 0.08900575]]\n",
      "Iteration 8557 | Cost: 0.2913101220443603 | Gradient: [[ 0.02853019]\n",
      " [-0.05250797]\n",
      " [ 0.08899944]]\n",
      "Iteration 8558 | Cost: 0.29129863046124715 | Gradient: [[ 0.02852913]\n",
      " [-0.05250489]\n",
      " [ 0.08899314]]\n",
      "Iteration 8559 | Cost: 0.29128714038461595 | Gradient: [[ 0.02852807]\n",
      " [-0.05250181]\n",
      " [ 0.08898683]]\n",
      "Iteration 8560 | Cost: 0.2912756518141812 | Gradient: [[ 0.02852701]\n",
      " [-0.05249872]\n",
      " [ 0.08898053]]\n",
      "Iteration 8561 | Cost: 0.29126416474965755 | Gradient: [[ 0.02852595]\n",
      " [-0.05249564]\n",
      " [ 0.08897423]]\n",
      "Iteration 8562 | Cost: 0.2912526791907598 | Gradient: [[ 0.02852489]\n",
      " [-0.05249256]\n",
      " [ 0.08896792]]\n",
      "Iteration 8563 | Cost: 0.2912411951372029 | Gradient: [[ 0.02852383]\n",
      " [-0.05248948]\n",
      " [ 0.08896162]]\n",
      "Iteration 8564 | Cost: 0.2912297125887017 | Gradient: [[ 0.02852277]\n",
      " [-0.0524864 ]\n",
      " [ 0.08895532]]\n",
      "Iteration 8565 | Cost: 0.2912182315449711 | Gradient: [[ 0.02852171]\n",
      " [-0.05248332]\n",
      " [ 0.08894902]]\n",
      "Iteration 8566 | Cost: 0.2912067520057262 | Gradient: [[ 0.02852065]\n",
      " [-0.05248024]\n",
      " [ 0.08894272]]\n",
      "Iteration 8567 | Cost: 0.2911952739706822 | Gradient: [[ 0.02851959]\n",
      " [-0.05247716]\n",
      " [ 0.08893643]]\n",
      "Iteration 8568 | Cost: 0.2911837974395542 | Gradient: [[ 0.02851853]\n",
      " [-0.05247408]\n",
      " [ 0.08893013]]\n",
      "Iteration 8569 | Cost: 0.2911723224120575 | Gradient: [[ 0.02851747]\n",
      " [-0.05247101]\n",
      " [ 0.08892383]]\n",
      "Iteration 8570 | Cost: 0.29116084888790733 | Gradient: [[ 0.0285164 ]\n",
      " [-0.05246793]\n",
      " [ 0.08891753]]\n",
      "Iteration 8571 | Cost: 0.29114937686681924 | Gradient: [[ 0.02851534]\n",
      " [-0.05246485]\n",
      " [ 0.08891124]]\n",
      "Iteration 8572 | Cost: 0.2911379063485086 | Gradient: [[ 0.02851428]\n",
      " [-0.05246178]\n",
      " [ 0.08890494]]\n",
      "Iteration 8573 | Cost: 0.29112643733269106 | Gradient: [[ 0.02851322]\n",
      " [-0.0524587 ]\n",
      " [ 0.08889865]]\n",
      "Iteration 8574 | Cost: 0.2911149698190821 | Gradient: [[ 0.02851216]\n",
      " [-0.05245563]\n",
      " [ 0.08889236]]\n",
      "Iteration 8575 | Cost: 0.29110350380739736 | Gradient: [[ 0.0285111 ]\n",
      " [-0.05245255]\n",
      " [ 0.08888607]]\n",
      "Iteration 8576 | Cost: 0.2910920392973527 | Gradient: [[ 0.02851003]\n",
      " [-0.05244948]\n",
      " [ 0.08887977]]\n",
      "Iteration 8577 | Cost: 0.2910805762886639 | Gradient: [[ 0.02850897]\n",
      " [-0.05244641]\n",
      " [ 0.08887348]]\n",
      "Iteration 8578 | Cost: 0.29106911478104686 | Gradient: [[ 0.02850791]\n",
      " [-0.05244333]\n",
      " [ 0.08886719]]\n",
      "Iteration 8579 | Cost: 0.29105765477421747 | Gradient: [[ 0.02850685]\n",
      " [-0.05244026]\n",
      " [ 0.0888609 ]]\n",
      "Iteration 8580 | Cost: 0.29104619626789174 | Gradient: [[ 0.02850579]\n",
      " [-0.05243719]\n",
      " [ 0.08885461]]\n",
      "Iteration 8581 | Cost: 0.29103473926178586 | Gradient: [[ 0.02850472]\n",
      " [-0.05243412]\n",
      " [ 0.08884833]]\n",
      "Iteration 8582 | Cost: 0.29102328375561587 | Gradient: [[ 0.02850366]\n",
      " [-0.05243105]\n",
      " [ 0.08884204]]\n",
      "Iteration 8583 | Cost: 0.29101182974909806 | Gradient: [[ 0.0285026 ]\n",
      " [-0.05242798]\n",
      " [ 0.08883575]]\n",
      "Iteration 8584 | Cost: 0.29100037724194877 | Gradient: [[ 0.02850154]\n",
      " [-0.05242491]\n",
      " [ 0.08882947]]\n",
      "Iteration 8585 | Cost: 0.29098892623388434 | Gradient: [[ 0.02850047]\n",
      " [-0.05242184]\n",
      " [ 0.08882318]]\n",
      "Iteration 8586 | Cost: 0.2909774767246211 | Gradient: [[ 0.02849941]\n",
      " [-0.05241877]\n",
      " [ 0.0888169 ]]\n",
      "Iteration 8587 | Cost: 0.29096602871387567 | Gradient: [[ 0.02849835]\n",
      " [-0.0524157 ]\n",
      " [ 0.08881061]]\n",
      "Iteration 8588 | Cost: 0.2909545822013646 | Gradient: [[ 0.02849729]\n",
      " [-0.05241264]\n",
      " [ 0.08880433]]\n",
      "Iteration 8589 | Cost: 0.2909431371868045 | Gradient: [[ 0.02849622]\n",
      " [-0.05240957]\n",
      " [ 0.08879805]]\n",
      "Iteration 8590 | Cost: 0.2909316936699121 | Gradient: [[ 0.02849516]\n",
      " [-0.0524065 ]\n",
      " [ 0.08879177]]\n",
      "Iteration 8591 | Cost: 0.29092025165040425 | Gradient: [[ 0.0284941 ]\n",
      " [-0.05240344]\n",
      " [ 0.08878549]]\n",
      "Iteration 8592 | Cost: 0.29090881112799766 | Gradient: [[ 0.02849303]\n",
      " [-0.05240037]\n",
      " [ 0.08877921]]\n",
      "Iteration 8593 | Cost: 0.29089737210240924 | Gradient: [[ 0.02849197]\n",
      " [-0.05239731]\n",
      " [ 0.08877293]]\n",
      "Iteration 8594 | Cost: 0.29088593457335615 | Gradient: [[ 0.02849091]\n",
      " [-0.05239425]\n",
      " [ 0.08876665]]\n",
      "Iteration 8595 | Cost: 0.2908744985405553 | Gradient: [[ 0.02848984]\n",
      " [-0.05239118]\n",
      " [ 0.08876037]]\n",
      "Iteration 8596 | Cost: 0.29086306400372386 | Gradient: [[ 0.02848878]\n",
      " [-0.05238812]\n",
      " [ 0.08875409]]\n",
      "Iteration 8597 | Cost: 0.290851630962579 | Gradient: [[ 0.02848772]\n",
      " [-0.05238506]\n",
      " [ 0.08874782]]\n",
      "Iteration 8598 | Cost: 0.29084019941683803 | Gradient: [[ 0.02848665]\n",
      " [-0.052382  ]\n",
      " [ 0.08874154]]\n",
      "Iteration 8599 | Cost: 0.2908287693662181 | Gradient: [[ 0.02848559]\n",
      " [-0.05237893]\n",
      " [ 0.08873527]]\n",
      "Iteration 8600 | Cost: 0.2908173408104369 | Gradient: [[ 0.02848453]\n",
      " [-0.05237587]\n",
      " [ 0.08872899]]\n",
      "Iteration 8601 | Cost: 0.2908059137492117 | Gradient: [[ 0.02848346]\n",
      " [-0.05237281]\n",
      " [ 0.08872272]]\n",
      "Iteration 8602 | Cost: 0.2907944881822601 | Gradient: [[ 0.0284824 ]\n",
      " [-0.05236975]\n",
      " [ 0.08871645]]\n",
      "Iteration 8603 | Cost: 0.2907830641092996 | Gradient: [[ 0.02848133]\n",
      " [-0.0523667 ]\n",
      " [ 0.08871018]]\n",
      "Iteration 8604 | Cost: 0.2907716415300481 | Gradient: [[ 0.02848027]\n",
      " [-0.05236364]\n",
      " [ 0.08870391]]\n",
      "Iteration 8605 | Cost: 0.2907602204442231 | Gradient: [[ 0.02847921]\n",
      " [-0.05236058]\n",
      " [ 0.08869763]]\n",
      "Iteration 8606 | Cost: 0.2907488008515426 | Gradient: [[ 0.02847814]\n",
      " [-0.05235752]\n",
      " [ 0.08869137]]\n",
      "Iteration 8607 | Cost: 0.2907373827517242 | Gradient: [[ 0.02847708]\n",
      " [-0.05235447]\n",
      " [ 0.0886851 ]]\n",
      "Iteration 8608 | Cost: 0.29072596614448615 | Gradient: [[ 0.02847601]\n",
      " [-0.05235141]\n",
      " [ 0.08867883]]\n",
      "Iteration 8609 | Cost: 0.2907145510295464 | Gradient: [[ 0.02847495]\n",
      " [-0.05234835]\n",
      " [ 0.08867256]]\n",
      "Iteration 8610 | Cost: 0.2907031374066229 | Gradient: [[ 0.02847388]\n",
      " [-0.0523453 ]\n",
      " [ 0.08866629]]\n",
      "Iteration 8611 | Cost: 0.2906917252754339 | Gradient: [[ 0.02847282]\n",
      " [-0.05234224]\n",
      " [ 0.08866003]]\n",
      "Iteration 8612 | Cost: 0.29068031463569766 | Gradient: [[ 0.02847176]\n",
      " [-0.05233919]\n",
      " [ 0.08865376]]\n",
      "Iteration 8613 | Cost: 0.2906689054871323 | Gradient: [[ 0.02847069]\n",
      " [-0.05233614]\n",
      " [ 0.0886475 ]]\n",
      "Iteration 8614 | Cost: 0.29065749782945627 | Gradient: [[ 0.02846963]\n",
      " [-0.05233308]\n",
      " [ 0.08864123]]\n",
      "Iteration 8615 | Cost: 0.29064609166238814 | Gradient: [[ 0.02846856]\n",
      " [-0.05233003]\n",
      " [ 0.08863497]]\n",
      "Iteration 8616 | Cost: 0.29063468698564615 | Gradient: [[ 0.0284675 ]\n",
      " [-0.05232698]\n",
      " [ 0.08862871]]\n",
      "Iteration 8617 | Cost: 0.29062328379894903 | Gradient: [[ 0.02846643]\n",
      " [-0.05232393]\n",
      " [ 0.08862245]]\n",
      "Iteration 8618 | Cost: 0.2906118821020154 | Gradient: [[ 0.02846537]\n",
      " [-0.05232088]\n",
      " [ 0.08861619]]\n",
      "Iteration 8619 | Cost: 0.29060048189456383 | Gradient: [[ 0.0284643 ]\n",
      " [-0.05231783]\n",
      " [ 0.08860993]]\n",
      "Iteration 8620 | Cost: 0.2905890831763132 | Gradient: [[ 0.02846324]\n",
      " [-0.05231478]\n",
      " [ 0.08860367]]\n",
      "Iteration 8621 | Cost: 0.29057768594698247 | Gradient: [[ 0.02846217]\n",
      " [-0.05231173]\n",
      " [ 0.08859741]]\n",
      "Iteration 8622 | Cost: 0.29056629020629027 | Gradient: [[ 0.0284611 ]\n",
      " [-0.05230868]\n",
      " [ 0.08859115]]\n",
      "Iteration 8623 | Cost: 0.2905548959539557 | Gradient: [[ 0.02846004]\n",
      " [-0.05230563]\n",
      " [ 0.08858489]]\n",
      "Iteration 8624 | Cost: 0.2905435031896979 | Gradient: [[ 0.02845897]\n",
      " [-0.05230258]\n",
      " [ 0.08857864]]\n",
      "Iteration 8625 | Cost: 0.2905321119132358 | Gradient: [[ 0.02845791]\n",
      " [-0.05229954]\n",
      " [ 0.08857238]]\n",
      "Iteration 8626 | Cost: 0.29052072212428864 | Gradient: [[ 0.02845684]\n",
      " [-0.05229649]\n",
      " [ 0.08856613]]\n",
      "Iteration 8627 | Cost: 0.2905093338225757 | Gradient: [[ 0.02845578]\n",
      " [-0.05229344]\n",
      " [ 0.08855987]]\n",
      "Iteration 8628 | Cost: 0.2904979470078163 | Gradient: [[ 0.02845471]\n",
      " [-0.0522904 ]\n",
      " [ 0.08855362]]\n",
      "Iteration 8629 | Cost: 0.29048656167972975 | Gradient: [[ 0.02845364]\n",
      " [-0.05228735]\n",
      " [ 0.08854737]]\n",
      "Iteration 8630 | Cost: 0.2904751778380355 | Gradient: [[ 0.02845258]\n",
      " [-0.05228431]\n",
      " [ 0.08854111]]\n",
      "Iteration 8631 | Cost: 0.29046379548245316 | Gradient: [[ 0.02845151]\n",
      " [-0.05228126]\n",
      " [ 0.08853486]]\n",
      "Iteration 8632 | Cost: 0.29045241461270227 | Gradient: [[ 0.02845045]\n",
      " [-0.05227822]\n",
      " [ 0.08852861]]\n",
      "Iteration 8633 | Cost: 0.2904410352285024 | Gradient: [[ 0.02844938]\n",
      " [-0.05227518]\n",
      " [ 0.08852236]]\n",
      "Iteration 8634 | Cost: 0.2904296573295734 | Gradient: [[ 0.02844831]\n",
      " [-0.05227214]\n",
      " [ 0.08851611]]\n",
      "Iteration 8635 | Cost: 0.29041828091563504 | Gradient: [[ 0.02844725]\n",
      " [-0.05226909]\n",
      " [ 0.08850987]]\n",
      "Iteration 8636 | Cost: 0.29040690598640706 | Gradient: [[ 0.02844618]\n",
      " [-0.05226605]\n",
      " [ 0.08850362]]\n",
      "Iteration 8637 | Cost: 0.2903955325416095 | Gradient: [[ 0.02844511]\n",
      " [-0.05226301]\n",
      " [ 0.08849737]]\n",
      "Iteration 8638 | Cost: 0.29038416058096234 | Gradient: [[ 0.02844405]\n",
      " [-0.05225997]\n",
      " [ 0.08849112]]\n",
      "Iteration 8639 | Cost: 0.2903727901041855 | Gradient: [[ 0.02844298]\n",
      " [-0.05225693]\n",
      " [ 0.08848488]]\n",
      "Iteration 8640 | Cost: 0.2903614211109993 | Gradient: [[ 0.02844191]\n",
      " [-0.05225389]\n",
      " [ 0.08847863]]\n",
      "Iteration 8641 | Cost: 0.2903500536011238 | Gradient: [[ 0.02844085]\n",
      " [-0.05225086]\n",
      " [ 0.08847239]]\n",
      "Iteration 8642 | Cost: 0.2903386875742794 | Gradient: [[ 0.02843978]\n",
      " [-0.05224782]\n",
      " [ 0.08846615]]\n",
      "Iteration 8643 | Cost: 0.2903273230301863 | Gradient: [[ 0.02843871]\n",
      " [-0.05224478]\n",
      " [ 0.08845991]]\n",
      "Iteration 8644 | Cost: 0.29031595996856496 | Gradient: [[ 0.02843765]\n",
      " [-0.05224174]\n",
      " [ 0.08845366]]\n",
      "Iteration 8645 | Cost: 0.29030459838913586 | Gradient: [[ 0.02843658]\n",
      " [-0.05223871]\n",
      " [ 0.08844742]]\n",
      "Iteration 8646 | Cost: 0.29029323829161946 | Gradient: [[ 0.02843551]\n",
      " [-0.05223567]\n",
      " [ 0.08844118]]\n",
      "Iteration 8647 | Cost: 0.29028187967573643 | Gradient: [[ 0.02843444]\n",
      " [-0.05223264]\n",
      " [ 0.08843494]]\n",
      "Iteration 8648 | Cost: 0.29027052254120744 | Gradient: [[ 0.02843338]\n",
      " [-0.0522296 ]\n",
      " [ 0.0884287 ]]\n",
      "Iteration 8649 | Cost: 0.29025916688775316 | Gradient: [[ 0.02843231]\n",
      " [-0.05222657]\n",
      " [ 0.08842247]]\n",
      "Iteration 8650 | Cost: 0.2902478127150945 | Gradient: [[ 0.02843124]\n",
      " [-0.05222353]\n",
      " [ 0.08841623]]\n",
      "Iteration 8651 | Cost: 0.29023646002295234 | Gradient: [[ 0.02843017]\n",
      " [-0.0522205 ]\n",
      " [ 0.08840999]]\n",
      "Iteration 8652 | Cost: 0.2902251088110474 | Gradient: [[ 0.02842911]\n",
      " [-0.05221747]\n",
      " [ 0.08840376]]\n",
      "Iteration 8653 | Cost: 0.2902137590791009 | Gradient: [[ 0.02842804]\n",
      " [-0.05221443]\n",
      " [ 0.08839752]]\n",
      "Iteration 8654 | Cost: 0.2902024108268339 | Gradient: [[ 0.02842697]\n",
      " [-0.0522114 ]\n",
      " [ 0.08839129]]\n",
      "Iteration 8655 | Cost: 0.29019106405396744 | Gradient: [[ 0.0284259 ]\n",
      " [-0.05220837]\n",
      " [ 0.08838505]]\n",
      "Iteration 8656 | Cost: 0.2901797187602229 | Gradient: [[ 0.02842484]\n",
      " [-0.05220534]\n",
      " [ 0.08837882]]\n",
      "Iteration 8657 | Cost: 0.2901683749453214 | Gradient: [[ 0.02842377]\n",
      " [-0.05220231]\n",
      " [ 0.08837259]]\n",
      "Iteration 8658 | Cost: 0.2901570326089843 | Gradient: [[ 0.0284227 ]\n",
      " [-0.05219928]\n",
      " [ 0.08836636]]\n",
      "Iteration 8659 | Cost: 0.2901456917509331 | Gradient: [[ 0.02842163]\n",
      " [-0.05219625]\n",
      " [ 0.08836012]]\n",
      "Iteration 8660 | Cost: 0.29013435237088914 | Gradient: [[ 0.02842056]\n",
      " [-0.05219322]\n",
      " [ 0.08835389]]\n",
      "Iteration 8661 | Cost: 0.2901230144685742 | Gradient: [[ 0.02841949]\n",
      " [-0.0521902 ]\n",
      " [ 0.08834767]]\n",
      "Iteration 8662 | Cost: 0.29011167804370963 | Gradient: [[ 0.02841843]\n",
      " [-0.05218717]\n",
      " [ 0.08834144]]\n",
      "Iteration 8663 | Cost: 0.2901003430960173 | Gradient: [[ 0.02841736]\n",
      " [-0.05218414]\n",
      " [ 0.08833521]]\n",
      "Iteration 8664 | Cost: 0.2900890096252189 | Gradient: [[ 0.02841629]\n",
      " [-0.05218112]\n",
      " [ 0.08832898]]\n",
      "Iteration 8665 | Cost: 0.29007767763103626 | Gradient: [[ 0.02841522]\n",
      " [-0.05217809]\n",
      " [ 0.08832276]]\n",
      "Iteration 8666 | Cost: 0.2900663471131912 | Gradient: [[ 0.02841415]\n",
      " [-0.05217506]\n",
      " [ 0.08831653]]\n",
      "Iteration 8667 | Cost: 0.29005501807140577 | Gradient: [[ 0.02841308]\n",
      " [-0.05217204]\n",
      " [ 0.0883103 ]]\n",
      "Iteration 8668 | Cost: 0.29004369050540185 | Gradient: [[ 0.02841201]\n",
      " [-0.05216902]\n",
      " [ 0.08830408]]\n",
      "Iteration 8669 | Cost: 0.2900323644149017 | Gradient: [[ 0.02841094]\n",
      " [-0.05216599]\n",
      " [ 0.08829786]]\n",
      "Iteration 8670 | Cost: 0.2900210397996274 | Gradient: [[ 0.02840988]\n",
      " [-0.05216297]\n",
      " [ 0.08829163]]\n",
      "Iteration 8671 | Cost: 0.29000971665930114 | Gradient: [[ 0.02840881]\n",
      " [-0.05215995]\n",
      " [ 0.08828541]]\n",
      "Iteration 8672 | Cost: 0.2899983949936452 | Gradient: [[ 0.02840774]\n",
      " [-0.05215692]\n",
      " [ 0.08827919]]\n",
      "Iteration 8673 | Cost: 0.289987074802382 | Gradient: [[ 0.02840667]\n",
      " [-0.0521539 ]\n",
      " [ 0.08827297]]\n",
      "Iteration 8674 | Cost: 0.2899757560852339 | Gradient: [[ 0.0284056 ]\n",
      " [-0.05215088]\n",
      " [ 0.08826675]]\n",
      "Iteration 8675 | Cost: 0.28996443884192347 | Gradient: [[ 0.02840453]\n",
      " [-0.05214786]\n",
      " [ 0.08826053]]\n",
      "Iteration 8676 | Cost: 0.2899531230721732 | Gradient: [[ 0.02840346]\n",
      " [-0.05214484]\n",
      " [ 0.08825431]]\n",
      "Iteration 8677 | Cost: 0.2899418087757057 | Gradient: [[ 0.02840239]\n",
      " [-0.05214182]\n",
      " [ 0.08824809]]\n",
      "Iteration 8678 | Cost: 0.28993049595224374 | Gradient: [[ 0.02840132]\n",
      " [-0.0521388 ]\n",
      " [ 0.08824188]]\n",
      "Iteration 8679 | Cost: 0.28991918460151 | Gradient: [[ 0.02840025]\n",
      " [-0.05213578]\n",
      " [ 0.08823566]]\n",
      "Iteration 8680 | Cost: 0.2899078747232272 | Gradient: [[ 0.02839918]\n",
      " [-0.05213277]\n",
      " [ 0.08822945]]\n",
      "Iteration 8681 | Cost: 0.2898965663171186 | Gradient: [[ 0.02839811]\n",
      " [-0.05212975]\n",
      " [ 0.08822323]]\n",
      "Iteration 8682 | Cost: 0.28988525938290677 | Gradient: [[ 0.02839704]\n",
      " [-0.05212673]\n",
      " [ 0.08821702]]\n",
      "Iteration 8683 | Cost: 0.289873953920315 | Gradient: [[ 0.02839597]\n",
      " [-0.05212372]\n",
      " [ 0.0882108 ]]\n",
      "Iteration 8684 | Cost: 0.28986264992906613 | Gradient: [[ 0.0283949 ]\n",
      " [-0.0521207 ]\n",
      " [ 0.08820459]]\n",
      "Iteration 8685 | Cost: 0.2898513474088836 | Gradient: [[ 0.02839383]\n",
      " [-0.05211769]\n",
      " [ 0.08819838]]\n",
      "Iteration 8686 | Cost: 0.28984004635949046 | Gradient: [[ 0.02839276]\n",
      " [-0.05211467]\n",
      " [ 0.08819217]]\n",
      "Iteration 8687 | Cost: 0.28982874678061 | Gradient: [[ 0.02839169]\n",
      " [-0.05211166]\n",
      " [ 0.08818596]]\n",
      "Iteration 8688 | Cost: 0.2898174486719656 | Gradient: [[ 0.02839062]\n",
      " [-0.05210864]\n",
      " [ 0.08817975]]\n",
      "Iteration 8689 | Cost: 0.2898061520332808 | Gradient: [[ 0.02838955]\n",
      " [-0.05210563]\n",
      " [ 0.08817354]]\n",
      "Iteration 8690 | Cost: 0.289794856864279 | Gradient: [[ 0.02838848]\n",
      " [-0.05210262]\n",
      " [ 0.08816733]]\n",
      "Iteration 8691 | Cost: 0.28978356316468373 | Gradient: [[ 0.02838741]\n",
      " [-0.0520996 ]\n",
      " [ 0.08816112]]\n",
      "Iteration 8692 | Cost: 0.2897722709342187 | Gradient: [[ 0.02838634]\n",
      " [-0.05209659]\n",
      " [ 0.08815492]]\n",
      "Iteration 8693 | Cost: 0.2897609801726075 | Gradient: [[ 0.02838527]\n",
      " [-0.05209358]\n",
      " [ 0.08814871]]\n",
      "Iteration 8694 | Cost: 0.28974969087957403 | Gradient: [[ 0.0283842 ]\n",
      " [-0.05209057]\n",
      " [ 0.08814251]]\n",
      "Iteration 8695 | Cost: 0.28973840305484194 | Gradient: [[ 0.02838313]\n",
      " [-0.05208756]\n",
      " [ 0.0881363 ]]\n",
      "Iteration 8696 | Cost: 0.28972711669813533 | Gradient: [[ 0.02838206]\n",
      " [-0.05208455]\n",
      " [ 0.0881301 ]]\n",
      "Iteration 8697 | Cost: 0.289715831809178 | Gradient: [[ 0.02838099]\n",
      " [-0.05208154]\n",
      " [ 0.08812389]]\n",
      "Iteration 8698 | Cost: 0.2897045483876941 | Gradient: [[ 0.02837992]\n",
      " [-0.05207853]\n",
      " [ 0.08811769]]\n",
      "Iteration 8699 | Cost: 0.2896932664334076 | Gradient: [[ 0.02837884]\n",
      " [-0.05207553]\n",
      " [ 0.08811149]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8700 | Cost: 0.28968198594604266 | Gradient: [[ 0.02837777]\n",
      " [-0.05207252]\n",
      " [ 0.08810529]]\n",
      "Iteration 8701 | Cost: 0.2896707069253237 | Gradient: [[ 0.0283767 ]\n",
      " [-0.05206951]\n",
      " [ 0.08809909]]\n",
      "Iteration 8702 | Cost: 0.2896594293709749 | Gradient: [[ 0.02837563]\n",
      " [-0.05206651]\n",
      " [ 0.08809289]]\n",
      "Iteration 8703 | Cost: 0.2896481532827205 | Gradient: [[ 0.02837456]\n",
      " [-0.0520635 ]\n",
      " [ 0.08808669]]\n",
      "Iteration 8704 | Cost: 0.2896368786602851 | Gradient: [[ 0.02837349]\n",
      " [-0.05206049]\n",
      " [ 0.08808049]]\n",
      "Iteration 8705 | Cost: 0.2896256055033931 | Gradient: [[ 0.02837242]\n",
      " [-0.05205749]\n",
      " [ 0.0880743 ]]\n",
      "Iteration 8706 | Cost: 0.28961433381176915 | Gradient: [[ 0.02837134]\n",
      " [-0.05205449]\n",
      " [ 0.0880681 ]]\n",
      "Iteration 8707 | Cost: 0.28960306358513777 | Gradient: [[ 0.02837027]\n",
      " [-0.05205148]\n",
      " [ 0.0880619 ]]\n",
      "Iteration 8708 | Cost: 0.28959179482322367 | Gradient: [[ 0.0283692 ]\n",
      " [-0.05204848]\n",
      " [ 0.08805571]]\n",
      "Iteration 8709 | Cost: 0.2895805275257517 | Gradient: [[ 0.02836813]\n",
      " [-0.05204548]\n",
      " [ 0.08804951]]\n",
      "Iteration 8710 | Cost: 0.2895692616924466 | Gradient: [[ 0.02836706]\n",
      " [-0.05204247]\n",
      " [ 0.08804332]]\n",
      "Iteration 8711 | Cost: 0.2895579973230333 | Gradient: [[ 0.02836599]\n",
      " [-0.05203947]\n",
      " [ 0.08803713]]\n",
      "Iteration 8712 | Cost: 0.28954673441723683 | Gradient: [[ 0.02836491]\n",
      " [-0.05203647]\n",
      " [ 0.08803094]]\n",
      "Iteration 8713 | Cost: 0.28953547297478205 | Gradient: [[ 0.02836384]\n",
      " [-0.05203347]\n",
      " [ 0.08802474]]\n",
      "Iteration 8714 | Cost: 0.28952421299539416 | Gradient: [[ 0.02836277]\n",
      " [-0.05203047]\n",
      " [ 0.08801855]]\n",
      "Iteration 8715 | Cost: 0.28951295447879827 | Gradient: [[ 0.0283617 ]\n",
      " [-0.05202747]\n",
      " [ 0.08801236]]\n",
      "Iteration 8716 | Cost: 0.28950169742471976 | Gradient: [[ 0.02836063]\n",
      " [-0.05202447]\n",
      " [ 0.08800617]]\n",
      "Iteration 8717 | Cost: 0.2894904418328838 | Gradient: [[ 0.02835955]\n",
      " [-0.05202147]\n",
      " [ 0.08799999]]\n",
      "Iteration 8718 | Cost: 0.2894791877030157 | Gradient: [[ 0.02835848]\n",
      " [-0.05201847]\n",
      " [ 0.0879938 ]]\n",
      "Iteration 8719 | Cost: 0.28946793503484086 | Gradient: [[ 0.02835741]\n",
      " [-0.05201548]\n",
      " [ 0.08798761]]\n",
      "Iteration 8720 | Cost: 0.2894566838280849 | Gradient: [[ 0.02835634]\n",
      " [-0.05201248]\n",
      " [ 0.08798142]]\n",
      "Iteration 8721 | Cost: 0.2894454340824733 | Gradient: [[ 0.02835526]\n",
      " [-0.05200948]\n",
      " [ 0.08797524]]\n",
      "Iteration 8722 | Cost: 0.2894341857977317 | Gradient: [[ 0.02835419]\n",
      " [-0.05200649]\n",
      " [ 0.08796905]]\n",
      "Iteration 8723 | Cost: 0.2894229389735859 | Gradient: [[ 0.02835312]\n",
      " [-0.05200349]\n",
      " [ 0.08796287]]\n",
      "Iteration 8724 | Cost: 0.28941169360976143 | Gradient: [[ 0.02835205]\n",
      " [-0.0520005 ]\n",
      " [ 0.08795669]]\n",
      "Iteration 8725 | Cost: 0.2894004497059842 | Gradient: [[ 0.02835097]\n",
      " [-0.0519975 ]\n",
      " [ 0.0879505 ]]\n",
      "Iteration 8726 | Cost: 0.28938920726198025 | Gradient: [[ 0.0283499 ]\n",
      " [-0.05199451]\n",
      " [ 0.08794432]]\n",
      "Iteration 8727 | Cost: 0.28937796627747525 | Gradient: [[ 0.02834883]\n",
      " [-0.05199152]\n",
      " [ 0.08793814]]\n",
      "Iteration 8728 | Cost: 0.2893667267521955 | Gradient: [[ 0.02834775]\n",
      " [-0.05198852]\n",
      " [ 0.08793196]]\n",
      "Iteration 8729 | Cost: 0.2893554886858669 | Gradient: [[ 0.02834668]\n",
      " [-0.05198553]\n",
      " [ 0.08792578]]\n",
      "Iteration 8730 | Cost: 0.28934425207821574 | Gradient: [[ 0.02834561]\n",
      " [-0.05198254]\n",
      " [ 0.0879196 ]]\n",
      "Iteration 8731 | Cost: 0.2893330169289682 | Gradient: [[ 0.02834453]\n",
      " [-0.05197955]\n",
      " [ 0.08791342]]\n",
      "Iteration 8732 | Cost: 0.28932178323785035 | Gradient: [[ 0.02834346]\n",
      " [-0.05197656]\n",
      " [ 0.08790724]]\n",
      "Iteration 8733 | Cost: 0.2893105510045889 | Gradient: [[ 0.02834239]\n",
      " [-0.05197357]\n",
      " [ 0.08790107]]\n",
      "Iteration 8734 | Cost: 0.28929932022891003 | Gradient: [[ 0.02834131]\n",
      " [-0.05197058]\n",
      " [ 0.08789489]]\n",
      "Iteration 8735 | Cost: 0.2892880909105402 | Gradient: [[ 0.02834024]\n",
      " [-0.05196759]\n",
      " [ 0.08788872]]\n",
      "Iteration 8736 | Cost: 0.289276863049206 | Gradient: [[ 0.02833917]\n",
      " [-0.0519646 ]\n",
      " [ 0.08788254]]\n",
      "Iteration 8737 | Cost: 0.2892656366446342 | Gradient: [[ 0.02833809]\n",
      " [-0.05196161]\n",
      " [ 0.08787637]]\n",
      "Iteration 8738 | Cost: 0.2892544116965513 | Gradient: [[ 0.02833702]\n",
      " [-0.05195862]\n",
      " [ 0.08787019]]\n",
      "Iteration 8739 | Cost: 0.28924318820468414 | Gradient: [[ 0.02833595]\n",
      " [-0.05195563]\n",
      " [ 0.08786402]]\n",
      "Iteration 8740 | Cost: 0.2892319661687594 | Gradient: [[ 0.02833487]\n",
      " [-0.05195265]\n",
      " [ 0.08785785]]\n",
      "Iteration 8741 | Cost: 0.28922074558850414 | Gradient: [[ 0.0283338 ]\n",
      " [-0.05194966]\n",
      " [ 0.08785168]]\n",
      "Iteration 8742 | Cost: 0.2892095264636452 | Gradient: [[ 0.02833272]\n",
      " [-0.05194668]\n",
      " [ 0.08784551]]\n",
      "Iteration 8743 | Cost: 0.28919830879390956 | Gradient: [[ 0.02833165]\n",
      " [-0.05194369]\n",
      " [ 0.08783934]]\n",
      "Iteration 8744 | Cost: 0.28918709257902436 | Gradient: [[ 0.02833058]\n",
      " [-0.05194071]\n",
      " [ 0.08783317]]\n",
      "Iteration 8745 | Cost: 0.2891758778187167 | Gradient: [[ 0.0283295 ]\n",
      " [-0.05193772]\n",
      " [ 0.087827  ]]\n",
      "Iteration 8746 | Cost: 0.2891646645127138 | Gradient: [[ 0.02832843]\n",
      " [-0.05193474]\n",
      " [ 0.08782083]]\n",
      "Iteration 8747 | Cost: 0.28915345266074294 | Gradient: [[ 0.02832735]\n",
      " [-0.05193175]\n",
      " [ 0.08781467]]\n",
      "Iteration 8748 | Cost: 0.28914224226253143 | Gradient: [[ 0.02832628]\n",
      " [-0.05192877]\n",
      " [ 0.0878085 ]]\n",
      "Iteration 8749 | Cost: 0.2891310333178067 | Gradient: [[ 0.02832521]\n",
      " [-0.05192579]\n",
      " [ 0.08780233]]\n",
      "Iteration 8750 | Cost: 0.2891198258262962 | Gradient: [[ 0.02832413]\n",
      " [-0.05192281]\n",
      " [ 0.08779617]]\n",
      "Iteration 8751 | Cost: 0.28910861978772756 | Gradient: [[ 0.02832306]\n",
      " [-0.05191983]\n",
      " [ 0.08779001]]\n",
      "Iteration 8752 | Cost: 0.2890974152018282 | Gradient: [[ 0.02832198]\n",
      " [-0.05191685]\n",
      " [ 0.08778384]]\n",
      "Iteration 8753 | Cost: 0.28908621206832585 | Gradient: [[ 0.02832091]\n",
      " [-0.05191387]\n",
      " [ 0.08777768]]\n",
      "Iteration 8754 | Cost: 0.28907501038694833 | Gradient: [[ 0.02831983]\n",
      " [-0.05191089]\n",
      " [ 0.08777152]]\n",
      "Iteration 8755 | Cost: 0.2890638101574234 | Gradient: [[ 0.02831876]\n",
      " [-0.05190791]\n",
      " [ 0.08776536]]\n",
      "Iteration 8756 | Cost: 0.2890526113794789 | Gradient: [[ 0.02831768]\n",
      " [-0.05190493]\n",
      " [ 0.0877592 ]]\n",
      "Iteration 8757 | Cost: 0.28904141405284267 | Gradient: [[ 0.02831661]\n",
      " [-0.05190195]\n",
      " [ 0.08775304]]\n",
      "Iteration 8758 | Cost: 0.28903021817724284 | Gradient: [[ 0.02831553]\n",
      " [-0.05189897]\n",
      " [ 0.08774688]]\n",
      "Iteration 8759 | Cost: 0.28901902375240734 | Gradient: [[ 0.02831446]\n",
      " [-0.051896  ]\n",
      " [ 0.08774072]]\n",
      "Iteration 8760 | Cost: 0.28900783077806447 | Gradient: [[ 0.02831338]\n",
      " [-0.05189302]\n",
      " [ 0.08773456]]\n",
      "Iteration 8761 | Cost: 0.28899663925394237 | Gradient: [[ 0.02831231]\n",
      " [-0.05189004]\n",
      " [ 0.08772841]]\n",
      "Iteration 8762 | Cost: 0.28898544917976915 | Gradient: [[ 0.02831123]\n",
      " [-0.05188707]\n",
      " [ 0.08772225]]\n",
      "Iteration 8763 | Cost: 0.2889742605552732 | Gradient: [[ 0.02831016]\n",
      " [-0.05188409]\n",
      " [ 0.08771609]]\n",
      "Iteration 8764 | Cost: 0.288963073380183 | Gradient: [[ 0.02830908]\n",
      " [-0.05188112]\n",
      " [ 0.08770994]]\n",
      "Iteration 8765 | Cost: 0.28895188765422686 | Gradient: [[ 0.02830801]\n",
      " [-0.05187814]\n",
      " [ 0.08770379]]\n",
      "Iteration 8766 | Cost: 0.28894070337713346 | Gradient: [[ 0.02830693]\n",
      " [-0.05187517]\n",
      " [ 0.08769763]]\n",
      "Iteration 8767 | Cost: 0.2889295205486312 | Gradient: [[ 0.02830586]\n",
      " [-0.0518722 ]\n",
      " [ 0.08769148]]\n",
      "Iteration 8768 | Cost: 0.2889183391684489 | Gradient: [[ 0.02830478]\n",
      " [-0.05186923]\n",
      " [ 0.08768533]]\n",
      "Iteration 8769 | Cost: 0.2889071592363151 | Gradient: [[ 0.0283037 ]\n",
      " [-0.05186625]\n",
      " [ 0.08767918]]\n",
      "Iteration 8770 | Cost: 0.2888959807519587 | Gradient: [[ 0.02830263]\n",
      " [-0.05186328]\n",
      " [ 0.08767303]]\n",
      "Iteration 8771 | Cost: 0.28888480371510855 | Gradient: [[ 0.02830155]\n",
      " [-0.05186031]\n",
      " [ 0.08766688]]\n",
      "Iteration 8772 | Cost: 0.28887362812549344 | Gradient: [[ 0.02830048]\n",
      " [-0.05185734]\n",
      " [ 0.08766073]]\n",
      "Iteration 8773 | Cost: 0.28886245398284244 | Gradient: [[ 0.0282994 ]\n",
      " [-0.05185437]\n",
      " [ 0.08765458]]\n",
      "Iteration 8774 | Cost: 0.2888512812868846 | Gradient: [[ 0.02829832]\n",
      " [-0.0518514 ]\n",
      " [ 0.08764843]]\n",
      "Iteration 8775 | Cost: 0.288840110037349 | Gradient: [[ 0.02829725]\n",
      " [-0.05184843]\n",
      " [ 0.08764229]]\n",
      "Iteration 8776 | Cost: 0.28882894023396477 | Gradient: [[ 0.02829617]\n",
      " [-0.05184546]\n",
      " [ 0.08763614]]\n",
      "Iteration 8777 | Cost: 0.2888177718764612 | Gradient: [[ 0.0282951]\n",
      " [-0.0518425]\n",
      " [ 0.08763  ]]\n",
      "Iteration 8778 | Cost: 0.28880660496456756 | Gradient: [[ 0.02829402]\n",
      " [-0.05183953]\n",
      " [ 0.08762385]]\n",
      "Iteration 8779 | Cost: 0.2887954394980132 | Gradient: [[ 0.02829294]\n",
      " [-0.05183656]\n",
      " [ 0.08761771]]\n",
      "Iteration 8780 | Cost: 0.2887842754765276 | Gradient: [[ 0.02829187]\n",
      " [-0.0518336 ]\n",
      " [ 0.08761157]]\n",
      "Iteration 8781 | Cost: 0.28877311289984015 | Gradient: [[ 0.02829079]\n",
      " [-0.05183063]\n",
      " [ 0.08760542]]\n",
      "Iteration 8782 | Cost: 0.2887619517676805 | Gradient: [[ 0.02828971]\n",
      " [-0.05182766]\n",
      " [ 0.08759928]]\n",
      "Iteration 8783 | Cost: 0.2887507920797783 | Gradient: [[ 0.02828864]\n",
      " [-0.0518247 ]\n",
      " [ 0.08759314]]\n",
      "Iteration 8784 | Cost: 0.28873963383586315 | Gradient: [[ 0.02828756]\n",
      " [-0.05182173]\n",
      " [ 0.087587  ]]\n",
      "Iteration 8785 | Cost: 0.2887284770356648 | Gradient: [[ 0.02828648]\n",
      " [-0.05181877]\n",
      " [ 0.08758086]]\n",
      "Iteration 8786 | Cost: 0.28871732167891323 | Gradient: [[ 0.02828541]\n",
      " [-0.05181581]\n",
      " [ 0.08757472]]\n",
      "Iteration 8787 | Cost: 0.2887061677653381 | Gradient: [[ 0.02828433]\n",
      " [-0.05181284]\n",
      " [ 0.08756859]]\n",
      "Iteration 8788 | Cost: 0.28869501529466945 | Gradient: [[ 0.02828325]\n",
      " [-0.05180988]\n",
      " [ 0.08756245]]\n",
      "Iteration 8789 | Cost: 0.28868386426663745 | Gradient: [[ 0.02828218]\n",
      " [-0.05180692]\n",
      " [ 0.08755631]]\n",
      "Iteration 8790 | Cost: 0.28867271468097194 | Gradient: [[ 0.0282811 ]\n",
      " [-0.05180396]\n",
      " [ 0.08755018]]\n",
      "Iteration 8791 | Cost: 0.2886615665374032 | Gradient: [[ 0.02828002]\n",
      " [-0.051801  ]\n",
      " [ 0.08754404]]\n",
      "Iteration 8792 | Cost: 0.28865041983566136 | Gradient: [[ 0.02827895]\n",
      " [-0.05179804]\n",
      " [ 0.08753791]]\n",
      "Iteration 8793 | Cost: 0.2886392745754767 | Gradient: [[ 0.02827787]\n",
      " [-0.05179508]\n",
      " [ 0.08753177]]\n",
      "Iteration 8794 | Cost: 0.2886281307565797 | Gradient: [[ 0.02827679]\n",
      " [-0.05179212]\n",
      " [ 0.08752564]]\n",
      "Iteration 8795 | Cost: 0.28861698837870065 | Gradient: [[ 0.02827571]\n",
      " [-0.05178916]\n",
      " [ 0.08751951]]\n",
      "Iteration 8796 | Cost: 0.2886058474415699 | Gradient: [[ 0.02827464]\n",
      " [-0.0517862 ]\n",
      " [ 0.08751338]]\n",
      "Iteration 8797 | Cost: 0.28859470794491826 | Gradient: [[ 0.02827356]\n",
      " [-0.05178324]\n",
      " [ 0.08750725]]\n",
      "Iteration 8798 | Cost: 0.28858356988847605 | Gradient: [[ 0.02827248]\n",
      " [-0.05178029]\n",
      " [ 0.08750112]]\n",
      "Iteration 8799 | Cost: 0.28857243327197407 | Gradient: [[ 0.0282714 ]\n",
      " [-0.05177733]\n",
      " [ 0.08749499]]\n",
      "Iteration 8800 | Cost: 0.2885612980951431 | Gradient: [[ 0.02827033]\n",
      " [-0.05177437]\n",
      " [ 0.08748886]]\n",
      "Iteration 8801 | Cost: 0.2885501643577138 | Gradient: [[ 0.02826925]\n",
      " [-0.05177142]\n",
      " [ 0.08748273]]\n",
      "Iteration 8802 | Cost: 0.28853903205941706 | Gradient: [[ 0.02826817]\n",
      " [-0.05176846]\n",
      " [ 0.0874766 ]]\n",
      "Iteration 8803 | Cost: 0.2885279011999839 | Gradient: [[ 0.02826709]\n",
      " [-0.05176551]\n",
      " [ 0.08747048]]\n",
      "Iteration 8804 | Cost: 0.28851677177914514 | Gradient: [[ 0.02826602]\n",
      " [-0.05176255]\n",
      " [ 0.08746435]]\n",
      "Iteration 8805 | Cost: 0.28850564379663196 | Gradient: [[ 0.02826494]\n",
      " [-0.0517596 ]\n",
      " [ 0.08745823]]\n",
      "Iteration 8806 | Cost: 0.2884945172521755 | Gradient: [[ 0.02826386]\n",
      " [-0.05175664]\n",
      " [ 0.0874521 ]]\n",
      "Iteration 8807 | Cost: 0.2884833921455068 | Gradient: [[ 0.02826278]\n",
      " [-0.05175369]\n",
      " [ 0.08744598]]\n",
      "Iteration 8808 | Cost: 0.28847226847635715 | Gradient: [[ 0.0282617 ]\n",
      " [-0.05175074]\n",
      " [ 0.08743986]]\n",
      "Iteration 8809 | Cost: 0.28846114624445796 | Gradient: [[ 0.02826063]\n",
      " [-0.05174779]\n",
      " [ 0.08743373]]\n",
      "Iteration 8810 | Cost: 0.28845002544954046 | Gradient: [[ 0.02825955]\n",
      " [-0.05174484]\n",
      " [ 0.08742761]]\n",
      "Iteration 8811 | Cost: 0.2884389060913362 | Gradient: [[ 0.02825847]\n",
      " [-0.05174188]\n",
      " [ 0.08742149]]\n",
      "Iteration 8812 | Cost: 0.2884277881695766 | Gradient: [[ 0.02825739]\n",
      " [-0.05173893]\n",
      " [ 0.08741537]]\n",
      "Iteration 8813 | Cost: 0.28841667168399326 | Gradient: [[ 0.02825631]\n",
      " [-0.05173598]\n",
      " [ 0.08740925]]\n",
      "Iteration 8814 | Cost: 0.28840555663431783 | Gradient: [[ 0.02825523]\n",
      " [-0.05173304]\n",
      " [ 0.08740313]]\n",
      "Iteration 8815 | Cost: 0.288394443020282 | Gradient: [[ 0.02825416]\n",
      " [-0.05173009]\n",
      " [ 0.08739702]]\n",
      "Iteration 8816 | Cost: 0.2883833308416174 | Gradient: [[ 0.02825308]\n",
      " [-0.05172714]\n",
      " [ 0.0873909 ]]\n",
      "Iteration 8817 | Cost: 0.28837222009805613 | Gradient: [[ 0.028252  ]\n",
      " [-0.05172419]\n",
      " [ 0.08738478]]\n",
      "Iteration 8818 | Cost: 0.28836111078932974 | Gradient: [[ 0.02825092]\n",
      " [-0.05172124]\n",
      " [ 0.08737867]]\n",
      "Iteration 8819 | Cost: 0.2883500029151705 | Gradient: [[ 0.02824984]\n",
      " [-0.0517183 ]\n",
      " [ 0.08737255]]\n",
      "Iteration 8820 | Cost: 0.2883388964753102 | Gradient: [[ 0.02824876]\n",
      " [-0.05171535]\n",
      " [ 0.08736644]]\n",
      "Iteration 8821 | Cost: 0.28832779146948107 | Gradient: [[ 0.02824768]\n",
      " [-0.0517124 ]\n",
      " [ 0.08736032]]\n",
      "Iteration 8822 | Cost: 0.28831668789741505 | Gradient: [[ 0.02824661]\n",
      " [-0.05170946]\n",
      " [ 0.08735421]]\n",
      "Iteration 8823 | Cost: 0.2883055857588446 | Gradient: [[ 0.02824553]\n",
      " [-0.05170651]\n",
      " [ 0.0873481 ]]\n",
      "Iteration 8824 | Cost: 0.28829448505350175 | Gradient: [[ 0.02824445]\n",
      " [-0.05170357]\n",
      " [ 0.08734199]]\n",
      "Iteration 8825 | Cost: 0.288283385781119 | Gradient: [[ 0.02824337]\n",
      " [-0.05170062]\n",
      " [ 0.08733588]]\n",
      "Iteration 8826 | Cost: 0.2882722879414288 | Gradient: [[ 0.02824229]\n",
      " [-0.05169768]\n",
      " [ 0.08732977]]\n",
      "Iteration 8827 | Cost: 0.28826119153416346 | Gradient: [[ 0.02824121]\n",
      " [-0.05169474]\n",
      " [ 0.08732366]]\n",
      "Iteration 8828 | Cost: 0.2882500965590556 | Gradient: [[ 0.02824013]\n",
      " [-0.0516918 ]\n",
      " [ 0.08731755]]\n",
      "Iteration 8829 | Cost: 0.28823900301583777 | Gradient: [[ 0.02823905]\n",
      " [-0.05168885]\n",
      " [ 0.08731144]]\n",
      "Iteration 8830 | Cost: 0.28822791090424266 | Gradient: [[ 0.02823797]\n",
      " [-0.05168591]\n",
      " [ 0.08730533]]\n",
      "Iteration 8831 | Cost: 0.288216820224003 | Gradient: [[ 0.02823689]\n",
      " [-0.05168297]\n",
      " [ 0.08729923]]\n",
      "Iteration 8832 | Cost: 0.2882057309748516 | Gradient: [[ 0.02823581]\n",
      " [-0.05168003]\n",
      " [ 0.08729312]]\n",
      "Iteration 8833 | Cost: 0.28819464315652116 | Gradient: [[ 0.02823473]\n",
      " [-0.05167709]\n",
      " [ 0.08728702]]\n",
      "Iteration 8834 | Cost: 0.28818355676874474 | Gradient: [[ 0.02823365]\n",
      " [-0.05167415]\n",
      " [ 0.08728091]]\n",
      "Iteration 8835 | Cost: 0.28817247181125527 | Gradient: [[ 0.02823257]\n",
      " [-0.05167121]\n",
      " [ 0.08727481]]\n",
      "Iteration 8836 | Cost: 0.28816138828378585 | Gradient: [[ 0.02823149]\n",
      " [-0.05166827]\n",
      " [ 0.08726871]]\n",
      "Iteration 8837 | Cost: 0.2881503061860695 | Gradient: [[ 0.02823041]\n",
      " [-0.05166534]\n",
      " [ 0.08726261]]\n",
      "Iteration 8838 | Cost: 0.28813922551783944 | Gradient: [[ 0.02822933]\n",
      " [-0.0516624 ]\n",
      " [ 0.0872565 ]]\n",
      "Iteration 8839 | Cost: 0.28812814627882893 | Gradient: [[ 0.02822825]\n",
      " [-0.05165946]\n",
      " [ 0.0872504 ]]\n",
      "Iteration 8840 | Cost: 0.28811706846877116 | Gradient: [[ 0.02822717]\n",
      " [-0.05165652]\n",
      " [ 0.0872443 ]]\n",
      "Iteration 8841 | Cost: 0.2881059920873996 | Gradient: [[ 0.02822609]\n",
      " [-0.05165359]\n",
      " [ 0.0872382 ]]\n",
      "Iteration 8842 | Cost: 0.2880949171344476 | Gradient: [[ 0.02822501]\n",
      " [-0.05165065]\n",
      " [ 0.08723211]]\n",
      "Iteration 8843 | Cost: 0.2880838436096487 | Gradient: [[ 0.02822393]\n",
      " [-0.05164772]\n",
      " [ 0.08722601]]\n",
      "Iteration 8844 | Cost: 0.2880727715127364 | Gradient: [[ 0.02822285]\n",
      " [-0.05164478]\n",
      " [ 0.08721991]]\n",
      "Iteration 8845 | Cost: 0.28806170084344446 | Gradient: [[ 0.02822177]\n",
      " [-0.05164185]\n",
      " [ 0.08721382]]\n",
      "Iteration 8846 | Cost: 0.28805063160150646 | Gradient: [[ 0.02822069]\n",
      " [-0.05163892]\n",
      " [ 0.08720772]]\n",
      "Iteration 8847 | Cost: 0.28803956378665607 | Gradient: [[ 0.02821961]\n",
      " [-0.05163598]\n",
      " [ 0.08720163]]\n",
      "Iteration 8848 | Cost: 0.2880284973986271 | Gradient: [[ 0.02821853]\n",
      " [-0.05163305]\n",
      " [ 0.08719553]]\n",
      "Iteration 8849 | Cost: 0.2880174324371536 | Gradient: [[ 0.02821745]\n",
      " [-0.05163012]\n",
      " [ 0.08718944]]\n",
      "Iteration 8850 | Cost: 0.28800636890196946 | Gradient: [[ 0.02821637]\n",
      " [-0.05162719]\n",
      " [ 0.08718334]]\n",
      "Iteration 8851 | Cost: 0.2879953067928085 | Gradient: [[ 0.02821529]\n",
      " [-0.05162425]\n",
      " [ 0.08717725]]\n",
      "Iteration 8852 | Cost: 0.28798424610940493 | Gradient: [[ 0.02821421]\n",
      " [-0.05162132]\n",
      " [ 0.08717116]]\n",
      "Iteration 8853 | Cost: 0.28797318685149287 | Gradient: [[ 0.02821313]\n",
      " [-0.05161839]\n",
      " [ 0.08716507]]\n",
      "Iteration 8854 | Cost: 0.28796212901880647 | Gradient: [[ 0.02821205]\n",
      " [-0.05161546]\n",
      " [ 0.08715898]]\n",
      "Iteration 8855 | Cost: 0.28795107261108005 | Gradient: [[ 0.02821097]\n",
      " [-0.05161254]\n",
      " [ 0.08715289]]\n",
      "Iteration 8856 | Cost: 0.2879400176280479 | Gradient: [[ 0.02820989]\n",
      " [-0.05160961]\n",
      " [ 0.0871468 ]]\n",
      "Iteration 8857 | Cost: 0.2879289640694443 | Gradient: [[ 0.02820881]\n",
      " [-0.05160668]\n",
      " [ 0.08714072]]\n",
      "Iteration 8858 | Cost: 0.2879179119350038 | Gradient: [[ 0.02820773]\n",
      " [-0.05160375]\n",
      " [ 0.08713463]]\n",
      "Iteration 8859 | Cost: 0.28790686122446096 | Gradient: [[ 0.02820665]\n",
      " [-0.05160082]\n",
      " [ 0.08712854]]\n",
      "Iteration 8860 | Cost: 0.2878958119375502 | Gradient: [[ 0.02820556]\n",
      " [-0.0515979 ]\n",
      " [ 0.08712246]]\n",
      "Iteration 8861 | Cost: 0.28788476407400626 | Gradient: [[ 0.02820448]\n",
      " [-0.05159497]\n",
      " [ 0.08711637]]\n",
      "Iteration 8862 | Cost: 0.28787371763356384 | Gradient: [[ 0.0282034 ]\n",
      " [-0.05159204]\n",
      " [ 0.08711029]]\n",
      "Iteration 8863 | Cost: 0.28786267261595766 | Gradient: [[ 0.02820232]\n",
      " [-0.05158912]\n",
      " [ 0.0871042 ]]\n",
      "Iteration 8864 | Cost: 0.2878516290209226 | Gradient: [[ 0.02820124]\n",
      " [-0.05158619]\n",
      " [ 0.08709812]]\n",
      "Iteration 8865 | Cost: 0.2878405868481934 | Gradient: [[ 0.02820016]\n",
      " [-0.05158327]\n",
      " [ 0.08709204]]\n",
      "Iteration 8866 | Cost: 0.2878295460975053 | Gradient: [[ 0.02819908]\n",
      " [-0.05158035]\n",
      " [ 0.08708596]]\n",
      "Iteration 8867 | Cost: 0.287818506768593 | Gradient: [[ 0.028198  ]\n",
      " [-0.05157742]\n",
      " [ 0.08707988]]\n",
      "Iteration 8868 | Cost: 0.2878074688611918 | Gradient: [[ 0.02819691]\n",
      " [-0.0515745 ]\n",
      " [ 0.0870738 ]]\n",
      "Iteration 8869 | Cost: 0.2877964323750367 | Gradient: [[ 0.02819583]\n",
      " [-0.05157158]\n",
      " [ 0.08706772]]\n",
      "Iteration 8870 | Cost: 0.28778539730986313 | Gradient: [[ 0.02819475]\n",
      " [-0.05156866]\n",
      " [ 0.08706164]]\n",
      "Iteration 8871 | Cost: 0.28777436366540604 | Gradient: [[ 0.02819367]\n",
      " [-0.05156573]\n",
      " [ 0.08705556]]\n",
      "Iteration 8872 | Cost: 0.287763331441401 | Gradient: [[ 0.02819259]\n",
      " [-0.05156281]\n",
      " [ 0.08704949]]\n",
      "Iteration 8873 | Cost: 0.28775230063758334 | Gradient: [[ 0.02819151]\n",
      " [-0.05155989]\n",
      " [ 0.08704341]]\n",
      "Iteration 8874 | Cost: 0.28774127125368854 | Gradient: [[ 0.02819042]\n",
      " [-0.05155697]\n",
      " [ 0.08703733]]\n",
      "Iteration 8875 | Cost: 0.287730243289452 | Gradient: [[ 0.02818934]\n",
      " [-0.05155405]\n",
      " [ 0.08703126]]\n",
      "Iteration 8876 | Cost: 0.28771921674460954 | Gradient: [[ 0.02818826]\n",
      " [-0.05155113]\n",
      " [ 0.08702519]]\n",
      "Iteration 8877 | Cost: 0.2877081916188966 | Gradient: [[ 0.02818718]\n",
      " [-0.05154822]\n",
      " [ 0.08701911]]\n",
      "Iteration 8878 | Cost: 0.2876971679120489 | Gradient: [[ 0.0281861 ]\n",
      " [-0.0515453 ]\n",
      " [ 0.08701304]]\n",
      "Iteration 8879 | Cost: 0.2876861456238024 | Gradient: [[ 0.02818501]\n",
      " [-0.05154238]\n",
      " [ 0.08700697]]\n",
      "Iteration 8880 | Cost: 0.2876751247538928 | Gradient: [[ 0.02818393]\n",
      " [-0.05153946]\n",
      " [ 0.0870009 ]]\n",
      "Iteration 8881 | Cost: 0.287664105302056 | Gradient: [[ 0.02818285]\n",
      " [-0.05153655]\n",
      " [ 0.08699483]]\n",
      "Iteration 8882 | Cost: 0.287653087268028 | Gradient: [[ 0.02818177]\n",
      " [-0.05153363]\n",
      " [ 0.08698876]]\n",
      "Iteration 8883 | Cost: 0.28764207065154485 | Gradient: [[ 0.02818068]\n",
      " [-0.05153072]\n",
      " [ 0.08698269]]\n",
      "Iteration 8884 | Cost: 0.2876310554523426 | Gradient: [[ 0.0281796 ]\n",
      " [-0.0515278 ]\n",
      " [ 0.08697662]]\n",
      "Iteration 8885 | Cost: 0.2876200416701573 | Gradient: [[ 0.02817852]\n",
      " [-0.05152489]\n",
      " [ 0.08697055]]\n",
      "Iteration 8886 | Cost: 0.28760902930472537 | Gradient: [[ 0.02817744]\n",
      " [-0.05152197]\n",
      " [ 0.08696448]]\n",
      "Iteration 8887 | Cost: 0.2875980183557831 | Gradient: [[ 0.02817635]\n",
      " [-0.05151906]\n",
      " [ 0.08695842]]\n",
      "Iteration 8888 | Cost: 0.28758700882306665 | Gradient: [[ 0.02817527]\n",
      " [-0.05151615]\n",
      " [ 0.08695235]]\n",
      "Iteration 8889 | Cost: 0.28757600070631245 | Gradient: [[ 0.02817419]\n",
      " [-0.05151323]\n",
      " [ 0.08694629]]\n",
      "Iteration 8890 | Cost: 0.2875649940052572 | Gradient: [[ 0.02817311]\n",
      " [-0.05151032]\n",
      " [ 0.08694022]]\n",
      "Iteration 8891 | Cost: 0.28755398871963717 | Gradient: [[ 0.02817202]\n",
      " [-0.05150741]\n",
      " [ 0.08693416]]\n",
      "Iteration 8892 | Cost: 0.28754298484918905 | Gradient: [[ 0.02817094]\n",
      " [-0.0515045 ]\n",
      " [ 0.0869281 ]]\n",
      "Iteration 8893 | Cost: 0.2875319823936495 | Gradient: [[ 0.02816986]\n",
      " [-0.05150159]\n",
      " [ 0.08692204]]\n",
      "Iteration 8894 | Cost: 0.28752098135275533 | Gradient: [[ 0.02816878]\n",
      " [-0.05149868]\n",
      " [ 0.08691597]]\n",
      "Iteration 8895 | Cost: 0.28750998172624315 | Gradient: [[ 0.02816769]\n",
      " [-0.05149577]\n",
      " [ 0.08690991]]\n",
      "Iteration 8896 | Cost: 0.28749898351384995 | Gradient: [[ 0.02816661]\n",
      " [-0.05149286]\n",
      " [ 0.08690385]]\n",
      "Iteration 8897 | Cost: 0.28748798671531256 | Gradient: [[ 0.02816553]\n",
      " [-0.05148995]\n",
      " [ 0.08689779]]\n",
      "Iteration 8898 | Cost: 0.28747699133036797 | Gradient: [[ 0.02816444]\n",
      " [-0.05148704]\n",
      " [ 0.08689174]]\n",
      "Iteration 8899 | Cost: 0.2874659973587533 | Gradient: [[ 0.02816336]\n",
      " [-0.05148413]\n",
      " [ 0.08688568]]\n",
      "Iteration 8900 | Cost: 0.2874550048002055 | Gradient: [[ 0.02816228]\n",
      " [-0.05148122]\n",
      " [ 0.08687962]]\n",
      "Iteration 8901 | Cost: 0.28744401365446187 | Gradient: [[ 0.02816119]\n",
      " [-0.05147832]\n",
      " [ 0.08687356]]\n",
      "Iteration 8902 | Cost: 0.2874330239212595 | Gradient: [[ 0.02816011]\n",
      " [-0.05147541]\n",
      " [ 0.08686751]]\n",
      "Iteration 8903 | Cost: 0.2874220356003358 | Gradient: [[ 0.02815903]\n",
      " [-0.05147251]\n",
      " [ 0.08686145]]\n",
      "Iteration 8904 | Cost: 0.28741104869142803 | Gradient: [[ 0.02815794]\n",
      " [-0.0514696 ]\n",
      " [ 0.0868554 ]]\n",
      "Iteration 8905 | Cost: 0.2874000631942737 | Gradient: [[ 0.02815686]\n",
      " [-0.0514667 ]\n",
      " [ 0.08684935]]\n",
      "Iteration 8906 | Cost: 0.28738907910861017 | Gradient: [[ 0.02815578]\n",
      " [-0.05146379]\n",
      " [ 0.08684329]]\n",
      "Iteration 8907 | Cost: 0.28737809643417506 | Gradient: [[ 0.02815469]\n",
      " [-0.05146089]\n",
      " [ 0.08683724]]\n",
      "Iteration 8908 | Cost: 0.2873671151707059 | Gradient: [[ 0.02815361]\n",
      " [-0.05145798]\n",
      " [ 0.08683119]]\n",
      "Iteration 8909 | Cost: 0.28735613531794046 | Gradient: [[ 0.02815253]\n",
      " [-0.05145508]\n",
      " [ 0.08682514]]\n",
      "Iteration 8910 | Cost: 0.28734515687561646 | Gradient: [[ 0.02815144]\n",
      " [-0.05145218]\n",
      " [ 0.08681909]]\n",
      "Iteration 8911 | Cost: 0.28733417984347154 | Gradient: [[ 0.02815036]\n",
      " [-0.05144928]\n",
      " [ 0.08681304]]\n",
      "Iteration 8912 | Cost: 0.28732320422124363 | Gradient: [[ 0.02814927]\n",
      " [-0.05144637]\n",
      " [ 0.08680699]]\n",
      "Iteration 8913 | Cost: 0.28731223000867073 | Gradient: [[ 0.02814819]\n",
      " [-0.05144347]\n",
      " [ 0.08680094]]\n",
      "Iteration 8914 | Cost: 0.2873012572054907 | Gradient: [[ 0.02814711]\n",
      " [-0.05144057]\n",
      " [ 0.0867949 ]]\n",
      "Iteration 8915 | Cost: 0.28729028581144167 | Gradient: [[ 0.02814602]\n",
      " [-0.05143767]\n",
      " [ 0.08678885]]\n",
      "Iteration 8916 | Cost: 0.2872793158262616 | Gradient: [[ 0.02814494]\n",
      " [-0.05143477]\n",
      " [ 0.08678281]]\n",
      "Iteration 8917 | Cost: 0.2872683472496888 | Gradient: [[ 0.02814385]\n",
      " [-0.05143187]\n",
      " [ 0.08677676]]\n",
      "Iteration 8918 | Cost: 0.2872573800814615 | Gradient: [[ 0.02814277]\n",
      " [-0.05142897]\n",
      " [ 0.08677072]]\n",
      "Iteration 8919 | Cost: 0.28724641432131787 | Gradient: [[ 0.02814169]\n",
      " [-0.05142608]\n",
      " [ 0.08676467]]\n",
      "Iteration 8920 | Cost: 0.2872354499689963 | Gradient: [[ 0.0281406 ]\n",
      " [-0.05142318]\n",
      " [ 0.08675863]]\n",
      "Iteration 8921 | Cost: 0.28722448702423525 | Gradient: [[ 0.02813952]\n",
      " [-0.05142028]\n",
      " [ 0.08675259]]\n",
      "Iteration 8922 | Cost: 0.28721352548677315 | Gradient: [[ 0.02813843]\n",
      " [-0.05141738]\n",
      " [ 0.08674655]]\n",
      "Iteration 8923 | Cost: 0.2872025653563486 | Gradient: [[ 0.02813735]\n",
      " [-0.05141449]\n",
      " [ 0.08674051]]\n",
      "Iteration 8924 | Cost: 0.28719160663270016 | Gradient: [[ 0.02813626]\n",
      " [-0.05141159]\n",
      " [ 0.08673447]]\n",
      "Iteration 8925 | Cost: 0.28718064931556647 | Gradient: [[ 0.02813518]\n",
      " [-0.0514087 ]\n",
      " [ 0.08672843]]\n",
      "Iteration 8926 | Cost: 0.28716969340468623 | Gradient: [[ 0.0281341 ]\n",
      " [-0.0514058 ]\n",
      " [ 0.08672239]]\n",
      "Iteration 8927 | Cost: 0.28715873889979837 | Gradient: [[ 0.02813301]\n",
      " [-0.05140291]\n",
      " [ 0.08671635]]\n",
      "Iteration 8928 | Cost: 0.2871477858006416 | Gradient: [[ 0.02813193]\n",
      " [-0.05140001]\n",
      " [ 0.08671031]]\n",
      "Iteration 8929 | Cost: 0.2871368341069549 | Gradient: [[ 0.02813084]\n",
      " [-0.05139712]\n",
      " [ 0.08670428]]\n",
      "Iteration 8930 | Cost: 0.2871258838184772 | Gradient: [[ 0.02812976]\n",
      " [-0.05139423]\n",
      " [ 0.08669824]]\n",
      "Iteration 8931 | Cost: 0.28711493493494755 | Gradient: [[ 0.02812867]\n",
      " [-0.05139133]\n",
      " [ 0.08669221]]\n",
      "Iteration 8932 | Cost: 0.287103987456105 | Gradient: [[ 0.02812759]\n",
      " [-0.05138844]\n",
      " [ 0.08668617]]\n",
      "Iteration 8933 | Cost: 0.28709304138168884 | Gradient: [[ 0.0281265 ]\n",
      " [-0.05138555]\n",
      " [ 0.08668014]]\n",
      "Iteration 8934 | Cost: 0.28708209671143825 | Gradient: [[ 0.02812542]\n",
      " [-0.05138266]\n",
      " [ 0.08667411]]\n",
      "Iteration 8935 | Cost: 0.28707115344509243 | Gradient: [[ 0.02812433]\n",
      " [-0.05137977]\n",
      " [ 0.08666807]]\n",
      "Iteration 8936 | Cost: 0.2870602115823908 | Gradient: [[ 0.02812325]\n",
      " [-0.05137688]\n",
      " [ 0.08666204]]\n",
      "Iteration 8937 | Cost: 0.2870492711230728 | Gradient: [[ 0.02812216]\n",
      " [-0.05137399]\n",
      " [ 0.08665601]]\n",
      "Iteration 8938 | Cost: 0.2870383320668778 | Gradient: [[ 0.02812108]\n",
      " [-0.0513711 ]\n",
      " [ 0.08664998]]\n",
      "Iteration 8939 | Cost: 0.28702739441354536 | Gradient: [[ 0.02811999]\n",
      " [-0.05136821]\n",
      " [ 0.08664395]]\n",
      "Iteration 8940 | Cost: 0.2870164581628152 | Gradient: [[ 0.02811891]\n",
      " [-0.05136532]\n",
      " [ 0.08663792]]\n",
      "Iteration 8941 | Cost: 0.2870055233144268 | Gradient: [[ 0.02811782]\n",
      " [-0.05136243]\n",
      " [ 0.0866319 ]]\n",
      "Iteration 8942 | Cost: 0.28699458986812 | Gradient: [[ 0.02811674]\n",
      " [-0.05135955]\n",
      " [ 0.08662587]]\n",
      "Iteration 8943 | Cost: 0.2869836578236345 | Gradient: [[ 0.02811565]\n",
      " [-0.05135666]\n",
      " [ 0.08661984]]\n",
      "Iteration 8944 | Cost: 0.2869727271807102 | Gradient: [[ 0.02811456]\n",
      " [-0.05135377]\n",
      " [ 0.08661382]]\n",
      "Iteration 8945 | Cost: 0.286961797939087 | Gradient: [[ 0.02811348]\n",
      " [-0.05135089]\n",
      " [ 0.08660779]]\n",
      "Iteration 8946 | Cost: 0.2869508700985049 | Gradient: [[ 0.02811239]\n",
      " [-0.051348  ]\n",
      " [ 0.08660177]]\n",
      "Iteration 8947 | Cost: 0.2869399436587038 | Gradient: [[ 0.02811131]\n",
      " [-0.05134512]\n",
      " [ 0.08659574]]\n",
      "Iteration 8948 | Cost: 0.28692901861942394 | Gradient: [[ 0.02811022]\n",
      " [-0.05134223]\n",
      " [ 0.08658972]]\n",
      "Iteration 8949 | Cost: 0.2869180949804054 | Gradient: [[ 0.02810914]\n",
      " [-0.05133935]\n",
      " [ 0.0865837 ]]\n",
      "Iteration 8950 | Cost: 0.28690717274138844 | Gradient: [[ 0.02810805]\n",
      " [-0.05133646]\n",
      " [ 0.08657768]]\n",
      "Iteration 8951 | Cost: 0.28689625190211326 | Gradient: [[ 0.02810697]\n",
      " [-0.05133358]\n",
      " [ 0.08657166]]\n",
      "Iteration 8952 | Cost: 0.28688533246232023 | Gradient: [[ 0.02810588]\n",
      " [-0.0513307 ]\n",
      " [ 0.08656564]]\n",
      "Iteration 8953 | Cost: 0.2868744144217499 | Gradient: [[ 0.02810479]\n",
      " [-0.05132782]\n",
      " [ 0.08655962]]\n",
      "Iteration 8954 | Cost: 0.2868634977801424 | Gradient: [[ 0.02810371]\n",
      " [-0.05132494]\n",
      " [ 0.0865536 ]]\n",
      "Iteration 8955 | Cost: 0.2868525825372386 | Gradient: [[ 0.02810262]\n",
      " [-0.05132205]\n",
      " [ 0.08654758]]\n",
      "Iteration 8956 | Cost: 0.28684166869277883 | Gradient: [[ 0.02810154]\n",
      " [-0.05131917]\n",
      " [ 0.08654156]]\n",
      "Iteration 8957 | Cost: 0.28683075624650395 | Gradient: [[ 0.02810045]\n",
      " [-0.05131629]\n",
      " [ 0.08653555]]\n",
      "Iteration 8958 | Cost: 0.28681984519815457 | Gradient: [[ 0.02809936]\n",
      " [-0.05131341]\n",
      " [ 0.08652953]]\n",
      "Iteration 8959 | Cost: 0.2868089355474714 | Gradient: [[ 0.02809828]\n",
      " [-0.05131053]\n",
      " [ 0.08652351]]\n",
      "Iteration 8960 | Cost: 0.2867980272941954 | Gradient: [[ 0.02809719]\n",
      " [-0.05130765]\n",
      " [ 0.0865175 ]]\n",
      "Iteration 8961 | Cost: 0.2867871204380673 | Gradient: [[ 0.0280961 ]\n",
      " [-0.05130478]\n",
      " [ 0.08651149]]\n",
      "Iteration 8962 | Cost: 0.2867762149788282 | Gradient: [[ 0.02809502]\n",
      " [-0.0513019 ]\n",
      " [ 0.08650547]]\n",
      "Iteration 8963 | Cost: 0.28676531091621904 | Gradient: [[ 0.02809393]\n",
      " [-0.05129902]\n",
      " [ 0.08649946]]\n",
      "Iteration 8964 | Cost: 0.286754408249981 | Gradient: [[ 0.02809285]\n",
      " [-0.05129614]\n",
      " [ 0.08649345]]\n",
      "Iteration 8965 | Cost: 0.2867435069798551 | Gradient: [[ 0.02809176]\n",
      " [-0.05129327]\n",
      " [ 0.08648744]]\n",
      "Iteration 8966 | Cost: 0.2867326071055827 | Gradient: [[ 0.02809067]\n",
      " [-0.05129039]\n",
      " [ 0.08648143]]\n",
      "Iteration 8967 | Cost: 0.2867217086269048 | Gradient: [[ 0.02808959]\n",
      " [-0.05128752]\n",
      " [ 0.08647542]]\n",
      "Iteration 8968 | Cost: 0.2867108115435631 | Gradient: [[ 0.0280885 ]\n",
      " [-0.05128464]\n",
      " [ 0.08646941]]\n",
      "Iteration 8969 | Cost: 0.2866999158552986 | Gradient: [[ 0.02808741]\n",
      " [-0.05128177]\n",
      " [ 0.0864634 ]]\n",
      "Iteration 8970 | Cost: 0.28668902156185294 | Gradient: [[ 0.02808633]\n",
      " [-0.05127889]\n",
      " [ 0.08645739]]\n",
      "Iteration 8971 | Cost: 0.28667812866296766 | Gradient: [[ 0.02808524]\n",
      " [-0.05127602]\n",
      " [ 0.08645139]]\n",
      "Iteration 8972 | Cost: 0.2866672371583842 | Gradient: [[ 0.02808415]\n",
      " [-0.05127314]\n",
      " [ 0.08644538]]\n",
      "Iteration 8973 | Cost: 0.28665634704784443 | Gradient: [[ 0.02808307]\n",
      " [-0.05127027]\n",
      " [ 0.08643938]]\n",
      "Iteration 8974 | Cost: 0.2866454583310898 | Gradient: [[ 0.02808198]\n",
      " [-0.0512674 ]\n",
      " [ 0.08643337]]\n",
      "Iteration 8975 | Cost: 0.2866345710078622 | Gradient: [[ 0.02808089]\n",
      " [-0.05126453]\n",
      " [ 0.08642737]]\n",
      "Iteration 8976 | Cost: 0.2866236850779034 | Gradient: [[ 0.02807981]\n",
      " [-0.05126166]\n",
      " [ 0.08642136]]\n",
      "Iteration 8977 | Cost: 0.2866128005409553 | Gradient: [[ 0.02807872]\n",
      " [-0.05125879]\n",
      " [ 0.08641536]]\n",
      "Iteration 8978 | Cost: 0.2866019173967599 | Gradient: [[ 0.02807763]\n",
      " [-0.05125591]\n",
      " [ 0.08640936]]\n",
      "Iteration 8979 | Cost: 0.28659103564505906 | Gradient: [[ 0.02807654]\n",
      " [-0.05125304]\n",
      " [ 0.08640336]]\n",
      "Iteration 8980 | Cost: 0.28658015528559483 | Gradient: [[ 0.02807546]\n",
      " [-0.05125018]\n",
      " [ 0.08639736]]\n",
      "Iteration 8981 | Cost: 0.2865692763181095 | Gradient: [[ 0.02807437]\n",
      " [-0.05124731]\n",
      " [ 0.08639136]]\n",
      "Iteration 8982 | Cost: 0.28655839874234523 | Gradient: [[ 0.02807328]\n",
      " [-0.05124444]\n",
      " [ 0.08638536]]\n",
      "Iteration 8983 | Cost: 0.28654752255804417 | Gradient: [[ 0.0280722 ]\n",
      " [-0.05124157]\n",
      " [ 0.08637936]]\n",
      "Iteration 8984 | Cost: 0.28653664776494875 | Gradient: [[ 0.02807111]\n",
      " [-0.0512387 ]\n",
      " [ 0.08637336]]\n",
      "Iteration 8985 | Cost: 0.28652577436280113 | Gradient: [[ 0.02807002]\n",
      " [-0.05123583]\n",
      " [ 0.08636737]]\n",
      "Iteration 8986 | Cost: 0.28651490235134397 | Gradient: [[ 0.02806893]\n",
      " [-0.05123297]\n",
      " [ 0.08636137]]\n",
      "Iteration 8987 | Cost: 0.28650403173031963 | Gradient: [[ 0.02806785]\n",
      " [-0.0512301 ]\n",
      " [ 0.08635538]]\n",
      "Iteration 8988 | Cost: 0.2864931624994707 | Gradient: [[ 0.02806676]\n",
      " [-0.05122724]\n",
      " [ 0.08634938]]\n",
      "Iteration 8989 | Cost: 0.2864822946585398 | Gradient: [[ 0.02806567]\n",
      " [-0.05122437]\n",
      " [ 0.08634339]]\n",
      "Iteration 8990 | Cost: 0.28647142820726956 | Gradient: [[ 0.02806458]\n",
      " [-0.05122151]\n",
      " [ 0.08633739]]\n",
      "Iteration 8991 | Cost: 0.2864605631454029 | Gradient: [[ 0.0280635 ]\n",
      " [-0.05121864]\n",
      " [ 0.0863314 ]]\n",
      "Iteration 8992 | Cost: 0.2864496994726824 | Gradient: [[ 0.02806241]\n",
      " [-0.05121578]\n",
      " [ 0.08632541]]\n",
      "Iteration 8993 | Cost: 0.28643883718885094 | Gradient: [[ 0.02806132]\n",
      " [-0.05121291]\n",
      " [ 0.08631942]]\n",
      "Iteration 8994 | Cost: 0.2864279762936515 | Gradient: [[ 0.02806023]\n",
      " [-0.05121005]\n",
      " [ 0.08631343]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8995 | Cost: 0.28641711678682713 | Gradient: [[ 0.02805914]\n",
      " [-0.05120719]\n",
      " [ 0.08630744]]\n",
      "Iteration 8996 | Cost: 0.2864062586681208 | Gradient: [[ 0.02805806]\n",
      " [-0.05120433]\n",
      " [ 0.08630145]]\n",
      "Iteration 8997 | Cost: 0.28639540193727553 | Gradient: [[ 0.02805697]\n",
      " [-0.05120146]\n",
      " [ 0.08629546]]\n",
      "Iteration 8998 | Cost: 0.2863845465940348 | Gradient: [[ 0.02805588]\n",
      " [-0.0511986 ]\n",
      " [ 0.08628947]]\n",
      "Iteration 8999 | Cost: 0.2863736926381414 | Gradient: [[ 0.02805479]\n",
      " [-0.05119574]\n",
      " [ 0.08628349]]\n",
      "Iteration 9000 | Cost: 0.2863628400693389 | Gradient: [[ 0.0280537 ]\n",
      " [-0.05119288]\n",
      " [ 0.0862775 ]]\n",
      "Iteration 9001 | Cost: 0.28635198888737046 | Gradient: [[ 0.02805262]\n",
      " [-0.05119002]\n",
      " [ 0.08627152]]\n",
      "Iteration 9002 | Cost: 0.2863411390919797 | Gradient: [[ 0.02805153]\n",
      " [-0.05118716]\n",
      " [ 0.08626553]]\n",
      "Iteration 9003 | Cost: 0.28633029068290994 | Gradient: [[ 0.02805044]\n",
      " [-0.0511843 ]\n",
      " [ 0.08625955]]\n",
      "Iteration 9004 | Cost: 0.2863194436599048 | Gradient: [[ 0.02804935]\n",
      " [-0.05118145]\n",
      " [ 0.08625356]]\n",
      "Iteration 9005 | Cost: 0.28630859802270775 | Gradient: [[ 0.02804826]\n",
      " [-0.05117859]\n",
      " [ 0.08624758]]\n",
      "Iteration 9006 | Cost: 0.2862977537710626 | Gradient: [[ 0.02804718]\n",
      " [-0.05117573]\n",
      " [ 0.0862416 ]]\n",
      "Iteration 9007 | Cost: 0.28628691090471303 | Gradient: [[ 0.02804609]\n",
      " [-0.05117287]\n",
      " [ 0.08623562]]\n",
      "Iteration 9008 | Cost: 0.28627606942340267 | Gradient: [[ 0.028045  ]\n",
      " [-0.05117002]\n",
      " [ 0.08622964]]\n",
      "Iteration 9009 | Cost: 0.2862652293268754 | Gradient: [[ 0.02804391]\n",
      " [-0.05116716]\n",
      " [ 0.08622366]]\n",
      "Iteration 9010 | Cost: 0.2862543906148754 | Gradient: [[ 0.02804282]\n",
      " [-0.0511643 ]\n",
      " [ 0.08621768]]\n",
      "Iteration 9011 | Cost: 0.2862435532871461 | Gradient: [[ 0.02804173]\n",
      " [-0.05116145]\n",
      " [ 0.0862117 ]]\n",
      "Iteration 9012 | Cost: 0.28623271734343203 | Gradient: [[ 0.02804064]\n",
      " [-0.05115859]\n",
      " [ 0.08620572]]\n",
      "Iteration 9013 | Cost: 0.286221882783477 | Gradient: [[ 0.02803956]\n",
      " [-0.05115574]\n",
      " [ 0.08619974]]\n",
      "Iteration 9014 | Cost: 0.2862110496070252 | Gradient: [[ 0.02803847]\n",
      " [-0.05115289]\n",
      " [ 0.08619377]]\n",
      "Iteration 9015 | Cost: 0.2862002178138208 | Gradient: [[ 0.02803738]\n",
      " [-0.05115003]\n",
      " [ 0.08618779]]\n",
      "Iteration 9016 | Cost: 0.2861893874036081 | Gradient: [[ 0.02803629]\n",
      " [-0.05114718]\n",
      " [ 0.08618182]]\n",
      "Iteration 9017 | Cost: 0.28617855837613143 | Gradient: [[ 0.0280352 ]\n",
      " [-0.05114433]\n",
      " [ 0.08617584]]\n",
      "Iteration 9018 | Cost: 0.2861677307311351 | Gradient: [[ 0.02803411]\n",
      " [-0.05114148]\n",
      " [ 0.08616987]]\n",
      "Iteration 9019 | Cost: 0.28615690446836367 | Gradient: [[ 0.02803302]\n",
      " [-0.05113862]\n",
      " [ 0.0861639 ]]\n",
      "Iteration 9020 | Cost: 0.28614607958756155 | Gradient: [[ 0.02803193]\n",
      " [-0.05113577]\n",
      " [ 0.08615792]]\n",
      "Iteration 9021 | Cost: 0.28613525608847334 | Gradient: [[ 0.02803085]\n",
      " [-0.05113292]\n",
      " [ 0.08615195]]\n",
      "Iteration 9022 | Cost: 0.2861244339708436 | Gradient: [[ 0.02802976]\n",
      " [-0.05113007]\n",
      " [ 0.08614598]]\n",
      "Iteration 9023 | Cost: 0.28611361323441714 | Gradient: [[ 0.02802867]\n",
      " [-0.05112722]\n",
      " [ 0.08614001]]\n",
      "Iteration 9024 | Cost: 0.2861027938789386 | Gradient: [[ 0.02802758]\n",
      " [-0.05112437]\n",
      " [ 0.08613404]]\n",
      "Iteration 9025 | Cost: 0.2860919759041528 | Gradient: [[ 0.02802649]\n",
      " [-0.05112153]\n",
      " [ 0.08612807]]\n",
      "Iteration 9026 | Cost: 0.28608115930980466 | Gradient: [[ 0.0280254 ]\n",
      " [-0.05111868]\n",
      " [ 0.08612211]]\n",
      "Iteration 9027 | Cost: 0.28607034409563903 | Gradient: [[ 0.02802431]\n",
      " [-0.05111583]\n",
      " [ 0.08611614]]\n",
      "Iteration 9028 | Cost: 0.28605953026140096 | Gradient: [[ 0.02802322]\n",
      " [-0.05111298]\n",
      " [ 0.08611017]]\n",
      "Iteration 9029 | Cost: 0.2860487178068355 | Gradient: [[ 0.02802213]\n",
      " [-0.05111013]\n",
      " [ 0.08610421]]\n",
      "Iteration 9030 | Cost: 0.28603790673168766 | Gradient: [[ 0.02802104]\n",
      " [-0.05110729]\n",
      " [ 0.08609824]]\n",
      "Iteration 9031 | Cost: 0.28602709703570267 | Gradient: [[ 0.02801995]\n",
      " [-0.05110444]\n",
      " [ 0.08609228]]\n",
      "Iteration 9032 | Cost: 0.2860162887186259 | Gradient: [[ 0.02801886]\n",
      " [-0.0511016 ]\n",
      " [ 0.08608631]]\n",
      "Iteration 9033 | Cost: 0.28600548178020246 | Gradient: [[ 0.02801777]\n",
      " [-0.05109875]\n",
      " [ 0.08608035]]\n",
      "Iteration 9034 | Cost: 0.2859946762201777 | Gradient: [[ 0.02801668]\n",
      " [-0.05109591]\n",
      " [ 0.08607439]]\n",
      "Iteration 9035 | Cost: 0.2859838720382971 | Gradient: [[ 0.0280156 ]\n",
      " [-0.05109306]\n",
      " [ 0.08606843]]\n",
      "Iteration 9036 | Cost: 0.28597306923430615 | Gradient: [[ 0.02801451]\n",
      " [-0.05109022]\n",
      " [ 0.08606246]]\n",
      "Iteration 9037 | Cost: 0.2859622678079503 | Gradient: [[ 0.02801342]\n",
      " [-0.05108738]\n",
      " [ 0.0860565 ]]\n",
      "Iteration 9038 | Cost: 0.2859514677589752 | Gradient: [[ 0.02801233]\n",
      " [-0.05108453]\n",
      " [ 0.08605054]]\n",
      "Iteration 9039 | Cost: 0.28594066908712645 | Gradient: [[ 0.02801124]\n",
      " [-0.05108169]\n",
      " [ 0.08604459]]\n",
      "Iteration 9040 | Cost: 0.28592987179214985 | Gradient: [[ 0.02801015]\n",
      " [-0.05107885]\n",
      " [ 0.08603863]]\n",
      "Iteration 9041 | Cost: 0.2859190758737911 | Gradient: [[ 0.02800906]\n",
      " [-0.05107601]\n",
      " [ 0.08603267]]\n",
      "Iteration 9042 | Cost: 0.285908281331796 | Gradient: [[ 0.02800797]\n",
      " [-0.05107317]\n",
      " [ 0.08602671]]\n",
      "Iteration 9043 | Cost: 0.28589748816591054 | Gradient: [[ 0.02800688]\n",
      " [-0.05107033]\n",
      " [ 0.08602076]]\n",
      "Iteration 9044 | Cost: 0.28588669637588066 | Gradient: [[ 0.02800579]\n",
      " [-0.05106749]\n",
      " [ 0.0860148 ]]\n",
      "Iteration 9045 | Cost: 0.28587590596145224 | Gradient: [[ 0.0280047 ]\n",
      " [-0.05106465]\n",
      " [ 0.08600885]]\n",
      "Iteration 9046 | Cost: 0.28586511692237154 | Gradient: [[ 0.02800361]\n",
      " [-0.05106181]\n",
      " [ 0.08600289]]\n",
      "Iteration 9047 | Cost: 0.28585432925838455 | Gradient: [[ 0.02800252]\n",
      " [-0.05105897]\n",
      " [ 0.08599694]]\n",
      "Iteration 9048 | Cost: 0.28584354296923753 | Gradient: [[ 0.02800143]\n",
      " [-0.05105613]\n",
      " [ 0.08599099]]\n",
      "Iteration 9049 | Cost: 0.28583275805467667 | Gradient: [[ 0.02800034]\n",
      " [-0.05105329]\n",
      " [ 0.08598504]]\n",
      "Iteration 9050 | Cost: 0.28582197451444846 | Gradient: [[ 0.02799925]\n",
      " [-0.05105045]\n",
      " [ 0.08597908]]\n",
      "Iteration 9051 | Cost: 0.285811192348299 | Gradient: [[ 0.02799816]\n",
      " [-0.05104762]\n",
      " [ 0.08597313]]\n",
      "Iteration 9052 | Cost: 0.28580041155597496 | Gradient: [[ 0.02799707]\n",
      " [-0.05104478]\n",
      " [ 0.08596718]]\n",
      "Iteration 9053 | Cost: 0.28578963213722275 | Gradient: [[ 0.02799598]\n",
      " [-0.05104194]\n",
      " [ 0.08596124]]\n",
      "Iteration 9054 | Cost: 0.2857788540917888 | Gradient: [[ 0.02799489]\n",
      " [-0.05103911]\n",
      " [ 0.08595529]]\n",
      "Iteration 9055 | Cost: 0.28576807741942 | Gradient: [[ 0.0279938 ]\n",
      " [-0.05103627]\n",
      " [ 0.08594934]]\n",
      "Iteration 9056 | Cost: 0.2857573021198628 | Gradient: [[ 0.0279927 ]\n",
      " [-0.05103344]\n",
      " [ 0.08594339]]\n",
      "Iteration 9057 | Cost: 0.285746528192864 | Gradient: [[ 0.02799161]\n",
      " [-0.05103061]\n",
      " [ 0.08593745]]\n",
      "Iteration 9058 | Cost: 0.2857357556381704 | Gradient: [[ 0.02799052]\n",
      " [-0.05102777]\n",
      " [ 0.0859315 ]]\n",
      "Iteration 9059 | Cost: 0.2857249844555288 | Gradient: [[ 0.02798943]\n",
      " [-0.05102494]\n",
      " [ 0.08592556]]\n",
      "Iteration 9060 | Cost: 0.2857142146446862 | Gradient: [[ 0.02798834]\n",
      " [-0.05102211]\n",
      " [ 0.08591961]]\n",
      "Iteration 9061 | Cost: 0.2857034462053895 | Gradient: [[ 0.02798725]\n",
      " [-0.05101927]\n",
      " [ 0.08591367]]\n",
      "Iteration 9062 | Cost: 0.2856926791373858 | Gradient: [[ 0.02798616]\n",
      " [-0.05101644]\n",
      " [ 0.08590773]]\n",
      "Iteration 9063 | Cost: 0.2856819134404222 | Gradient: [[ 0.02798507]\n",
      " [-0.05101361]\n",
      " [ 0.08590178]]\n",
      "Iteration 9064 | Cost: 0.2856711491142458 | Gradient: [[ 0.02798398]\n",
      " [-0.05101078]\n",
      " [ 0.08589584]]\n",
      "Iteration 9065 | Cost: 0.28566038615860373 | Gradient: [[ 0.02798289]\n",
      " [-0.05100795]\n",
      " [ 0.0858899 ]]\n",
      "Iteration 9066 | Cost: 0.2856496245732434 | Gradient: [[ 0.0279818 ]\n",
      " [-0.05100512]\n",
      " [ 0.08588396]]\n",
      "Iteration 9067 | Cost: 0.28563886435791214 | Gradient: [[ 0.02798071]\n",
      " [-0.05100229]\n",
      " [ 0.08587802]]\n",
      "Iteration 9068 | Cost: 0.2856281055123573 | Gradient: [[ 0.02797962]\n",
      " [-0.05099946]\n",
      " [ 0.08587208]]\n",
      "Iteration 9069 | Cost: 0.2856173480363263 | Gradient: [[ 0.02797853]\n",
      " [-0.05099663]\n",
      " [ 0.08586615]]\n",
      "Iteration 9070 | Cost: 0.2856065919295668 | Gradient: [[ 0.02797743]\n",
      " [-0.0509938 ]\n",
      " [ 0.08586021]]\n",
      "Iteration 9071 | Cost: 0.28559583719182613 | Gradient: [[ 0.02797634]\n",
      " [-0.05099097]\n",
      " [ 0.08585427]]\n",
      "Iteration 9072 | Cost: 0.2855850838228521 | Gradient: [[ 0.02797525]\n",
      " [-0.05098815]\n",
      " [ 0.08584834]]\n",
      "Iteration 9073 | Cost: 0.28557433182239234 | Gradient: [[ 0.02797416]\n",
      " [-0.05098532]\n",
      " [ 0.0858424 ]]\n",
      "Iteration 9074 | Cost: 0.28556358119019454 | Gradient: [[ 0.02797307]\n",
      " [-0.05098249]\n",
      " [ 0.08583647]]\n",
      "Iteration 9075 | Cost: 0.28555283192600667 | Gradient: [[ 0.02797198]\n",
      " [-0.05097967]\n",
      " [ 0.08583053]]\n",
      "Iteration 9076 | Cost: 0.28554208402957654 | Gradient: [[ 0.02797089]\n",
      " [-0.05097684]\n",
      " [ 0.0858246 ]]\n",
      "Iteration 9077 | Cost: 0.285531337500652 | Gradient: [[ 0.0279698 ]\n",
      " [-0.05097402]\n",
      " [ 0.08581867]]\n",
      "Iteration 9078 | Cost: 0.28552059233898114 | Gradient: [[ 0.02796871]\n",
      " [-0.05097119]\n",
      " [ 0.08581274]]\n",
      "Iteration 9079 | Cost: 0.2855098485443119 | Gradient: [[ 0.02796761]\n",
      " [-0.05096837]\n",
      " [ 0.08580681]]\n",
      "Iteration 9080 | Cost: 0.28549910611639245 | Gradient: [[ 0.02796652]\n",
      " [-0.05096554]\n",
      " [ 0.08580087]]\n",
      "Iteration 9081 | Cost: 0.28548836505497105 | Gradient: [[ 0.02796543]\n",
      " [-0.05096272]\n",
      " [ 0.08579495]]\n",
      "Iteration 9082 | Cost: 0.28547762535979576 | Gradient: [[ 0.02796434]\n",
      " [-0.0509599 ]\n",
      " [ 0.08578902]]\n",
      "Iteration 9083 | Cost: 0.285466887030615 | Gradient: [[ 0.02796325]\n",
      " [-0.05095707]\n",
      " [ 0.08578309]]\n",
      "Iteration 9084 | Cost: 0.28545615006717695 | Gradient: [[ 0.02796216]\n",
      " [-0.05095425]\n",
      " [ 0.08577716]]\n",
      "Iteration 9085 | Cost: 0.28544541446923016 | Gradient: [[ 0.02796107]\n",
      " [-0.05095143]\n",
      " [ 0.08577123]]\n",
      "Iteration 9086 | Cost: 0.28543468023652313 | Gradient: [[ 0.02795997]\n",
      " [-0.05094861]\n",
      " [ 0.08576531]]\n",
      "Iteration 9087 | Cost: 0.28542394736880433 | Gradient: [[ 0.02795888]\n",
      " [-0.05094579]\n",
      " [ 0.08575938]]\n",
      "Iteration 9088 | Cost: 0.2854132158658223 | Gradient: [[ 0.02795779]\n",
      " [-0.05094297]\n",
      " [ 0.08575346]]\n",
      "Iteration 9089 | Cost: 0.28540248572732574 | Gradient: [[ 0.0279567 ]\n",
      " [-0.05094015]\n",
      " [ 0.08574753]]\n",
      "Iteration 9090 | Cost: 0.2853917569530633 | Gradient: [[ 0.02795561]\n",
      " [-0.05093733]\n",
      " [ 0.08574161]]\n",
      "Iteration 9091 | Cost: 0.2853810295427837 | Gradient: [[ 0.02795451]\n",
      " [-0.05093451]\n",
      " [ 0.08573569]]\n",
      "Iteration 9092 | Cost: 0.28537030349623593 | Gradient: [[ 0.02795342]\n",
      " [-0.05093169]\n",
      " [ 0.08572977]]\n",
      "Iteration 9093 | Cost: 0.2853595788131688 | Gradient: [[ 0.02795233]\n",
      " [-0.05092887]\n",
      " [ 0.08572385]]\n",
      "Iteration 9094 | Cost: 0.28534885549333117 | Gradient: [[ 0.02795124]\n",
      " [-0.05092605]\n",
      " [ 0.08571793]]\n",
      "Iteration 9095 | Cost: 0.2853381335364721 | Gradient: [[ 0.02795015]\n",
      " [-0.05092324]\n",
      " [ 0.08571201]]\n",
      "Iteration 9096 | Cost: 0.28532741294234065 | Gradient: [[ 0.02794906]\n",
      " [-0.05092042]\n",
      " [ 0.08570609]]\n",
      "Iteration 9097 | Cost: 0.2853166937106859 | Gradient: [[ 0.02794796]\n",
      " [-0.0509176 ]\n",
      " [ 0.08570017]]\n",
      "Iteration 9098 | Cost: 0.2853059758412571 | Gradient: [[ 0.02794687]\n",
      " [-0.05091479]\n",
      " [ 0.08569425]]\n",
      "Iteration 9099 | Cost: 0.28529525933380345 | Gradient: [[ 0.02794578]\n",
      " [-0.05091197]\n",
      " [ 0.08568833]]\n",
      "Iteration 9100 | Cost: 0.28528454418807436 | Gradient: [[ 0.02794469]\n",
      " [-0.05090916]\n",
      " [ 0.08568242]]\n",
      "Iteration 9101 | Cost: 0.28527383040381893 | Gradient: [[ 0.02794359]\n",
      " [-0.05090634]\n",
      " [ 0.0856765 ]]\n",
      "Iteration 9102 | Cost: 0.2852631179807868 | Gradient: [[ 0.0279425 ]\n",
      " [-0.05090353]\n",
      " [ 0.08567059]]\n",
      "Iteration 9103 | Cost: 0.2852524069187273 | Gradient: [[ 0.02794141]\n",
      " [-0.05090072]\n",
      " [ 0.08566467]]\n",
      "Iteration 9104 | Cost: 0.28524169721739 | Gradient: [[ 0.02794032]\n",
      " [-0.0508979 ]\n",
      " [ 0.08565876]]\n",
      "Iteration 9105 | Cost: 0.28523098887652465 | Gradient: [[ 0.02793923]\n",
      " [-0.05089509]\n",
      " [ 0.08565285]]\n",
      "Iteration 9106 | Cost: 0.2852202818958807 | Gradient: [[ 0.02793813]\n",
      " [-0.05089228]\n",
      " [ 0.08564693]]\n",
      "Iteration 9107 | Cost: 0.2852095762752079 | Gradient: [[ 0.02793704]\n",
      " [-0.05088947]\n",
      " [ 0.08564102]]\n",
      "Iteration 9108 | Cost: 0.2851988720142561 | Gradient: [[ 0.02793595]\n",
      " [-0.05088665]\n",
      " [ 0.08563511]]\n",
      "Iteration 9109 | Cost: 0.28518816911277506 | Gradient: [[ 0.02793486]\n",
      " [-0.05088384]\n",
      " [ 0.0856292 ]]\n",
      "Iteration 9110 | Cost: 0.28517746757051465 | Gradient: [[ 0.02793376]\n",
      " [-0.05088103]\n",
      " [ 0.08562329]]\n",
      "Iteration 9111 | Cost: 0.2851667673872249 | Gradient: [[ 0.02793267]\n",
      " [-0.05087822]\n",
      " [ 0.08561738]]\n",
      "Iteration 9112 | Cost: 0.28515606856265585 | Gradient: [[ 0.02793158]\n",
      " [-0.05087541]\n",
      " [ 0.08561148]]\n",
      "Iteration 9113 | Cost: 0.2851453710965574 | Gradient: [[ 0.02793049]\n",
      " [-0.0508726 ]\n",
      " [ 0.08560557]]\n",
      "Iteration 9114 | Cost: 0.28513467498867984 | Gradient: [[ 0.02792939]\n",
      " [-0.0508698 ]\n",
      " [ 0.08559966]]\n",
      "Iteration 9115 | Cost: 0.28512398023877317 | Gradient: [[ 0.0279283 ]\n",
      " [-0.05086699]\n",
      " [ 0.08559376]]\n",
      "Iteration 9116 | Cost: 0.2851132868465878 | Gradient: [[ 0.02792721]\n",
      " [-0.05086418]\n",
      " [ 0.08558785]]\n",
      "Iteration 9117 | Cost: 0.285102594811874 | Gradient: [[ 0.02792612]\n",
      " [-0.05086137]\n",
      " [ 0.08558195]]\n",
      "Iteration 9118 | Cost: 0.28509190413438207 | Gradient: [[ 0.02792502]\n",
      " [-0.05085857]\n",
      " [ 0.08557604]]\n",
      "Iteration 9119 | Cost: 0.2850812148138624 | Gradient: [[ 0.02792393]\n",
      " [-0.05085576]\n",
      " [ 0.08557014]]\n",
      "Iteration 9120 | Cost: 0.28507052685006556 | Gradient: [[ 0.02792284]\n",
      " [-0.05085295]\n",
      " [ 0.08556424]]\n",
      "Iteration 9121 | Cost: 0.2850598402427421 | Gradient: [[ 0.02792174]\n",
      " [-0.05085015]\n",
      " [ 0.08555834]]\n",
      "Iteration 9122 | Cost: 0.2850491549916426 | Gradient: [[ 0.02792065]\n",
      " [-0.05084734]\n",
      " [ 0.08555244]]\n",
      "Iteration 9123 | Cost: 0.2850384710965176 | Gradient: [[ 0.02791956]\n",
      " [-0.05084454]\n",
      " [ 0.08554653]]\n",
      "Iteration 9124 | Cost: 0.2850277885571179 | Gradient: [[ 0.02791846]\n",
      " [-0.05084173]\n",
      " [ 0.08554064]]\n",
      "Iteration 9125 | Cost: 0.2850171073731943 | Gradient: [[ 0.02791737]\n",
      " [-0.05083893]\n",
      " [ 0.08553474]]\n",
      "Iteration 9126 | Cost: 0.28500642754449756 | Gradient: [[ 0.02791628]\n",
      " [-0.05083613]\n",
      " [ 0.08552884]]\n",
      "Iteration 9127 | Cost: 0.2849957490707786 | Gradient: [[ 0.02791519]\n",
      " [-0.05083332]\n",
      " [ 0.08552294]]\n",
      "Iteration 9128 | Cost: 0.28498507195178846 | Gradient: [[ 0.02791409]\n",
      " [-0.05083052]\n",
      " [ 0.08551704]]\n",
      "Iteration 9129 | Cost: 0.284974396187278 | Gradient: [[ 0.027913  ]\n",
      " [-0.05082772]\n",
      " [ 0.08551115]]\n",
      "Iteration 9130 | Cost: 0.28496372177699836 | Gradient: [[ 0.02791191]\n",
      " [-0.05082492]\n",
      " [ 0.08550525]]\n",
      "Iteration 9131 | Cost: 0.2849530487207007 | Gradient: [[ 0.02791081]\n",
      " [-0.05082211]\n",
      " [ 0.08549936]]\n",
      "Iteration 9132 | Cost: 0.2849423770181362 | Gradient: [[ 0.02790972]\n",
      " [-0.05081931]\n",
      " [ 0.08549346]]\n",
      "Iteration 9133 | Cost: 0.284931706669056 | Gradient: [[ 0.02790863]\n",
      " [-0.05081651]\n",
      " [ 0.08548757]]\n",
      "Iteration 9134 | Cost: 0.2849210376732115 | Gradient: [[ 0.02790753]\n",
      " [-0.05081371]\n",
      " [ 0.08548168]]\n",
      "Iteration 9135 | Cost: 0.28491037003035397 | Gradient: [[ 0.02790644]\n",
      " [-0.05081091]\n",
      " [ 0.08547579]]\n",
      "Iteration 9136 | Cost: 0.2848997037402348 | Gradient: [[ 0.02790535]\n",
      " [-0.05080811]\n",
      " [ 0.08546989]]\n",
      "Iteration 9137 | Cost: 0.28488903880260574 | Gradient: [[ 0.02790425]\n",
      " [-0.05080532]\n",
      " [ 0.085464  ]]\n",
      "Iteration 9138 | Cost: 0.28487837521721804 | Gradient: [[ 0.02790316]\n",
      " [-0.05080252]\n",
      " [ 0.08545811]]\n",
      "Iteration 9139 | Cost: 0.2848677129838234 | Gradient: [[ 0.02790207]\n",
      " [-0.05079972]\n",
      " [ 0.08545222]]\n",
      "Iteration 9140 | Cost: 0.28485705210217344 | Gradient: [[ 0.02790097]\n",
      " [-0.05079692]\n",
      " [ 0.08544634]]\n",
      "Iteration 9141 | Cost: 0.28484639257201994 | Gradient: [[ 0.02789988]\n",
      " [-0.05079413]\n",
      " [ 0.08544045]]\n",
      "Iteration 9142 | Cost: 0.28483573439311455 | Gradient: [[ 0.02789878]\n",
      " [-0.05079133]\n",
      " [ 0.08543456]]\n",
      "Iteration 9143 | Cost: 0.2848250775652092 | Gradient: [[ 0.02789769]\n",
      " [-0.05078853]\n",
      " [ 0.08542867]]\n",
      "Iteration 9144 | Cost: 0.28481442208805574 | Gradient: [[ 0.0278966 ]\n",
      " [-0.05078574]\n",
      " [ 0.08542279]]\n",
      "Iteration 9145 | Cost: 0.28480376796140616 | Gradient: [[ 0.0278955 ]\n",
      " [-0.05078294]\n",
      " [ 0.0854169 ]]\n",
      "Iteration 9146 | Cost: 0.2847931151850123 | Gradient: [[ 0.02789441]\n",
      " [-0.05078015]\n",
      " [ 0.08541102]]\n",
      "Iteration 9147 | Cost: 0.2847824637586265 | Gradient: [[ 0.02789332]\n",
      " [-0.05077735]\n",
      " [ 0.08540514]]\n",
      "Iteration 9148 | Cost: 0.2847718136820006 | Gradient: [[ 0.02789222]\n",
      " [-0.05077456]\n",
      " [ 0.08539925]]\n",
      "Iteration 9149 | Cost: 0.28476116495488696 | Gradient: [[ 0.02789113]\n",
      " [-0.05077177]\n",
      " [ 0.08539337]]\n",
      "Iteration 9150 | Cost: 0.2847505175770378 | Gradient: [[ 0.02789003]\n",
      " [-0.05076897]\n",
      " [ 0.08538749]]\n",
      "Iteration 9151 | Cost: 0.2847398715482053 | Gradient: [[ 0.02788894]\n",
      " [-0.05076618]\n",
      " [ 0.08538161]]\n",
      "Iteration 9152 | Cost: 0.2847292268681419 | Gradient: [[ 0.02788785]\n",
      " [-0.05076339]\n",
      " [ 0.08537573]]\n",
      "Iteration 9153 | Cost: 0.2847185835366 | Gradient: [[ 0.02788675]\n",
      " [-0.0507606 ]\n",
      " [ 0.08536985]]\n",
      "Iteration 9154 | Cost: 0.28470794155333207 | Gradient: [[ 0.02788566]\n",
      " [-0.05075781]\n",
      " [ 0.08536397]]\n",
      "Iteration 9155 | Cost: 0.2846973009180907 | Gradient: [[ 0.02788456]\n",
      " [-0.05075502]\n",
      " [ 0.08535809]]\n",
      "Iteration 9156 | Cost: 0.28468666163062833 | Gradient: [[ 0.02788347]\n",
      " [-0.05075223]\n",
      " [ 0.08535221]]\n",
      "Iteration 9157 | Cost: 0.2846760236906978 | Gradient: [[ 0.02788238]\n",
      " [-0.05074944]\n",
      " [ 0.08534634]]\n",
      "Iteration 9158 | Cost: 0.2846653870980516 | Gradient: [[ 0.02788128]\n",
      " [-0.05074665]\n",
      " [ 0.08534046]]\n",
      "Iteration 9159 | Cost: 0.28465475185244277 | Gradient: [[ 0.02788019]\n",
      " [-0.05074386]\n",
      " [ 0.08533459]]\n",
      "Iteration 9160 | Cost: 0.28464411795362377 | Gradient: [[ 0.02787909]\n",
      " [-0.05074107]\n",
      " [ 0.08532871]]\n",
      "Iteration 9161 | Cost: 0.2846334854013478 | Gradient: [[ 0.027878  ]\n",
      " [-0.05073828]\n",
      " [ 0.08532284]]\n",
      "Iteration 9162 | Cost: 0.2846228541953676 | Gradient: [[ 0.0278769 ]\n",
      " [-0.05073549]\n",
      " [ 0.08531696]]\n",
      "Iteration 9163 | Cost: 0.28461222433543615 | Gradient: [[ 0.02787581]\n",
      " [-0.05073271]\n",
      " [ 0.08531109]]\n",
      "Iteration 9164 | Cost: 0.2846015958213067 | Gradient: [[ 0.02787472]\n",
      " [-0.05072992]\n",
      " [ 0.08530522]]\n",
      "Iteration 9165 | Cost: 0.2845909686527322 | Gradient: [[ 0.02787362]\n",
      " [-0.05072713]\n",
      " [ 0.08529935]]\n",
      "Iteration 9166 | Cost: 0.28458034282946587 | Gradient: [[ 0.02787253]\n",
      " [-0.05072435]\n",
      " [ 0.08529348]]\n",
      "Iteration 9167 | Cost: 0.28456971835126094 | Gradient: [[ 0.02787143]\n",
      " [-0.05072156]\n",
      " [ 0.08528761]]\n",
      "Iteration 9168 | Cost: 0.28455909521787065 | Gradient: [[ 0.02787034]\n",
      " [-0.05071878]\n",
      " [ 0.08528174]]\n",
      "Iteration 9169 | Cost: 0.2845484734290484 | Gradient: [[ 0.02786924]\n",
      " [-0.05071599]\n",
      " [ 0.08527587]]\n",
      "Iteration 9170 | Cost: 0.28453785298454753 | Gradient: [[ 0.02786815]\n",
      " [-0.05071321]\n",
      " [ 0.08527   ]]\n",
      "Iteration 9171 | Cost: 0.2845272338841216 | Gradient: [[ 0.02786705]\n",
      " [-0.05071042]\n",
      " [ 0.08526414]]\n",
      "Iteration 9172 | Cost: 0.284516616127524 | Gradient: [[ 0.02786596]\n",
      " [-0.05070764]\n",
      " [ 0.08525827]]\n",
      "Iteration 9173 | Cost: 0.28450599971450846 | Gradient: [[ 0.02786486]\n",
      " [-0.05070486]\n",
      " [ 0.0852524 ]]\n",
      "Iteration 9174 | Cost: 0.28449538464482843 | Gradient: [[ 0.02786377]\n",
      " [-0.05070207]\n",
      " [ 0.08524654]]\n",
      "Iteration 9175 | Cost: 0.28448477091823776 | Gradient: [[ 0.02786268]\n",
      " [-0.05069929]\n",
      " [ 0.08524067]]\n",
      "Iteration 9176 | Cost: 0.28447415853449015 | Gradient: [[ 0.02786158]\n",
      " [-0.05069651]\n",
      " [ 0.08523481]]\n",
      "Iteration 9177 | Cost: 0.2844635474933393 | Gradient: [[ 0.02786049]\n",
      " [-0.05069373]\n",
      " [ 0.08522895]]\n",
      "Iteration 9178 | Cost: 0.28445293779453923 | Gradient: [[ 0.02785939]\n",
      " [-0.05069095]\n",
      " [ 0.08522309]]\n",
      "Iteration 9179 | Cost: 0.2844423294378438 | Gradient: [[ 0.0278583 ]\n",
      " [-0.05068817]\n",
      " [ 0.08521722]]\n",
      "Iteration 9180 | Cost: 0.28443172242300696 | Gradient: [[ 0.0278572 ]\n",
      " [-0.05068539]\n",
      " [ 0.08521136]]\n",
      "Iteration 9181 | Cost: 0.2844211167497829 | Gradient: [[ 0.02785611]\n",
      " [-0.05068261]\n",
      " [ 0.0852055 ]]\n",
      "Iteration 9182 | Cost: 0.2844105124179254 | Gradient: [[ 0.02785501]\n",
      " [-0.05067983]\n",
      " [ 0.08519964]]\n",
      "Iteration 9183 | Cost: 0.28439990942718896 | Gradient: [[ 0.02785392]\n",
      " [-0.05067705]\n",
      " [ 0.08519378]]\n",
      "Iteration 9184 | Cost: 0.28438930777732757 | Gradient: [[ 0.02785282]\n",
      " [-0.05067427]\n",
      " [ 0.08518793]]\n",
      "Iteration 9185 | Cost: 0.2843787074680956 | Gradient: [[ 0.02785173]\n",
      " [-0.05067149]\n",
      " [ 0.08518207]]\n",
      "Iteration 9186 | Cost: 0.28436810849924743 | Gradient: [[ 0.02785063]\n",
      " [-0.05066872]\n",
      " [ 0.08517621]]\n",
      "Iteration 9187 | Cost: 0.2843575108705373 | Gradient: [[ 0.02784954]\n",
      " [-0.05066594]\n",
      " [ 0.08517036]]\n",
      "Iteration 9188 | Cost: 0.28434691458171973 | Gradient: [[ 0.02784844]\n",
      " [-0.05066316]\n",
      " [ 0.0851645 ]]\n",
      "Iteration 9189 | Cost: 0.28433631963254924 | Gradient: [[ 0.02784735]\n",
      " [-0.05066039]\n",
      " [ 0.08515865]]\n",
      "Iteration 9190 | Cost: 0.28432572602278033 | Gradient: [[ 0.02784625]\n",
      " [-0.05065761]\n",
      " [ 0.08515279]]\n",
      "Iteration 9191 | Cost: 0.28431513375216766 | Gradient: [[ 0.02784516]\n",
      " [-0.05065484]\n",
      " [ 0.08514694]]\n",
      "Iteration 9192 | Cost: 0.2843045428204658 | Gradient: [[ 0.02784406]\n",
      " [-0.05065206]\n",
      " [ 0.08514109]]\n",
      "Iteration 9193 | Cost: 0.28429395322742973 | Gradient: [[ 0.02784296]\n",
      " [-0.05064929]\n",
      " [ 0.08513523]]\n",
      "Iteration 9194 | Cost: 0.28428336497281403 | Gradient: [[ 0.02784187]\n",
      " [-0.05064651]\n",
      " [ 0.08512938]]\n",
      "Iteration 9195 | Cost: 0.2842727780563736 | Gradient: [[ 0.02784077]\n",
      " [-0.05064374]\n",
      " [ 0.08512353]]\n",
      "Iteration 9196 | Cost: 0.28426219247786333 | Gradient: [[ 0.02783968]\n",
      " [-0.05064097]\n",
      " [ 0.08511768]]\n",
      "Iteration 9197 | Cost: 0.2842516082370382 | Gradient: [[ 0.02783858]\n",
      " [-0.0506382 ]\n",
      " [ 0.08511183]]\n",
      "Iteration 9198 | Cost: 0.2842410253336533 | Gradient: [[ 0.02783749]\n",
      " [-0.05063542]\n",
      " [ 0.08510599]]\n",
      "Iteration 9199 | Cost: 0.28423044376746354 | Gradient: [[ 0.02783639]\n",
      " [-0.05063265]\n",
      " [ 0.08510014]]\n",
      "Iteration 9200 | Cost: 0.28421986353822426 | Gradient: [[ 0.0278353 ]\n",
      " [-0.05062988]\n",
      " [ 0.08509429]]\n",
      "Iteration 9201 | Cost: 0.28420928464569045 | Gradient: [[ 0.0278342 ]\n",
      " [-0.05062711]\n",
      " [ 0.08508844]]\n",
      "Iteration 9202 | Cost: 0.28419870708961753 | Gradient: [[ 0.02783311]\n",
      " [-0.05062434]\n",
      " [ 0.0850826 ]]\n",
      "Iteration 9203 | Cost: 0.2841881308697607 | Gradient: [[ 0.02783201]\n",
      " [-0.05062157]\n",
      " [ 0.08507675]]\n",
      "Iteration 9204 | Cost: 0.28417755598587535 | Gradient: [[ 0.02783091]\n",
      " [-0.0506188 ]\n",
      " [ 0.08507091]]\n",
      "Iteration 9205 | Cost: 0.28416698243771704 | Gradient: [[ 0.02782982]\n",
      " [-0.05061603]\n",
      " [ 0.08506506]]\n",
      "Iteration 9206 | Cost: 0.284156410225041 | Gradient: [[ 0.02782872]\n",
      " [-0.05061326]\n",
      " [ 0.08505922]]\n",
      "Iteration 9207 | Cost: 0.28414583934760296 | Gradient: [[ 0.02782763]\n",
      " [-0.05061049]\n",
      " [ 0.08505338]]\n",
      "Iteration 9208 | Cost: 0.28413526980515835 | Gradient: [[ 0.02782653]\n",
      " [-0.05060772]\n",
      " [ 0.08504754]]\n",
      "Iteration 9209 | Cost: 0.28412470159746306 | Gradient: [[ 0.02782544]\n",
      " [-0.05060496]\n",
      " [ 0.0850417 ]]\n",
      "Iteration 9210 | Cost: 0.2841141347242725 | Gradient: [[ 0.02782434]\n",
      " [-0.05060219]\n",
      " [ 0.08503586]]\n",
      "Iteration 9211 | Cost: 0.28410356918534274 | Gradient: [[ 0.02782324]\n",
      " [-0.05059942]\n",
      " [ 0.08503002]]\n",
      "Iteration 9212 | Cost: 0.28409300498042944 | Gradient: [[ 0.02782215]\n",
      " [-0.05059666]\n",
      " [ 0.08502418]]\n",
      "Iteration 9213 | Cost: 0.2840824421092884 | Gradient: [[ 0.02782105]\n",
      " [-0.05059389]\n",
      " [ 0.08501834]]\n",
      "Iteration 9214 | Cost: 0.28407188057167576 | Gradient: [[ 0.02781996]\n",
      " [-0.05059113]\n",
      " [ 0.0850125 ]]\n",
      "Iteration 9215 | Cost: 0.28406132036734744 | Gradient: [[ 0.02781886]\n",
      " [-0.05058836]\n",
      " [ 0.08500667]]\n",
      "Iteration 9216 | Cost: 0.28405076149605946 | Gradient: [[ 0.02781776]\n",
      " [-0.0505856 ]\n",
      " [ 0.08500083]]\n",
      "Iteration 9217 | Cost: 0.2840402039575679 | Gradient: [[ 0.02781667]\n",
      " [-0.05058283]\n",
      " [ 0.08499499]]\n",
      "Iteration 9218 | Cost: 0.284029647751629 | Gradient: [[ 0.02781557]\n",
      " [-0.05058007]\n",
      " [ 0.08498916]]\n",
      "Iteration 9219 | Cost: 0.28401909287799904 | Gradient: [[ 0.02781448]\n",
      " [-0.05057731]\n",
      " [ 0.08498333]]\n",
      "Iteration 9220 | Cost: 0.28400853933643416 | Gradient: [[ 0.02781338]\n",
      " [-0.05057454]\n",
      " [ 0.08497749]]\n",
      "Iteration 9221 | Cost: 0.2839979871266908 | Gradient: [[ 0.02781228]\n",
      " [-0.05057178]\n",
      " [ 0.08497166]]\n",
      "Iteration 9222 | Cost: 0.28398743624852524 | Gradient: [[ 0.02781119]\n",
      " [-0.05056902]\n",
      " [ 0.08496583]]\n",
      "Iteration 9223 | Cost: 0.2839768867016941 | Gradient: [[ 0.02781009]\n",
      " [-0.05056626]\n",
      " [ 0.08496   ]]\n",
      "Iteration 9224 | Cost: 0.28396633848595376 | Gradient: [[ 0.027809  ]\n",
      " [-0.0505635 ]\n",
      " [ 0.08495417]]\n",
      "Iteration 9225 | Cost: 0.2839557916010608 | Gradient: [[ 0.0278079 ]\n",
      " [-0.05056073]\n",
      " [ 0.08494834]]\n",
      "Iteration 9226 | Cost: 0.283945246046772 | Gradient: [[ 0.0278068 ]\n",
      " [-0.05055797]\n",
      " [ 0.08494251]]\n",
      "Iteration 9227 | Cost: 0.28393470182284386 | Gradient: [[ 0.02780571]\n",
      " [-0.05055521]\n",
      " [ 0.08493668]]\n",
      "Iteration 9228 | Cost: 0.2839241589290332 | Gradient: [[ 0.02780461]\n",
      " [-0.05055246]\n",
      " [ 0.08493085]]\n",
      "Iteration 9229 | Cost: 0.2839136173650969 | Gradient: [[ 0.02780351]\n",
      " [-0.0505497 ]\n",
      " [ 0.08492502]]\n",
      "Iteration 9230 | Cost: 0.2839030771307916 | Gradient: [[ 0.02780242]\n",
      " [-0.05054694]\n",
      " [ 0.0849192 ]]\n",
      "Iteration 9231 | Cost: 0.2838925382258744 | Gradient: [[ 0.02780132]\n",
      " [-0.05054418]\n",
      " [ 0.08491337]]\n",
      "Iteration 9232 | Cost: 0.28388200065010216 | Gradient: [[ 0.02780022]\n",
      " [-0.05054142]\n",
      " [ 0.08490755]]\n",
      "Iteration 9233 | Cost: 0.28387146440323197 | Gradient: [[ 0.02779913]\n",
      " [-0.05053866]\n",
      " [ 0.08490172]]\n",
      "Iteration 9234 | Cost: 0.2838609294850209 | Gradient: [[ 0.02779803]\n",
      " [-0.05053591]\n",
      " [ 0.0848959 ]]\n",
      "Iteration 9235 | Cost: 0.28385039589522604 | Gradient: [[ 0.02779693]\n",
      " [-0.05053315]\n",
      " [ 0.08489007]]\n",
      "Iteration 9236 | Cost: 0.2838398636336047 | Gradient: [[ 0.02779584]\n",
      " [-0.0505304 ]\n",
      " [ 0.08488425]]\n",
      "Iteration 9237 | Cost: 0.283829332699914 | Gradient: [[ 0.02779474]\n",
      " [-0.05052764]\n",
      " [ 0.08487843]]\n",
      "Iteration 9238 | Cost: 0.28381880309391133 | Gradient: [[ 0.02779364]\n",
      " [-0.05052488]\n",
      " [ 0.08487261]]\n",
      "Iteration 9239 | Cost: 0.28380827481535403 | Gradient: [[ 0.02779255]\n",
      " [-0.05052213]\n",
      " [ 0.08486679]]\n",
      "Iteration 9240 | Cost: 0.2837977478639996 | Gradient: [[ 0.02779145]\n",
      " [-0.05051938]\n",
      " [ 0.08486097]]\n",
      "Iteration 9241 | Cost: 0.28378722223960534 | Gradient: [[ 0.02779035]\n",
      " [-0.05051662]\n",
      " [ 0.08485515]]\n",
      "Iteration 9242 | Cost: 0.28377669794192895 | Gradient: [[ 0.02778926]\n",
      " [-0.05051387]\n",
      " [ 0.08484933]]\n",
      "Iteration 9243 | Cost: 0.283766174970728 | Gradient: [[ 0.02778816]\n",
      " [-0.05051111]\n",
      " [ 0.08484351]]\n",
      "Iteration 9244 | Cost: 0.28375565332576014 | Gradient: [[ 0.02778706]\n",
      " [-0.05050836]\n",
      " [ 0.0848377 ]]\n",
      "Iteration 9245 | Cost: 0.283745133006783 | Gradient: [[ 0.02778597]\n",
      " [-0.05050561]\n",
      " [ 0.08483188]]\n",
      "Iteration 9246 | Cost: 0.28373461401355443 | Gradient: [[ 0.02778487]\n",
      " [-0.05050286]\n",
      " [ 0.08482607]]\n",
      "Iteration 9247 | Cost: 0.28372409634583223 | Gradient: [[ 0.02778377]\n",
      " [-0.05050011]\n",
      " [ 0.08482025]]\n",
      "Iteration 9248 | Cost: 0.28371358000337427 | Gradient: [[ 0.02778268]\n",
      " [-0.05049736]\n",
      " [ 0.08481444]]\n",
      "Iteration 9249 | Cost: 0.28370306498593845 | Gradient: [[ 0.02778158]\n",
      " [-0.05049461]\n",
      " [ 0.08480862]]\n",
      "Iteration 9250 | Cost: 0.28369255129328286 | Gradient: [[ 0.02778048]\n",
      " [-0.05049186]\n",
      " [ 0.08480281]]\n",
      "Iteration 9251 | Cost: 0.28368203892516547 | Gradient: [[ 0.02777939]\n",
      " [-0.05048911]\n",
      " [ 0.084797  ]]\n",
      "Iteration 9252 | Cost: 0.28367152788134437 | Gradient: [[ 0.02777829]\n",
      " [-0.05048636]\n",
      " [ 0.08479119]]\n",
      "Iteration 9253 | Cost: 0.2836610181615779 | Gradient: [[ 0.02777719]\n",
      " [-0.05048361]\n",
      " [ 0.08478538]]\n",
      "Iteration 9254 | Cost: 0.28365050976562395 | Gradient: [[ 0.02777609]\n",
      " [-0.05048086]\n",
      " [ 0.08477957]]\n",
      "Iteration 9255 | Cost: 0.2836400026932411 | Gradient: [[ 0.027775  ]\n",
      " [-0.05047811]\n",
      " [ 0.08477376]]\n",
      "Iteration 9256 | Cost: 0.2836294969441875 | Gradient: [[ 0.0277739 ]\n",
      " [-0.05047536]\n",
      " [ 0.08476795]]\n",
      "Iteration 9257 | Cost: 0.2836189925182217 | Gradient: [[ 0.0277728 ]\n",
      " [-0.05047262]\n",
      " [ 0.08476214]]\n",
      "Iteration 9258 | Cost: 0.28360848941510197 | Gradient: [[ 0.02777171]\n",
      " [-0.05046987]\n",
      " [ 0.08475633]]\n",
      "Iteration 9259 | Cost: 0.28359798763458693 | Gradient: [[ 0.02777061]\n",
      " [-0.05046712]\n",
      " [ 0.08475053]]\n",
      "Iteration 9260 | Cost: 0.2835874871764351 | Gradient: [[ 0.02776951]\n",
      " [-0.05046438]\n",
      " [ 0.08474472]]\n",
      "Iteration 9261 | Cost: 0.28357698804040515 | Gradient: [[ 0.02776841]\n",
      " [-0.05046163]\n",
      " [ 0.08473891]]\n",
      "Iteration 9262 | Cost: 0.2835664902262557 | Gradient: [[ 0.02776732]\n",
      " [-0.05045889]\n",
      " [ 0.08473311]]\n",
      "Iteration 9263 | Cost: 0.28355599373374535 | Gradient: [[ 0.02776622]\n",
      " [-0.05045614]\n",
      " [ 0.08472731]]\n",
      "Iteration 9264 | Cost: 0.28354549856263317 | Gradient: [[ 0.02776512]\n",
      " [-0.0504534 ]\n",
      " [ 0.0847215 ]]\n",
      "Iteration 9265 | Cost: 0.28353500471267784 | Gradient: [[ 0.02776403]\n",
      " [-0.05045065]\n",
      " [ 0.0847157 ]]\n",
      "Iteration 9266 | Cost: 0.2835245121836381 | Gradient: [[ 0.02776293]\n",
      " [-0.05044791]\n",
      " [ 0.0847099 ]]\n",
      "Iteration 9267 | Cost: 0.28351402097527323 | Gradient: [[ 0.02776183]\n",
      " [-0.05044517]\n",
      " [ 0.0847041 ]]\n",
      "Iteration 9268 | Cost: 0.28350353108734205 | Gradient: [[ 0.02776073]\n",
      " [-0.05044242]\n",
      " [ 0.0846983 ]]\n",
      "Iteration 9269 | Cost: 0.28349304251960367 | Gradient: [[ 0.02775964]\n",
      " [-0.05043968]\n",
      " [ 0.0846925 ]]\n",
      "Iteration 9270 | Cost: 0.2834825552718172 | Gradient: [[ 0.02775854]\n",
      " [-0.05043694]\n",
      " [ 0.0846867 ]]\n",
      "Iteration 9271 | Cost: 0.2834720693437418 | Gradient: [[ 0.02775744]\n",
      " [-0.0504342 ]\n",
      " [ 0.0846809 ]]\n",
      "Iteration 9272 | Cost: 0.2834615847351367 | Gradient: [[ 0.02775634]\n",
      " [-0.05043146]\n",
      " [ 0.0846751 ]]\n",
      "Iteration 9273 | Cost: 0.2834511014457613 | Gradient: [[ 0.02775525]\n",
      " [-0.05042872]\n",
      " [ 0.0846693 ]]\n",
      "Iteration 9274 | Cost: 0.2834406194753748 | Gradient: [[ 0.02775415]\n",
      " [-0.05042598]\n",
      " [ 0.08466351]]\n",
      "Iteration 9275 | Cost: 0.28343013882373674 | Gradient: [[ 0.02775305]\n",
      " [-0.05042324]\n",
      " [ 0.08465771]]\n",
      "Iteration 9276 | Cost: 0.2834196594906065 | Gradient: [[ 0.02775195]\n",
      " [-0.0504205 ]\n",
      " [ 0.08465192]]\n",
      "Iteration 9277 | Cost: 0.2834091814757435 | Gradient: [[ 0.02775085]\n",
      " [-0.05041776]\n",
      " [ 0.08464612]]\n",
      "Iteration 9278 | Cost: 0.2833987047789076 | Gradient: [[ 0.02774976]\n",
      " [-0.05041502]\n",
      " [ 0.08464033]]\n",
      "Iteration 9279 | Cost: 0.28338822939985825 | Gradient: [[ 0.02774866]\n",
      " [-0.05041228]\n",
      " [ 0.08463453]]\n",
      "Iteration 9280 | Cost: 0.2833777553383551 | Gradient: [[ 0.02774756]\n",
      " [-0.05040955]\n",
      " [ 0.08462874]]\n",
      "Iteration 9281 | Cost: 0.28336728259415794 | Gradient: [[ 0.02774646]\n",
      " [-0.05040681]\n",
      " [ 0.08462295]]\n",
      "Iteration 9282 | Cost: 0.2833568111670266 | Gradient: [[ 0.02774537]\n",
      " [-0.05040407]\n",
      " [ 0.08461716]]\n",
      "Iteration 9283 | Cost: 0.2833463410567209 | Gradient: [[ 0.02774427]\n",
      " [-0.05040134]\n",
      " [ 0.08461137]]\n",
      "Iteration 9284 | Cost: 0.2833358722630007 | Gradient: [[ 0.02774317]\n",
      " [-0.0503986 ]\n",
      " [ 0.08460558]]\n",
      "Iteration 9285 | Cost: 0.2833254047856262 | Gradient: [[ 0.02774207]\n",
      " [-0.05039586]\n",
      " [ 0.08459979]]\n",
      "Iteration 9286 | Cost: 0.28331493862435714 | Gradient: [[ 0.02774097]\n",
      " [-0.05039313]\n",
      " [ 0.084594  ]]\n",
      "Iteration 9287 | Cost: 0.2833044737789537 | Gradient: [[ 0.02773988]\n",
      " [-0.05039039]\n",
      " [ 0.08458821]]\n",
      "Iteration 9288 | Cost: 0.28329401024917605 | Gradient: [[ 0.02773878]\n",
      " [-0.05038766]\n",
      " [ 0.08458243]]\n",
      "Iteration 9289 | Cost: 0.2832835480347844 | Gradient: [[ 0.02773768]\n",
      " [-0.05038493]\n",
      " [ 0.08457664]]\n",
      "Iteration 9290 | Cost: 0.28327308713553895 | Gradient: [[ 0.02773658]\n",
      " [-0.05038219]\n",
      " [ 0.08457086]]\n",
      "Iteration 9291 | Cost: 0.2832626275512 | Gradient: [[ 0.02773548]\n",
      " [-0.05037946]\n",
      " [ 0.08456507]]\n",
      "Iteration 9292 | Cost: 0.28325216928152797 | Gradient: [[ 0.02773439]\n",
      " [-0.05037673]\n",
      " [ 0.08455929]]\n",
      "Iteration 9293 | Cost: 0.2832417123262832 | Gradient: [[ 0.02773329]\n",
      " [-0.05037399]\n",
      " [ 0.0845535 ]]\n",
      "Iteration 9294 | Cost: 0.28323125668522625 | Gradient: [[ 0.02773219]\n",
      " [-0.05037126]\n",
      " [ 0.08454772]]\n",
      "Iteration 9295 | Cost: 0.2832208023581176 | Gradient: [[ 0.02773109]\n",
      " [-0.05036853]\n",
      " [ 0.08454194]]\n",
      "Iteration 9296 | Cost: 0.2832103493447178 | Gradient: [[ 0.02772999]\n",
      " [-0.0503658 ]\n",
      " [ 0.08453616]]\n",
      "Iteration 9297 | Cost: 0.2831998976447875 | Gradient: [[ 0.0277289 ]\n",
      " [-0.05036307]\n",
      " [ 0.08453038]]\n",
      "Iteration 9298 | Cost: 0.2831894472580874 | Gradient: [[ 0.0277278 ]\n",
      " [-0.05036034]\n",
      " [ 0.0845246 ]]\n",
      "Iteration 9299 | Cost: 0.28317899818437836 | Gradient: [[ 0.0277267 ]\n",
      " [-0.05035761]\n",
      " [ 0.08451882]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9300 | Cost: 0.2831685504234211 | Gradient: [[ 0.0277256 ]\n",
      " [-0.05035488]\n",
      " [ 0.08451304]]\n",
      "Iteration 9301 | Cost: 0.2831581039749765 | Gradient: [[ 0.0277245 ]\n",
      " [-0.05035215]\n",
      " [ 0.08450726]]\n",
      "Iteration 9302 | Cost: 0.28314765883880544 | Gradient: [[ 0.0277234 ]\n",
      " [-0.05034942]\n",
      " [ 0.08450148]]\n",
      "Iteration 9303 | Cost: 0.28313721501466893 | Gradient: [[ 0.02772231]\n",
      " [-0.0503467 ]\n",
      " [ 0.08449571]]\n",
      "Iteration 9304 | Cost: 0.283126772502328 | Gradient: [[ 0.02772121]\n",
      " [-0.05034397]\n",
      " [ 0.08448993]]\n",
      "Iteration 9305 | Cost: 0.28311633130154373 | Gradient: [[ 0.02772011]\n",
      " [-0.05034124]\n",
      " [ 0.08448415]]\n",
      "Iteration 9306 | Cost: 0.2831058914120773 | Gradient: [[ 0.02771901]\n",
      " [-0.05033851]\n",
      " [ 0.08447838]]\n",
      "Iteration 9307 | Cost: 0.2830954528336899 | Gradient: [[ 0.02771791]\n",
      " [-0.05033579]\n",
      " [ 0.08447261]]\n",
      "Iteration 9308 | Cost: 0.28308501556614274 | Gradient: [[ 0.02771681]\n",
      " [-0.05033306]\n",
      " [ 0.08446683]]\n",
      "Iteration 9309 | Cost: 0.2830745796091971 | Gradient: [[ 0.02771572]\n",
      " [-0.05033034]\n",
      " [ 0.08446106]]\n",
      "Iteration 9310 | Cost: 0.28306414496261445 | Gradient: [[ 0.02771462]\n",
      " [-0.05032761]\n",
      " [ 0.08445529]]\n",
      "Iteration 9311 | Cost: 0.2830537116261562 | Gradient: [[ 0.02771352]\n",
      " [-0.05032489]\n",
      " [ 0.08444952]]\n",
      "Iteration 9312 | Cost: 0.2830432795995838 | Gradient: [[ 0.02771242]\n",
      " [-0.05032216]\n",
      " [ 0.08444375]]\n",
      "Iteration 9313 | Cost: 0.28303284888265884 | Gradient: [[ 0.02771132]\n",
      " [-0.05031944]\n",
      " [ 0.08443798]]\n",
      "Iteration 9314 | Cost: 0.2830224194751428 | Gradient: [[ 0.02771022]\n",
      " [-0.05031671]\n",
      " [ 0.08443221]]\n",
      "Iteration 9315 | Cost: 0.2830119913767974 | Gradient: [[ 0.02770912]\n",
      " [-0.05031399]\n",
      " [ 0.08442644]]\n",
      "Iteration 9316 | Cost: 0.28300156458738435 | Gradient: [[ 0.02770803]\n",
      " [-0.05031127]\n",
      " [ 0.08442067]]\n",
      "Iteration 9317 | Cost: 0.2829911391066653 | Gradient: [[ 0.02770693]\n",
      " [-0.05030855]\n",
      " [ 0.0844149 ]]\n",
      "Iteration 9318 | Cost: 0.28298071493440213 | Gradient: [[ 0.02770583]\n",
      " [-0.05030582]\n",
      " [ 0.08440914]]\n",
      "Iteration 9319 | Cost: 0.2829702920703568 | Gradient: [[ 0.02770473]\n",
      " [-0.0503031 ]\n",
      " [ 0.08440337]]\n",
      "Iteration 9320 | Cost: 0.28295987051429117 | Gradient: [[ 0.02770363]\n",
      " [-0.05030038]\n",
      " [ 0.08439761]]\n",
      "Iteration 9321 | Cost: 0.28294945026596713 | Gradient: [[ 0.02770253]\n",
      " [-0.05029766]\n",
      " [ 0.08439184]]\n",
      "Iteration 9322 | Cost: 0.28293903132514686 | Gradient: [[ 0.02770143]\n",
      " [-0.05029494]\n",
      " [ 0.08438608]]\n",
      "Iteration 9323 | Cost: 0.2829286136915924 | Gradient: [[ 0.02770033]\n",
      " [-0.05029222]\n",
      " [ 0.08438031]]\n",
      "Iteration 9324 | Cost: 0.28291819736506585 | Gradient: [[ 0.02769924]\n",
      " [-0.0502895 ]\n",
      " [ 0.08437455]]\n",
      "Iteration 9325 | Cost: 0.28290778234532943 | Gradient: [[ 0.02769814]\n",
      " [-0.05028678]\n",
      " [ 0.08436879]]\n",
      "Iteration 9326 | Cost: 0.2828973686321454 | Gradient: [[ 0.02769704]\n",
      " [-0.05028406]\n",
      " [ 0.08436303]]\n",
      "Iteration 9327 | Cost: 0.2828869562252761 | Gradient: [[ 0.02769594]\n",
      " [-0.05028134]\n",
      " [ 0.08435727]]\n",
      "Iteration 9328 | Cost: 0.2828765451244839 | Gradient: [[ 0.02769484]\n",
      " [-0.05027863]\n",
      " [ 0.08435151]]\n",
      "Iteration 9329 | Cost: 0.28286613532953125 | Gradient: [[ 0.02769374]\n",
      " [-0.05027591]\n",
      " [ 0.08434575]]\n",
      "Iteration 9330 | Cost: 0.2828557268401805 | Gradient: [[ 0.02769264]\n",
      " [-0.05027319]\n",
      " [ 0.08433999]]\n",
      "Iteration 9331 | Cost: 0.28284531965619436 | Gradient: [[ 0.02769154]\n",
      " [-0.05027048]\n",
      " [ 0.08433423]]\n",
      "Iteration 9332 | Cost: 0.28283491377733533 | Gradient: [[ 0.02769044]\n",
      " [-0.05026776]\n",
      " [ 0.08432848]]\n",
      "Iteration 9333 | Cost: 0.282824509203366 | Gradient: [[ 0.02768934]\n",
      " [-0.05026504]\n",
      " [ 0.08432272]]\n",
      "Iteration 9334 | Cost: 0.28281410593404915 | Gradient: [[ 0.02768825]\n",
      " [-0.05026233]\n",
      " [ 0.08431696]]\n",
      "Iteration 9335 | Cost: 0.2828037039691475 | Gradient: [[ 0.02768715]\n",
      " [-0.05025961]\n",
      " [ 0.08431121]]\n",
      "Iteration 9336 | Cost: 0.2827933033084239 | Gradient: [[ 0.02768605]\n",
      " [-0.0502569 ]\n",
      " [ 0.08430545]]\n",
      "Iteration 9337 | Cost: 0.2827829039516412 | Gradient: [[ 0.02768495]\n",
      " [-0.05025418]\n",
      " [ 0.0842997 ]]\n",
      "Iteration 9338 | Cost: 0.2827725058985623 | Gradient: [[ 0.02768385]\n",
      " [-0.05025147]\n",
      " [ 0.08429395]]\n",
      "Iteration 9339 | Cost: 0.2827621091489502 | Gradient: [[ 0.02768275]\n",
      " [-0.05024876]\n",
      " [ 0.0842882 ]]\n",
      "Iteration 9340 | Cost: 0.282751713702568 | Gradient: [[ 0.02768165]\n",
      " [-0.05024604]\n",
      " [ 0.08428244]]\n",
      "Iteration 9341 | Cost: 0.2827413195591787 | Gradient: [[ 0.02768055]\n",
      " [-0.05024333]\n",
      " [ 0.08427669]]\n",
      "Iteration 9342 | Cost: 0.28273092671854544 | Gradient: [[ 0.02767945]\n",
      " [-0.05024062]\n",
      " [ 0.08427094]]\n",
      "Iteration 9343 | Cost: 0.28272053518043144 | Gradient: [[ 0.02767835]\n",
      " [-0.05023791]\n",
      " [ 0.08426519]]\n",
      "Iteration 9344 | Cost: 0.28271014494459995 | Gradient: [[ 0.02767725]\n",
      " [-0.0502352 ]\n",
      " [ 0.08425944]]\n",
      "Iteration 9345 | Cost: 0.2826997560108143 | Gradient: [[ 0.02767615]\n",
      " [-0.05023249]\n",
      " [ 0.0842537 ]]\n",
      "Iteration 9346 | Cost: 0.2826893683788379 | Gradient: [[ 0.02767506]\n",
      " [-0.05022977]\n",
      " [ 0.08424795]]\n",
      "Iteration 9347 | Cost: 0.28267898204843406 | Gradient: [[ 0.02767396]\n",
      " [-0.05022706]\n",
      " [ 0.0842422 ]]\n",
      "Iteration 9348 | Cost: 0.28266859701936636 | Gradient: [[ 0.02767286]\n",
      " [-0.05022436]\n",
      " [ 0.08423646]]\n",
      "Iteration 9349 | Cost: 0.28265821329139823 | Gradient: [[ 0.02767176]\n",
      " [-0.05022165]\n",
      " [ 0.08423071]]\n",
      "Iteration 9350 | Cost: 0.28264783086429335 | Gradient: [[ 0.02767066]\n",
      " [-0.05021894]\n",
      " [ 0.08422496]]\n",
      "Iteration 9351 | Cost: 0.28263744973781524 | Gradient: [[ 0.02766956]\n",
      " [-0.05021623]\n",
      " [ 0.08421922]]\n",
      "Iteration 9352 | Cost: 0.28262706991172776 | Gradient: [[ 0.02766846]\n",
      " [-0.05021352]\n",
      " [ 0.08421348]]\n",
      "Iteration 9353 | Cost: 0.28261669138579454 | Gradient: [[ 0.02766736]\n",
      " [-0.05021081]\n",
      " [ 0.08420773]]\n",
      "Iteration 9354 | Cost: 0.28260631415977944 | Gradient: [[ 0.02766626]\n",
      " [-0.05020811]\n",
      " [ 0.08420199]]\n",
      "Iteration 9355 | Cost: 0.2825959382334463 | Gradient: [[ 0.02766516]\n",
      " [-0.0502054 ]\n",
      " [ 0.08419625]]\n",
      "Iteration 9356 | Cost: 0.282585563606559 | Gradient: [[ 0.02766406]\n",
      " [-0.05020269]\n",
      " [ 0.08419051]]\n",
      "Iteration 9357 | Cost: 0.28257519027888156 | Gradient: [[ 0.02766296]\n",
      " [-0.05019999]\n",
      " [ 0.08418477]]\n",
      "Iteration 9358 | Cost: 0.28256481825017804 | Gradient: [[ 0.02766186]\n",
      " [-0.05019728]\n",
      " [ 0.08417903]]\n",
      "Iteration 9359 | Cost: 0.2825544475202124 | Gradient: [[ 0.02766076]\n",
      " [-0.05019457]\n",
      " [ 0.08417329]]\n",
      "Iteration 9360 | Cost: 0.28254407808874893 | Gradient: [[ 0.02765966]\n",
      " [-0.05019187]\n",
      " [ 0.08416755]]\n",
      "Iteration 9361 | Cost: 0.28253370995555166 | Gradient: [[ 0.02765856]\n",
      " [-0.05018917]\n",
      " [ 0.08416182]]\n",
      "Iteration 9362 | Cost: 0.282523343120385 | Gradient: [[ 0.02765746]\n",
      " [-0.05018646]\n",
      " [ 0.08415608]]\n",
      "Iteration 9363 | Cost: 0.28251297758301314 | Gradient: [[ 0.02765636]\n",
      " [-0.05018376]\n",
      " [ 0.08415034]]\n",
      "Iteration 9364 | Cost: 0.2825026133432005 | Gradient: [[ 0.02765526]\n",
      " [-0.05018105]\n",
      " [ 0.08414461]]\n",
      "Iteration 9365 | Cost: 0.2824922504007114 | Gradient: [[ 0.02765416]\n",
      " [-0.05017835]\n",
      " [ 0.08413887]]\n",
      "Iteration 9366 | Cost: 0.28248188875531044 | Gradient: [[ 0.02765307]\n",
      " [-0.05017565]\n",
      " [ 0.08413314]]\n",
      "Iteration 9367 | Cost: 0.282471528406762 | Gradient: [[ 0.02765197]\n",
      " [-0.05017295]\n",
      " [ 0.0841274 ]]\n",
      "Iteration 9368 | Cost: 0.28246116935483073 | Gradient: [[ 0.02765087]\n",
      " [-0.05017025]\n",
      " [ 0.08412167]]\n",
      "Iteration 9369 | Cost: 0.2824508115992812 | Gradient: [[ 0.02764977]\n",
      " [-0.05016754]\n",
      " [ 0.08411594]]\n",
      "Iteration 9370 | Cost: 0.28244045513987825 | Gradient: [[ 0.02764867]\n",
      " [-0.05016484]\n",
      " [ 0.08411021]]\n",
      "Iteration 9371 | Cost: 0.2824300999763865 | Gradient: [[ 0.02764757]\n",
      " [-0.05016214]\n",
      " [ 0.08410448]]\n",
      "Iteration 9372 | Cost: 0.28241974610857074 | Gradient: [[ 0.02764647]\n",
      " [-0.05015944]\n",
      " [ 0.08409875]]\n",
      "Iteration 9373 | Cost: 0.2824093935361959 | Gradient: [[ 0.02764537]\n",
      " [-0.05015674]\n",
      " [ 0.08409302]]\n",
      "Iteration 9374 | Cost: 0.28239904225902684 | Gradient: [[ 0.02764427]\n",
      " [-0.05015404]\n",
      " [ 0.08408729]]\n",
      "Iteration 9375 | Cost: 0.2823886922768284 | Gradient: [[ 0.02764317]\n",
      " [-0.05015135]\n",
      " [ 0.08408156]]\n",
      "Iteration 9376 | Cost: 0.28237834358936575 | Gradient: [[ 0.02764207]\n",
      " [-0.05014865]\n",
      " [ 0.08407583]]\n",
      "Iteration 9377 | Cost: 0.2823679961964039 | Gradient: [[ 0.02764097]\n",
      " [-0.05014595]\n",
      " [ 0.08407011]]\n",
      "Iteration 9378 | Cost: 0.282357650097708 | Gradient: [[ 0.02763987]\n",
      " [-0.05014325]\n",
      " [ 0.08406438]]\n",
      "Iteration 9379 | Cost: 0.2823473052930432 | Gradient: [[ 0.02763877]\n",
      " [-0.05014055]\n",
      " [ 0.08405866]]\n",
      "Iteration 9380 | Cost: 0.28233696178217477 | Gradient: [[ 0.02763767]\n",
      " [-0.05013786]\n",
      " [ 0.08405293]]\n",
      "Iteration 9381 | Cost: 0.28232661956486793 | Gradient: [[ 0.02763657]\n",
      " [-0.05013516]\n",
      " [ 0.08404721]]\n",
      "Iteration 9382 | Cost: 0.28231627864088815 | Gradient: [[ 0.02763547]\n",
      " [-0.05013247]\n",
      " [ 0.08404148]]\n",
      "Iteration 9383 | Cost: 0.2823059390100007 | Gradient: [[ 0.02763437]\n",
      " [-0.05012977]\n",
      " [ 0.08403576]]\n",
      "Iteration 9384 | Cost: 0.282295600671971 | Gradient: [[ 0.02763327]\n",
      " [-0.05012707]\n",
      " [ 0.08403004]]\n",
      "Iteration 9385 | Cost: 0.28228526362656464 | Gradient: [[ 0.02763217]\n",
      " [-0.05012438]\n",
      " [ 0.08402432]]\n",
      "Iteration 9386 | Cost: 0.28227492787354724 | Gradient: [[ 0.02763107]\n",
      " [-0.05012169]\n",
      " [ 0.0840186 ]]\n",
      "Iteration 9387 | Cost: 0.28226459341268434 | Gradient: [[ 0.02762997]\n",
      " [-0.05011899]\n",
      " [ 0.08401288]]\n",
      "Iteration 9388 | Cost: 0.28225426024374156 | Gradient: [[ 0.02762887]\n",
      " [-0.0501163 ]\n",
      " [ 0.08400716]]\n",
      "Iteration 9389 | Cost: 0.28224392836648476 | Gradient: [[ 0.02762777]\n",
      " [-0.0501136 ]\n",
      " [ 0.08400144]]\n",
      "Iteration 9390 | Cost: 0.2822335977806796 | Gradient: [[ 0.02762667]\n",
      " [-0.05011091]\n",
      " [ 0.08399572]]\n",
      "Iteration 9391 | Cost: 0.2822232684860919 | Gradient: [[ 0.02762557]\n",
      " [-0.05010822]\n",
      " [ 0.08399   ]]\n",
      "Iteration 9392 | Cost: 0.28221294048248763 | Gradient: [[ 0.02762447]\n",
      " [-0.05010553]\n",
      " [ 0.08398429]]\n",
      "Iteration 9393 | Cost: 0.2822026137696327 | Gradient: [[ 0.02762336]\n",
      " [-0.05010284]\n",
      " [ 0.08397857]]\n",
      "Iteration 9394 | Cost: 0.28219228834729315 | Gradient: [[ 0.02762226]\n",
      " [-0.05010014]\n",
      " [ 0.08397286]]\n",
      "Iteration 9395 | Cost: 0.2821819642152349 | Gradient: [[ 0.02762116]\n",
      " [-0.05009745]\n",
      " [ 0.08396714]]\n",
      "Iteration 9396 | Cost: 0.28217164137322426 | Gradient: [[ 0.02762006]\n",
      " [-0.05009476]\n",
      " [ 0.08396143]]\n",
      "Iteration 9397 | Cost: 0.28216131982102716 | Gradient: [[ 0.02761896]\n",
      " [-0.05009207]\n",
      " [ 0.08395571]]\n",
      "Iteration 9398 | Cost: 0.28215099955841005 | Gradient: [[ 0.02761786]\n",
      " [-0.05008938]\n",
      " [ 0.08395   ]]\n",
      "Iteration 9399 | Cost: 0.28214068058513897 | Gradient: [[ 0.02761676]\n",
      " [-0.05008669]\n",
      " [ 0.08394429]]\n",
      "Iteration 9400 | Cost: 0.2821303629009804 | Gradient: [[ 0.02761566]\n",
      " [-0.05008401]\n",
      " [ 0.08393858]]\n",
      "Iteration 9401 | Cost: 0.28212004650570066 | Gradient: [[ 0.02761456]\n",
      " [-0.05008132]\n",
      " [ 0.08393287]]\n",
      "Iteration 9402 | Cost: 0.28210973139906614 | Gradient: [[ 0.02761346]\n",
      " [-0.05007863]\n",
      " [ 0.08392716]]\n",
      "Iteration 9403 | Cost: 0.28209941758084345 | Gradient: [[ 0.02761236]\n",
      " [-0.05007594]\n",
      " [ 0.08392145]]\n",
      "Iteration 9404 | Cost: 0.28208910505079904 | Gradient: [[ 0.02761126]\n",
      " [-0.05007325]\n",
      " [ 0.08391574]]\n",
      "Iteration 9405 | Cost: 0.2820787938086995 | Gradient: [[ 0.02761016]\n",
      " [-0.05007057]\n",
      " [ 0.08391003]]\n",
      "Iteration 9406 | Cost: 0.2820684838543116 | Gradient: [[ 0.02760906]\n",
      " [-0.05006788]\n",
      " [ 0.08390433]]\n",
      "Iteration 9407 | Cost: 0.28205817518740184 | Gradient: [[ 0.02760796]\n",
      " [-0.05006519]\n",
      " [ 0.08389862]]\n",
      "Iteration 9408 | Cost: 0.2820478678077371 | Gradient: [[ 0.02760686]\n",
      " [-0.05006251]\n",
      " [ 0.08389291]]\n",
      "Iteration 9409 | Cost: 0.2820375617150842 | Gradient: [[ 0.02760576]\n",
      " [-0.05005982]\n",
      " [ 0.08388721]]\n",
      "Iteration 9410 | Cost: 0.28202725690921 | Gradient: [[ 0.02760466]\n",
      " [-0.05005714]\n",
      " [ 0.0838815 ]]\n",
      "Iteration 9411 | Cost: 0.28201695338988136 | Gradient: [[ 0.02760356]\n",
      " [-0.05005445]\n",
      " [ 0.0838758 ]]\n",
      "Iteration 9412 | Cost: 0.28200665115686535 | Gradient: [[ 0.02760246]\n",
      " [-0.05005177]\n",
      " [ 0.0838701 ]]\n",
      "Iteration 9413 | Cost: 0.28199635020992886 | Gradient: [[ 0.02760136]\n",
      " [-0.05004909]\n",
      " [ 0.08386439]]\n",
      "Iteration 9414 | Cost: 0.28198605054883913 | Gradient: [[ 0.02760026]\n",
      " [-0.0500464 ]\n",
      " [ 0.08385869]]\n",
      "Iteration 9415 | Cost: 0.2819757521733632 | Gradient: [[ 0.02759915]\n",
      " [-0.05004372]\n",
      " [ 0.08385299]]\n",
      "Iteration 9416 | Cost: 0.28196545508326826 | Gradient: [[ 0.02759805]\n",
      " [-0.05004104]\n",
      " [ 0.08384729]]\n",
      "Iteration 9417 | Cost: 0.28195515927832154 | Gradient: [[ 0.02759695]\n",
      " [-0.05003836]\n",
      " [ 0.08384159]]\n",
      "Iteration 9418 | Cost: 0.2819448647582905 | Gradient: [[ 0.02759585]\n",
      " [-0.05003567]\n",
      " [ 0.08383589]]\n",
      "Iteration 9419 | Cost: 0.2819345715229424 | Gradient: [[ 0.02759475]\n",
      " [-0.05003299]\n",
      " [ 0.08383019]]\n",
      "Iteration 9420 | Cost: 0.2819242795720445 | Gradient: [[ 0.02759365]\n",
      " [-0.05003031]\n",
      " [ 0.0838245 ]]\n",
      "Iteration 9421 | Cost: 0.28191398890536434 | Gradient: [[ 0.02759255]\n",
      " [-0.05002763]\n",
      " [ 0.0838188 ]]\n",
      "Iteration 9422 | Cost: 0.28190369952266964 | Gradient: [[ 0.02759145]\n",
      " [-0.05002495]\n",
      " [ 0.0838131 ]]\n",
      "Iteration 9423 | Cost: 0.2818934114237278 | Gradient: [[ 0.02759035]\n",
      " [-0.05002227]\n",
      " [ 0.08380741]]\n",
      "Iteration 9424 | Cost: 0.2818831246083064 | Gradient: [[ 0.02758925]\n",
      " [-0.05001959]\n",
      " [ 0.08380171]]\n",
      "Iteration 9425 | Cost: 0.2818728390761731 | Gradient: [[ 0.02758815]\n",
      " [-0.05001691]\n",
      " [ 0.08379602]]\n",
      "Iteration 9426 | Cost: 0.28186255482709577 | Gradient: [[ 0.02758705]\n",
      " [-0.05001423]\n",
      " [ 0.08379032]]\n",
      "Iteration 9427 | Cost: 0.2818522718608421 | Gradient: [[ 0.02758595]\n",
      " [-0.05001156]\n",
      " [ 0.08378463]]\n",
      "Iteration 9428 | Cost: 0.28184199017718 | Gradient: [[ 0.02758484]\n",
      " [-0.05000888]\n",
      " [ 0.08377894]]\n",
      "Iteration 9429 | Cost: 0.28183170977587724 | Gradient: [[ 0.02758374]\n",
      " [-0.0500062 ]\n",
      " [ 0.08377325]]\n",
      "Iteration 9430 | Cost: 0.2818214306567019 | Gradient: [[ 0.02758264]\n",
      " [-0.05000352]\n",
      " [ 0.08376755]]\n",
      "Iteration 9431 | Cost: 0.281811152819422 | Gradient: [[ 0.02758154]\n",
      " [-0.05000085]\n",
      " [ 0.08376186]]\n",
      "Iteration 9432 | Cost: 0.28180087626380546 | Gradient: [[ 0.02758044]\n",
      " [-0.04999817]\n",
      " [ 0.08375617]]\n",
      "Iteration 9433 | Cost: 0.28179060098962044 | Gradient: [[ 0.02757934]\n",
      " [-0.0499955 ]\n",
      " [ 0.08375048]]\n",
      "Iteration 9434 | Cost: 0.2817803269966351 | Gradient: [[ 0.02757824]\n",
      " [-0.04999282]\n",
      " [ 0.0837448 ]]\n",
      "Iteration 9435 | Cost: 0.2817700542846177 | Gradient: [[ 0.02757714]\n",
      " [-0.04999015]\n",
      " [ 0.08373911]]\n",
      "Iteration 9436 | Cost: 0.28175978285333647 | Gradient: [[ 0.02757604]\n",
      " [-0.04998747]\n",
      " [ 0.08373342]]\n",
      "Iteration 9437 | Cost: 0.28174951270255977 | Gradient: [[ 0.02757494]\n",
      " [-0.0499848 ]\n",
      " [ 0.08372773]]\n",
      "Iteration 9438 | Cost: 0.2817392438320559 | Gradient: [[ 0.02757384]\n",
      " [-0.04998212]\n",
      " [ 0.08372205]]\n",
      "Iteration 9439 | Cost: 0.2817289762415934 | Gradient: [[ 0.02757273]\n",
      " [-0.04997945]\n",
      " [ 0.08371636]]\n",
      "Iteration 9440 | Cost: 0.28171870993094067 | Gradient: [[ 0.02757163]\n",
      " [-0.04997678]\n",
      " [ 0.08371068]]\n",
      "Iteration 9441 | Cost: 0.2817084448998663 | Gradient: [[ 0.02757053]\n",
      " [-0.0499741 ]\n",
      " [ 0.083705  ]]\n",
      "Iteration 9442 | Cost: 0.28169818114813894 | Gradient: [[ 0.02756943]\n",
      " [-0.04997143]\n",
      " [ 0.08369931]]\n",
      "Iteration 9443 | Cost: 0.28168791867552706 | Gradient: [[ 0.02756833]\n",
      " [-0.04996876]\n",
      " [ 0.08369363]]\n",
      "Iteration 9444 | Cost: 0.2816776574817995 | Gradient: [[ 0.02756723]\n",
      " [-0.04996609]\n",
      " [ 0.08368795]]\n",
      "Iteration 9445 | Cost: 0.28166739756672493 | Gradient: [[ 0.02756613]\n",
      " [-0.04996342]\n",
      " [ 0.08368227]]\n",
      "Iteration 9446 | Cost: 0.28165713893007227 | Gradient: [[ 0.02756503]\n",
      " [-0.04996075]\n",
      " [ 0.08367659]]\n",
      "Iteration 9447 | Cost: 0.2816468815716103 | Gradient: [[ 0.02756393]\n",
      " [-0.04995808]\n",
      " [ 0.08367091]]\n",
      "Iteration 9448 | Cost: 0.2816366254911079 | Gradient: [[ 0.02756282]\n",
      " [-0.04995541]\n",
      " [ 0.08366523]]\n",
      "Iteration 9449 | Cost: 0.2816263706883341 | Gradient: [[ 0.02756172]\n",
      " [-0.04995274]\n",
      " [ 0.08365955]]\n",
      "Iteration 9450 | Cost: 0.281616117163058 | Gradient: [[ 0.02756062]\n",
      " [-0.04995007]\n",
      " [ 0.08365387]]\n",
      "Iteration 9451 | Cost: 0.2816058649150485 | Gradient: [[ 0.02755952]\n",
      " [-0.0499474 ]\n",
      " [ 0.08364819]]\n",
      "Iteration 9452 | Cost: 0.28159561394407484 | Gradient: [[ 0.02755842]\n",
      " [-0.04994473]\n",
      " [ 0.08364252]]\n",
      "Iteration 9453 | Cost: 0.2815853642499062 | Gradient: [[ 0.02755732]\n",
      " [-0.04994206]\n",
      " [ 0.08363684]]\n",
      "Iteration 9454 | Cost: 0.28157511583231176 | Gradient: [[ 0.02755622]\n",
      " [-0.04993939]\n",
      " [ 0.08363117]]\n",
      "Iteration 9455 | Cost: 0.2815648686910609 | Gradient: [[ 0.02755512]\n",
      " [-0.04993673]\n",
      " [ 0.08362549]]\n",
      "Iteration 9456 | Cost: 0.2815546228259229 | Gradient: [[ 0.02755401]\n",
      " [-0.04993406]\n",
      " [ 0.08361982]]\n",
      "Iteration 9457 | Cost: 0.28154437823666717 | Gradient: [[ 0.02755291]\n",
      " [-0.04993139]\n",
      " [ 0.08361415]]\n",
      "Iteration 9458 | Cost: 0.2815341349230631 | Gradient: [[ 0.02755181]\n",
      " [-0.04992873]\n",
      " [ 0.08360847]]\n",
      "Iteration 9459 | Cost: 0.2815238928848803 | Gradient: [[ 0.02755071]\n",
      " [-0.04992606]\n",
      " [ 0.0836028 ]]\n",
      "Iteration 9460 | Cost: 0.2815136521218883 | Gradient: [[ 0.02754961]\n",
      " [-0.0499234 ]\n",
      " [ 0.08359713]]\n",
      "Iteration 9461 | Cost: 0.28150341263385664 | Gradient: [[ 0.02754851]\n",
      " [-0.04992073]\n",
      " [ 0.08359146]]\n",
      "Iteration 9462 | Cost: 0.2814931744205551 | Gradient: [[ 0.02754741]\n",
      " [-0.04991807]\n",
      " [ 0.08358579]]\n",
      "Iteration 9463 | Cost: 0.28148293748175324 | Gradient: [[ 0.0275463 ]\n",
      " [-0.0499154 ]\n",
      " [ 0.08358012]]\n",
      "Iteration 9464 | Cost: 0.28147270181722106 | Gradient: [[ 0.0275452 ]\n",
      " [-0.04991274]\n",
      " [ 0.08357445]]\n",
      "Iteration 9465 | Cost: 0.28146246742672815 | Gradient: [[ 0.0275441 ]\n",
      " [-0.04991008]\n",
      " [ 0.08356878]]\n",
      "Iteration 9466 | Cost: 0.2814522343100445 | Gradient: [[ 0.027543  ]\n",
      " [-0.04990741]\n",
      " [ 0.08356312]]\n",
      "Iteration 9467 | Cost: 0.28144200246694007 | Gradient: [[ 0.0275419 ]\n",
      " [-0.04990475]\n",
      " [ 0.08355745]]\n",
      "Iteration 9468 | Cost: 0.2814317718971848 | Gradient: [[ 0.0275408 ]\n",
      " [-0.04990209]\n",
      " [ 0.08355179]]\n",
      "Iteration 9469 | Cost: 0.28142154260054875 | Gradient: [[ 0.0275397 ]\n",
      " [-0.04989943]\n",
      " [ 0.08354612]]\n",
      "Iteration 9470 | Cost: 0.28141131457680196 | Gradient: [[ 0.02753859]\n",
      " [-0.04989677]\n",
      " [ 0.08354046]]\n",
      "Iteration 9471 | Cost: 0.2814010878257146 | Gradient: [[ 0.02753749]\n",
      " [-0.04989411]\n",
      " [ 0.08353479]]\n",
      "Iteration 9472 | Cost: 0.2813908623470569 | Gradient: [[ 0.02753639]\n",
      " [-0.04989144]\n",
      " [ 0.08352913]]\n",
      "Iteration 9473 | Cost: 0.2813806381405991 | Gradient: [[ 0.02753529]\n",
      " [-0.04988878]\n",
      " [ 0.08352347]]\n",
      "Iteration 9474 | Cost: 0.2813704152061115 | Gradient: [[ 0.02753419]\n",
      " [-0.04988612]\n",
      " [ 0.0835178 ]]\n",
      "Iteration 9475 | Cost: 0.2813601935433644 | Gradient: [[ 0.02753309]\n",
      " [-0.04988347]\n",
      " [ 0.08351214]]\n",
      "Iteration 9476 | Cost: 0.28134997315212823 | Gradient: [[ 0.02753198]\n",
      " [-0.04988081]\n",
      " [ 0.08350648]]\n",
      "Iteration 9477 | Cost: 0.2813397540321736 | Gradient: [[ 0.02753088]\n",
      " [-0.04987815]\n",
      " [ 0.08350082]]\n",
      "Iteration 9478 | Cost: 0.2813295361832709 | Gradient: [[ 0.02752978]\n",
      " [-0.04987549]\n",
      " [ 0.08349516]]\n",
      "Iteration 9479 | Cost: 0.28131931960519063 | Gradient: [[ 0.02752868]\n",
      " [-0.04987283]\n",
      " [ 0.08348951]]\n",
      "Iteration 9480 | Cost: 0.28130910429770356 | Gradient: [[ 0.02752758]\n",
      " [-0.04987017]\n",
      " [ 0.08348385]]\n",
      "Iteration 9481 | Cost: 0.28129889026058025 | Gradient: [[ 0.02752648]\n",
      " [-0.04986752]\n",
      " [ 0.08347819]]\n",
      "Iteration 9482 | Cost: 0.28128867749359154 | Gradient: [[ 0.02752537]\n",
      " [-0.04986486]\n",
      " [ 0.08347253]]\n",
      "Iteration 9483 | Cost: 0.2812784659965082 | Gradient: [[ 0.02752427]\n",
      " [-0.0498622 ]\n",
      " [ 0.08346688]]\n",
      "Iteration 9484 | Cost: 0.28126825576910097 | Gradient: [[ 0.02752317]\n",
      " [-0.04985955]\n",
      " [ 0.08346122]]\n",
      "Iteration 9485 | Cost: 0.28125804681114075 | Gradient: [[ 0.02752207]\n",
      " [-0.04985689]\n",
      " [ 0.08345557]]\n",
      "Iteration 9486 | Cost: 0.2812478391223986 | Gradient: [[ 0.02752097]\n",
      " [-0.04985424]\n",
      " [ 0.08344992]]\n",
      "Iteration 9487 | Cost: 0.28123763270264546 | Gradient: [[ 0.02751987]\n",
      " [-0.04985158]\n",
      " [ 0.08344426]]\n",
      "Iteration 9488 | Cost: 0.28122742755165236 | Gradient: [[ 0.02751876]\n",
      " [-0.04984893]\n",
      " [ 0.08343861]]\n",
      "Iteration 9489 | Cost: 0.2812172236691903 | Gradient: [[ 0.02751766]\n",
      " [-0.04984627]\n",
      " [ 0.08343296]]\n",
      "Iteration 9490 | Cost: 0.2812070210550306 | Gradient: [[ 0.02751656]\n",
      " [-0.04984362]\n",
      " [ 0.08342731]]\n",
      "Iteration 9491 | Cost: 0.28119681970894433 | Gradient: [[ 0.02751546]\n",
      " [-0.04984097]\n",
      " [ 0.08342166]]\n",
      "Iteration 9492 | Cost: 0.2811866196307029 | Gradient: [[ 0.02751436]\n",
      " [-0.04983831]\n",
      " [ 0.08341601]]\n",
      "Iteration 9493 | Cost: 0.28117642082007754 | Gradient: [[ 0.02751325]\n",
      " [-0.04983566]\n",
      " [ 0.08341036]]\n",
      "Iteration 9494 | Cost: 0.28116622327683966 | Gradient: [[ 0.02751215]\n",
      " [-0.04983301]\n",
      " [ 0.08340471]]\n",
      "Iteration 9495 | Cost: 0.2811560270007606 | Gradient: [[ 0.02751105]\n",
      " [-0.04983036]\n",
      " [ 0.08339906]]\n",
      "Iteration 9496 | Cost: 0.28114583199161186 | Gradient: [[ 0.02750995]\n",
      " [-0.04982771]\n",
      " [ 0.08339341]]\n",
      "Iteration 9497 | Cost: 0.2811356382491651 | Gradient: [[ 0.02750885]\n",
      " [-0.04982506]\n",
      " [ 0.08338777]]\n",
      "Iteration 9498 | Cost: 0.2811254457731916 | Gradient: [[ 0.02750775]\n",
      " [-0.04982241]\n",
      " [ 0.08338212]]\n",
      "Iteration 9499 | Cost: 0.28111525456346326 | Gradient: [[ 0.02750664]\n",
      " [-0.04981976]\n",
      " [ 0.08337648]]\n",
      "Iteration 9500 | Cost: 0.2811050646197517 | Gradient: [[ 0.02750554]\n",
      " [-0.04981711]\n",
      " [ 0.08337083]]\n",
      "Iteration 9501 | Cost: 0.2810948759418286 | Gradient: [[ 0.02750444]\n",
      " [-0.04981446]\n",
      " [ 0.08336519]]\n",
      "Iteration 9502 | Cost: 0.2810846885294657 | Gradient: [[ 0.02750334]\n",
      " [-0.04981181]\n",
      " [ 0.08335954]]\n",
      "Iteration 9503 | Cost: 0.2810745023824351 | Gradient: [[ 0.02750224]\n",
      " [-0.04980916]\n",
      " [ 0.0833539 ]]\n",
      "Iteration 9504 | Cost: 0.28106431750050836 | Gradient: [[ 0.02750113]\n",
      " [-0.04980651]\n",
      " [ 0.08334826]]\n",
      "Iteration 9505 | Cost: 0.2810541338834577 | Gradient: [[ 0.02750003]\n",
      " [-0.04980386]\n",
      " [ 0.08334262]]\n",
      "Iteration 9506 | Cost: 0.28104395153105494 | Gradient: [[ 0.02749893]\n",
      " [-0.04980122]\n",
      " [ 0.08333698]]\n",
      "Iteration 9507 | Cost: 0.28103377044307215 | Gradient: [[ 0.02749783]\n",
      " [-0.04979857]\n",
      " [ 0.08333134]]\n",
      "Iteration 9508 | Cost: 0.28102359061928156 | Gradient: [[ 0.02749673]\n",
      " [-0.04979592]\n",
      " [ 0.0833257 ]]\n",
      "Iteration 9509 | Cost: 0.2810134120594552 | Gradient: [[ 0.02749562]\n",
      " [-0.04979327]\n",
      " [ 0.08332006]]\n",
      "Iteration 9510 | Cost: 0.28100323476336536 | Gradient: [[ 0.02749452]\n",
      " [-0.04979063]\n",
      " [ 0.08331442]]\n",
      "Iteration 9511 | Cost: 0.2809930587307843 | Gradient: [[ 0.02749342]\n",
      " [-0.04978798]\n",
      " [ 0.08330879]]\n",
      "Iteration 9512 | Cost: 0.2809828839614843 | Gradient: [[ 0.02749232]\n",
      " [-0.04978534]\n",
      " [ 0.08330315]]\n",
      "Iteration 9513 | Cost: 0.28097271045523775 | Gradient: [[ 0.02749122]\n",
      " [-0.04978269]\n",
      " [ 0.08329751]]\n",
      "Iteration 9514 | Cost: 0.2809625382118171 | Gradient: [[ 0.02749011]\n",
      " [-0.04978005]\n",
      " [ 0.08329188]]\n",
      "Iteration 9515 | Cost: 0.28095236723099476 | Gradient: [[ 0.02748901]\n",
      " [-0.04977741]\n",
      " [ 0.08328624]]\n",
      "Iteration 9516 | Cost: 0.28094219751254323 | Gradient: [[ 0.02748791]\n",
      " [-0.04977476]\n",
      " [ 0.08328061]]\n",
      "Iteration 9517 | Cost: 0.28093202905623527 | Gradient: [[ 0.02748681]\n",
      " [-0.04977212]\n",
      " [ 0.08327498]]\n",
      "Iteration 9518 | Cost: 0.2809218618618433 | Gradient: [[ 0.0274857 ]\n",
      " [-0.04976948]\n",
      " [ 0.08326934]]\n",
      "Iteration 9519 | Cost: 0.2809116959291401 | Gradient: [[ 0.0274846 ]\n",
      " [-0.04976683]\n",
      " [ 0.08326371]]\n",
      "Iteration 9520 | Cost: 0.28090153125789846 | Gradient: [[ 0.0274835 ]\n",
      " [-0.04976419]\n",
      " [ 0.08325808]]\n",
      "Iteration 9521 | Cost: 0.2808913678478911 | Gradient: [[ 0.0274824 ]\n",
      " [-0.04976155]\n",
      " [ 0.08325245]]\n",
      "Iteration 9522 | Cost: 0.28088120569889086 | Gradient: [[ 0.0274813 ]\n",
      " [-0.04975891]\n",
      " [ 0.08324682]]\n",
      "Iteration 9523 | Cost: 0.28087104481067077 | Gradient: [[ 0.02748019]\n",
      " [-0.04975627]\n",
      " [ 0.08324119]]\n",
      "Iteration 9524 | Cost: 0.28086088518300356 | Gradient: [[ 0.02747909]\n",
      " [-0.04975363]\n",
      " [ 0.08323556]]\n",
      "Iteration 9525 | Cost: 0.2808507268156623 | Gradient: [[ 0.02747799]\n",
      " [-0.04975099]\n",
      " [ 0.08322993]]\n",
      "Iteration 9526 | Cost: 0.28084056970842014 | Gradient: [[ 0.02747689]\n",
      " [-0.04974835]\n",
      " [ 0.08322431]]\n",
      "Iteration 9527 | Cost: 0.28083041386105007 | Gradient: [[ 0.02747578]\n",
      " [-0.04974571]\n",
      " [ 0.08321868]]\n",
      "Iteration 9528 | Cost: 0.2808202592733254 | Gradient: [[ 0.02747468]\n",
      " [-0.04974307]\n",
      " [ 0.08321305]]\n",
      "Iteration 9529 | Cost: 0.28081010594501915 | Gradient: [[ 0.02747358]\n",
      " [-0.04974043]\n",
      " [ 0.08320743]]\n",
      "Iteration 9530 | Cost: 0.2807999538759047 | Gradient: [[ 0.02747248]\n",
      " [-0.04973779]\n",
      " [ 0.0832018 ]]\n",
      "Iteration 9531 | Cost: 0.28078980306575535 | Gradient: [[ 0.02747138]\n",
      " [-0.04973515]\n",
      " [ 0.08319618]]\n",
      "Iteration 9532 | Cost: 0.2807796535143444 | Gradient: [[ 0.02747027]\n",
      " [-0.04973251]\n",
      " [ 0.08319056]]\n",
      "Iteration 9533 | Cost: 0.2807695052214454 | Gradient: [[ 0.02746917]\n",
      " [-0.04972988]\n",
      " [ 0.08318493]]\n",
      "Iteration 9534 | Cost: 0.28075935818683173 | Gradient: [[ 0.02746807]\n",
      " [-0.04972724]\n",
      " [ 0.08317931]]\n",
      "Iteration 9535 | Cost: 0.28074921241027695 | Gradient: [[ 0.02746697]\n",
      " [-0.0497246 ]\n",
      " [ 0.08317369]]\n",
      "Iteration 9536 | Cost: 0.28073906789155456 | Gradient: [[ 0.02746586]\n",
      " [-0.04972197]\n",
      " [ 0.08316807]]\n",
      "Iteration 9537 | Cost: 0.2807289246304383 | Gradient: [[ 0.02746476]\n",
      " [-0.04971933]\n",
      " [ 0.08316245]]\n",
      "Iteration 9538 | Cost: 0.2807187826267018 | Gradient: [[ 0.02746366]\n",
      " [-0.0497167 ]\n",
      " [ 0.08315683]]\n",
      "Iteration 9539 | Cost: 0.28070864188011874 | Gradient: [[ 0.02746256]\n",
      " [-0.04971406]\n",
      " [ 0.08315121]]\n",
      "Iteration 9540 | Cost: 0.28069850239046296 | Gradient: [[ 0.02746145]\n",
      " [-0.04971143]\n",
      " [ 0.08314559]]\n",
      "Iteration 9541 | Cost: 0.2806883641575084 | Gradient: [[ 0.02746035]\n",
      " [-0.04970879]\n",
      " [ 0.08313998]]\n",
      "Iteration 9542 | Cost: 0.28067822718102875 | Gradient: [[ 0.02745925]\n",
      " [-0.04970616]\n",
      " [ 0.08313436]]\n",
      "Iteration 9543 | Cost: 0.28066809146079813 | Gradient: [[ 0.02745815]\n",
      " [-0.04970353]\n",
      " [ 0.08312874]]\n",
      "Iteration 9544 | Cost: 0.28065795699659035 | Gradient: [[ 0.02745704]\n",
      " [-0.04970089]\n",
      " [ 0.08312313]]\n",
      "Iteration 9545 | Cost: 0.2806478237881796 | Gradient: [[ 0.02745594]\n",
      " [-0.04969826]\n",
      " [ 0.08311751]]\n",
      "Iteration 9546 | Cost: 0.2806376918353401 | Gradient: [[ 0.02745484]\n",
      " [-0.04969563]\n",
      " [ 0.0831119 ]]\n",
      "Iteration 9547 | Cost: 0.28062756113784565 | Gradient: [[ 0.02745374]\n",
      " [-0.049693  ]\n",
      " [ 0.08310628]]\n",
      "Iteration 9548 | Cost: 0.2806174316954707 | Gradient: [[ 0.02745264]\n",
      " [-0.04969037]\n",
      " [ 0.08310067]]\n",
      "Iteration 9549 | Cost: 0.28060730350798946 | Gradient: [[ 0.02745153]\n",
      " [-0.04968773]\n",
      " [ 0.08309506]]\n",
      "Iteration 9550 | Cost: 0.28059717657517624 | Gradient: [[ 0.02745043]\n",
      " [-0.0496851 ]\n",
      " [ 0.08308945]]\n",
      "Iteration 9551 | Cost: 0.28058705089680547 | Gradient: [[ 0.02744933]\n",
      " [-0.04968247]\n",
      " [ 0.08308384]]\n",
      "Iteration 9552 | Cost: 0.28057692647265137 | Gradient: [[ 0.02744822]\n",
      " [-0.04967984]\n",
      " [ 0.08307823]]\n",
      "Iteration 9553 | Cost: 0.2805668033024886 | Gradient: [[ 0.02744712]\n",
      " [-0.04967721]\n",
      " [ 0.08307262]]\n",
      "Iteration 9554 | Cost: 0.2805566813860916 | Gradient: [[ 0.02744602]\n",
      " [-0.04967458]\n",
      " [ 0.08306701]]\n",
      "Iteration 9555 | Cost: 0.28054656072323486 | Gradient: [[ 0.02744492]\n",
      " [-0.04967195]\n",
      " [ 0.0830614 ]]\n",
      "Iteration 9556 | Cost: 0.2805364413136931 | Gradient: [[ 0.02744381]\n",
      " [-0.04966933]\n",
      " [ 0.08305579]]\n",
      "Iteration 9557 | Cost: 0.2805263231572411 | Gradient: [[ 0.02744271]\n",
      " [-0.0496667 ]\n",
      " [ 0.08305019]]\n",
      "Iteration 9558 | Cost: 0.28051620625365326 | Gradient: [[ 0.02744161]\n",
      " [-0.04966407]\n",
      " [ 0.08304458]]\n",
      "Iteration 9559 | Cost: 0.2805060906027046 | Gradient: [[ 0.02744051]\n",
      " [-0.04966144]\n",
      " [ 0.08303897]]\n",
      "Iteration 9560 | Cost: 0.28049597620416994 | Gradient: [[ 0.0274394 ]\n",
      " [-0.04965882]\n",
      " [ 0.08303337]]\n",
      "Iteration 9561 | Cost: 0.2804858630578241 | Gradient: [[ 0.0274383 ]\n",
      " [-0.04965619]\n",
      " [ 0.08302777]]\n",
      "Iteration 9562 | Cost: 0.28047575116344203 | Gradient: [[ 0.0274372 ]\n",
      " [-0.04965356]\n",
      " [ 0.08302216]]\n",
      "Iteration 9563 | Cost: 0.28046564052079875 | Gradient: [[ 0.0274361 ]\n",
      " [-0.04965094]\n",
      " [ 0.08301656]]\n",
      "Iteration 9564 | Cost: 0.2804555311296692 | Gradient: [[ 0.02743499]\n",
      " [-0.04964831]\n",
      " [ 0.08301096]]\n",
      "Iteration 9565 | Cost: 0.28044542298982855 | Gradient: [[ 0.02743389]\n",
      " [-0.04964569]\n",
      " [ 0.08300535]]\n",
      "Iteration 9566 | Cost: 0.2804353161010519 | Gradient: [[ 0.02743279]\n",
      " [-0.04964306]\n",
      " [ 0.08299975]]\n",
      "Iteration 9567 | Cost: 0.28042521046311447 | Gradient: [[ 0.02743169]\n",
      " [-0.04964044]\n",
      " [ 0.08299415]]\n",
      "Iteration 9568 | Cost: 0.2804151060757915 | Gradient: [[ 0.02743058]\n",
      " [-0.04963781]\n",
      " [ 0.08298855]]\n",
      "Iteration 9569 | Cost: 0.2804050029388583 | Gradient: [[ 0.02742948]\n",
      " [-0.04963519]\n",
      " [ 0.08298295]]\n",
      "Iteration 9570 | Cost: 0.2803949010520902 | Gradient: [[ 0.02742838]\n",
      " [-0.04963257]\n",
      " [ 0.08297736]]\n",
      "Iteration 9571 | Cost: 0.28038480041526254 | Gradient: [[ 0.02742728]\n",
      " [-0.04962994]\n",
      " [ 0.08297176]]\n",
      "Iteration 9572 | Cost: 0.2803747010281509 | Gradient: [[ 0.02742617]\n",
      " [-0.04962732]\n",
      " [ 0.08296616]]\n",
      "Iteration 9573 | Cost: 0.28036460289053067 | Gradient: [[ 0.02742507]\n",
      " [-0.0496247 ]\n",
      " [ 0.08296057]]\n",
      "Iteration 9574 | Cost: 0.2803545060021775 | Gradient: [[ 0.02742397]\n",
      " [-0.04962208]\n",
      " [ 0.08295497]]\n",
      "Iteration 9575 | Cost: 0.28034441036286684 | Gradient: [[ 0.02742286]\n",
      " [-0.04961946]\n",
      " [ 0.08294937]]\n",
      "Iteration 9576 | Cost: 0.2803343159723745 | Gradient: [[ 0.02742176]\n",
      " [-0.04961684]\n",
      " [ 0.08294378]]\n",
      "Iteration 9577 | Cost: 0.28032422283047614 | Gradient: [[ 0.02742066]\n",
      " [-0.04961421]\n",
      " [ 0.08293819]]\n",
      "Iteration 9578 | Cost: 0.28031413093694757 | Gradient: [[ 0.02741956]\n",
      " [-0.04961159]\n",
      " [ 0.08293259]]\n",
      "Iteration 9579 | Cost: 0.2803040402915644 | Gradient: [[ 0.02741845]\n",
      " [-0.04960897]\n",
      " [ 0.082927  ]]\n",
      "Iteration 9580 | Cost: 0.2802939508941028 | Gradient: [[ 0.02741735]\n",
      " [-0.04960635]\n",
      " [ 0.08292141]]\n",
      "Iteration 9581 | Cost: 0.2802838627443385 | Gradient: [[ 0.02741625]\n",
      " [-0.04960374]\n",
      " [ 0.08291582]]\n",
      "Iteration 9582 | Cost: 0.2802737758420475 | Gradient: [[ 0.02741514]\n",
      " [-0.04960112]\n",
      " [ 0.08291023]]\n",
      "Iteration 9583 | Cost: 0.28026369018700586 | Gradient: [[ 0.02741404]\n",
      " [-0.0495985 ]\n",
      " [ 0.08290464]]\n",
      "Iteration 9584 | Cost: 0.2802536057789895 | Gradient: [[ 0.02741294]\n",
      " [-0.04959588]\n",
      " [ 0.08289905]]\n",
      "Iteration 9585 | Cost: 0.2802435226177748 | Gradient: [[ 0.02741184]\n",
      " [-0.04959326]\n",
      " [ 0.08289346]]\n",
      "Iteration 9586 | Cost: 0.2802334407031377 | Gradient: [[ 0.02741073]\n",
      " [-0.04959065]\n",
      " [ 0.08288787]]\n",
      "Iteration 9587 | Cost: 0.2802233600348546 | Gradient: [[ 0.02740963]\n",
      " [-0.04958803]\n",
      " [ 0.08288229]]\n",
      "Iteration 9588 | Cost: 0.2802132806127016 | Gradient: [[ 0.02740853]\n",
      " [-0.04958541]\n",
      " [ 0.0828767 ]]\n",
      "Iteration 9589 | Cost: 0.2802032024364552 | Gradient: [[ 0.02740743]\n",
      " [-0.0495828 ]\n",
      " [ 0.08287111]]\n",
      "Iteration 9590 | Cost: 0.28019312550589165 | Gradient: [[ 0.02740632]\n",
      " [-0.04958018]\n",
      " [ 0.08286553]]\n",
      "Iteration 9591 | Cost: 0.28018304982078757 | Gradient: [[ 0.02740522]\n",
      " [-0.04957756]\n",
      " [ 0.08285994]]\n",
      "Iteration 9592 | Cost: 0.2801729753809192 | Gradient: [[ 0.02740412]\n",
      " [-0.04957495]\n",
      " [ 0.08285436]]\n",
      "Iteration 9593 | Cost: 0.2801629021860632 | Gradient: [[ 0.02740301]\n",
      " [-0.04957234]\n",
      " [ 0.08284878]]\n",
      "Iteration 9594 | Cost: 0.28015283023599613 | Gradient: [[ 0.02740191]\n",
      " [-0.04956972]\n",
      " [ 0.08284319]]\n",
      "Iteration 9595 | Cost: 0.28014275953049467 | Gradient: [[ 0.02740081]\n",
      " [-0.04956711]\n",
      " [ 0.08283761]]\n",
      "Iteration 9596 | Cost: 0.2801326900693355 | Gradient: [[ 0.0273997 ]\n",
      " [-0.04956449]\n",
      " [ 0.08283203]]\n",
      "Iteration 9597 | Cost: 0.2801226218522954 | Gradient: [[ 0.0273986 ]\n",
      " [-0.04956188]\n",
      " [ 0.08282645]]\n",
      "Iteration 9598 | Cost: 0.28011255487915104 | Gradient: [[ 0.0273975 ]\n",
      " [-0.04955927]\n",
      " [ 0.08282087]]\n",
      "Iteration 9599 | Cost: 0.2801024891496794 | Gradient: [[ 0.0273964 ]\n",
      " [-0.04955665]\n",
      " [ 0.08281529]]\n",
      "Iteration 9600 | Cost: 0.28009242466365725 | Gradient: [[ 0.02739529]\n",
      " [-0.04955404]\n",
      " [ 0.08280971]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9601 | Cost: 0.2800823614208616 | Gradient: [[ 0.02739419]\n",
      " [-0.04955143]\n",
      " [ 0.08280413]]\n",
      "Iteration 9602 | Cost: 0.2800722994210695 | Gradient: [[ 0.02739309]\n",
      " [-0.04954882]\n",
      " [ 0.08279856]]\n",
      "Iteration 9603 | Cost: 0.28006223866405794 | Gradient: [[ 0.02739198]\n",
      " [-0.04954621]\n",
      " [ 0.08279298]]\n",
      "Iteration 9604 | Cost: 0.28005217914960395 | Gradient: [[ 0.02739088]\n",
      " [-0.0495436 ]\n",
      " [ 0.0827874 ]]\n",
      "Iteration 9605 | Cost: 0.28004212087748487 | Gradient: [[ 0.02738978]\n",
      " [-0.04954099]\n",
      " [ 0.08278183]]\n",
      "Iteration 9606 | Cost: 0.28003206384747775 | Gradient: [[ 0.02738868]\n",
      " [-0.04953838]\n",
      " [ 0.08277625]]\n",
      "Iteration 9607 | Cost: 0.2800220080593599 | Gradient: [[ 0.02738757]\n",
      " [-0.04953577]\n",
      " [ 0.08277068]]\n",
      "Iteration 9608 | Cost: 0.2800119535129086 | Gradient: [[ 0.02738647]\n",
      " [-0.04953316]\n",
      " [ 0.08276511]]\n",
      "Iteration 9609 | Cost: 0.2800019002079012 | Gradient: [[ 0.02738537]\n",
      " [-0.04953055]\n",
      " [ 0.08275953]]\n",
      "Iteration 9610 | Cost: 0.2799918481441152 | Gradient: [[ 0.02738426]\n",
      " [-0.04952794]\n",
      " [ 0.08275396]]\n",
      "Iteration 9611 | Cost: 0.279981797321328 | Gradient: [[ 0.02738316]\n",
      " [-0.04952533]\n",
      " [ 0.08274839]]\n",
      "Iteration 9612 | Cost: 0.279971747739317 | Gradient: [[ 0.02738206]\n",
      " [-0.04952273]\n",
      " [ 0.08274282]]\n",
      "Iteration 9613 | Cost: 0.2799616993978599 | Gradient: [[ 0.02738095]\n",
      " [-0.04952012]\n",
      " [ 0.08273725]]\n",
      "Iteration 9614 | Cost: 0.2799516522967343 | Gradient: [[ 0.02737985]\n",
      " [-0.04951751]\n",
      " [ 0.08273168]]\n",
      "Iteration 9615 | Cost: 0.2799416064357179 | Gradient: [[ 0.02737875]\n",
      " [-0.04951491]\n",
      " [ 0.08272611]]\n",
      "Iteration 9616 | Cost: 0.27993156181458834 | Gradient: [[ 0.02737765]\n",
      " [-0.0495123 ]\n",
      " [ 0.08272054]]\n",
      "Iteration 9617 | Cost: 0.2799215184331234 | Gradient: [[ 0.02737654]\n",
      " [-0.04950969]\n",
      " [ 0.08271497]]\n",
      "Iteration 9618 | Cost: 0.27991147629110086 | Gradient: [[ 0.02737544]\n",
      " [-0.04950709]\n",
      " [ 0.08270941]]\n",
      "Iteration 9619 | Cost: 0.27990143538829876 | Gradient: [[ 0.02737434]\n",
      " [-0.04950448]\n",
      " [ 0.08270384]]\n",
      "Iteration 9620 | Cost: 0.27989139572449484 | Gradient: [[ 0.02737323]\n",
      " [-0.04950188]\n",
      " [ 0.08269828]]\n",
      "Iteration 9621 | Cost: 0.27988135729946706 | Gradient: [[ 0.02737213]\n",
      " [-0.04949927]\n",
      " [ 0.08269271]]\n",
      "Iteration 9622 | Cost: 0.2798713201129936 | Gradient: [[ 0.02737103]\n",
      " [-0.04949667]\n",
      " [ 0.08268715]]\n",
      "Iteration 9623 | Cost: 0.2798612841648524 | Gradient: [[ 0.02736992]\n",
      " [-0.04949407]\n",
      " [ 0.08268158]]\n",
      "Iteration 9624 | Cost: 0.27985124945482165 | Gradient: [[ 0.02736882]\n",
      " [-0.04949146]\n",
      " [ 0.08267602]]\n",
      "Iteration 9625 | Cost: 0.2798412159826795 | Gradient: [[ 0.02736772]\n",
      " [-0.04948886]\n",
      " [ 0.08267046]]\n",
      "Iteration 9626 | Cost: 0.27983118374820426 | Gradient: [[ 0.02736661]\n",
      " [-0.04948626]\n",
      " [ 0.0826649 ]]\n",
      "Iteration 9627 | Cost: 0.27982115275117403 | Gradient: [[ 0.02736551]\n",
      " [-0.04948366]\n",
      " [ 0.08265933]]\n",
      "Iteration 9628 | Cost: 0.2798111229913673 | Gradient: [[ 0.02736441]\n",
      " [-0.04948105]\n",
      " [ 0.08265377]]\n",
      "Iteration 9629 | Cost: 0.2798010944685624 | Gradient: [[ 0.0273633 ]\n",
      " [-0.04947845]\n",
      " [ 0.08264821]]\n",
      "Iteration 9630 | Cost: 0.2797910671825377 | Gradient: [[ 0.0273622 ]\n",
      " [-0.04947585]\n",
      " [ 0.08264266]]\n",
      "Iteration 9631 | Cost: 0.2797810411330718 | Gradient: [[ 0.0273611 ]\n",
      " [-0.04947325]\n",
      " [ 0.0826371 ]]\n",
      "Iteration 9632 | Cost: 0.27977101631994317 | Gradient: [[ 0.02736   ]\n",
      " [-0.04947065]\n",
      " [ 0.08263154]]\n",
      "Iteration 9633 | Cost: 0.2797609927429303 | Gradient: [[ 0.02735889]\n",
      " [-0.04946805]\n",
      " [ 0.08262598]]\n",
      "Iteration 9634 | Cost: 0.279750970401812 | Gradient: [[ 0.02735779]\n",
      " [-0.04946545]\n",
      " [ 0.08262043]]\n",
      "Iteration 9635 | Cost: 0.27974094929636695 | Gradient: [[ 0.02735669]\n",
      " [-0.04946285]\n",
      " [ 0.08261487]]\n",
      "Iteration 9636 | Cost: 0.2797309294263737 | Gradient: [[ 0.02735558]\n",
      " [-0.04946025]\n",
      " [ 0.08260932]]\n",
      "Iteration 9637 | Cost: 0.2797209107916111 | Gradient: [[ 0.02735448]\n",
      " [-0.04945766]\n",
      " [ 0.08260376]]\n",
      "Iteration 9638 | Cost: 0.27971089339185823 | Gradient: [[ 0.02735338]\n",
      " [-0.04945506]\n",
      " [ 0.08259821]]\n",
      "Iteration 9639 | Cost: 0.2797008772268937 | Gradient: [[ 0.02735227]\n",
      " [-0.04945246]\n",
      " [ 0.08259265]]\n",
      "Iteration 9640 | Cost: 0.2796908622964964 | Gradient: [[ 0.02735117]\n",
      " [-0.04944986]\n",
      " [ 0.0825871 ]]\n",
      "Iteration 9641 | Cost: 0.2796808486004456 | Gradient: [[ 0.02735007]\n",
      " [-0.04944727]\n",
      " [ 0.08258155]]\n",
      "Iteration 9642 | Cost: 0.2796708361385203 | Gradient: [[ 0.02734896]\n",
      " [-0.04944467]\n",
      " [ 0.082576  ]]\n",
      "Iteration 9643 | Cost: 0.27966082491049926 | Gradient: [[ 0.02734786]\n",
      " [-0.04944207]\n",
      " [ 0.08257045]]\n",
      "Iteration 9644 | Cost: 0.279650814916162 | Gradient: [[ 0.02734676]\n",
      " [-0.04943948]\n",
      " [ 0.0825649 ]]\n",
      "Iteration 9645 | Cost: 0.2796408061552875 | Gradient: [[ 0.02734565]\n",
      " [-0.04943688]\n",
      " [ 0.08255935]]\n",
      "Iteration 9646 | Cost: 0.27963079862765516 | Gradient: [[ 0.02734455]\n",
      " [-0.04943429]\n",
      " [ 0.0825538 ]]\n",
      "Iteration 9647 | Cost: 0.27962079233304415 | Gradient: [[ 0.02734345]\n",
      " [-0.04943169]\n",
      " [ 0.08254825]]\n",
      "Iteration 9648 | Cost: 0.27961078727123384 | Gradient: [[ 0.02734234]\n",
      " [-0.0494291 ]\n",
      " [ 0.0825427 ]]\n",
      "Iteration 9649 | Cost: 0.2796007834420037 | Gradient: [[ 0.02734124]\n",
      " [-0.0494265 ]\n",
      " [ 0.08253716]]\n",
      "Iteration 9650 | Cost: 0.27959078084513306 | Gradient: [[ 0.02734014]\n",
      " [-0.04942391]\n",
      " [ 0.08253161]]\n",
      "Iteration 9651 | Cost: 0.2795807794804015 | Gradient: [[ 0.02733903]\n",
      " [-0.04942132]\n",
      " [ 0.08252607]]\n",
      "Iteration 9652 | Cost: 0.27957077934758856 | Gradient: [[ 0.02733793]\n",
      " [-0.04941872]\n",
      " [ 0.08252052]]\n",
      "Iteration 9653 | Cost: 0.27956078044647376 | Gradient: [[ 0.02733683]\n",
      " [-0.04941613]\n",
      " [ 0.08251498]]\n",
      "Iteration 9654 | Cost: 0.27955078277683687 | Gradient: [[ 0.02733572]\n",
      " [-0.04941354]\n",
      " [ 0.08250943]]\n",
      "Iteration 9655 | Cost: 0.2795407863384576 | Gradient: [[ 0.02733462]\n",
      " [-0.04941095]\n",
      " [ 0.08250389]]\n",
      "Iteration 9656 | Cost: 0.27953079113111556 | Gradient: [[ 0.02733352]\n",
      " [-0.04940835]\n",
      " [ 0.08249835]]\n",
      "Iteration 9657 | Cost: 0.27952079715459066 | Gradient: [[ 0.02733241]\n",
      " [-0.04940576]\n",
      " [ 0.08249281]]\n",
      "Iteration 9658 | Cost: 0.2795108044086627 | Gradient: [[ 0.02733131]\n",
      " [-0.04940317]\n",
      " [ 0.08248727]]\n",
      "Iteration 9659 | Cost: 0.2795008128931116 | Gradient: [[ 0.02733021]\n",
      " [-0.04940058]\n",
      " [ 0.08248173]]\n",
      "Iteration 9660 | Cost: 0.2794908226077174 | Gradient: [[ 0.0273291 ]\n",
      " [-0.04939799]\n",
      " [ 0.08247619]]\n",
      "Iteration 9661 | Cost: 0.27948083355226 | Gradient: [[ 0.027328  ]\n",
      " [-0.0493954 ]\n",
      " [ 0.08247065]]\n",
      "Iteration 9662 | Cost: 0.2794708457265195 | Gradient: [[ 0.0273269 ]\n",
      " [-0.04939281]\n",
      " [ 0.08246511]]\n",
      "Iteration 9663 | Cost: 0.27946085913027596 | Gradient: [[ 0.02732579]\n",
      " [-0.04939022]\n",
      " [ 0.08245957]]\n",
      "Iteration 9664 | Cost: 0.2794508737633095 | Gradient: [[ 0.02732469]\n",
      " [-0.04938763]\n",
      " [ 0.08245404]]\n",
      "Iteration 9665 | Cost: 0.2794408896254005 | Gradient: [[ 0.02732359]\n",
      " [-0.04938505]\n",
      " [ 0.0824485 ]]\n",
      "Iteration 9666 | Cost: 0.279430906716329 | Gradient: [[ 0.02732248]\n",
      " [-0.04938246]\n",
      " [ 0.08244296]]\n",
      "Iteration 9667 | Cost: 0.2794209250358755 | Gradient: [[ 0.02732138]\n",
      " [-0.04937987]\n",
      " [ 0.08243743]]\n",
      "Iteration 9668 | Cost: 0.2794109445838202 | Gradient: [[ 0.02732028]\n",
      " [-0.04937728]\n",
      " [ 0.08243189]]\n",
      "Iteration 9669 | Cost: 0.27940096535994363 | Gradient: [[ 0.02731917]\n",
      " [-0.0493747 ]\n",
      " [ 0.08242636]]\n",
      "Iteration 9670 | Cost: 0.2793909873640262 | Gradient: [[ 0.02731807]\n",
      " [-0.04937211]\n",
      " [ 0.08242083]]\n",
      "Iteration 9671 | Cost: 0.27938101059584836 | Gradient: [[ 0.02731697]\n",
      " [-0.04936952]\n",
      " [ 0.08241529]]\n",
      "Iteration 9672 | Cost: 0.2793710350551908 | Gradient: [[ 0.02731586]\n",
      " [-0.04936694]\n",
      " [ 0.08240976]]\n",
      "Iteration 9673 | Cost: 0.27936106074183403 | Gradient: [[ 0.02731476]\n",
      " [-0.04936435]\n",
      " [ 0.08240423]]\n",
      "Iteration 9674 | Cost: 0.2793510876555587 | Gradient: [[ 0.02731366]\n",
      " [-0.04936177]\n",
      " [ 0.0823987 ]]\n",
      "Iteration 9675 | Cost: 0.27934111579614557 | Gradient: [[ 0.02731255]\n",
      " [-0.04935918]\n",
      " [ 0.08239317]]\n",
      "Iteration 9676 | Cost: 0.2793311451633754 | Gradient: [[ 0.02731145]\n",
      " [-0.0493566 ]\n",
      " [ 0.08238764]]\n",
      "Iteration 9677 | Cost: 0.279321175757029 | Gradient: [[ 0.02731035]\n",
      " [-0.04935402]\n",
      " [ 0.08238211]]\n",
      "Iteration 9678 | Cost: 0.2793112075768872 | Gradient: [[ 0.02730924]\n",
      " [-0.04935143]\n",
      " [ 0.08237659]]\n",
      "Iteration 9679 | Cost: 0.279301240622731 | Gradient: [[ 0.02730814]\n",
      " [-0.04934885]\n",
      " [ 0.08237106]]\n",
      "Iteration 9680 | Cost: 0.27929127489434125 | Gradient: [[ 0.02730704]\n",
      " [-0.04934627]\n",
      " [ 0.08236553]]\n",
      "Iteration 9681 | Cost: 0.27928131039149895 | Gradient: [[ 0.02730593]\n",
      " [-0.04934368]\n",
      " [ 0.08236001]]\n",
      "Iteration 9682 | Cost: 0.27927134711398527 | Gradient: [[ 0.02730483]\n",
      " [-0.0493411 ]\n",
      " [ 0.08235448]]\n",
      "Iteration 9683 | Cost: 0.27926138506158127 | Gradient: [[ 0.02730373]\n",
      " [-0.04933852]\n",
      " [ 0.08234896]]\n",
      "Iteration 9684 | Cost: 0.27925142423406807 | Gradient: [[ 0.02730262]\n",
      " [-0.04933594]\n",
      " [ 0.08234343]]\n",
      "Iteration 9685 | Cost: 0.27924146463122695 | Gradient: [[ 0.02730152]\n",
      " [-0.04933336]\n",
      " [ 0.08233791]]\n",
      "Iteration 9686 | Cost: 0.27923150625283916 | Gradient: [[ 0.02730042]\n",
      " [-0.04933078]\n",
      " [ 0.08233239]]\n",
      "Iteration 9687 | Cost: 0.279221549098686 | Gradient: [[ 0.02729931]\n",
      " [-0.0493282 ]\n",
      " [ 0.08232686]]\n",
      "Iteration 9688 | Cost: 0.2792115931685489 | Gradient: [[ 0.02729821]\n",
      " [-0.04932562]\n",
      " [ 0.08232134]]\n",
      "Iteration 9689 | Cost: 0.2792016384622091 | Gradient: [[ 0.02729711]\n",
      " [-0.04932304]\n",
      " [ 0.08231582]]\n",
      "Iteration 9690 | Cost: 0.2791916849794482 | Gradient: [[ 0.027296  ]\n",
      " [-0.04932046]\n",
      " [ 0.0823103 ]]\n",
      "Iteration 9691 | Cost: 0.27918173272004776 | Gradient: [[ 0.0272949 ]\n",
      " [-0.04931788]\n",
      " [ 0.08230478]]\n",
      "Iteration 9692 | Cost: 0.2791717816837892 | Gradient: [[ 0.0272938 ]\n",
      " [-0.0493153 ]\n",
      " [ 0.08229926]]\n",
      "Iteration 9693 | Cost: 0.2791618318704542 | Gradient: [[ 0.02729269]\n",
      " [-0.04931272]\n",
      " [ 0.08229375]]\n",
      "Iteration 9694 | Cost: 0.27915188327982443 | Gradient: [[ 0.02729159]\n",
      " [-0.04931014]\n",
      " [ 0.08228823]]\n",
      "Iteration 9695 | Cost: 0.2791419359116817 | Gradient: [[ 0.02729049]\n",
      " [-0.04930757]\n",
      " [ 0.08228271]]\n",
      "Iteration 9696 | Cost: 0.27913198976580755 | Gradient: [[ 0.02728938]\n",
      " [-0.04930499]\n",
      " [ 0.0822772 ]]\n",
      "Iteration 9697 | Cost: 0.27912204484198394 | Gradient: [[ 0.02728828]\n",
      " [-0.04930241]\n",
      " [ 0.08227168]]\n",
      "Iteration 9698 | Cost: 0.2791121011399928 | Gradient: [[ 0.02728718]\n",
      " [-0.04929984]\n",
      " [ 0.08226617]]\n",
      "Iteration 9699 | Cost: 0.27910215865961585 | Gradient: [[ 0.02728607]\n",
      " [-0.04929726]\n",
      " [ 0.08226065]]\n",
      "Iteration 9700 | Cost: 0.2790922174006352 | Gradient: [[ 0.02728497]\n",
      " [-0.04929468]\n",
      " [ 0.08225514]]\n",
      "Iteration 9701 | Cost: 0.27908227736283286 | Gradient: [[ 0.02728387]\n",
      " [-0.04929211]\n",
      " [ 0.08224962]]\n",
      "Iteration 9702 | Cost: 0.2790723385459909 | Gradient: [[ 0.02728276]\n",
      " [-0.04928953]\n",
      " [ 0.08224411]]\n",
      "Iteration 9703 | Cost: 0.2790624009498913 | Gradient: [[ 0.02728166]\n",
      " [-0.04928696]\n",
      " [ 0.0822386 ]]\n",
      "Iteration 9704 | Cost: 0.2790524645743163 | Gradient: [[ 0.02728055]\n",
      " [-0.04928439]\n",
      " [ 0.08223309]]\n",
      "Iteration 9705 | Cost: 0.2790425294190483 | Gradient: [[ 0.02727945]\n",
      " [-0.04928181]\n",
      " [ 0.08222758]]\n",
      "Iteration 9706 | Cost: 0.2790325954838693 | Gradient: [[ 0.02727835]\n",
      " [-0.04927924]\n",
      " [ 0.08222207]]\n",
      "Iteration 9707 | Cost: 0.27902266276856164 | Gradient: [[ 0.02727724]\n",
      " [-0.04927666]\n",
      " [ 0.08221656]]\n",
      "Iteration 9708 | Cost: 0.2790127312729078 | Gradient: [[ 0.02727614]\n",
      " [-0.04927409]\n",
      " [ 0.08221105]]\n",
      "Iteration 9709 | Cost: 0.2790028009966902 | Gradient: [[ 0.02727504]\n",
      " [-0.04927152]\n",
      " [ 0.08220554]]\n",
      "Iteration 9710 | Cost: 0.27899287193969124 | Gradient: [[ 0.02727393]\n",
      " [-0.04926895]\n",
      " [ 0.08220004]]\n",
      "Iteration 9711 | Cost: 0.2789829441016935 | Gradient: [[ 0.02727283]\n",
      " [-0.04926638]\n",
      " [ 0.08219453]]\n",
      "Iteration 9712 | Cost: 0.2789730174824793 | Gradient: [[ 0.02727173]\n",
      " [-0.0492638 ]\n",
      " [ 0.08218902]]\n",
      "Iteration 9713 | Cost: 0.2789630920818316 | Gradient: [[ 0.02727062]\n",
      " [-0.04926123]\n",
      " [ 0.08218352]]\n",
      "Iteration 9714 | Cost: 0.2789531678995329 | Gradient: [[ 0.02726952]\n",
      " [-0.04925866]\n",
      " [ 0.08217801]]\n",
      "Iteration 9715 | Cost: 0.2789432449353659 | Gradient: [[ 0.02726842]\n",
      " [-0.04925609]\n",
      " [ 0.08217251]]\n",
      "Iteration 9716 | Cost: 0.27893332318911335 | Gradient: [[ 0.02726731]\n",
      " [-0.04925352]\n",
      " [ 0.08216701]]\n",
      "Iteration 9717 | Cost: 0.27892340266055815 | Gradient: [[ 0.02726621]\n",
      " [-0.04925095]\n",
      " [ 0.0821615 ]]\n",
      "Iteration 9718 | Cost: 0.2789134833494831 | Gradient: [[ 0.02726511]\n",
      " [-0.04924838]\n",
      " [ 0.082156  ]]\n",
      "Iteration 9719 | Cost: 0.27890356525567106 | Gradient: [[ 0.027264  ]\n",
      " [-0.04924581]\n",
      " [ 0.0821505 ]]\n",
      "Iteration 9720 | Cost: 0.27889364837890507 | Gradient: [[ 0.0272629 ]\n",
      " [-0.04924325]\n",
      " [ 0.082145  ]]\n",
      "Iteration 9721 | Cost: 0.2788837327189681 | Gradient: [[ 0.0272618 ]\n",
      " [-0.04924068]\n",
      " [ 0.0821395 ]]\n",
      "Iteration 9722 | Cost: 0.27887381827564334 | Gradient: [[ 0.02726069]\n",
      " [-0.04923811]\n",
      " [ 0.082134  ]]\n",
      "Iteration 9723 | Cost: 0.2788639050487136 | Gradient: [[ 0.02725959]\n",
      " [-0.04923554]\n",
      " [ 0.0821285 ]]\n",
      "Iteration 9724 | Cost: 0.2788539930379624 | Gradient: [[ 0.02725849]\n",
      " [-0.04923298]\n",
      " [ 0.082123  ]]\n",
      "Iteration 9725 | Cost: 0.2788440822431727 | Gradient: [[ 0.02725738]\n",
      " [-0.04923041]\n",
      " [ 0.08211751]]\n",
      "Iteration 9726 | Cost: 0.27883417266412786 | Gradient: [[ 0.02725628]\n",
      " [-0.04922784]\n",
      " [ 0.08211201]]\n",
      "Iteration 9727 | Cost: 0.278824264300611 | Gradient: [[ 0.02725517]\n",
      " [-0.04922528]\n",
      " [ 0.08210651]]\n",
      "Iteration 9728 | Cost: 0.27881435715240593 | Gradient: [[ 0.02725407]\n",
      " [-0.04922271]\n",
      " [ 0.08210102]]\n",
      "Iteration 9729 | Cost: 0.27880445121929553 | Gradient: [[ 0.02725297]\n",
      " [-0.04922015]\n",
      " [ 0.08209552]]\n",
      "Iteration 9730 | Cost: 0.2787945465010636 | Gradient: [[ 0.02725186]\n",
      " [-0.04921758]\n",
      " [ 0.08209003]]\n",
      "Iteration 9731 | Cost: 0.27878464299749356 | Gradient: [[ 0.02725076]\n",
      " [-0.04921502]\n",
      " [ 0.08208454]]\n",
      "Iteration 9732 | Cost: 0.27877474070836894 | Gradient: [[ 0.02724966]\n",
      " [-0.04921245]\n",
      " [ 0.08207904]]\n",
      "Iteration 9733 | Cost: 0.2787648396334733 | Gradient: [[ 0.02724855]\n",
      " [-0.04920989]\n",
      " [ 0.08207355]]\n",
      "Iteration 9734 | Cost: 0.27875493977259047 | Gradient: [[ 0.02724745]\n",
      " [-0.04920732]\n",
      " [ 0.08206806]]\n",
      "Iteration 9735 | Cost: 0.27874504112550397 | Gradient: [[ 0.02724635]\n",
      " [-0.04920476]\n",
      " [ 0.08206257]]\n",
      "Iteration 9736 | Cost: 0.2787351436919977 | Gradient: [[ 0.02724524]\n",
      " [-0.0492022 ]\n",
      " [ 0.08205708]]\n",
      "Iteration 9737 | Cost: 0.2787252474718553 | Gradient: [[ 0.02724414]\n",
      " [-0.04919964]\n",
      " [ 0.08205159]]\n",
      "Iteration 9738 | Cost: 0.27871535246486073 | Gradient: [[ 0.02724304]\n",
      " [-0.04919707]\n",
      " [ 0.0820461 ]]\n",
      "Iteration 9739 | Cost: 0.27870545867079793 | Gradient: [[ 0.02724193]\n",
      " [-0.04919451]\n",
      " [ 0.08204061]]\n",
      "Iteration 9740 | Cost: 0.2786955660894508 | Gradient: [[ 0.02724083]\n",
      " [-0.04919195]\n",
      " [ 0.08203512]]\n",
      "Iteration 9741 | Cost: 0.2786856747206033 | Gradient: [[ 0.02723973]\n",
      " [-0.04918939]\n",
      " [ 0.08202963]]\n",
      "Iteration 9742 | Cost: 0.27867578456403946 | Gradient: [[ 0.02723862]\n",
      " [-0.04918683]\n",
      " [ 0.08202415]]\n",
      "Iteration 9743 | Cost: 0.2786658956195436 | Gradient: [[ 0.02723752]\n",
      " [-0.04918427]\n",
      " [ 0.08201866]]\n",
      "Iteration 9744 | Cost: 0.27865600788689954 | Gradient: [[ 0.02723641]\n",
      " [-0.04918171]\n",
      " [ 0.08201318]]\n",
      "Iteration 9745 | Cost: 0.2786461213658918 | Gradient: [[ 0.02723531]\n",
      " [-0.04917915]\n",
      " [ 0.08200769]]\n",
      "Iteration 9746 | Cost: 0.27863623605630444 | Gradient: [[ 0.02723421]\n",
      " [-0.04917659]\n",
      " [ 0.08200221]]\n",
      "Iteration 9747 | Cost: 0.27862635195792174 | Gradient: [[ 0.0272331 ]\n",
      " [-0.04917403]\n",
      " [ 0.08199673]]\n",
      "Iteration 9748 | Cost: 0.27861646907052817 | Gradient: [[ 0.027232  ]\n",
      " [-0.04917147]\n",
      " [ 0.08199124]]\n",
      "Iteration 9749 | Cost: 0.27860658739390803 | Gradient: [[ 0.0272309 ]\n",
      " [-0.04916891]\n",
      " [ 0.08198576]]\n",
      "Iteration 9750 | Cost: 0.2785967069278458 | Gradient: [[ 0.02722979]\n",
      " [-0.04916635]\n",
      " [ 0.08198028]]\n",
      "Iteration 9751 | Cost: 0.278586827672126 | Gradient: [[ 0.02722869]\n",
      " [-0.0491638 ]\n",
      " [ 0.0819748 ]]\n",
      "Iteration 9752 | Cost: 0.2785769496265332 | Gradient: [[ 0.02722759]\n",
      " [-0.04916124]\n",
      " [ 0.08196932]]\n",
      "Iteration 9753 | Cost: 0.2785670727908519 | Gradient: [[ 0.02722648]\n",
      " [-0.04915868]\n",
      " [ 0.08196384]]\n",
      "Iteration 9754 | Cost: 0.2785571971648668 | Gradient: [[ 0.02722538]\n",
      " [-0.04915613]\n",
      " [ 0.08195836]]\n",
      "Iteration 9755 | Cost: 0.2785473227483625 | Gradient: [[ 0.02722428]\n",
      " [-0.04915357]\n",
      " [ 0.08195288]]\n",
      "Iteration 9756 | Cost: 0.2785374495411239 | Gradient: [[ 0.02722317]\n",
      " [-0.04915101]\n",
      " [ 0.0819474 ]]\n",
      "Iteration 9757 | Cost: 0.2785275775429357 | Gradient: [[ 0.02722207]\n",
      " [-0.04914846]\n",
      " [ 0.08194193]]\n",
      "Iteration 9758 | Cost: 0.27851770675358284 | Gradient: [[ 0.02722097]\n",
      " [-0.0491459 ]\n",
      " [ 0.08193645]]\n",
      "Iteration 9759 | Cost: 0.27850783717285005 | Gradient: [[ 0.02721986]\n",
      " [-0.04914335]\n",
      " [ 0.08193098]]\n",
      "Iteration 9760 | Cost: 0.27849796880052224 | Gradient: [[ 0.02721876]\n",
      " [-0.04914079]\n",
      " [ 0.0819255 ]]\n",
      "Iteration 9761 | Cost: 0.2784881016363846 | Gradient: [[ 0.02721765]\n",
      " [-0.04913824]\n",
      " [ 0.08192003]]\n",
      "Iteration 9762 | Cost: 0.2784782356802221 | Gradient: [[ 0.02721655]\n",
      " [-0.04913569]\n",
      " [ 0.08191455]]\n",
      "Iteration 9763 | Cost: 0.27846837093181975 | Gradient: [[ 0.02721545]\n",
      " [-0.04913313]\n",
      " [ 0.08190908]]\n",
      "Iteration 9764 | Cost: 0.2784585073909628 | Gradient: [[ 0.02721434]\n",
      " [-0.04913058]\n",
      " [ 0.08190361]]\n",
      "Iteration 9765 | Cost: 0.2784486450574362 | Gradient: [[ 0.02721324]\n",
      " [-0.04912803]\n",
      " [ 0.08189814]]\n",
      "Iteration 9766 | Cost: 0.2784387839310255 | Gradient: [[ 0.02721214]\n",
      " [-0.04912548]\n",
      " [ 0.08189266]]\n",
      "Iteration 9767 | Cost: 0.27842892401151587 | Gradient: [[ 0.02721103]\n",
      " [-0.04912292]\n",
      " [ 0.08188719]]\n",
      "Iteration 9768 | Cost: 0.2784190652986925 | Gradient: [[ 0.02720993]\n",
      " [-0.04912037]\n",
      " [ 0.08188172]]\n",
      "Iteration 9769 | Cost: 0.2784092077923408 | Gradient: [[ 0.02720883]\n",
      " [-0.04911782]\n",
      " [ 0.08187625]]\n",
      "Iteration 9770 | Cost: 0.27839935149224637 | Gradient: [[ 0.02720772]\n",
      " [-0.04911527]\n",
      " [ 0.08187079]]\n",
      "Iteration 9771 | Cost: 0.2783894963981946 | Gradient: [[ 0.02720662]\n",
      " [-0.04911272]\n",
      " [ 0.08186532]]\n",
      "Iteration 9772 | Cost: 0.27837964250997094 | Gradient: [[ 0.02720552]\n",
      " [-0.04911017]\n",
      " [ 0.08185985]]\n",
      "Iteration 9773 | Cost: 0.27836978982736105 | Gradient: [[ 0.02720441]\n",
      " [-0.04910762]\n",
      " [ 0.08185438]]\n",
      "Iteration 9774 | Cost: 0.2783599383501505 | Gradient: [[ 0.02720331]\n",
      " [-0.04910507]\n",
      " [ 0.08184892]]\n",
      "Iteration 9775 | Cost: 0.27835008807812506 | Gradient: [[ 0.02720221]\n",
      " [-0.04910252]\n",
      " [ 0.08184345]]\n",
      "Iteration 9776 | Cost: 0.2783402390110704 | Gradient: [[ 0.0272011 ]\n",
      " [-0.04909997]\n",
      " [ 0.08183799]]\n",
      "Iteration 9777 | Cost: 0.2783303911487723 | Gradient: [[ 0.0272    ]\n",
      " [-0.04909742]\n",
      " [ 0.08183252]]\n",
      "Iteration 9778 | Cost: 0.2783205444910165 | Gradient: [[ 0.02719889]\n",
      " [-0.04909488]\n",
      " [ 0.08182706]]\n",
      "Iteration 9779 | Cost: 0.2783106990375891 | Gradient: [[ 0.02719779]\n",
      " [-0.04909233]\n",
      " [ 0.0818216 ]]\n",
      "Iteration 9780 | Cost: 0.27830085478827565 | Gradient: [[ 0.02719669]\n",
      " [-0.04908978]\n",
      " [ 0.08181614]]\n",
      "Iteration 9781 | Cost: 0.27829101174286247 | Gradient: [[ 0.02719558]\n",
      " [-0.04908723]\n",
      " [ 0.08181067]]\n",
      "Iteration 9782 | Cost: 0.27828116990113533 | Gradient: [[ 0.02719448]\n",
      " [-0.04908469]\n",
      " [ 0.08180521]]\n",
      "Iteration 9783 | Cost: 0.27827132926288045 | Gradient: [[ 0.02719338]\n",
      " [-0.04908214]\n",
      " [ 0.08179975]]\n",
      "Iteration 9784 | Cost: 0.27826148982788385 | Gradient: [[ 0.02719227]\n",
      " [-0.04907959]\n",
      " [ 0.08179429]]\n",
      "Iteration 9785 | Cost: 0.2782516515959318 | Gradient: [[ 0.02719117]\n",
      " [-0.04907705]\n",
      " [ 0.08178883]]\n",
      "Iteration 9786 | Cost: 0.2782418145668104 | Gradient: [[ 0.02719007]\n",
      " [-0.0490745 ]\n",
      " [ 0.08178338]]\n",
      "Iteration 9787 | Cost: 0.278231978740306 | Gradient: [[ 0.02718896]\n",
      " [-0.04907196]\n",
      " [ 0.08177792]]\n",
      "Iteration 9788 | Cost: 0.27822214411620483 | Gradient: [[ 0.02718786]\n",
      " [-0.04906941]\n",
      " [ 0.08177246]]\n",
      "Iteration 9789 | Cost: 0.2782123106942933 | Gradient: [[ 0.02718676]\n",
      " [-0.04906687]\n",
      " [ 0.081767  ]]\n",
      "Iteration 9790 | Cost: 0.2782024784743578 | Gradient: [[ 0.02718565]\n",
      " [-0.04906433]\n",
      " [ 0.08176155]]\n",
      "Iteration 9791 | Cost: 0.27819264745618477 | Gradient: [[ 0.02718455]\n",
      " [-0.04906178]\n",
      " [ 0.08175609]]\n",
      "Iteration 9792 | Cost: 0.27818281763956076 | Gradient: [[ 0.02718345]\n",
      " [-0.04905924]\n",
      " [ 0.08175064]]\n",
      "Iteration 9793 | Cost: 0.27817298902427234 | Gradient: [[ 0.02718234]\n",
      " [-0.0490567 ]\n",
      " [ 0.08174519]]\n",
      "Iteration 9794 | Cost: 0.27816316161010607 | Gradient: [[ 0.02718124]\n",
      " [-0.04905415]\n",
      " [ 0.08173973]]\n",
      "Iteration 9795 | Cost: 0.27815333539684856 | Gradient: [[ 0.02718013]\n",
      " [-0.04905161]\n",
      " [ 0.08173428]]\n",
      "Iteration 9796 | Cost: 0.27814351038428653 | Gradient: [[ 0.02717903]\n",
      " [-0.04904907]\n",
      " [ 0.08172883]]\n",
      "Iteration 9797 | Cost: 0.2781336865722068 | Gradient: [[ 0.02717793]\n",
      " [-0.04904653]\n",
      " [ 0.08172338]]\n",
      "Iteration 9798 | Cost: 0.27812386396039607 | Gradient: [[ 0.02717682]\n",
      " [-0.04904399]\n",
      " [ 0.08171793]]\n",
      "Iteration 9799 | Cost: 0.27811404254864125 | Gradient: [[ 0.02717572]\n",
      " [-0.04904145]\n",
      " [ 0.08171248]]\n",
      "Iteration 9800 | Cost: 0.2781042223367292 | Gradient: [[ 0.02717462]\n",
      " [-0.0490389 ]\n",
      " [ 0.08170703]]\n",
      "Iteration 9801 | Cost: 0.27809440332444696 | Gradient: [[ 0.02717351]\n",
      " [-0.04903636]\n",
      " [ 0.08170158]]\n",
      "Iteration 9802 | Cost: 0.27808458551158133 | Gradient: [[ 0.02717241]\n",
      " [-0.04903383]\n",
      " [ 0.08169613]]\n",
      "Iteration 9803 | Cost: 0.27807476889791954 | Gradient: [[ 0.02717131]\n",
      " [-0.04903129]\n",
      " [ 0.08169068]]\n",
      "Iteration 9804 | Cost: 0.2780649534832486 | Gradient: [[ 0.0271702 ]\n",
      " [-0.04902875]\n",
      " [ 0.08168524]]\n",
      "Iteration 9805 | Cost: 0.2780551392673556 | Gradient: [[ 0.0271691 ]\n",
      " [-0.04902621]\n",
      " [ 0.08167979]]\n",
      "Iteration 9806 | Cost: 0.27804532625002776 | Gradient: [[ 0.027168  ]\n",
      " [-0.04902367]\n",
      " [ 0.08167434]]\n",
      "Iteration 9807 | Cost: 0.2780355144310524 | Gradient: [[ 0.02716689]\n",
      " [-0.04902113]\n",
      " [ 0.0816689 ]]\n",
      "Iteration 9808 | Cost: 0.2780257038102167 | Gradient: [[ 0.02716579]\n",
      " [-0.04901859]\n",
      " [ 0.08166345]]\n",
      "Iteration 9809 | Cost: 0.27801589438730795 | Gradient: [[ 0.02716469]\n",
      " [-0.04901606]\n",
      " [ 0.08165801]]\n",
      "Iteration 9810 | Cost: 0.2780060861621136 | Gradient: [[ 0.02716358]\n",
      " [-0.04901352]\n",
      " [ 0.08165257]]\n",
      "Iteration 9811 | Cost: 0.2779962791344211 | Gradient: [[ 0.02716248]\n",
      " [-0.04901098]\n",
      " [ 0.08164713]]\n",
      "Iteration 9812 | Cost: 0.277986473304018 | Gradient: [[ 0.02716138]\n",
      " [-0.04900845]\n",
      " [ 0.08164168]]\n",
      "Iteration 9813 | Cost: 0.2779766686706916 | Gradient: [[ 0.02716027]\n",
      " [-0.04900591]\n",
      " [ 0.08163624]]\n",
      "Iteration 9814 | Cost: 0.27796686523422964 | Gradient: [[ 0.02715917]\n",
      " [-0.04900337]\n",
      " [ 0.0816308 ]]\n",
      "Iteration 9815 | Cost: 0.27795706299441975 | Gradient: [[ 0.02715807]\n",
      " [-0.04900084]\n",
      " [ 0.08162536]]\n",
      "Iteration 9816 | Cost: 0.2779472619510495 | Gradient: [[ 0.02715696]\n",
      " [-0.0489983 ]\n",
      " [ 0.08161992]]\n",
      "Iteration 9817 | Cost: 0.2779374621039067 | Gradient: [[ 0.02715586]\n",
      " [-0.04899577]\n",
      " [ 0.08161448]]\n",
      "Iteration 9818 | Cost: 0.27792766345277903 | Gradient: [[ 0.02715475]\n",
      " [-0.04899324]\n",
      " [ 0.08160905]]\n",
      "Iteration 9819 | Cost: 0.27791786599745444 | Gradient: [[ 0.02715365]\n",
      " [-0.0489907 ]\n",
      " [ 0.08160361]]\n",
      "Iteration 9820 | Cost: 0.27790806973772064 | Gradient: [[ 0.02715255]\n",
      " [-0.04898817]\n",
      " [ 0.08159817]]\n",
      "Iteration 9821 | Cost: 0.2778982746733657 | Gradient: [[ 0.02715144]\n",
      " [-0.04898563]\n",
      " [ 0.08159274]]\n",
      "Iteration 9822 | Cost: 0.2778884808041774 | Gradient: [[ 0.02715034]\n",
      " [-0.0489831 ]\n",
      " [ 0.0815873 ]]\n",
      "Iteration 9823 | Cost: 0.2778786881299439 | Gradient: [[ 0.02714924]\n",
      " [-0.04898057]\n",
      " [ 0.08158187]]\n",
      "Iteration 9824 | Cost: 0.2778688966504531 | Gradient: [[ 0.02714813]\n",
      " [-0.04897804]\n",
      " [ 0.08157643]]\n",
      "Iteration 9825 | Cost: 0.27785910636549327 | Gradient: [[ 0.02714703]\n",
      " [-0.04897551]\n",
      " [ 0.081571  ]]\n",
      "Iteration 9826 | Cost: 0.2778493172748525 | Gradient: [[ 0.02714593]\n",
      " [-0.04897297]\n",
      " [ 0.08156557]]\n",
      "Iteration 9827 | Cost: 0.277839529378319 | Gradient: [[ 0.02714482]\n",
      " [-0.04897044]\n",
      " [ 0.08156013]]\n",
      "Iteration 9828 | Cost: 0.27782974267568095 | Gradient: [[ 0.02714372]\n",
      " [-0.04896791]\n",
      " [ 0.0815547 ]]\n",
      "Iteration 9829 | Cost: 0.2778199571667268 | Gradient: [[ 0.02714262]\n",
      " [-0.04896538]\n",
      " [ 0.08154927]]\n",
      "Iteration 9830 | Cost: 0.27781017285124476 | Gradient: [[ 0.02714151]\n",
      " [-0.04896285]\n",
      " [ 0.08154384]]\n",
      "Iteration 9831 | Cost: 0.27780038972902327 | Gradient: [[ 0.02714041]\n",
      " [-0.04896032]\n",
      " [ 0.08153841]]\n",
      "Iteration 9832 | Cost: 0.27779060779985076 | Gradient: [[ 0.02713931]\n",
      " [-0.04895779]\n",
      " [ 0.08153298]]\n",
      "Iteration 9833 | Cost: 0.27778082706351576 | Gradient: [[ 0.0271382 ]\n",
      " [-0.04895526]\n",
      " [ 0.08152755]]\n",
      "Iteration 9834 | Cost: 0.27777104751980675 | Gradient: [[ 0.0271371 ]\n",
      " [-0.04895273]\n",
      " [ 0.08152213]]\n",
      "Iteration 9835 | Cost: 0.2777612691685124 | Gradient: [[ 0.027136  ]\n",
      " [-0.04895021]\n",
      " [ 0.0815167 ]]\n",
      "Iteration 9836 | Cost: 0.2777514920094213 | Gradient: [[ 0.02713489]\n",
      " [-0.04894768]\n",
      " [ 0.08151127]]\n",
      "Iteration 9837 | Cost: 0.27774171604232206 | Gradient: [[ 0.02713379]\n",
      " [-0.04894515]\n",
      " [ 0.08150585]]\n",
      "Iteration 9838 | Cost: 0.2777319412670035 | Gradient: [[ 0.02713269]\n",
      " [-0.04894262]\n",
      " [ 0.08150042]]\n",
      "Iteration 9839 | Cost: 0.2777221676832544 | Gradient: [[ 0.02713158]\n",
      " [-0.0489401 ]\n",
      " [ 0.081495  ]]\n",
      "Iteration 9840 | Cost: 0.27771239529086356 | Gradient: [[ 0.02713048]\n",
      " [-0.04893757]\n",
      " [ 0.08148957]]\n",
      "Iteration 9841 | Cost: 0.27770262408961993 | Gradient: [[ 0.02712938]\n",
      " [-0.04893504]\n",
      " [ 0.08148415]]\n",
      "Iteration 9842 | Cost: 0.2776928540793123 | Gradient: [[ 0.02712827]\n",
      " [-0.04893252]\n",
      " [ 0.08147873]]\n",
      "Iteration 9843 | Cost: 0.27768308525972973 | Gradient: [[ 0.02712717]\n",
      " [-0.04892999]\n",
      " [ 0.0814733 ]]\n",
      "Iteration 9844 | Cost: 0.2776733176306613 | Gradient: [[ 0.02712607]\n",
      " [-0.04892747]\n",
      " [ 0.08146788]]\n",
      "Iteration 9845 | Cost: 0.2776635511918959 | Gradient: [[ 0.02712496]\n",
      " [-0.04892494]\n",
      " [ 0.08146246]]\n",
      "Iteration 9846 | Cost: 0.2776537859432228 | Gradient: [[ 0.02712386]\n",
      " [-0.04892242]\n",
      " [ 0.08145704]]\n",
      "Iteration 9847 | Cost: 0.27764402188443116 | Gradient: [[ 0.02712276]\n",
      " [-0.04891989]\n",
      " [ 0.08145162]]\n",
      "Iteration 9848 | Cost: 0.27763425901531014 | Gradient: [[ 0.02712165]\n",
      " [-0.04891737]\n",
      " [ 0.0814462 ]]\n",
      "Iteration 9849 | Cost: 0.2776244973356489 | Gradient: [[ 0.02712055]\n",
      " [-0.04891484]\n",
      " [ 0.08144079]]\n",
      "Iteration 9850 | Cost: 0.27761473684523696 | Gradient: [[ 0.02711945]\n",
      " [-0.04891232]\n",
      " [ 0.08143537]]\n",
      "Iteration 9851 | Cost: 0.27760497754386354 | Gradient: [[ 0.02711834]\n",
      " [-0.0489098 ]\n",
      " [ 0.08142995]]\n",
      "Iteration 9852 | Cost: 0.27759521943131804 | Gradient: [[ 0.02711724]\n",
      " [-0.04890727]\n",
      " [ 0.08142454]]\n",
      "Iteration 9853 | Cost: 0.2775854625073899 | Gradient: [[ 0.02711614]\n",
      " [-0.04890475]\n",
      " [ 0.08141912]]\n",
      "Iteration 9854 | Cost: 0.2775757067718688 | Gradient: [[ 0.02711503]\n",
      " [-0.04890223]\n",
      " [ 0.0814137 ]]\n",
      "Iteration 9855 | Cost: 0.27756595222454417 | Gradient: [[ 0.02711393]\n",
      " [-0.04889971]\n",
      " [ 0.08140829]]\n",
      "Iteration 9856 | Cost: 0.2775561988652055 | Gradient: [[ 0.02711283]\n",
      " [-0.04889719]\n",
      " [ 0.08140288]]\n",
      "Iteration 9857 | Cost: 0.27754644669364265 | Gradient: [[ 0.02711172]\n",
      " [-0.04889467]\n",
      " [ 0.08139746]]\n",
      "Iteration 9858 | Cost: 0.27753669570964506 | Gradient: [[ 0.02711062]\n",
      " [-0.04889215]\n",
      " [ 0.08139205]]\n",
      "Iteration 9859 | Cost: 0.27752694591300264 | Gradient: [[ 0.02710952]\n",
      " [-0.04888963]\n",
      " [ 0.08138664]]\n",
      "Iteration 9860 | Cost: 0.2775171973035051 | Gradient: [[ 0.02710841]\n",
      " [-0.04888711]\n",
      " [ 0.08138123]]\n",
      "Iteration 9861 | Cost: 0.2775074498809424 | Gradient: [[ 0.02710731]\n",
      " [-0.04888459]\n",
      " [ 0.08137582]]\n",
      "Iteration 9862 | Cost: 0.2774977036451043 | Gradient: [[ 0.02710621]\n",
      " [-0.04888207]\n",
      " [ 0.08137041]]\n",
      "Iteration 9863 | Cost: 0.27748795859578074 | Gradient: [[ 0.0271051 ]\n",
      " [-0.04887955]\n",
      " [ 0.081365  ]]\n",
      "Iteration 9864 | Cost: 0.2774782147327618 | Gradient: [[ 0.027104  ]\n",
      " [-0.04887703]\n",
      " [ 0.08135959]]\n",
      "Iteration 9865 | Cost: 0.2774684720558373 | Gradient: [[ 0.0271029 ]\n",
      " [-0.04887451]\n",
      " [ 0.08135418]]\n",
      "Iteration 9866 | Cost: 0.27745873056479753 | Gradient: [[ 0.02710179]\n",
      " [-0.04887199]\n",
      " [ 0.08134877]]\n",
      "Iteration 9867 | Cost: 0.27744899025943254 | Gradient: [[ 0.02710069]\n",
      " [-0.04886948]\n",
      " [ 0.08134337]]\n",
      "Iteration 9868 | Cost: 0.27743925113953244 | Gradient: [[ 0.02709959]\n",
      " [-0.04886696]\n",
      " [ 0.08133796]]\n",
      "Iteration 9869 | Cost: 0.2774295132048875 | Gradient: [[ 0.02709848]\n",
      " [-0.04886444]\n",
      " [ 0.08133255]]\n",
      "Iteration 9870 | Cost: 0.277419776455288 | Gradient: [[ 0.02709738]\n",
      " [-0.04886193]\n",
      " [ 0.08132715]]\n",
      "Iteration 9871 | Cost: 0.27741004089052423 | Gradient: [[ 0.02709628]\n",
      " [-0.04885941]\n",
      " [ 0.08132175]]\n",
      "Iteration 9872 | Cost: 0.27740030651038655 | Gradient: [[ 0.02709517]\n",
      " [-0.04885689]\n",
      " [ 0.08131634]]\n",
      "Iteration 9873 | Cost: 0.2773905733146653 | Gradient: [[ 0.02709407]\n",
      " [-0.04885438]\n",
      " [ 0.08131094]]\n",
      "Iteration 9874 | Cost: 0.2773808413031511 | Gradient: [[ 0.02709297]\n",
      " [-0.04885186]\n",
      " [ 0.08130554]]\n",
      "Iteration 9875 | Cost: 0.2773711104756343 | Gradient: [[ 0.02709186]\n",
      " [-0.04884935]\n",
      " [ 0.08130013]]\n",
      "Iteration 9876 | Cost: 0.27736138083190554 | Gradient: [[ 0.02709076]\n",
      " [-0.04884683]\n",
      " [ 0.08129473]]\n",
      "Iteration 9877 | Cost: 0.2773516523717554 | Gradient: [[ 0.02708966]\n",
      " [-0.04884432]\n",
      " [ 0.08128933]]\n",
      "Iteration 9878 | Cost: 0.2773419250949745 | Gradient: [[ 0.02708855]\n",
      " [-0.04884181]\n",
      " [ 0.08128393]]\n",
      "Iteration 9879 | Cost: 0.2773321990013535 | Gradient: [[ 0.02708745]\n",
      " [-0.04883929]\n",
      " [ 0.08127853]]\n",
      "Iteration 9880 | Cost: 0.2773224740906833 | Gradient: [[ 0.02708635]\n",
      " [-0.04883678]\n",
      " [ 0.08127313]]\n",
      "Iteration 9881 | Cost: 0.27731275036275443 | Gradient: [[ 0.02708524]\n",
      " [-0.04883427]\n",
      " [ 0.08126774]]\n",
      "Iteration 9882 | Cost: 0.27730302781735794 | Gradient: [[ 0.02708414]\n",
      " [-0.04883175]\n",
      " [ 0.08126234]]\n",
      "Iteration 9883 | Cost: 0.2772933064542847 | Gradient: [[ 0.02708304]\n",
      " [-0.04882924]\n",
      " [ 0.08125694]]\n",
      "Iteration 9884 | Cost: 0.27728358627332556 | Gradient: [[ 0.02708193]\n",
      " [-0.04882673]\n",
      " [ 0.08125155]]\n",
      "Iteration 9885 | Cost: 0.2772738672742715 | Gradient: [[ 0.02708083]\n",
      " [-0.04882422]\n",
      " [ 0.08124615]]\n",
      "Iteration 9886 | Cost: 0.2772641494569136 | Gradient: [[ 0.02707973]\n",
      " [-0.04882171]\n",
      " [ 0.08124076]]\n",
      "Iteration 9887 | Cost: 0.2772544328210429 | Gradient: [[ 0.02707862]\n",
      " [-0.0488192 ]\n",
      " [ 0.08123536]]\n",
      "Iteration 9888 | Cost: 0.2772447173664505 | Gradient: [[ 0.02707752]\n",
      " [-0.04881669]\n",
      " [ 0.08122997]]\n",
      "Iteration 9889 | Cost: 0.27723500309292765 | Gradient: [[ 0.02707642]\n",
      " [-0.04881418]\n",
      " [ 0.08122458]]\n",
      "Iteration 9890 | Cost: 0.27722529000026547 | Gradient: [[ 0.02707532]\n",
      " [-0.04881167]\n",
      " [ 0.08121918]]\n",
      "Iteration 9891 | Cost: 0.27721557808825525 | Gradient: [[ 0.02707421]\n",
      " [-0.04880916]\n",
      " [ 0.08121379]]\n",
      "Iteration 9892 | Cost: 0.2772058673566884 | Gradient: [[ 0.02707311]\n",
      " [-0.04880665]\n",
      " [ 0.0812084 ]]\n",
      "Iteration 9893 | Cost: 0.27719615780535617 | Gradient: [[ 0.02707201]\n",
      " [-0.04880414]\n",
      " [ 0.08120301]]\n",
      "Iteration 9894 | Cost: 0.2771864494340499 | Gradient: [[ 0.0270709 ]\n",
      " [-0.04880163]\n",
      " [ 0.08119762]]\n",
      "Iteration 9895 | Cost: 0.2771767422425612 | Gradient: [[ 0.0270698 ]\n",
      " [-0.04879912]\n",
      " [ 0.08119223]]\n",
      "Iteration 9896 | Cost: 0.27716703623068156 | Gradient: [[ 0.0270687 ]\n",
      " [-0.04879661]\n",
      " [ 0.08118684]]\n",
      "Iteration 9897 | Cost: 0.2771573313982025 | Gradient: [[ 0.02706759]\n",
      " [-0.04879411]\n",
      " [ 0.08118145]]\n",
      "Iteration 9898 | Cost: 0.27714762774491547 | Gradient: [[ 0.02706649]\n",
      " [-0.0487916 ]\n",
      " [ 0.08117607]]\n",
      "Iteration 9899 | Cost: 0.2771379252706123 | Gradient: [[ 0.02706539]\n",
      " [-0.04878909]\n",
      " [ 0.08117068]]\n",
      "Iteration 9900 | Cost: 0.2771282239750846 | Gradient: [[ 0.02706428]\n",
      " [-0.04878659]\n",
      " [ 0.0811653 ]]\n",
      "Iteration 9901 | Cost: 0.277118523858124 | Gradient: [[ 0.02706318]\n",
      " [-0.04878408]\n",
      " [ 0.08115991]]\n",
      "Iteration 9902 | Cost: 0.27710882491952266 | Gradient: [[ 0.02706208]\n",
      " [-0.04878157]\n",
      " [ 0.08115452]]\n",
      "Iteration 9903 | Cost: 0.277099127159072 | Gradient: [[ 0.02706097]\n",
      " [-0.04877907]\n",
      " [ 0.08114914]]\n",
      "Iteration 9904 | Cost: 0.27708943057656404 | Gradient: [[ 0.02705987]\n",
      " [-0.04877656]\n",
      " [ 0.08114376]]\n",
      "Iteration 9905 | Cost: 0.27707973517179074 | Gradient: [[ 0.02705877]\n",
      " [-0.04877406]\n",
      " [ 0.08113837]]\n",
      "Iteration 9906 | Cost: 0.27707004094454407 | Gradient: [[ 0.02705767]\n",
      " [-0.04877155]\n",
      " [ 0.08113299]]\n",
      "Iteration 9907 | Cost: 0.27706034789461603 | Gradient: [[ 0.02705656]\n",
      " [-0.04876905]\n",
      " [ 0.08112761]]\n",
      "Iteration 9908 | Cost: 0.27705065602179874 | Gradient: [[ 0.02705546]\n",
      " [-0.04876655]\n",
      " [ 0.08112223]]\n",
      "Iteration 9909 | Cost: 0.2770409653258841 | Gradient: [[ 0.02705436]\n",
      " [-0.04876404]\n",
      " [ 0.08111685]]\n",
      "Iteration 9910 | Cost: 0.27703127580666465 | Gradient: [[ 0.02705325]\n",
      " [-0.04876154]\n",
      " [ 0.08111147]]\n",
      "Iteration 9911 | Cost: 0.2770215874639323 | Gradient: [[ 0.02705215]\n",
      " [-0.04875904]\n",
      " [ 0.08110609]]\n",
      "Iteration 9912 | Cost: 0.2770119002974794 | Gradient: [[ 0.02705105]\n",
      " [-0.04875654]\n",
      " [ 0.08110071]]\n",
      "Iteration 9913 | Cost: 0.2770022143070982 | Gradient: [[ 0.02704994]\n",
      " [-0.04875403]\n",
      " [ 0.08109533]]\n",
      "Iteration 9914 | Cost: 0.27699252949258113 | Gradient: [[ 0.02704884]\n",
      " [-0.04875153]\n",
      " [ 0.08108996]]\n",
      "Iteration 9915 | Cost: 0.2769828458537206 | Gradient: [[ 0.02704774]\n",
      " [-0.04874903]\n",
      " [ 0.08108458]]\n",
      "Iteration 9916 | Cost: 0.27697316339030903 | Gradient: [[ 0.02704664]\n",
      " [-0.04874653]\n",
      " [ 0.0810792 ]]\n",
      "Iteration 9917 | Cost: 0.27696348210213884 | Gradient: [[ 0.02704553]\n",
      " [-0.04874403]\n",
      " [ 0.08107383]]\n",
      "Iteration 9918 | Cost: 0.2769538019890026 | Gradient: [[ 0.02704443]\n",
      " [-0.04874153]\n",
      " [ 0.08106845]]\n",
      "Iteration 9919 | Cost: 0.276944123050693 | Gradient: [[ 0.02704333]\n",
      " [-0.04873903]\n",
      " [ 0.08106308]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9920 | Cost: 0.27693444528700256 | Gradient: [[ 0.02704222]\n",
      " [-0.04873653]\n",
      " [ 0.08105771]]\n",
      "Iteration 9921 | Cost: 0.2769247686977239 | Gradient: [[ 0.02704112]\n",
      " [-0.04873403]\n",
      " [ 0.08105233]]\n",
      "Iteration 9922 | Cost: 0.27691509328265 | Gradient: [[ 0.02704002]\n",
      " [-0.04873153]\n",
      " [ 0.08104696]]\n",
      "Iteration 9923 | Cost: 0.27690541904157345 | Gradient: [[ 0.02703891]\n",
      " [-0.04872903]\n",
      " [ 0.08104159]]\n",
      "Iteration 9924 | Cost: 0.27689574597428707 | Gradient: [[ 0.02703781]\n",
      " [-0.04872653]\n",
      " [ 0.08103622]]\n",
      "Iteration 9925 | Cost: 0.27688607408058374 | Gradient: [[ 0.02703671]\n",
      " [-0.04872403]\n",
      " [ 0.08103085]]\n",
      "Iteration 9926 | Cost: 0.27687640336025643 | Gradient: [[ 0.02703561]\n",
      " [-0.04872154]\n",
      " [ 0.08102548]]\n",
      "Iteration 9927 | Cost: 0.276866733813098 | Gradient: [[ 0.0270345 ]\n",
      " [-0.04871904]\n",
      " [ 0.08102011]]\n",
      "Iteration 9928 | Cost: 0.2768570654389015 | Gradient: [[ 0.0270334 ]\n",
      " [-0.04871654]\n",
      " [ 0.08101474]]\n",
      "Iteration 9929 | Cost: 0.2768473982374601 | Gradient: [[ 0.0270323 ]\n",
      " [-0.04871404]\n",
      " [ 0.08100937]]\n",
      "Iteration 9930 | Cost: 0.2768377322085668 | Gradient: [[ 0.02703119]\n",
      " [-0.04871155]\n",
      " [ 0.08100401]]\n",
      "Iteration 9931 | Cost: 0.2768280673520147 | Gradient: [[ 0.02703009]\n",
      " [-0.04870905]\n",
      " [ 0.08099864]]\n",
      "Iteration 9932 | Cost: 0.27681840366759713 | Gradient: [[ 0.02702899]\n",
      " [-0.04870656]\n",
      " [ 0.08099328]]\n",
      "Iteration 9933 | Cost: 0.27680874115510723 | Gradient: [[ 0.02702789]\n",
      " [-0.04870406]\n",
      " [ 0.08098791]]\n",
      "Iteration 9934 | Cost: 0.2767990798143384 | Gradient: [[ 0.02702678]\n",
      " [-0.04870157]\n",
      " [ 0.08098255]]\n",
      "Iteration 9935 | Cost: 0.27678941964508375 | Gradient: [[ 0.02702568]\n",
      " [-0.04869907]\n",
      " [ 0.08097718]]\n",
      "Iteration 9936 | Cost: 0.2767797606471369 | Gradient: [[ 0.02702458]\n",
      " [-0.04869658]\n",
      " [ 0.08097182]]\n",
      "Iteration 9937 | Cost: 0.2767701028202912 | Gradient: [[ 0.02702347]\n",
      " [-0.04869408]\n",
      " [ 0.08096646]]\n",
      "Iteration 9938 | Cost: 0.27676044616434015 | Gradient: [[ 0.02702237]\n",
      " [-0.04869159]\n",
      " [ 0.08096109]]\n",
      "Iteration 9939 | Cost: 0.2767507906790771 | Gradient: [[ 0.02702127]\n",
      " [-0.0486891 ]\n",
      " [ 0.08095573]]\n",
      "Iteration 9940 | Cost: 0.2767411363642959 | Gradient: [[ 0.02702017]\n",
      " [-0.0486866 ]\n",
      " [ 0.08095037]]\n",
      "Iteration 9941 | Cost: 0.27673148321979013 | Gradient: [[ 0.02701906]\n",
      " [-0.04868411]\n",
      " [ 0.08094501]]\n",
      "Iteration 9942 | Cost: 0.2767218312453532 | Gradient: [[ 0.02701796]\n",
      " [-0.04868162]\n",
      " [ 0.08093965]]\n",
      "Iteration 9943 | Cost: 0.2767121804407791 | Gradient: [[ 0.02701686]\n",
      " [-0.04867912]\n",
      " [ 0.08093429]]\n",
      "Iteration 9944 | Cost: 0.2767025308058613 | Gradient: [[ 0.02701575]\n",
      " [-0.04867663]\n",
      " [ 0.08092893]]\n",
      "Iteration 9945 | Cost: 0.276692882340394 | Gradient: [[ 0.02701465]\n",
      " [-0.04867414]\n",
      " [ 0.08092358]]\n",
      "Iteration 9946 | Cost: 0.2766832350441707 | Gradient: [[ 0.02701355]\n",
      " [-0.04867165]\n",
      " [ 0.08091822]]\n",
      "Iteration 9947 | Cost: 0.2766735889169855 | Gradient: [[ 0.02701245]\n",
      " [-0.04866916]\n",
      " [ 0.08091286]]\n",
      "Iteration 9948 | Cost: 0.2766639439586322 | Gradient: [[ 0.02701134]\n",
      " [-0.04866667]\n",
      " [ 0.08090751]]\n",
      "Iteration 9949 | Cost: 0.27665430016890497 | Gradient: [[ 0.02701024]\n",
      " [-0.04866418]\n",
      " [ 0.08090215]]\n",
      "Iteration 9950 | Cost: 0.2766446575475977 | Gradient: [[ 0.02700914]\n",
      " [-0.04866169]\n",
      " [ 0.0808968 ]]\n",
      "Iteration 9951 | Cost: 0.2766350160945045 | Gradient: [[ 0.02700803]\n",
      " [-0.0486592 ]\n",
      " [ 0.08089144]]\n",
      "Iteration 9952 | Cost: 0.27662537580941954 | Gradient: [[ 0.02700693]\n",
      " [-0.04865671]\n",
      " [ 0.08088609]]\n",
      "Iteration 9953 | Cost: 0.276615736692137 | Gradient: [[ 0.02700583]\n",
      " [-0.04865422]\n",
      " [ 0.08088074]]\n",
      "Iteration 9954 | Cost: 0.27660609874245107 | Gradient: [[ 0.02700473]\n",
      " [-0.04865173]\n",
      " [ 0.08087538]]\n",
      "Iteration 9955 | Cost: 0.276596461960156 | Gradient: [[ 0.02700362]\n",
      " [-0.04864924]\n",
      " [ 0.08087003]]\n",
      "Iteration 9956 | Cost: 0.2765868263450462 | Gradient: [[ 0.02700252]\n",
      " [-0.04864676]\n",
      " [ 0.08086468]]\n",
      "Iteration 9957 | Cost: 0.2765771918969161 | Gradient: [[ 0.02700142]\n",
      " [-0.04864427]\n",
      " [ 0.08085933]]\n",
      "Iteration 9958 | Cost: 0.27656755861555987 | Gradient: [[ 0.02700032]\n",
      " [-0.04864178]\n",
      " [ 0.08085398]]\n",
      "Iteration 9959 | Cost: 0.27655792650077204 | Gradient: [[ 0.02699921]\n",
      " [-0.0486393 ]\n",
      " [ 0.08084863]]\n",
      "Iteration 9960 | Cost: 0.2765482955523473 | Gradient: [[ 0.02699811]\n",
      " [-0.04863681]\n",
      " [ 0.08084328]]\n",
      "Iteration 9961 | Cost: 0.27653866577008 | Gradient: [[ 0.02699701]\n",
      " [-0.04863432]\n",
      " [ 0.08083794]]\n",
      "Iteration 9962 | Cost: 0.2765290371537648 | Gradient: [[ 0.0269959 ]\n",
      " [-0.04863184]\n",
      " [ 0.08083259]]\n",
      "Iteration 9963 | Cost: 0.2765194097031964 | Gradient: [[ 0.0269948 ]\n",
      " [-0.04862935]\n",
      " [ 0.08082724]]\n",
      "Iteration 9964 | Cost: 0.2765097834181694 | Gradient: [[ 0.0269937 ]\n",
      " [-0.04862687]\n",
      " [ 0.0808219 ]]\n",
      "Iteration 9965 | Cost: 0.27650015829847857 | Gradient: [[ 0.0269926 ]\n",
      " [-0.04862438]\n",
      " [ 0.08081655]]\n",
      "Iteration 9966 | Cost: 0.27649053434391874 | Gradient: [[ 0.02699149]\n",
      " [-0.0486219 ]\n",
      " [ 0.08081121]]\n",
      "Iteration 9967 | Cost: 0.2764809115542847 | Gradient: [[ 0.02699039]\n",
      " [-0.04861941]\n",
      " [ 0.08080586]]\n",
      "Iteration 9968 | Cost: 0.27647128992937137 | Gradient: [[ 0.02698929]\n",
      " [-0.04861693]\n",
      " [ 0.08080052]]\n",
      "Iteration 9969 | Cost: 0.2764616694689736 | Gradient: [[ 0.02698819]\n",
      " [-0.04861444]\n",
      " [ 0.08079518]]\n",
      "Iteration 9970 | Cost: 0.2764520501728864 | Gradient: [[ 0.02698708]\n",
      " [-0.04861196]\n",
      " [ 0.08078984]]\n",
      "Iteration 9971 | Cost: 0.2764424320409048 | Gradient: [[ 0.02698598]\n",
      " [-0.04860948]\n",
      " [ 0.08078449]]\n",
      "Iteration 9972 | Cost: 0.2764328150728238 | Gradient: [[ 0.02698488]\n",
      " [-0.048607  ]\n",
      " [ 0.08077915]]\n",
      "Iteration 9973 | Cost: 0.27642319926843856 | Gradient: [[ 0.02698378]\n",
      " [-0.04860451]\n",
      " [ 0.08077381]]\n",
      "Iteration 9974 | Cost: 0.27641358462754423 | Gradient: [[ 0.02698267]\n",
      " [-0.04860203]\n",
      " [ 0.08076847]]\n",
      "Iteration 9975 | Cost: 0.2764039711499361 | Gradient: [[ 0.02698157]\n",
      " [-0.04859955]\n",
      " [ 0.08076313]]\n",
      "Iteration 9976 | Cost: 0.27639435883540914 | Gradient: [[ 0.02698047]\n",
      " [-0.04859707]\n",
      " [ 0.0807578 ]]\n",
      "Iteration 9977 | Cost: 0.276384747683759 | Gradient: [[ 0.02697937]\n",
      " [-0.04859459]\n",
      " [ 0.08075246]]\n",
      "Iteration 9978 | Cost: 0.2763751376947807 | Gradient: [[ 0.02697826]\n",
      " [-0.04859211]\n",
      " [ 0.08074712]]\n",
      "Iteration 9979 | Cost: 0.2763655288682699 | Gradient: [[ 0.02697716]\n",
      " [-0.04858963]\n",
      " [ 0.08074178]]\n",
      "Iteration 9980 | Cost: 0.27635592120402186 | Gradient: [[ 0.02697606]\n",
      " [-0.04858715]\n",
      " [ 0.08073645]]\n",
      "Iteration 9981 | Cost: 0.27634631470183213 | Gradient: [[ 0.02697496]\n",
      " [-0.04858467]\n",
      " [ 0.08073111]]\n",
      "Iteration 9982 | Cost: 0.2763367093614962 | Gradient: [[ 0.02697385]\n",
      " [-0.04858219]\n",
      " [ 0.08072578]]\n",
      "Iteration 9983 | Cost: 0.2763271051828097 | Gradient: [[ 0.02697275]\n",
      " [-0.04857971]\n",
      " [ 0.08072044]]\n",
      "Iteration 9984 | Cost: 0.2763175021655681 | Gradient: [[ 0.02697165]\n",
      " [-0.04857723]\n",
      " [ 0.08071511]]\n",
      "Iteration 9985 | Cost: 0.27630790030956726 | Gradient: [[ 0.02697055]\n",
      " [-0.04857475]\n",
      " [ 0.08070978]]\n",
      "Iteration 9986 | Cost: 0.2762982996146027 | Gradient: [[ 0.02696944]\n",
      " [-0.04857227]\n",
      " [ 0.08070445]]\n",
      "Iteration 9987 | Cost: 0.27628870008047035 | Gradient: [[ 0.02696834]\n",
      " [-0.0485698 ]\n",
      " [ 0.08069911]]\n",
      "Iteration 9988 | Cost: 0.2762791017069659 | Gradient: [[ 0.02696724]\n",
      " [-0.04856732]\n",
      " [ 0.08069378]]\n",
      "Iteration 9989 | Cost: 0.27626950449388527 | Gradient: [[ 0.02696614]\n",
      " [-0.04856484]\n",
      " [ 0.08068845]]\n",
      "Iteration 9990 | Cost: 0.2762599084410243 | Gradient: [[ 0.02696503]\n",
      " [-0.04856237]\n",
      " [ 0.08068312]]\n",
      "Iteration 9991 | Cost: 0.276250313548179 | Gradient: [[ 0.02696393]\n",
      " [-0.04855989]\n",
      " [ 0.08067779]]\n",
      "Iteration 9992 | Cost: 0.2762407198151452 | Gradient: [[ 0.02696283]\n",
      " [-0.04855741]\n",
      " [ 0.08067247]]\n",
      "Iteration 9993 | Cost: 0.27623112724171917 | Gradient: [[ 0.02696173]\n",
      " [-0.04855494]\n",
      " [ 0.08066714]]\n",
      "Iteration 9994 | Cost: 0.2762215358276968 | Gradient: [[ 0.02696062]\n",
      " [-0.04855246]\n",
      " [ 0.08066181]]\n",
      "Iteration 9995 | Cost: 0.27621194557287426 | Gradient: [[ 0.02695952]\n",
      " [-0.04854999]\n",
      " [ 0.08065648]]\n",
      "Iteration 9996 | Cost: 0.2762023564770478 | Gradient: [[ 0.02695842]\n",
      " [-0.04854751]\n",
      " [ 0.08065116]]\n",
      "Iteration 9997 | Cost: 0.2761927685400135 | Gradient: [[ 0.02695732]\n",
      " [-0.04854504]\n",
      " [ 0.08064583]]\n",
      "Iteration 9998 | Cost: 0.27618318176156775 | Gradient: [[ 0.02695622]\n",
      " [-0.04854256]\n",
      " [ 0.08064051]]\n",
      "Iteration 9999 | Cost: 0.27617359614150677 | Gradient: [[ 0.02695511]\n",
      " [-0.04854009]\n",
      " [ 0.08063518]]\n"
     ]
    }
   ],
   "source": [
    "theta_gd = gradient_descent(X, y, alpha=0.001, iteration=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11019899],\n",
       "       [ 1.17175658],\n",
       "       [-1.08866382]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(fit_intercept=True).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.30512124],\n",
       "       [ 3.44772256],\n",
       "       [-4.20943545]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack((lr.coef_.T, lr.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newton Method Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_method(X, y, iteration, alpha=0.05, tolerance=1e-4):\n",
    "    '''Use gradient descent to get parameter vector theta \n",
    "       for linear regression and logistic regression\n",
    "    Args:\n",
    "        X: feature matrix with shape (m, n)\n",
    "        y: target vector with shape (m, 1)\n",
    "        iteration: number of max iterations\n",
    "        alpha: learning rate for gradient descent\n",
    "        tolerance: set threshold to determine when to converge \n",
    "                   based on old vs. new paramter changes at end of each iteration\n",
    "    Returns:\n",
    "        Parameter vector, array like'''\n",
    "    N = X.shape[0]\n",
    "    X = np.hstack((X, np.ones(N).reshape(N, 1))) \n",
    "    theta = np.zeros(X.shape[1]).reshape(X.shape[1], 1)\n",
    "    X_trans = X.T\n",
    "    \n",
    "    for i in range(0, iteration):\n",
    "        z = np.dot(X, theta)\n",
    "        h = sigmoid(z)   # hypothesis\n",
    "        error = h - y\n",
    "        cost = (-y * np.log(h) - (1-y) * np.log(1 - h)).mean()\n",
    "        gradient = np.dot(X_trans, error) / len(X)\n",
    "        #calculate Hessian\n",
    "        hessian = h * (1-h) * X_trans.dot(X) / len(X)\n",
    "        print(\"Iteration {} | Cost: {} | Gradient: {}\".format(i, cost, gradient))\n",
    "        # update theta\n",
    "        theta_new = theta - np.dot(np.linalg.inv(hessian), gradient)\n",
    "        if sum(abs(theta_new - theta)).all() < tolerance:\n",
    "            break\n",
    "        theta = theta_new\n",
    "    return theta_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X.shape[0]\n",
    "X = np.hstack((X, np.ones(N).reshape(N, 1))) \n",
    "theta = np.zeros(X.shape[1]).reshape(X.shape[1], 1)\n",
    "X_trans = X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.dot(X, theta)\n",
    "h = sigmoid(z)   # hypothesis\n",
    "error = h - y\n",
    "cost = (-y * np.log(h) - (1-y) * np.log(1 - h)).mean()\n",
    "gradient = np.dot(X_trans, error) / len(X)\n",
    "hessian = h * (1-h) * X.dot(X_trans) / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hessian.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1000,1) (4,4) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-41ede4f59330>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnewton_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-ccfadff2897f>\u001b[0m in \u001b[0;36mnewton_method\u001b[0;34m(X, y, iteration, alpha, tolerance)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m#calculate Hessian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mhessian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX_trans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Iteration {} | Cost: {} | Gradient: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# update theta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1000,1) (4,4) "
     ]
    }
   ],
   "source": [
    "newton_method(X, y,alpha=0.001, iteration=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
